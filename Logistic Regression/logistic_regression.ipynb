{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "In this notebook we would look into the working of the Logistic Regression Model\n",
    "\n",
    "Logistic Regression Using Gradient Descent\n",
    "\n",
    "$$\n",
    "Θ = Θ + α(y-h(ΘTX))X\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_path = \"ds1_test.csv\"\n",
    "\n",
    "train_data = pd.read_csv(train_path)\n",
    "train_data.head()\n",
    "\n",
    "X = train_data.iloc[:, :-1].values\n",
    "y = train_data.iloc[:, -1].values\n",
    "\n",
    "# Add a bias term to the features\n",
    "X = np.hstack((np.ones((X.shape[0], 1)), X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters dimension : (100, 2)\n",
      "values dimensions : (100,)\n"
     ]
    }
   ],
   "source": [
    "parameters = train_data[[\"x_1\", \"x_2\"]]\n",
    "values = train_data[\"y\"]\n",
    "print(f\"parameters dimension : {parameters.shape}\\nvalues dimensions : {values.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))  # Create a new figure\n",
    "\n",
    "# Plotting the histogram for x_1\n",
    "plt.subplot(3, 2, 1)  # 1 row, 2 columns, subplot 1\n",
    "plt.hist(parameters[\"x_1\"], bins=30, color=\"blue\", alpha=0.7)\n",
    "plt.xlabel(\"x_1\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of x_1\")\n",
    "\n",
    "# Plotting the histogram for x_2\n",
    "plt.subplot(3, 2, 2)  # 1 row, 2 columns, subplot 2\n",
    "plt.hist(parameters[\"x_2\"], bins=30, color=\"green\", alpha=0.7)\n",
    "plt.xlabel(\"x_2\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of x_2\")\n",
    "\n",
    "plt.subplot(3, 2, 3)  # 1 row, 2 columns, subplot 2\n",
    "plt.hist(values, bins=30, color=\"red\", alpha=0.7)\n",
    "plt.xlabel(\"y\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of y\")\n",
    "\n",
    "plt.tight_layout()  # Adjust spacing between subplots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionUsingGradientDescent:\n",
    "    def __init__(self, theta=None, step_size=0.0045, max_iter=10000, eps=1e-5):\n",
    "        self.theta = theta\n",
    "        self.step_size = step_size\n",
    "        self.max_iter = max_iter\n",
    "        self.eps = eps\n",
    "\n",
    "    def calculateGradient(self, x, y):\n",
    "        hx = self._sigmoid(x.dot(self.theta))\n",
    "        return x.T.dot(y - hx) / len(y)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        rows, features = x.shape\n",
    "        if self.theta is None:\n",
    "            self.theta = np.zeros(features)\n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "            previous_theta = np.copy(self.theta)\n",
    "            gradient = self.calculateGradient(x, y)\n",
    "            self.theta = self.theta + self.step_size * gradient\n",
    "            loss = self._loss(x, y)\n",
    "\n",
    "            print(f\"Loss in iteration {i}: {loss}\")\n",
    "            print(f\"Theta: {self.theta}\")\n",
    "\n",
    "            if np.all(np.abs(self.theta - previous_theta) < self.eps):\n",
    "                print(\"Converged.\")\n",
    "                return np.copy(self.theta)\n",
    "                break\n",
    "        return np.copy(self.theta)\n",
    "\n",
    "    @staticmethod\n",
    "    def _sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def _loss(self, x, y):\n",
    "        \"\"\"Get the empirical loss for logistic regression.\"\"\"\n",
    "        hx = self._sigmoid(x.dot(self.theta))\n",
    "        loss = -np.mean(y * np.log(hx) + (1 - y) * np.log(1 - hx))\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in iteration 0: 0.6675432859078272\n",
      "Theta: [0.         0.00190569 0.01120256]\n",
      "Loss in iteration 1: 0.6515253478303173\n",
      "Theta: [-0.00010678  0.00353241  0.01999442]\n",
      "Loss in iteration 2: 0.6409549078171457\n",
      "Theta: [-0.00029392  0.0049532   0.02706744]\n",
      "Loss in iteration 3: 0.6335864080625356\n",
      "Theta: [-0.00054233  0.00622072  0.03291877]\n",
      "Loss in iteration 4: 0.628218119707376\n",
      "Theta: [-0.00083893  0.0073703   0.03787107]\n",
      "Loss in iteration 5: 0.6241719029376221\n",
      "Theta: [-0.00117457  0.00842607  0.04213598]\n",
      "Loss in iteration 6: 0.6210405620644736\n",
      "Theta: [-0.00154258  0.00940521  0.04585785]\n",
      "Loss in iteration 7: 0.618565694527348\n",
      "Theta: [-0.00193792  0.0103204   0.04913927]\n",
      "Loss in iteration 8: 0.6165756084956479\n",
      "Theta: [-0.00235669  0.01118133  0.05205589]\n",
      "Loss in iteration 9: 0.6149518555449895\n",
      "Theta: [-0.00279576  0.01199561  0.05466521]\n",
      "Loss in iteration 10: 0.6136101633826406\n",
      "Theta: [-0.00325259  0.01276934  0.05701215]\n",
      "Loss in iteration 11: 0.6124890305172922\n",
      "Theta: [-0.00372507  0.01350752  0.0591325 ]\n",
      "Loss in iteration 12: 0.6115426111940733\n",
      "Theta: [-0.00421144  0.01421428  0.06105535]\n",
      "Loss in iteration 13: 0.6107361136440207\n",
      "Theta: [-0.00471019  0.01489312  0.0628047 ]\n",
      "Loss in iteration 14: 0.6100427300169682\n",
      "Theta: [-0.00522004  0.01554701  0.0644006 ]\n",
      "Loss in iteration 15: 0.6094415325123567\n",
      "Theta: [-0.00573987  0.01617848  0.06585999]\n",
      "Loss in iteration 16: 0.6089159976484236\n",
      "Theta: [-0.0062687   0.01678975  0.06719736]\n",
      "Loss in iteration 17: 0.6084529498393981\n",
      "Theta: [-0.00680569  0.01738273  0.06842516]\n",
      "Loss in iteration 18: 0.608041791481768\n",
      "Theta: [-0.00735007  0.01795912  0.0695542 ]\n",
      "Loss in iteration 19: 0.607673932895328\n",
      "Theta: [-0.00790118  0.01852041  0.07059391]\n",
      "Loss in iteration 20: 0.6073423642602068\n",
      "Theta: [-0.00845843  0.0190679   0.07155261]\n",
      "Loss in iteration 21: 0.607041330114227\n",
      "Theta: [-0.00902127  0.01960279  0.0724376 ]\n",
      "Loss in iteration 22: 0.6067660790297333\n",
      "Theta: [-0.00958923  0.02012611  0.0732554 ]\n",
      "Loss in iteration 23: 0.6065126691385259\n",
      "Theta: [-0.01016187  0.02063882  0.07401179]\n",
      "Loss in iteration 24: 0.6062778156483583\n",
      "Theta: [-0.01073881  0.02114177  0.07471196]\n",
      "Loss in iteration 25: 0.606058770281\n",
      "Theta: [-0.01131969  0.02163571  0.07536057]\n",
      "Loss in iteration 26: 0.6058532252210461\n",
      "Theta: [-0.01190418  0.02212136  0.0759618 ]\n",
      "Loss in iteration 27: 0.6056592360584736\n",
      "Theta: [-0.012492    0.02259933  0.07651945]\n",
      "Loss in iteration 28: 0.605475159574106\n",
      "Theta: [-0.01308288  0.02307021  0.07703694]\n",
      "Loss in iteration 29: 0.6052996032144295\n",
      "Theta: [-0.01367656  0.02353452  0.07751739]\n",
      "Loss in iteration 30: 0.605131383838209\n",
      "Theta: [-0.01427284  0.02399273  0.07796364]\n",
      "Loss in iteration 31: 0.6049694938660601\n",
      "Theta: [-0.01487149  0.02444529  0.07837826]\n",
      "Loss in iteration 32: 0.6048130733770898\n",
      "Theta: [-0.01547234  0.02489259  0.07876363]\n",
      "Loss in iteration 33: 0.6046613870102194\n",
      "Theta: [-0.0160752   0.02533501  0.0791219 ]\n",
      "Loss in iteration 34: 0.6045138047677796\n",
      "Theta: [-0.01667992  0.02577289  0.07945505]\n",
      "Loss in iteration 35: 0.6043697860040509\n",
      "Theta: [-0.01728636  0.02620653  0.07976491]\n",
      "Loss in iteration 36: 0.6042288660251905\n",
      "Theta: [-0.01789436  0.02663622  0.08005314]\n",
      "Loss in iteration 37: 0.604090644839447\n",
      "Theta: [-0.01850382  0.02706224  0.08032129]\n",
      "Loss in iteration 38: 0.6039547776850281\n",
      "Theta: [-0.0191146   0.02748482  0.08057077]\n",
      "Loss in iteration 39: 0.6038209670330672\n",
      "Theta: [-0.01972661  0.02790419  0.0808029 ]\n",
      "Loss in iteration 40: 0.6036889558188783\n",
      "Theta: [-0.02033974  0.02832057  0.08101888]\n",
      "Loss in iteration 41: 0.6035585216993401\n",
      "Theta: [-0.0209539   0.02873414  0.08121983]\n",
      "Loss in iteration 42: 0.6034294721701304\n",
      "Theta: [-0.021569    0.02914508  0.08140678]\n",
      "Loss in iteration 43: 0.6033016404055518\n",
      "Theta: [-0.02218497  0.02955357  0.0815807 ]\n",
      "Loss in iteration 44: 0.6031748817072188\n",
      "Theta: [-0.02280172  0.02995976  0.08174247]\n",
      "Loss in iteration 45: 0.6030490704670803\n",
      "Theta: [-0.0234192   0.03036379  0.08189292]\n",
      "Loss in iteration 46: 0.6029240975659406\n",
      "Theta: [-0.02403733  0.03076579  0.0820328 ]\n",
      "Loss in iteration 47: 0.6027998681415514\n",
      "Theta: [-0.02465607  0.0311659   0.08216283]\n",
      "Loss in iteration 48: 0.6026762996709767\n",
      "Theta: [-0.02527534  0.03156422  0.08228367]\n",
      "Loss in iteration 49: 0.6025533203207254\n",
      "Theta: [-0.0258951   0.03196086  0.08239593]\n",
      "Loss in iteration 50: 0.6024308675254528\n",
      "Theta: [-0.0265153   0.03235593  0.08250018]\n",
      "Loss in iteration 51: 0.6023088867620969\n",
      "Theta: [-0.0271359   0.03274951  0.08259695]\n",
      "Loss in iteration 52: 0.602187330491396\n",
      "Theta: [-0.02775685  0.0331417   0.08268674]\n",
      "Loss in iteration 53: 0.6020661572429766\n",
      "Theta: [-0.02837812  0.03353258  0.08276999]\n",
      "Loss in iteration 54: 0.6019453308237606\n",
      "Theta: [-0.02899967  0.03392221  0.08284716]\n",
      "Loss in iteration 55: 0.60182481963244\n",
      "Theta: [-0.02962146  0.03431068  0.08291862]\n",
      "Loss in iteration 56: 0.6017045960652989\n",
      "Theta: [-0.03024347  0.03469804  0.08298476]\n",
      "Loss in iteration 57: 0.6015846360007941\n",
      "Theta: [-0.03086566  0.03508436  0.08304592]\n",
      "Loss in iteration 58: 0.6014649183521144\n",
      "Theta: [-0.031488    0.0354697   0.08310242]\n",
      "Loss in iteration 59: 0.6013454246784823\n",
      "Theta: [-0.03211048  0.03585411  0.08315458]\n",
      "Loss in iteration 60: 0.6012261388472606\n",
      "Theta: [-0.03273306  0.03623763  0.08320267]\n",
      "Loss in iteration 61: 0.6011070467400388\n",
      "Theta: [-0.03335572  0.03662032  0.08324695]\n",
      "Loss in iteration 62: 0.6009881359968271\n",
      "Theta: [-0.03397845  0.03700222  0.08328767]\n",
      "Loss in iteration 63: 0.6008693957932973\n",
      "Theta: [-0.03460122  0.03738338  0.08332506]\n",
      "Loss in iteration 64: 0.6007508166466988\n",
      "Theta: [-0.03522402  0.03776382  0.08335933]\n",
      "Loss in iteration 65: 0.6006323902466777\n",
      "Theta: [-0.03584682  0.03814358  0.08339069]\n",
      "Loss in iteration 66: 0.6005141093077395\n",
      "Theta: [-0.03646961  0.0385227   0.08341933]\n",
      "Loss in iteration 67: 0.6003959674405297\n",
      "Theta: [-0.03709238  0.03890121  0.08344541]\n",
      "Loss in iteration 68: 0.600277959039487\n",
      "Theta: [-0.03771511  0.03927914  0.0834691 ]\n",
      "Loss in iteration 69: 0.6001600791847528\n",
      "Theta: [-0.03833779  0.03965651  0.08349056]\n",
      "Loss in iteration 70: 0.6000423235564945\n",
      "Theta: [-0.03896041  0.04003336  0.08350993]\n",
      "Loss in iteration 71: 0.599924688360051\n",
      "Theta: [-0.03958295  0.04040969  0.08352734]\n",
      "Loss in iteration 72: 0.5998071702605086\n",
      "Theta: [-0.04020541  0.04078555  0.08354292]\n",
      "Loss in iteration 73: 0.5996897663255066\n",
      "Theta: [-0.04082777  0.04116094  0.08355679]\n",
      "Loss in iteration 74: 0.5995724739752221\n",
      "Theta: [-0.04145002  0.04153589  0.08356905]\n",
      "Loss in iteration 75: 0.5994552909386202\n",
      "Theta: [-0.04207217  0.04191041  0.08357981]\n",
      "Loss in iteration 76: 0.5993382152151797\n",
      "Theta: [-0.04269419  0.04228453  0.08358916]\n",
      "Loss in iteration 77: 0.5992212450413968\n",
      "Theta: [-0.04331608  0.04265826  0.0835972 ]\n",
      "Loss in iteration 78: 0.599104378861467\n",
      "Theta: [-0.04393783  0.0430316   0.083604  ]\n",
      "Loss in iteration 79: 0.5989876153016178\n",
      "Theta: [-0.04455944  0.04340459  0.08360965]\n",
      "Loss in iteration 80: 0.5988709531476348\n",
      "Theta: [-0.0451809   0.04377723  0.08361422]\n",
      "Loss in iteration 81: 0.5987543913251772\n",
      "Theta: [-0.04580221  0.04414953  0.08361778]\n",
      "Loss in iteration 82: 0.5986379288825381\n",
      "Theta: [-0.04642335  0.04452151  0.0836204 ]\n",
      "Loss in iteration 83: 0.5985215649755391\n",
      "Theta: [-0.04704433  0.04489317  0.08362213]\n",
      "Loss in iteration 84: 0.5984052988542968\n",
      "Theta: [-0.04766513  0.04526452  0.08362303]\n",
      "Loss in iteration 85: 0.5982891298516256\n",
      "Theta: [-0.04828576  0.04563559  0.08362315]\n",
      "Loss in iteration 86: 0.5981730573728731\n",
      "Theta: [-0.04890622  0.04600636  0.08362255]\n",
      "Loss in iteration 87: 0.5980570808870103\n",
      "Theta: [-0.04952648  0.04637686  0.08362127]\n",
      "Loss in iteration 88: 0.5979411999188226\n",
      "Theta: [-0.05014656  0.04674709  0.08361935]\n",
      "Loss in iteration 89: 0.5978254140420609\n",
      "Theta: [-0.05076645  0.04711706  0.08361683]\n",
      "Loss in iteration 90: 0.5977097228734389\n",
      "Theta: [-0.05138614  0.04748677  0.08361376]\n",
      "Loss in iteration 91: 0.5975941260673681\n",
      "Theta: [-0.05200564  0.04785623  0.08361017]\n",
      "Loss in iteration 92: 0.5974786233113392\n",
      "Theta: [-0.05262494  0.04822545  0.08360609]\n",
      "Loss in iteration 93: 0.5973632143218739\n",
      "Theta: [-0.05324403  0.04859443  0.08360155]\n",
      "Loss in iteration 94: 0.5972478988409726\n",
      "Theta: [-0.05386292  0.04896318  0.08359659]\n",
      "Loss in iteration 95: 0.5971326766329983\n",
      "Theta: [-0.0544816   0.04933171  0.08359123]\n",
      "Loss in iteration 96: 0.5970175474819436\n",
      "Theta: [-0.05510007  0.04970001  0.08358549]\n",
      "Loss in iteration 97: 0.5969025111890324\n",
      "Theta: [-0.05571833  0.05006809  0.0835794 ]\n",
      "Loss in iteration 98: 0.5967875675706167\n",
      "Theta: [-0.05633638  0.05043596  0.08357299]\n",
      "Loss in iteration 99: 0.5966727164563296\n",
      "Theta: [-0.05695421  0.05080361  0.08356627]\n",
      "Loss in iteration 100: 0.5965579576874659\n",
      "Theta: [-0.05757183  0.05117107  0.08355926]\n",
      "Loss in iteration 101: 0.5964432911155615\n",
      "Theta: [-0.05818923  0.05153832  0.08355199]\n",
      "Loss in iteration 102: 0.5963287166011447\n",
      "Theta: [-0.0588064   0.05190536  0.08354446]\n",
      "Loss in iteration 103: 0.5962142340126428\n",
      "Theta: [-0.05942336  0.05227222  0.08353671]\n",
      "Loss in iteration 104: 0.5960998432254199\n",
      "Theta: [-0.06004009  0.05263887  0.08352873]\n",
      "Loss in iteration 105: 0.5959855441209356\n",
      "Theta: [-0.0606566   0.05300534  0.08352055]\n",
      "Loss in iteration 106: 0.5958713365860033\n",
      "Theta: [-0.06127289  0.05337162  0.08351218]\n",
      "Loss in iteration 107: 0.5957572205121417\n",
      "Theta: [-0.06188895  0.05373771  0.08350363]\n",
      "Loss in iteration 108: 0.5956431957950042\n",
      "Theta: [-0.06250478  0.05410361  0.08349492]\n",
      "Loss in iteration 109: 0.5955292623338784\n",
      "Theta: [-0.06312039  0.05446934  0.08348605]\n",
      "Loss in iteration 110: 0.5954154200312469\n",
      "Theta: [-0.06373576  0.05483488  0.08347704]\n",
      "Loss in iteration 111: 0.5953016687924019\n",
      "Theta: [-0.06435091  0.05520024  0.08346789]\n",
      "Loss in iteration 112: 0.5951880085251066\n",
      "Theta: [-0.06496583  0.05556543  0.08345861]\n",
      "Loss in iteration 113: 0.5950744391392971\n",
      "Theta: [-0.06558052  0.05593044  0.08344922]\n",
      "Loss in iteration 114: 0.5949609605468237\n",
      "Theta: [-0.06619498  0.05629528  0.08343972]\n",
      "Loss in iteration 115: 0.5948475726612191\n",
      "Theta: [-0.06680921  0.05665994  0.08343012]\n",
      "Loss in iteration 116: 0.5947342753975\n",
      "Theta: [-0.0674232   0.05702444  0.08342042]\n",
      "Loss in iteration 117: 0.5946210686719889\n",
      "Theta: [-0.06803697  0.05738876  0.08341063]\n",
      "Loss in iteration 118: 0.5945079524021594\n",
      "Theta: [-0.06865049  0.05775292  0.08340076]\n",
      "Loss in iteration 119: 0.5943949265065012\n",
      "Theta: [-0.06926379  0.0581169   0.08339081]\n",
      "Loss in iteration 120: 0.5942819909043989\n",
      "Theta: [-0.06987685  0.05848072  0.0833808 ]\n",
      "Loss in iteration 121: 0.5941691455160298\n",
      "Theta: [-0.07048968  0.05884438  0.08337071]\n",
      "Loss in iteration 122: 0.5940563902622686\n",
      "Theta: [-0.07110228  0.05920787  0.08336057]\n",
      "Loss in iteration 123: 0.5939437250646094\n",
      "Theta: [-0.07171464  0.05957119  0.08335037]\n",
      "Loss in iteration 124: 0.5938311498450931\n",
      "Theta: [-0.07232676  0.05993436  0.08334011]\n",
      "Loss in iteration 125: 0.5937186645262461\n",
      "Theta: [-0.07293865  0.06029736  0.08332981]\n",
      "Loss in iteration 126: 0.5936062690310255\n",
      "Theta: [-0.07355031  0.0606602   0.08331946]\n",
      "Loss in iteration 127: 0.5934939632827702\n",
      "Theta: [-0.07416173  0.06102287  0.08330907]\n",
      "Loss in iteration 128: 0.59338174720516\n",
      "Theta: [-0.07477291  0.06138539  0.08329865]\n",
      "Loss in iteration 129: 0.5932696207221786\n",
      "Theta: [-0.07538386  0.06174775  0.08328818]\n",
      "Loss in iteration 130: 0.5931575837580799\n",
      "Theta: [-0.07599457  0.06210995  0.08327769]\n",
      "Loss in iteration 131: 0.5930456362373608\n",
      "Theta: [-0.07660505  0.06247199  0.08326716]\n",
      "Loss in iteration 132: 0.5929337780847355\n",
      "Theta: [-0.07721529  0.06283387  0.08325661]\n",
      "Loss in iteration 133: 0.5928220092251144\n",
      "Theta: [-0.07782529  0.0631956   0.08324603]\n",
      "Loss in iteration 134: 0.5927103295835836\n",
      "Theta: [-0.07843506  0.06355716  0.08323543]\n",
      "Loss in iteration 135: 0.5925987390853895\n",
      "Theta: [-0.07904458  0.06391858  0.0832248 ]\n",
      "Loss in iteration 136: 0.5924872376559229\n",
      "Theta: [-0.07965388  0.06427983  0.08321416]\n",
      "Loss in iteration 137: 0.5923758252207064\n",
      "Theta: [-0.08026293  0.06464093  0.0832035 ]\n",
      "Loss in iteration 138: 0.5922645017053826\n",
      "Theta: [-0.08087175  0.06500187  0.08319283]\n",
      "Loss in iteration 139: 0.5921532670357048\n",
      "Theta: [-0.08148034  0.06536266  0.08318214]\n",
      "Loss in iteration 140: 0.5920421211375282\n",
      "Theta: [-0.08208868  0.0657233   0.08317144]\n",
      "Loss in iteration 141: 0.5919310639368018\n",
      "Theta: [-0.08269679  0.06608378  0.08316072]\n",
      "Loss in iteration 142: 0.5918200953595611\n",
      "Theta: [-0.08330467  0.0664441   0.08315   ]\n",
      "Loss in iteration 143: 0.591709215331924\n",
      "Theta: [-0.0839123   0.06680427  0.08313927]\n",
      "Loss in iteration 144: 0.5915984237800838\n",
      "Theta: [-0.0845197   0.06716429  0.08312853]\n",
      "Loss in iteration 145: 0.5914877206303053\n",
      "Theta: [-0.08512686  0.06752415  0.08311779]\n",
      "Loss in iteration 146: 0.5913771058089217\n",
      "Theta: [-0.08573379  0.06788387  0.08310704]\n",
      "Loss in iteration 147: 0.5912665792423298\n",
      "Theta: [-0.08634047  0.06824343  0.08309628]\n",
      "Loss in iteration 148: 0.5911561408569878\n",
      "Theta: [-0.08694693  0.06860283  0.08308552]\n",
      "Loss in iteration 149: 0.591045790579412\n",
      "Theta: [-0.08755314  0.06896209  0.08307476]\n",
      "Loss in iteration 150: 0.5909355283361755\n",
      "Theta: [-0.08815912  0.06932119  0.08306399]\n",
      "Loss in iteration 151: 0.5908253540539048\n",
      "Theta: [-0.08876486  0.06968014  0.08305323]\n",
      "Loss in iteration 152: 0.5907152676592795\n",
      "Theta: [-0.08937036  0.07003894  0.08304246]\n",
      "Loss in iteration 153: 0.5906052690790294\n",
      "Theta: [-0.08997563  0.07039758  0.0830317 ]\n",
      "Loss in iteration 154: 0.5904953582399343\n",
      "Theta: [-0.09058066  0.07075608  0.08302093]\n",
      "Loss in iteration 155: 0.5903855350688216\n",
      "Theta: [-0.09118546  0.07111442  0.08301017]\n",
      "Loss in iteration 156: 0.5902757994925668\n",
      "Theta: [-0.09179001  0.07147262  0.0829994 ]\n",
      "Loss in iteration 157: 0.5901661514380917\n",
      "Theta: [-0.09239433  0.07183066  0.08298864]\n",
      "Loss in iteration 158: 0.5900565908323628\n",
      "Theta: [-0.09299842  0.07218855  0.08297788]\n",
      "Loss in iteration 159: 0.5899471176023924\n",
      "Theta: [-0.09360227  0.07254629  0.08296713]\n",
      "Loss in iteration 160: 0.5898377316752371\n",
      "Theta: [-0.09420588  0.07290389  0.08295638]\n",
      "Loss in iteration 161: 0.5897284329779968\n",
      "Theta: [-0.09480926  0.07326133  0.08294563]\n",
      "Loss in iteration 162: 0.589619221437816\n",
      "Theta: [-0.0954124   0.07361862  0.08293488]\n",
      "Loss in iteration 163: 0.5895100969818808\n",
      "Theta: [-0.0960153   0.07397576  0.08292414]\n",
      "Loss in iteration 164: 0.5894010595374212\n",
      "Theta: [-0.09661797  0.07433275  0.08291341]\n",
      "Loss in iteration 165: 0.5892921090317091\n",
      "Theta: [-0.0972204   0.07468959  0.08290268]\n",
      "Loss in iteration 166: 0.5891832453920591\n",
      "Theta: [-0.0978226   0.07504628  0.08289195]\n",
      "Loss in iteration 167: 0.5890744685458273\n",
      "Theta: [-0.09842456  0.07540283  0.08288123]\n",
      "Loss in iteration 168: 0.588965778420412\n",
      "Theta: [-0.09902628  0.07575922  0.08287052]\n",
      "Loss in iteration 169: 0.5888571749432533\n",
      "Theta: [-0.09962777  0.07611546  0.08285981]\n",
      "Loss in iteration 170: 0.5887486580418329\n",
      "Theta: [-0.10022902  0.07647156  0.08284911]\n",
      "Loss in iteration 171: 0.588640227643674\n",
      "Theta: [-0.10083004  0.07682751  0.08283841]\n",
      "Loss in iteration 172: 0.5885318836763411\n",
      "Theta: [-0.10143082  0.0771833   0.08282772]\n",
      "Loss in iteration 173: 0.5884236260674408\n",
      "Theta: [-0.10203137  0.07753895  0.08281704]\n",
      "Loss in iteration 174: 0.5883154547446203\n",
      "Theta: [-0.10263168  0.07789445  0.08280636]\n",
      "Loss in iteration 175: 0.5882073696355685\n",
      "Theta: [-0.10323175  0.0782498   0.08279569]\n",
      "Loss in iteration 176: 0.5880993706680158\n",
      "Theta: [-0.1038316   0.07860501  0.08278503]\n",
      "Loss in iteration 177: 0.5879914577697334\n",
      "Theta: [-0.1044312   0.07896006  0.08277438]\n",
      "Loss in iteration 178: 0.5878836308685342\n",
      "Theta: [-0.10503057  0.07931497  0.08276373]\n",
      "Loss in iteration 179: 0.5877758898922725\n",
      "Theta: [-0.10562971  0.07966972  0.08275309]\n",
      "Loss in iteration 180: 0.5876682347688436\n",
      "Theta: [-0.10622861  0.08002434  0.08274246]\n",
      "Loss in iteration 181: 0.5875606654261842\n",
      "Theta: [-0.10682728  0.0803788   0.08273183]\n",
      "Loss in iteration 182: 0.5874531817922723\n",
      "Theta: [-0.10742571  0.08073311  0.08272122]\n",
      "Loss in iteration 183: 0.5873457837951279\n",
      "Theta: [-0.10802391  0.08108728  0.08271061]\n",
      "Loss in iteration 184: 0.5872384713628116\n",
      "Theta: [-0.10862187  0.0814413   0.0827    ]\n",
      "Loss in iteration 185: 0.5871312444234256\n",
      "Theta: [-0.1092196   0.08179517  0.08268941]\n",
      "Loss in iteration 186: 0.5870241029051138\n",
      "Theta: [-0.1098171   0.08214889  0.08267883]\n",
      "Loss in iteration 187: 0.5869170467360613\n",
      "Theta: [-0.11041436  0.08250247  0.08266825]\n",
      "Loss in iteration 188: 0.5868100758444952\n",
      "Theta: [-0.11101138  0.0828559   0.08265768]\n",
      "Loss in iteration 189: 0.5867031901586838\n",
      "Theta: [-0.11160818  0.08320918  0.08264712]\n",
      "Loss in iteration 190: 0.5865963896069367\n",
      "Theta: [-0.11220473  0.08356232  0.08263657]\n",
      "Loss in iteration 191: 0.586489674117606\n",
      "Theta: [-0.11280106  0.0839153   0.08262602]\n",
      "Loss in iteration 192: 0.5863830436190846\n",
      "Theta: [-0.11339715  0.08426815  0.08261549]\n",
      "Loss in iteration 193: 0.5862764980398074\n",
      "Theta: [-0.11399301  0.08462084  0.08260496]\n",
      "Loss in iteration 194: 0.5861700373082513\n",
      "Theta: [-0.11458863  0.08497339  0.08259444]\n",
      "Loss in iteration 195: 0.5860636613529349\n",
      "Theta: [-0.11518402  0.08532579  0.08258393]\n",
      "Loss in iteration 196: 0.5859573701024183\n",
      "Theta: [-0.11577918  0.08567804  0.08257343]\n",
      "Loss in iteration 197: 0.5858511634853039\n",
      "Theta: [-0.11637411  0.08603015  0.08256293]\n",
      "Loss in iteration 198: 0.5857450414302359\n",
      "Theta: [-0.1169688   0.08638211  0.08255245]\n",
      "Loss in iteration 199: 0.5856390038659002\n",
      "Theta: [-0.11756326  0.08673393  0.08254197]\n",
      "Loss in iteration 200: 0.5855330507210251\n",
      "Theta: [-0.11815748  0.08708559  0.0825315 ]\n",
      "Loss in iteration 201: 0.5854271819243807\n",
      "Theta: [-0.11875147  0.08743712  0.08252104]\n",
      "Loss in iteration 202: 0.5853213974047791\n",
      "Theta: [-0.11934523  0.08778849  0.08251059]\n",
      "Loss in iteration 203: 0.5852156970910748\n",
      "Theta: [-0.11993876  0.08813972  0.08250015]\n",
      "Loss in iteration 204: 0.5851100809121643\n",
      "Theta: [-0.12053206  0.08849081  0.08248971]\n",
      "Loss in iteration 205: 0.5850045487969865\n",
      "Theta: [-0.12112512  0.08884174  0.08247929]\n",
      "Loss in iteration 206: 0.5848991006745221\n",
      "Theta: [-0.12171795  0.08919254  0.08246887]\n",
      "Loss in iteration 207: 0.5847937364737947\n",
      "Theta: [-0.12231054  0.08954318  0.08245847]\n",
      "Loss in iteration 208: 0.5846884561238699\n",
      "Theta: [-0.12290291  0.08989369  0.08244807]\n",
      "Loss in iteration 209: 0.5845832595538555\n",
      "Theta: [-0.12349504  0.09024404  0.08243768]\n",
      "Loss in iteration 210: 0.584478146692902\n",
      "Theta: [-0.12408694  0.09059425  0.08242729]\n",
      "Loss in iteration 211: 0.5843731174702025\n",
      "Theta: [-0.12467861  0.09094432  0.08241692]\n",
      "Loss in iteration 212: 0.5842681718149921\n",
      "Theta: [-0.12527005  0.09129423  0.08240656]\n",
      "Loss in iteration 213: 0.5841633096565488\n",
      "Theta: [-0.12586126  0.09164401  0.0823962 ]\n",
      "Loss in iteration 214: 0.5840585309241934\n",
      "Theta: [-0.12645223  0.09199364  0.08238585]\n",
      "Loss in iteration 215: 0.5839538355472885\n",
      "Theta: [-0.12704297  0.09234312  0.08237552]\n",
      "Loss in iteration 216: 0.5838492234552403\n",
      "Theta: [-0.12763349  0.09269246  0.08236519]\n",
      "Loss in iteration 217: 0.5837446945774972\n",
      "Theta: [-0.12822377  0.09304165  0.08235486]\n",
      "Loss in iteration 218: 0.5836402488435501\n",
      "Theta: [-0.12881382  0.0933907   0.08234455]\n",
      "Loss in iteration 219: 0.5835358861829334\n",
      "Theta: [-0.12940363  0.09373961  0.08233425]\n",
      "Loss in iteration 220: 0.5834316065252236\n",
      "Theta: [-0.12999322  0.09408837  0.08232395]\n",
      "Loss in iteration 221: 0.5833274098000406\n",
      "Theta: [-0.13058258  0.09443698  0.08231367]\n",
      "Loss in iteration 222: 0.5832232959370469\n",
      "Theta: [-0.1311717   0.09478545  0.08230339]\n",
      "Loss in iteration 223: 0.5831192648659477\n",
      "Theta: [-0.1317606   0.09513378  0.08229312]\n",
      "Loss in iteration 224: 0.5830153165164917\n",
      "Theta: [-0.13234926  0.09548196  0.08228286]\n",
      "Loss in iteration 225: 0.5829114508184703\n",
      "Theta: [-0.13293769  0.09583     0.08227261]\n",
      "Loss in iteration 226: 0.582807667701718\n",
      "Theta: [-0.13352589  0.09617789  0.08226237]\n",
      "Loss in iteration 227: 0.5827039670961122\n",
      "Theta: [-0.13411387  0.09652564  0.08225213]\n",
      "Loss in iteration 228: 0.5826003489315735\n",
      "Theta: [-0.13470161  0.09687324  0.08224191]\n",
      "Loss in iteration 229: 0.5824968131380661\n",
      "Theta: [-0.13528912  0.0972207   0.08223169]\n",
      "Loss in iteration 230: 0.5823933596455967\n",
      "Theta: [-0.1358764   0.09756802  0.08222148]\n",
      "Loss in iteration 231: 0.5822899883842155\n",
      "Theta: [-0.13646346  0.09791519  0.08221129]\n",
      "Loss in iteration 232: 0.5821866992840161\n",
      "Theta: [-0.13705028  0.09826222  0.08220109]\n",
      "Loss in iteration 233: 0.5820834922751355\n",
      "Theta: [-0.13763687  0.09860911  0.08219091]\n",
      "Loss in iteration 234: 0.5819803672877533\n",
      "Theta: [-0.13822323  0.09895585  0.08218074]\n",
      "Loss in iteration 235: 0.5818773242520932\n",
      "Theta: [-0.13880937  0.09930245  0.08217057]\n",
      "Loss in iteration 236: 0.581774363098422\n",
      "Theta: [-0.13939527  0.0996489   0.08216042]\n",
      "Loss in iteration 237: 0.58167148375705\n",
      "Theta: [-0.13998094  0.09999522  0.08215027]\n",
      "Loss in iteration 238: 0.5815686861583312\n",
      "Theta: [-0.14056639  0.10034138  0.08214013]\n",
      "Loss in iteration 239: 0.5814659702326626\n",
      "Theta: [-0.1411516   0.10068741  0.08213   ]\n",
      "Loss in iteration 240: 0.5813633359104848\n",
      "Theta: [-0.14173659  0.10103329  0.08211988]\n",
      "Loss in iteration 241: 0.5812607831222825\n",
      "Theta: [-0.14232135  0.10137903  0.08210977]\n",
      "Loss in iteration 242: 0.5811583117985836\n",
      "Theta: [-0.14290588  0.10172463  0.08209966]\n",
      "Loss in iteration 243: 0.5810559218699596\n",
      "Theta: [-0.14349018  0.10207008  0.08208957]\n",
      "Loss in iteration 244: 0.5809536132670258\n",
      "Theta: [-0.14407425  0.10241539  0.08207948]\n",
      "Loss in iteration 245: 0.5808513859204409\n",
      "Theta: [-0.14465809  0.10276056  0.0820694 ]\n",
      "Loss in iteration 246: 0.5807492397609081\n",
      "Theta: [-0.14524171  0.10310558  0.08205933]\n",
      "Loss in iteration 247: 0.5806471747191734\n",
      "Theta: [-0.14582509  0.10345046  0.08204927]\n",
      "Loss in iteration 248: 0.5805451907260273\n",
      "Theta: [-0.14640825  0.1037952   0.08203922]\n",
      "Loss in iteration 249: 0.5804432877123036\n",
      "Theta: [-0.14699118  0.1041398   0.08202917]\n",
      "Loss in iteration 250: 0.5803414656088804\n",
      "Theta: [-0.14757388  0.10448425  0.08201914]\n",
      "Loss in iteration 251: 0.5802397243466797\n",
      "Theta: [-0.14815635  0.10482857  0.08200911]\n",
      "Loss in iteration 252: 0.580138063856667\n",
      "Theta: [-0.1487386   0.10517274  0.08199909]\n",
      "Loss in iteration 253: 0.5800364840698522\n",
      "Theta: [-0.14932062  0.10551676  0.08198908]\n",
      "Loss in iteration 254: 0.5799349849172888\n",
      "Theta: [-0.14990241  0.10586065  0.08197908]\n",
      "Loss in iteration 255: 0.5798335663300744\n",
      "Theta: [-0.15048397  0.10620439  0.08196908]\n",
      "Loss in iteration 256: 0.5797322282393509\n",
      "Theta: [-0.1510653  0.106548   0.0819591]\n",
      "Loss in iteration 257: 0.5796309705763042\n",
      "Theta: [-0.15164641  0.10689146  0.08194912]\n",
      "Loss in iteration 258: 0.5795297932721641\n",
      "Theta: [-0.15222729  0.10723477  0.08193915]\n",
      "Loss in iteration 259: 0.5794286962582045\n",
      "Theta: [-0.15280794  0.10757795  0.08192919]\n",
      "Loss in iteration 260: 0.579327679465744\n",
      "Theta: [-0.15338837  0.10792099  0.08191924]\n",
      "Loss in iteration 261: 0.5792267428261448\n",
      "Theta: [-0.15396857  0.10826388  0.0819093 ]\n",
      "Loss in iteration 262: 0.5791258862708133\n",
      "Theta: [-0.15454854  0.10860663  0.08189936]\n",
      "Loss in iteration 263: 0.5790251097312007\n",
      "Theta: [-0.15512828  0.10894924  0.08188944]\n",
      "Loss in iteration 264: 0.5789244131388022\n",
      "Theta: [-0.1557078   0.10929171  0.08187952]\n",
      "Loss in iteration 265: 0.5788237964251569\n",
      "Theta: [-0.15628709  0.10963404  0.08186961]\n",
      "Loss in iteration 266: 0.578723259521849\n",
      "Theta: [-0.15686616  0.10997623  0.08185971]\n",
      "Loss in iteration 267: 0.5786228023605064\n",
      "Theta: [-0.15744499  0.11031827  0.08184982]\n",
      "Loss in iteration 268: 0.5785224248728018\n",
      "Theta: [-0.15802361  0.11066018  0.08183993]\n",
      "Loss in iteration 269: 0.5784221269904521\n",
      "Theta: [-0.15860199  0.11100194  0.08183006]\n",
      "Loss in iteration 270: 0.5783219086452188\n",
      "Theta: [-0.15918015  0.11134356  0.08182019]\n",
      "Loss in iteration 271: 0.5782217697689079\n",
      "Theta: [-0.15975808  0.11168505  0.08181033]\n",
      "Loss in iteration 272: 0.5781217102933698\n",
      "Theta: [-0.16033579  0.11202639  0.08180048]\n",
      "Loss in iteration 273: 0.5780217301504991\n",
      "Theta: [-0.16091327  0.11236759  0.08179064]\n",
      "Loss in iteration 274: 0.5779218292722355\n",
      "Theta: [-0.16149053  0.11270865  0.0817808 ]\n",
      "Loss in iteration 275: 0.5778220075905631\n",
      "Theta: [-0.16206756  0.11304957  0.08177098]\n",
      "Loss in iteration 276: 0.5777222650375106\n",
      "Theta: [-0.16264436  0.11339035  0.08176116]\n",
      "Loss in iteration 277: 0.5776226015451512\n",
      "Theta: [-0.16322094  0.11373099  0.08175135]\n",
      "Loss in iteration 278: 0.5775230170456029\n",
      "Theta: [-0.1637973   0.11407149  0.08174155]\n",
      "Loss in iteration 279: 0.5774235114710285\n",
      "Theta: [-0.16437343  0.11441184  0.08173176]\n",
      "Loss in iteration 280: 0.5773240847536352\n",
      "Theta: [-0.16494933  0.11475206  0.08172197]\n",
      "Loss in iteration 281: 0.5772247368256754\n",
      "Theta: [-0.16552501  0.11509214  0.0817122 ]\n",
      "Loss in iteration 282: 0.5771254676194455\n",
      "Theta: [-0.16610046  0.11543208  0.08170243]\n",
      "Loss in iteration 283: 0.5770262770672874\n",
      "Theta: [-0.16667569  0.11577188  0.08169267]\n",
      "Loss in iteration 284: 0.5769271651015877\n",
      "Theta: [-0.16725069  0.11611154  0.08168292]\n",
      "Loss in iteration 285: 0.5768281316547773\n",
      "Theta: [-0.16782547  0.11645106  0.08167318]\n",
      "Loss in iteration 286: 0.5767291766593327\n",
      "Theta: [-0.16840002  0.11679044  0.08166344]\n",
      "Loss in iteration 287: 0.5766303000477749\n",
      "Theta: [-0.16897435  0.11712968  0.08165371]\n",
      "Loss in iteration 288: 0.5765315017526697\n",
      "Theta: [-0.16954846  0.11746878  0.08164399]\n",
      "Loss in iteration 289: 0.5764327817066282\n",
      "Theta: [-0.17012234  0.11780774  0.08163428]\n",
      "Loss in iteration 290: 0.576334139842306\n",
      "Theta: [-0.170696    0.11814656  0.08162458]\n",
      "Loss in iteration 291: 0.576235576092404\n",
      "Theta: [-0.17126943  0.11848524  0.08161489]\n",
      "Loss in iteration 292: 0.576137090389668\n",
      "Theta: [-0.17184264  0.11882379  0.0816052 ]\n",
      "Loss in iteration 293: 0.576038682666889\n",
      "Theta: [-0.17241562  0.11916219  0.08159552]\n",
      "Loss in iteration 294: 0.5759403528569025\n",
      "Theta: [-0.17298838  0.11950046  0.08158585]\n",
      "Loss in iteration 295: 0.5758421008925899\n",
      "Theta: [-0.17356092  0.11983858  0.08157619]\n",
      "Loss in iteration 296: 0.575743926706877\n",
      "Theta: [-0.17413323  0.12017657  0.08156654]\n",
      "Loss in iteration 297: 0.5756458302327351\n",
      "Theta: [-0.17470532  0.12051442  0.08155689]\n",
      "Loss in iteration 298: 0.5755478114031802\n",
      "Theta: [-0.17527719  0.12085213  0.08154725]\n",
      "Loss in iteration 299: 0.5754498701512744\n",
      "Theta: [-0.17584883  0.1211897   0.08153762]\n",
      "Loss in iteration 300: 0.5753520064101233\n",
      "Theta: [-0.17642025  0.12152713  0.081528  ]\n",
      "Loss in iteration 301: 0.5752542201128796\n",
      "Theta: [-0.17699145  0.12186443  0.08151839]\n",
      "Loss in iteration 302: 0.57515651119274\n",
      "Theta: [-0.17756242  0.12220158  0.08150878]\n",
      "Loss in iteration 303: 0.5750588795829471\n",
      "Theta: [-0.17813317  0.1225386   0.08149919]\n",
      "Loss in iteration 304: 0.5749613252167881\n",
      "Theta: [-0.1787037   0.12287548  0.0814896 ]\n",
      "Loss in iteration 305: 0.574863848027596\n",
      "Theta: [-0.17927401  0.12321222  0.08148002]\n",
      "Loss in iteration 306: 0.5747664479487491\n",
      "Theta: [-0.17984409  0.12354882  0.08147044]\n",
      "Loss in iteration 307: 0.5746691249136705\n",
      "Theta: [-0.18041395  0.12388529  0.08146088]\n",
      "Loss in iteration 308: 0.5745718788558296\n",
      "Theta: [-0.18098359  0.12422161  0.08145132]\n",
      "Loss in iteration 309: 0.5744747097087399\n",
      "Theta: [-0.181553    0.1245578   0.08144177]\n",
      "Loss in iteration 310: 0.5743776174059617\n",
      "Theta: [-0.18212219  0.12489385  0.08143223]\n",
      "Loss in iteration 311: 0.5742806018810995\n",
      "Theta: [-0.18269116  0.12522977  0.0814227 ]\n",
      "Loss in iteration 312: 0.5741836630678038\n",
      "Theta: [-0.18325991  0.12556554  0.08141317]\n",
      "Loss in iteration 313: 0.5740868008997706\n",
      "Theta: [-0.18382844  0.12590118  0.08140366]\n",
      "Loss in iteration 314: 0.573990015310741\n",
      "Theta: [-0.18439674  0.12623668  0.08139415]\n",
      "Loss in iteration 315: 0.573893306234502\n",
      "Theta: [-0.18496483  0.12657205  0.08138464]\n",
      "Loss in iteration 316: 0.5737966736048858\n",
      "Theta: [-0.18553269  0.12690727  0.08137515]\n",
      "Loss in iteration 317: 0.5737001173557702\n",
      "Theta: [-0.18610033  0.12724236  0.08136567]\n",
      "Loss in iteration 318: 0.5736036374210789\n",
      "Theta: [-0.18666775  0.12757731  0.08135619]\n",
      "Loss in iteration 319: 0.5735072337347803\n",
      "Theta: [-0.18723494  0.12791212  0.08134672]\n",
      "Loss in iteration 320: 0.573410906230889\n",
      "Theta: [-0.18780192  0.1282468   0.08133726]\n",
      "Loss in iteration 321: 0.5733146548434654\n",
      "Theta: [-0.18836867  0.12858134  0.0813278 ]\n",
      "Loss in iteration 322: 0.573218479506615\n",
      "Theta: [-0.18893521  0.12891575  0.08131836]\n",
      "Loss in iteration 323: 0.573122380154489\n",
      "Theta: [-0.18950152  0.12925001  0.08130892]\n",
      "Loss in iteration 324: 0.5730263567212847\n",
      "Theta: [-0.19006761  0.12958414  0.08129949]\n",
      "Loss in iteration 325: 0.5729304091412444\n",
      "Theta: [-0.19063348  0.12991813  0.08129006]\n",
      "Loss in iteration 326: 0.5728345373486564\n",
      "Theta: [-0.19119913  0.13025199  0.08128065]\n",
      "Loss in iteration 327: 0.5727387412778548\n",
      "Theta: [-0.19176456  0.13058571  0.08127124]\n",
      "Loss in iteration 328: 0.5726430208632195\n",
      "Theta: [-0.19232977  0.13091929  0.08126184]\n",
      "Loss in iteration 329: 0.5725473760391757\n",
      "Theta: [-0.19289475  0.13125274  0.08125245]\n",
      "Loss in iteration 330: 0.5724518067401946\n",
      "Theta: [-0.19345952  0.13158605  0.08124307]\n",
      "Loss in iteration 331: 0.5723563129007931\n",
      "Theta: [-0.19402407  0.13191923  0.08123369]\n",
      "Loss in iteration 332: 0.5722608944555341\n",
      "Theta: [-0.1945884   0.13225226  0.08122432]\n",
      "Loss in iteration 333: 0.572165551339026\n",
      "Theta: [-0.19515251  0.13258517  0.08121496]\n",
      "Loss in iteration 334: 0.5720702834859231\n",
      "Theta: [-0.19571639  0.13291793  0.08120561]\n",
      "Loss in iteration 335: 0.5719750908309257\n",
      "Theta: [-0.19628006  0.13325056  0.08119627]\n",
      "Loss in iteration 336: 0.5718799733087797\n",
      "Theta: [-0.19684351  0.13358306  0.08118693]\n",
      "Loss in iteration 337: 0.5717849308542768\n",
      "Theta: [-0.19740674  0.13391542  0.0811776 ]\n",
      "Loss in iteration 338: 0.5716899634022549\n",
      "Theta: [-0.19796975  0.13424764  0.08116828]\n",
      "Loss in iteration 339: 0.5715950708875974\n",
      "Theta: [-0.19853253  0.13457973  0.08115896]\n",
      "Loss in iteration 340: 0.5715002532452337\n",
      "Theta: [-0.1990951   0.13491168  0.08114966]\n",
      "Loss in iteration 341: 0.5714055104101398\n",
      "Theta: [-0.19965746  0.13524349  0.08114036]\n",
      "Loss in iteration 342: 0.5713108423173362\n",
      "Theta: [-0.20021959  0.13557517  0.08113107]\n",
      "Loss in iteration 343: 0.5712162489018907\n",
      "Theta: [-0.2007815   0.13590672  0.08112178]\n",
      "Loss in iteration 344: 0.5711217300989163\n",
      "Theta: [-0.20134319  0.13623813  0.08111251]\n",
      "Loss in iteration 345: 0.5710272858435723\n",
      "Theta: [-0.20190467  0.13656941  0.08110324]\n",
      "Loss in iteration 346: 0.5709329160710638\n",
      "Theta: [-0.20246592  0.13690055  0.08109398]\n",
      "Loss in iteration 347: 0.570838620716642\n",
      "Theta: [-0.20302696  0.13723155  0.08108473]\n",
      "Loss in iteration 348: 0.5707443997156042\n",
      "Theta: [-0.20358778  0.13756242  0.08107548]\n",
      "Loss in iteration 349: 0.5706502530032932\n",
      "Theta: [-0.20414838  0.13789316  0.08106625]\n",
      "Loss in iteration 350: 0.5705561805150985\n",
      "Theta: [-0.20470876  0.13822376  0.08105702]\n",
      "Loss in iteration 351: 0.5704621821864554\n",
      "Theta: [-0.20526893  0.13855422  0.08104779]\n",
      "Loss in iteration 352: 0.570368257952845\n",
      "Theta: [-0.20582887  0.13888455  0.08103858]\n",
      "Loss in iteration 353: 0.5702744077497949\n",
      "Theta: [-0.2063886   0.13921475  0.08102937]\n",
      "Loss in iteration 354: 0.5701806315128786\n",
      "Theta: [-0.20694811  0.13954481  0.08102017]\n",
      "Loss in iteration 355: 0.5700869291777156\n",
      "Theta: [-0.2075074   0.13987474  0.08101098]\n",
      "Loss in iteration 356: 0.5699933006799717\n",
      "Theta: [-0.20806647  0.14020453  0.0810018 ]\n",
      "Loss in iteration 357: 0.5698997459553583\n",
      "Theta: [-0.20862533  0.14053419  0.08099262]\n",
      "Loss in iteration 358: 0.5698062649396338\n",
      "Theta: [-0.20918397  0.14086372  0.08098345]\n",
      "Loss in iteration 359: 0.5697128575686021\n",
      "Theta: [-0.20974239  0.14119311  0.08097429]\n",
      "Loss in iteration 360: 0.5696195237781133\n",
      "Theta: [-0.21030059  0.14152236  0.08096514]\n",
      "Loss in iteration 361: 0.5695262635040641\n",
      "Theta: [-0.21085858  0.14185149  0.08095599]\n",
      "Loss in iteration 362: 0.5694330766823967\n",
      "Theta: [-0.21141635  0.14218047  0.08094685]\n",
      "Loss in iteration 363: 0.5693399632491002\n",
      "Theta: [-0.2119739   0.14250933  0.08093772]\n",
      "Loss in iteration 364: 0.5692469231402093\n",
      "Theta: [-0.21253123  0.14283805  0.0809286 ]\n",
      "Loss in iteration 365: 0.5691539562918053\n",
      "Theta: [-0.21308835  0.14316664  0.08091948]\n",
      "Loss in iteration 366: 0.5690610626400154\n",
      "Theta: [-0.21364525  0.14349509  0.08091037]\n",
      "Loss in iteration 367: 0.5689682421210136\n",
      "Theta: [-0.21420194  0.14382341  0.08090127]\n",
      "Loss in iteration 368: 0.5688754946710194\n",
      "Theta: [-0.21475841  0.1441516   0.08089217]\n",
      "Loss in iteration 369: 0.5687828202262988\n",
      "Theta: [-0.21531466  0.14447965  0.08088309]\n",
      "Loss in iteration 370: 0.5686902187231644\n",
      "Theta: [-0.21587069  0.14480757  0.08087401]\n",
      "Loss in iteration 371: 0.5685976900979748\n",
      "Theta: [-0.21642651  0.14513536  0.08086494]\n",
      "Loss in iteration 372: 0.5685052342871346\n",
      "Theta: [-0.21698211  0.14546301  0.08085587]\n",
      "Loss in iteration 373: 0.5684128512270953\n",
      "Theta: [-0.2175375   0.14579053  0.08084681]\n",
      "Loss in iteration 374: 0.5683205408543544\n",
      "Theta: [-0.21809267  0.14611792  0.08083776]\n",
      "Loss in iteration 375: 0.5682283031054551\n",
      "Theta: [-0.21864762  0.14644518  0.08082872]\n",
      "Loss in iteration 376: 0.568136137916988\n",
      "Theta: [-0.21920236  0.1467723   0.08081969]\n",
      "Loss in iteration 377: 0.5680440452255897\n",
      "Theta: [-0.21975688  0.14709929  0.08081066]\n",
      "Loss in iteration 378: 0.5679520249679422\n",
      "Theta: [-0.22031119  0.14742614  0.08080164]\n",
      "Loss in iteration 379: 0.5678600770807752\n",
      "Theta: [-0.22086528  0.14775287  0.08079263]\n",
      "Loss in iteration 380: 0.5677682015008638\n",
      "Theta: [-0.22141916  0.14807946  0.08078362]\n",
      "Loss in iteration 381: 0.5676763981650299\n",
      "Theta: [-0.22197282  0.14840592  0.08077462]\n",
      "Loss in iteration 382: 0.5675846670101418\n",
      "Theta: [-0.22252626  0.14873224  0.08076563]\n",
      "Loss in iteration 383: 0.5674930079731133\n",
      "Theta: [-0.22307949  0.14905844  0.08075665]\n",
      "Loss in iteration 384: 0.5674014209909061\n",
      "Theta: [-0.22363251  0.1493845   0.08074767]\n",
      "Loss in iteration 385: 0.5673099060005268\n",
      "Theta: [-0.22418531  0.14971043  0.0807387 ]\n",
      "Loss in iteration 386: 0.5672184629390294\n",
      "Theta: [-0.22473789  0.15003623  0.08072974]\n",
      "Loss in iteration 387: 0.5671270917435138\n",
      "Theta: [-0.22529026  0.15036189  0.08072079]\n",
      "Loss in iteration 388: 0.5670357923511268\n",
      "Theta: [-0.22584242  0.15068743  0.08071184]\n",
      "Loss in iteration 389: 0.5669445646990606\n",
      "Theta: [-0.22639436  0.15101283  0.0807029 ]\n",
      "Loss in iteration 390: 0.5668534087245548\n",
      "Theta: [-0.22694609  0.1513381   0.08069397]\n",
      "Loss in iteration 391: 0.5667623243648953\n",
      "Theta: [-0.2274976   0.15166324  0.08068504]\n",
      "Loss in iteration 392: 0.5666713115574139\n",
      "Theta: [-0.2280489   0.15198824  0.08067613]\n",
      "Loss in iteration 393: 0.5665803702394893\n",
      "Theta: [-0.22859998  0.15231312  0.08066722]\n",
      "Loss in iteration 394: 0.5664895003485465\n",
      "Theta: [-0.22915085  0.15263786  0.08065831]\n",
      "Loss in iteration 395: 0.5663987018220569\n",
      "Theta: [-0.2297015   0.15296247  0.08064942]\n",
      "Loss in iteration 396: 0.5663079745975385\n",
      "Theta: [-0.23025195  0.15328695  0.08064053]\n",
      "Loss in iteration 397: 0.5662173186125554\n",
      "Theta: [-0.23080217  0.1536113   0.08063164]\n",
      "Loss in iteration 398: 0.566126733804719\n",
      "Theta: [-0.23135219  0.15393552  0.08062277]\n",
      "Loss in iteration 399: 0.5660362201116859\n",
      "Theta: [-0.23190199  0.15425961  0.0806139 ]\n",
      "Loss in iteration 400: 0.5659457774711601\n",
      "Theta: [-0.23245158  0.15458356  0.08060504]\n",
      "Loss in iteration 401: 0.5658554058208922\n",
      "Theta: [-0.23300095  0.15490739  0.08059619]\n",
      "Loss in iteration 402: 0.5657651050986787\n",
      "Theta: [-0.23355011  0.15523108  0.08058734]\n",
      "Loss in iteration 403: 0.5656748752423628\n",
      "Theta: [-0.23409906  0.15555465  0.0805785 ]\n",
      "Loss in iteration 404: 0.5655847161898341\n",
      "Theta: [-0.23464779  0.15587808  0.08056967]\n",
      "Loss in iteration 405: 0.5654946278790292\n",
      "Theta: [-0.23519631  0.15620138  0.08056085]\n",
      "Loss in iteration 406: 0.5654046102479303\n",
      "Theta: [-0.23574462  0.15652455  0.08055203]\n",
      "Loss in iteration 407: 0.5653146632345668\n",
      "Theta: [-0.23629271  0.15684759  0.08054322]\n",
      "Loss in iteration 408: 0.5652247867770148\n",
      "Theta: [-0.2368406   0.1571705   0.08053442]\n",
      "Loss in iteration 409: 0.5651349808133963\n",
      "Theta: [-0.23738827  0.15749328  0.08052562]\n",
      "Loss in iteration 410: 0.56504524528188\n",
      "Theta: [-0.23793572  0.15781593  0.08051683]\n",
      "Loss in iteration 411: 0.5649555801206813\n",
      "Theta: [-0.23848297  0.15813845  0.08050805]\n",
      "Loss in iteration 412: 0.5648659852680622\n",
      "Theta: [-0.23903     0.15846084  0.08049927]\n",
      "Loss in iteration 413: 0.5647764606623306\n",
      "Theta: [-0.23957682  0.1587831   0.08049051]\n",
      "Loss in iteration 414: 0.5646870062418418\n",
      "Theta: [-0.24012343  0.15910523  0.08048175]\n",
      "Loss in iteration 415: 0.5645976219449967\n",
      "Theta: [-0.24066982  0.15942723  0.08047299]\n",
      "Loss in iteration 416: 0.564508307710244\n",
      "Theta: [-0.24121601  0.1597491   0.08046424]\n",
      "Loss in iteration 417: 0.5644190634760776\n",
      "Theta: [-0.24176198  0.16007083  0.0804555 ]\n",
      "Loss in iteration 418: 0.5643298891810388\n",
      "Theta: [-0.24230774  0.16039244  0.08044677]\n",
      "Loss in iteration 419: 0.5642407847637153\n",
      "Theta: [-0.24285329  0.16071392  0.08043805]\n",
      "Loss in iteration 420: 0.564151750162741\n",
      "Theta: [-0.24339862  0.16103527  0.08042933]\n",
      "Loss in iteration 421: 0.5640627853167964\n",
      "Theta: [-0.24394375  0.1613565   0.08042062]\n",
      "Loss in iteration 422: 0.5639738901646093\n",
      "Theta: [-0.24448866  0.16167759  0.08041191]\n",
      "Loss in iteration 423: 0.563885064644953\n",
      "Theta: [-0.24503337  0.16199855  0.08040321]\n",
      "Loss in iteration 424: 0.5637963086966481\n",
      "Theta: [-0.24557786  0.16231938  0.08039452]\n",
      "Loss in iteration 425: 0.5637076222585613\n",
      "Theta: [-0.24612214  0.16264008  0.08038584]\n",
      "Loss in iteration 426: 0.5636190052696064\n",
      "Theta: [-0.24666621  0.16296066  0.08037716]\n",
      "Loss in iteration 427: 0.563530457668743\n",
      "Theta: [-0.24721006  0.1632811   0.08036849]\n",
      "Loss in iteration 428: 0.5634419793949781\n",
      "Theta: [-0.24775371  0.16360142  0.08035983]\n",
      "Loss in iteration 429: 0.5633535703873647\n",
      "Theta: [-0.24829715  0.16392161  0.08035117]\n",
      "Loss in iteration 430: 0.5632652305850021\n",
      "Theta: [-0.24884038  0.16424167  0.08034252]\n",
      "Loss in iteration 431: 0.5631769599270372\n",
      "Theta: [-0.24938339  0.1645616   0.08033388]\n",
      "Loss in iteration 432: 0.5630887583526626\n",
      "Theta: [-0.2499262   0.1648814   0.08032525]\n",
      "Loss in iteration 433: 0.5630006258011176\n",
      "Theta: [-0.25046879  0.16520107  0.08031662]\n",
      "Loss in iteration 434: 0.5629125622116882\n",
      "Theta: [-0.25101118  0.16552061  0.080308  ]\n",
      "Loss in iteration 435: 0.562824567523707\n",
      "Theta: [-0.25155335  0.16584003  0.08029938]\n",
      "Loss in iteration 436: 0.5627366416765534\n",
      "Theta: [-0.25209531  0.16615932  0.08029077]\n",
      "Loss in iteration 437: 0.5626487846096523\n",
      "Theta: [-0.25263707  0.16647847  0.08028217]\n",
      "Loss in iteration 438: 0.5625609962624767\n",
      "Theta: [-0.25317861  0.1667975   0.08027358]\n",
      "Loss in iteration 439: 0.5624732765745449\n",
      "Theta: [-0.25371995  0.16711641  0.08026499]\n",
      "Loss in iteration 440: 0.5623856254854226\n",
      "Theta: [-0.25426107  0.16743518  0.08025641]\n",
      "Loss in iteration 441: 0.5622980429347217\n",
      "Theta: [-0.25480199  0.16775383  0.08024784]\n",
      "Loss in iteration 442: 0.5622105288621007\n",
      "Theta: [-0.2553427   0.16807235  0.08023927]\n",
      "Loss in iteration 443: 0.5621230832072643\n",
      "Theta: [-0.25588319  0.16839074  0.08023071]\n",
      "Loss in iteration 444: 0.5620357059099645\n",
      "Theta: [-0.25642348  0.168709    0.08022216]\n",
      "Loss in iteration 445: 0.5619483969099995\n",
      "Theta: [-0.25696356  0.16902713  0.08021361]\n",
      "Loss in iteration 446: 0.5618611561472137\n",
      "Theta: [-0.25750343  0.16934514  0.08020507]\n",
      "Loss in iteration 447: 0.561773983561499\n",
      "Theta: [-0.25804309  0.16966302  0.08019654]\n",
      "Loss in iteration 448: 0.5616868790927929\n",
      "Theta: [-0.25858254  0.16998077  0.08018801]\n",
      "Loss in iteration 449: 0.5615998426810798\n",
      "Theta: [-0.25912178  0.1702984   0.08017949]\n",
      "Loss in iteration 450: 0.5615128742663906\n",
      "Theta: [-0.25966082  0.17061589  0.08017098]\n",
      "Loss in iteration 451: 0.5614259737888031\n",
      "Theta: [-0.26019964  0.17093326  0.08016248]\n",
      "Loss in iteration 452: 0.5613391411884414\n",
      "Theta: [-0.26073826  0.1712505   0.08015398]\n",
      "Loss in iteration 453: 0.561252376405476\n",
      "Theta: [-0.26127667  0.17156762  0.08014549]\n",
      "Loss in iteration 454: 0.5611656793801238\n",
      "Theta: [-0.26181487  0.17188461  0.080137  ]\n",
      "Loss in iteration 455: 0.5610790500526491\n",
      "Theta: [-0.26235286  0.17220147  0.08012852]\n",
      "Loss in iteration 456: 0.5609924883633619\n",
      "Theta: [-0.26289064  0.1725182   0.08012005]\n",
      "Loss in iteration 457: 0.5609059942526191\n",
      "Theta: [-0.26342822  0.17283481  0.08011158]\n",
      "Loss in iteration 458: 0.560819567660824\n",
      "Theta: [-0.26396558  0.17315129  0.08010312]\n",
      "Loss in iteration 459: 0.5607332085284263\n",
      "Theta: [-0.26450274  0.17346765  0.08009467]\n",
      "Loss in iteration 460: 0.5606469167959228\n",
      "Theta: [-0.2650397   0.17378387  0.08008623]\n",
      "Loss in iteration 461: 0.5605606924038562\n",
      "Theta: [-0.26557644  0.17409997  0.08007779]\n",
      "Loss in iteration 462: 0.5604745352928162\n",
      "Theta: [-0.26611298  0.17441595  0.08006936]\n",
      "Loss in iteration 463: 0.5603884454034384\n",
      "Theta: [-0.26664931  0.1747318   0.08006093]\n",
      "Loss in iteration 464: 0.5603024226764057\n",
      "Theta: [-0.26718543  0.17504752  0.08005251]\n",
      "Loss in iteration 465: 0.560216467052447\n",
      "Theta: [-0.26772134  0.17536311  0.0800441 ]\n",
      "Loss in iteration 466: 0.5601305784723378\n",
      "Theta: [-0.26825705  0.17567858  0.08003569]\n",
      "Loss in iteration 467: 0.5600447568769003\n",
      "Theta: [-0.26879255  0.17599392  0.0800273 ]\n",
      "Loss in iteration 468: 0.559959002207003\n",
      "Theta: [-0.26932785  0.17630914  0.0800189 ]\n",
      "Loss in iteration 469: 0.5598733144035609\n",
      "Theta: [-0.26986293  0.17662423  0.08001052]\n",
      "Loss in iteration 470: 0.5597876934075356\n",
      "Theta: [-0.27039781  0.1769392   0.08000214]\n",
      "Loss in iteration 471: 0.5597021391599354\n",
      "Theta: [-0.27093249  0.17725404  0.07999377]\n",
      "Loss in iteration 472: 0.5596166516018144\n",
      "Theta: [-0.27146695  0.17756875  0.0799854 ]\n",
      "Loss in iteration 473: 0.5595312306742741\n",
      "Theta: [-0.27200121  0.17788334  0.07997704]\n",
      "Loss in iteration 474: 0.5594458763184617\n",
      "Theta: [-0.27253527  0.1781978   0.07996869]\n",
      "Loss in iteration 475: 0.5593605884755712\n",
      "Theta: [-0.27306911  0.17851213  0.07996034]\n",
      "Loss in iteration 476: 0.5592753670868433\n",
      "Theta: [-0.27360276  0.17882634  0.079952  ]\n",
      "Loss in iteration 477: 0.5591902120935647\n",
      "Theta: [-0.27413619  0.17914043  0.07994367]\n",
      "Loss in iteration 478: 0.5591051234370689\n",
      "Theta: [-0.27466942  0.17945439  0.07993534]\n",
      "Loss in iteration 479: 0.5590201010587357\n",
      "Theta: [-0.27520244  0.17976823  0.07992702]\n",
      "Loss in iteration 480: 0.5589351448999914\n",
      "Theta: [-0.27573526  0.18008193  0.07991871]\n",
      "Loss in iteration 481: 0.5588502549023088\n",
      "Theta: [-0.27626787  0.18039552  0.0799104 ]\n",
      "Loss in iteration 482: 0.5587654310072068\n",
      "Theta: [-0.27680028  0.18070898  0.0799021 ]\n",
      "Loss in iteration 483: 0.5586806731562516\n",
      "Theta: [-0.27733248  0.18102231  0.07989381]\n",
      "Loss in iteration 484: 0.5585959812910546\n",
      "Theta: [-0.27786447  0.18133552  0.07988552]\n",
      "Loss in iteration 485: 0.5585113553532746\n",
      "Theta: [-0.27839626  0.18164861  0.07987724]\n",
      "Loss in iteration 486: 0.5584267952846166\n",
      "Theta: [-0.27892785  0.18196157  0.07986896]\n",
      "Loss in iteration 487: 0.5583423010268316\n",
      "Theta: [-0.27945923  0.1822744   0.07986069]\n",
      "Loss in iteration 488: 0.5582578725217175\n",
      "Theta: [-0.2799904   0.18258711  0.07985243]\n",
      "Loss in iteration 489: 0.5581735097111181\n",
      "Theta: [-0.28052137  0.1828997   0.07984418]\n",
      "Loss in iteration 490: 0.5580892125369245\n",
      "Theta: [-0.28105213  0.18321216  0.07983593]\n",
      "Loss in iteration 491: 0.5580049809410731\n",
      "Theta: [-0.28158269  0.1835245   0.07982768]\n",
      "Loss in iteration 492: 0.5579208148655471\n",
      "Theta: [-0.28211305  0.18383671  0.07981945]\n",
      "Loss in iteration 493: 0.5578367142523764\n",
      "Theta: [-0.2826432   0.1841488   0.07981122]\n",
      "Loss in iteration 494: 0.5577526790436369\n",
      "Theta: [-0.28317314  0.18446076  0.079803  ]\n",
      "Loss in iteration 495: 0.557668709181451\n",
      "Theta: [-0.28370289  0.1847726   0.07979478]\n",
      "Loss in iteration 496: 0.5575848046079872\n",
      "Theta: [-0.28423242  0.18508432  0.07978657]\n",
      "Loss in iteration 497: 0.5575009652654607\n",
      "Theta: [-0.28476176  0.18539591  0.07977836]\n",
      "Loss in iteration 498: 0.557417191096133\n",
      "Theta: [-0.28529088  0.18570738  0.07977017]\n",
      "Loss in iteration 499: 0.5573334820423117\n",
      "Theta: [-0.28581981  0.18601873  0.07976197]\n",
      "Loss in iteration 500: 0.557249838046351\n",
      "Theta: [-0.28634853  0.18632995  0.07975379]\n",
      "Loss in iteration 501: 0.5571662590506511\n",
      "Theta: [-0.28687705  0.18664104  0.07974561]\n",
      "Loss in iteration 502: 0.5570827449976584\n",
      "Theta: [-0.28740536  0.18695202  0.07973744]\n",
      "Loss in iteration 503: 0.5569992958298666\n",
      "Theta: [-0.28793347  0.18726287  0.07972927]\n",
      "Loss in iteration 504: 0.5569159114898142\n",
      "Theta: [-0.28846138  0.18757359  0.07972111]\n",
      "Loss in iteration 505: 0.5568325919200873\n",
      "Theta: [-0.28898908  0.1878842   0.07971296]\n",
      "Loss in iteration 506: 0.5567493370633175\n",
      "Theta: [-0.28951658  0.18819468  0.07970481]\n",
      "Loss in iteration 507: 0.5566661468621827\n",
      "Theta: [-0.29004387  0.18850503  0.07969667]\n",
      "Loss in iteration 508: 0.5565830212594076\n",
      "Theta: [-0.29057097  0.18881527  0.07968854]\n",
      "Loss in iteration 509: 0.5564999601977627\n",
      "Theta: [-0.29109786  0.18912538  0.07968041]\n",
      "Loss in iteration 510: 0.5564169636200649\n",
      "Theta: [-0.29162454  0.18943536  0.07967228]\n",
      "Loss in iteration 511: 0.556334031469177\n",
      "Theta: [-0.29215103  0.18974523  0.07966417]\n",
      "Loss in iteration 512: 0.5562511636880086\n",
      "Theta: [-0.29267731  0.19005497  0.07965606]\n",
      "Loss in iteration 513: 0.5561683602195151\n",
      "Theta: [-0.29320339  0.19036459  0.07964796]\n",
      "Loss in iteration 514: 0.5560856210066983\n",
      "Theta: [-0.29372926  0.19067408  0.07963986]\n",
      "Loss in iteration 515: 0.5560029459926061\n",
      "Theta: [-0.29425494  0.19098346  0.07963177]\n",
      "Loss in iteration 516: 0.5559203351203327\n",
      "Theta: [-0.29478041  0.19129271  0.07962368]\n",
      "Loss in iteration 517: 0.5558377883330183\n",
      "Theta: [-0.29530568  0.19160184  0.07961561]\n",
      "Loss in iteration 518: 0.5557553055738494\n",
      "Theta: [-0.29583074  0.19191084  0.07960753]\n",
      "Loss in iteration 519: 0.5556728867860588\n",
      "Theta: [-0.29635561  0.19221972  0.07959947]\n",
      "Loss in iteration 520: 0.555590531912925\n",
      "Theta: [-0.29688027  0.19252849  0.07959141]\n",
      "Loss in iteration 521: 0.555508240897773\n",
      "Theta: [-0.29740473  0.19283712  0.07958335]\n",
      "Loss in iteration 522: 0.5554260136839742\n",
      "Theta: [-0.29792899  0.19314564  0.07957531]\n",
      "Loss in iteration 523: 0.5553438502149454\n",
      "Theta: [-0.29845305  0.19345403  0.07956727]\n",
      "Loss in iteration 524: 0.55526175043415\n",
      "Theta: [-0.2989769   0.19376231  0.07955923]\n",
      "Loss in iteration 525: 0.5551797142850978\n",
      "Theta: [-0.29950056  0.19407046  0.0795512 ]\n",
      "Loss in iteration 526: 0.5550977417113439\n",
      "Theta: [-0.30002401  0.19437849  0.07954318]\n",
      "Loss in iteration 527: 0.5550158326564899\n",
      "Theta: [-0.30054726  0.19468639  0.07953516]\n",
      "Loss in iteration 528: 0.5549339870641837\n",
      "Theta: [-0.30107031  0.19499418  0.07952715]\n",
      "Loss in iteration 529: 0.5548522048781188\n",
      "Theta: [-0.30159316  0.19530184  0.07951915]\n",
      "Loss in iteration 530: 0.5547704860420353\n",
      "Theta: [-0.3021158   0.19560938  0.07951115]\n",
      "Loss in iteration 531: 0.5546888304997186\n",
      "Theta: [-0.30263825  0.1959168   0.07950316]\n",
      "Loss in iteration 532: 0.5546072381950009\n",
      "Theta: [-0.3031605   0.1962241   0.07949517]\n",
      "Loss in iteration 533: 0.5545257090717599\n",
      "Theta: [-0.30368254  0.19653128  0.07948719]\n",
      "Loss in iteration 534: 0.5544442430739196\n",
      "Theta: [-0.30420438  0.19683833  0.07947922]\n",
      "Loss in iteration 535: 0.5543628401454499\n",
      "Theta: [-0.30472603  0.19714527  0.07947125]\n",
      "Loss in iteration 536: 0.5542815002303666\n",
      "Theta: [-0.30524747  0.19745208  0.07946329]\n",
      "Loss in iteration 537: 0.5542002232727316\n",
      "Theta: [-0.30576871  0.19775877  0.07945533]\n",
      "Loss in iteration 538: 0.5541190092166526\n",
      "Theta: [-0.30628976  0.19806534  0.07944738]\n",
      "Loss in iteration 539: 0.5540378580062836\n",
      "Theta: [-0.3068106   0.19837179  0.07943944]\n",
      "Loss in iteration 540: 0.5539567695858242\n",
      "Theta: [-0.30733124  0.19867812  0.0794315 ]\n",
      "Loss in iteration 541: 0.5538757438995199\n",
      "Theta: [-0.30785168  0.19898433  0.07942357]\n",
      "Loss in iteration 542: 0.5537947808916627\n",
      "Theta: [-0.30837192  0.19929042  0.07941564]\n",
      "Loss in iteration 543: 0.5537138805065898\n",
      "Theta: [-0.30889196  0.19959639  0.07940772]\n",
      "Loss in iteration 544: 0.5536330426886843\n",
      "Theta: [-0.30941181  0.19990223  0.07939981]\n",
      "Loss in iteration 545: 0.5535522673823758\n",
      "Theta: [-0.30993145  0.20020796  0.0793919 ]\n",
      "Loss in iteration 546: 0.5534715545321396\n",
      "Theta: [-0.31045089  0.20051356  0.079384  ]\n",
      "Loss in iteration 547: 0.5533909040824964\n",
      "Theta: [-0.31097014  0.20081905  0.07937611]\n",
      "Loss in iteration 548: 0.5533103159780132\n",
      "Theta: [-0.31148918  0.20112441  0.07936822]\n",
      "Loss in iteration 549: 0.5532297901633024\n",
      "Theta: [-0.31200802  0.20142966  0.07936033]\n",
      "Loss in iteration 550: 0.5531493265830228\n",
      "Theta: [-0.31252667  0.20173478  0.07935246]\n",
      "Loss in iteration 551: 0.5530689251818789\n",
      "Theta: [-0.31304512  0.20203979  0.07934458]\n",
      "Loss in iteration 552: 0.5529885859046201\n",
      "Theta: [-0.31356336  0.20234467  0.07933672]\n",
      "Loss in iteration 553: 0.552908308696043\n",
      "Theta: [-0.31408141  0.20264943  0.07932886]\n",
      "Loss in iteration 554: 0.552828093500989\n",
      "Theta: [-0.31459926  0.20295408  0.07932101]\n",
      "Loss in iteration 555: 0.5527479402643458\n",
      "Theta: [-0.31511691  0.2032586   0.07931316]\n",
      "Loss in iteration 556: 0.5526678489310463\n",
      "Theta: [-0.31563437  0.20356301  0.07930532]\n",
      "Loss in iteration 557: 0.5525878194460692\n",
      "Theta: [-0.31615162  0.20386729  0.07929748]\n",
      "Loss in iteration 558: 0.5525078517544395\n",
      "Theta: [-0.31666868  0.20417146  0.07928965]\n",
      "Loss in iteration 559: 0.5524279458012277\n",
      "Theta: [-0.31718553  0.2044755   0.07928183]\n",
      "Loss in iteration 560: 0.5523481015315493\n",
      "Theta: [-0.31770219  0.20477943  0.07927401]\n",
      "Loss in iteration 561: 0.5522683188905666\n",
      "Theta: [-0.31821865  0.20508323  0.0792662 ]\n",
      "Loss in iteration 562: 0.5521885978234868\n",
      "Theta: [-0.31873492  0.20538692  0.07925839]\n",
      "Loss in iteration 563: 0.552108938275563\n",
      "Theta: [-0.31925098  0.20569049  0.07925059]\n",
      "Loss in iteration 564: 0.5520293401920936\n",
      "Theta: [-0.31976685  0.20599394  0.07924279]\n",
      "Loss in iteration 565: 0.5519498035184233\n",
      "Theta: [-0.32028252  0.20629727  0.07923501]\n",
      "Loss in iteration 566: 0.5518703281999418\n",
      "Theta: [-0.32079799  0.20660048  0.07922722]\n",
      "Loss in iteration 567: 0.5517909141820847\n",
      "Theta: [-0.32131326  0.20690357  0.07921944]\n",
      "Loss in iteration 568: 0.5517115614103333\n",
      "Theta: [-0.32182834  0.20720654  0.07921167]\n",
      "Loss in iteration 569: 0.5516322698302143\n",
      "Theta: [-0.32234322  0.2075094   0.07920391]\n",
      "Loss in iteration 570: 0.5515530393872997\n",
      "Theta: [-0.3228579   0.20781213  0.07919615]\n",
      "Loss in iteration 571: 0.5514738700272075\n",
      "Theta: [-0.32337238  0.20811475  0.07918839]\n",
      "Loss in iteration 572: 0.5513947616956011\n",
      "Theta: [-0.32388667  0.20841724  0.07918065]\n",
      "Loss in iteration 573: 0.5513157143381893\n",
      "Theta: [-0.32440076  0.20871962  0.0791729 ]\n",
      "Loss in iteration 574: 0.5512367279007262\n",
      "Theta: [-0.32491465  0.20902188  0.07916517]\n",
      "Loss in iteration 575: 0.551157802329012\n",
      "Theta: [-0.32542835  0.20932403  0.07915744]\n",
      "Loss in iteration 576: 0.5510789375688919\n",
      "Theta: [-0.32594185  0.20962605  0.07914971]\n",
      "Loss in iteration 577: 0.5510001335662565\n",
      "Theta: [-0.32645515  0.20992795  0.07914199]\n",
      "Loss in iteration 578: 0.5509213902670428\n",
      "Theta: [-0.32696826  0.21022974  0.07913428]\n",
      "Loss in iteration 579: 0.5508427076172314\n",
      "Theta: [-0.32748117  0.21053141  0.07912657]\n",
      "Loss in iteration 580: 0.55076408556285\n",
      "Theta: [-0.32799388  0.21083296  0.07911887]\n",
      "Loss in iteration 581: 0.5506855240499708\n",
      "Theta: [-0.3285064   0.21113439  0.07911117]\n",
      "Loss in iteration 582: 0.5506070230247117\n",
      "Theta: [-0.32901872  0.21143571  0.07910348]\n",
      "Loss in iteration 583: 0.550528582433236\n",
      "Theta: [-0.32953085  0.21173691  0.0790958 ]\n",
      "Loss in iteration 584: 0.5504502022217523\n",
      "Theta: [-0.33004277  0.21203798  0.07908812]\n",
      "Loss in iteration 585: 0.5503718823365145\n",
      "Theta: [-0.33055451  0.21233895  0.07908045]\n",
      "Loss in iteration 586: 0.5502936227238218\n",
      "Theta: [-0.33106604  0.21263979  0.07907278]\n",
      "Loss in iteration 587: 0.5502154233300186\n",
      "Theta: [-0.33157739  0.21294052  0.07906512]\n",
      "Loss in iteration 588: 0.5501372841014951\n",
      "Theta: [-0.33208853  0.21324112  0.07905746]\n",
      "Loss in iteration 589: 0.5500592049846861\n",
      "Theta: [-0.33259948  0.21354161  0.07904981]\n",
      "Loss in iteration 590: 0.5499811859260721\n",
      "Theta: [-0.33311024  0.21384199  0.07904216]\n",
      "Loss in iteration 591: 0.5499032268721787\n",
      "Theta: [-0.3336208   0.21414224  0.07903453]\n",
      "Loss in iteration 592: 0.5498253277695766\n",
      "Theta: [-0.33413116  0.21444238  0.07902689]\n",
      "Loss in iteration 593: 0.5497474885648821\n",
      "Theta: [-0.33464133  0.2147424   0.07901926]\n",
      "Loss in iteration 594: 0.5496697092047566\n",
      "Theta: [-0.3351513   0.21504231  0.07901164]\n",
      "Loss in iteration 595: 0.549591989635906\n",
      "Theta: [-0.33566108  0.2153421   0.07900402]\n",
      "Loss in iteration 596: 0.5495143298050824\n",
      "Theta: [-0.33617067  0.21564177  0.07899641]\n",
      "Loss in iteration 597: 0.5494367296590822\n",
      "Theta: [-0.33668006  0.21594132  0.07898881]\n",
      "Loss in iteration 598: 0.5493591891447477\n",
      "Theta: [-0.33718925  0.21624076  0.07898121]\n",
      "Loss in iteration 599: 0.5492817082089656\n",
      "Theta: [-0.33769825  0.21654008  0.07897361]\n",
      "Loss in iteration 600: 0.5492042867986681\n",
      "Theta: [-0.33820706  0.21683928  0.07896603]\n",
      "Loss in iteration 601: 0.5491269248608323\n",
      "Theta: [-0.33871567  0.21713837  0.07895844]\n",
      "Loss in iteration 602: 0.5490496223424806\n",
      "Theta: [-0.33922409  0.21743734  0.07895087]\n",
      "Loss in iteration 603: 0.5489723791906802\n",
      "Theta: [-0.33973231  0.21773619  0.07894329]\n",
      "Loss in iteration 604: 0.5488951953525437\n",
      "Theta: [-0.34024034  0.21803493  0.07893573]\n",
      "Loss in iteration 605: 0.5488180707752283\n",
      "Theta: [-0.34074817  0.21833355  0.07892817]\n",
      "Loss in iteration 606: 0.5487410054059361\n",
      "Theta: [-0.34125581  0.21863205  0.07892061]\n",
      "Loss in iteration 607: 0.5486639991919146\n",
      "Theta: [-0.34176326  0.21893044  0.07891306]\n",
      "Loss in iteration 608: 0.5485870520804564\n",
      "Theta: [-0.34227051  0.21922871  0.07890552]\n",
      "Loss in iteration 609: 0.5485101640188984\n",
      "Theta: [-0.34277757  0.21952687  0.07889798]\n",
      "Loss in iteration 610: 0.5484333349546229\n",
      "Theta: [-0.34328444  0.21982491  0.07889045]\n",
      "Loss in iteration 611: 0.5483565648350572\n",
      "Theta: [-0.34379111  0.22012283  0.07888292]\n",
      "Loss in iteration 612: 0.548279853607673\n",
      "Theta: [-0.34429759  0.22042064  0.0788754 ]\n",
      "Loss in iteration 613: 0.5482032012199872\n",
      "Theta: [-0.34480387  0.22071833  0.07886788]\n",
      "Loss in iteration 614: 0.5481266076195621\n",
      "Theta: [-0.34530996  0.22101591  0.07886037]\n",
      "Loss in iteration 615: 0.5480500727540036\n",
      "Theta: [-0.34581586  0.22131337  0.07885286]\n",
      "Loss in iteration 616: 0.5479735965709633\n",
      "Theta: [-0.34632157  0.22161072  0.07884536]\n",
      "Loss in iteration 617: 0.5478971790181378\n",
      "Theta: [-0.34682708  0.22190795  0.07883787]\n",
      "Loss in iteration 618: 0.5478208200432676\n",
      "Theta: [-0.3473324   0.22220506  0.07883038]\n",
      "Loss in iteration 619: 0.547744519594139\n",
      "Theta: [-0.34783753  0.22250206  0.0788229 ]\n",
      "Loss in iteration 620: 0.547668277618582\n",
      "Theta: [-0.34834246  0.22279894  0.07881542]\n",
      "Loss in iteration 621: 0.5475920940644723\n",
      "Theta: [-0.34884721  0.22309571  0.07880795]\n",
      "Loss in iteration 622: 0.5475159688797298\n",
      "Theta: [-0.34935175  0.22339236  0.07880048]\n",
      "Loss in iteration 623: 0.5474399020123191\n",
      "Theta: [-0.34985611  0.2236889   0.07879302]\n",
      "Loss in iteration 624: 0.5473638934102498\n",
      "Theta: [-0.35036028  0.22398532  0.07878556]\n",
      "Loss in iteration 625: 0.5472879430215758\n",
      "Theta: [-0.35086425  0.22428163  0.07877811]\n",
      "Loss in iteration 626: 0.5472120507943962\n",
      "Theta: [-0.35136803  0.22457782  0.07877067]\n",
      "Loss in iteration 627: 0.5471362166768537\n",
      "Theta: [-0.35187162  0.2248739   0.07876323]\n",
      "Loss in iteration 628: 0.5470604406171367\n",
      "Theta: [-0.35237502  0.22516986  0.07875579]\n",
      "Loss in iteration 629: 0.5469847225634777\n",
      "Theta: [-0.35287822  0.22546571  0.07874836]\n",
      "Loss in iteration 630: 0.5469090624641537\n",
      "Theta: [-0.35338123  0.22576145  0.07874094]\n",
      "Loss in iteration 631: 0.5468334602674865\n",
      "Theta: [-0.35388405  0.22605706  0.07873352]\n",
      "Loss in iteration 632: 0.5467579159218422\n",
      "Theta: [-0.35438668  0.22635257  0.07872611]\n",
      "Loss in iteration 633: 0.5466824293756318\n",
      "Theta: [-0.35488912  0.22664796  0.0787187 ]\n",
      "Loss in iteration 634: 0.54660700057731\n",
      "Theta: [-0.35539137  0.22694323  0.0787113 ]\n",
      "Loss in iteration 635: 0.5465316294753769\n",
      "Theta: [-0.35589343  0.2272384   0.0787039 ]\n",
      "Loss in iteration 636: 0.546456316018377\n",
      "Theta: [-0.35639529  0.22753344  0.07869651]\n",
      "Loss in iteration 637: 0.5463810601548982\n",
      "Theta: [-0.35689696  0.22782838  0.07868912]\n",
      "Loss in iteration 638: 0.546305861833574\n",
      "Theta: [-0.35739845  0.22812319  0.07868174]\n",
      "Loss in iteration 639: 0.5462307210030817\n",
      "Theta: [-0.35789974  0.2284179   0.07867437]\n",
      "Loss in iteration 640: 0.5461556376121431\n",
      "Theta: [-0.35840084  0.22871249  0.078667  ]\n",
      "Loss in iteration 641: 0.5460806116095245\n",
      "Theta: [-0.35890175  0.22900697  0.07865963]\n",
      "Loss in iteration 642: 0.5460056429440364\n",
      "Theta: [-0.35940247  0.22930133  0.07865227]\n",
      "Loss in iteration 643: 0.5459307315645338\n",
      "Theta: [-0.359903    0.22959558  0.07864492]\n",
      "Loss in iteration 644: 0.5458558774199157\n",
      "Theta: [-0.36040333  0.22988971  0.07863757]\n",
      "Loss in iteration 645: 0.5457810804591255\n",
      "Theta: [-0.36090348  0.23018373  0.07863022]\n",
      "Loss in iteration 646: 0.5457063406311512\n",
      "Theta: [-0.36140344  0.23047764  0.07862288]\n",
      "Loss in iteration 647: 0.5456316578850245\n",
      "Theta: [-0.36190321  0.23077144  0.07861555]\n",
      "Loss in iteration 648: 0.5455570321698222\n",
      "Theta: [-0.36240279  0.23106512  0.07860822]\n",
      "Loss in iteration 649: 0.5454824634346639\n",
      "Theta: [-0.36290217  0.23135869  0.0786009 ]\n",
      "Loss in iteration 650: 0.545407951628715\n",
      "Theta: [-0.36340137  0.23165214  0.07859358]\n",
      "Loss in iteration 651: 0.5453334967011838\n",
      "Theta: [-0.36390038  0.23194548  0.07858627]\n",
      "Loss in iteration 652: 0.5452590986013232\n",
      "Theta: [-0.3643992   0.23223871  0.07857896]\n",
      "Loss in iteration 653: 0.5451847572784306\n",
      "Theta: [-0.36489782  0.23253183  0.07857166]\n",
      "Loss in iteration 654: 0.545110472681847\n",
      "Theta: [-0.36539626  0.23282483  0.07856437]\n",
      "Loss in iteration 655: 0.5450362447609577\n",
      "Theta: [-0.36589451  0.23311772  0.07855707]\n",
      "Loss in iteration 656: 0.5449620734651921\n",
      "Theta: [-0.36639257  0.23341049  0.07854979]\n",
      "Loss in iteration 657: 0.5448879587440235\n",
      "Theta: [-0.36689044  0.23370315  0.07854251]\n",
      "Loss in iteration 658: 0.5448139005469694\n",
      "Theta: [-0.36738812  0.23399571  0.07853523]\n",
      "Loss in iteration 659: 0.5447398988235911\n",
      "Theta: [-0.36788562  0.23428814  0.07852796]\n",
      "Loss in iteration 660: 0.5446659535234941\n",
      "Theta: [-0.36838292  0.23458047  0.0785207 ]\n",
      "Loss in iteration 661: 0.5445920645963279\n",
      "Theta: [-0.36888003  0.23487268  0.07851344]\n",
      "Loss in iteration 662: 0.5445182319917858\n",
      "Theta: [-0.36937696  0.23516478  0.07850618]\n",
      "Loss in iteration 663: 0.5444444556596048\n",
      "Theta: [-0.3698737   0.23545677  0.07849893]\n",
      "Loss in iteration 664: 0.5443707355495666\n",
      "Theta: [-0.37037024  0.23574864  0.07849169]\n",
      "Loss in iteration 665: 0.5442970716114959\n",
      "Theta: [-0.3708666   0.2360404   0.07848445]\n",
      "Loss in iteration 666: 0.5442234637952617\n",
      "Theta: [-0.37136278  0.23633206  0.07847721]\n",
      "Loss in iteration 667: 0.5441499120507765\n",
      "Theta: [-0.37185876  0.23662359  0.07846998]\n",
      "Loss in iteration 668: 0.5440764163279972\n",
      "Theta: [-0.37235455  0.23691502  0.07846276]\n",
      "Loss in iteration 669: 0.5440029765769243\n",
      "Theta: [-0.37285016  0.23720633  0.07845554]\n",
      "Loss in iteration 670: 0.5439295927476018\n",
      "Theta: [-0.37334558  0.23749754  0.07844833]\n",
      "Loss in iteration 671: 0.5438562647901175\n",
      "Theta: [-0.37384081  0.23778863  0.07844112]\n",
      "Loss in iteration 672: 0.5437829926546035\n",
      "Theta: [-0.37433585  0.2380796   0.07843391]\n",
      "Loss in iteration 673: 0.543709776291235\n",
      "Theta: [-0.37483071  0.23837047  0.07842672]\n",
      "Loss in iteration 674: 0.5436366156502309\n",
      "Theta: [-0.37532537  0.23866123  0.07841952]\n",
      "Loss in iteration 675: 0.543563510681854\n",
      "Theta: [-0.37581985  0.23895187  0.07841233]\n",
      "Loss in iteration 676: 0.5434904613364111\n",
      "Theta: [-0.37631414  0.2392424   0.07840515]\n",
      "Loss in iteration 677: 0.5434174675642519\n",
      "Theta: [-0.37680825  0.23953282  0.07839797]\n",
      "Loss in iteration 678: 0.5433445293157704\n",
      "Theta: [-0.37730217  0.23982313  0.0783908 ]\n",
      "Loss in iteration 679: 0.5432716465414036\n",
      "Theta: [-0.37779589  0.24011333  0.07838363]\n",
      "Loss in iteration 680: 0.5431988191916323\n",
      "Theta: [-0.37828944  0.24040341  0.07837647]\n",
      "Loss in iteration 681: 0.5431260472169811\n",
      "Theta: [-0.37878279  0.24069339  0.07836931]\n",
      "Loss in iteration 682: 0.5430533305680177\n",
      "Theta: [-0.37927596  0.24098325  0.07836216]\n",
      "Loss in iteration 683: 0.5429806691953539\n",
      "Theta: [-0.37976894  0.241273    0.07835501]\n",
      "Loss in iteration 684: 0.5429080630496442\n",
      "Theta: [-0.38026174  0.24156265  0.07834787]\n",
      "Loss in iteration 685: 0.5428355120815873\n",
      "Theta: [-0.38075435  0.24185218  0.07834073]\n",
      "Loss in iteration 686: 0.5427630162419245\n",
      "Theta: [-0.38124677  0.2421416   0.0783336 ]\n",
      "Loss in iteration 687: 0.5426905754814414\n",
      "Theta: [-0.381739    0.2424309   0.07832647]\n",
      "Loss in iteration 688: 0.5426181897509667\n",
      "Theta: [-0.38223105  0.2427201   0.07831935]\n",
      "Loss in iteration 689: 0.5425458590013722\n",
      "Theta: [-0.38272291  0.24300919  0.07831223]\n",
      "Loss in iteration 690: 0.5424735831835733\n",
      "Theta: [-0.38321459  0.24329817  0.07830512]\n",
      "Loss in iteration 691: 0.5424013622485288\n",
      "Theta: [-0.38370608  0.24358703  0.07829801]\n",
      "Loss in iteration 692: 0.5423291961472403\n",
      "Theta: [-0.38419738  0.24387579  0.0782909 ]\n",
      "Loss in iteration 693: 0.5422570848307534\n",
      "Theta: [-0.3846885   0.24416443  0.07828381]\n",
      "Loss in iteration 694: 0.5421850282501568\n",
      "Theta: [-0.38517943  0.24445297  0.07827671]\n",
      "Loss in iteration 695: 0.5421130263565818\n",
      "Theta: [-0.38567017  0.24474139  0.07826963]\n",
      "Loss in iteration 696: 0.5420410791012036\n",
      "Theta: [-0.38616073  0.2450297   0.07826254]\n",
      "Loss in iteration 697: 0.5419691864352405\n",
      "Theta: [-0.38665111  0.24531791  0.07825546]\n",
      "Loss in iteration 698: 0.5418973483099537\n",
      "Theta: [-0.3871413   0.245606    0.07824839]\n",
      "Loss in iteration 699: 0.5418255646766478\n",
      "Theta: [-0.3876313   0.24589398  0.07824132]\n",
      "Loss in iteration 700: 0.5417538354866707\n",
      "Theta: [-0.38812112  0.24618186  0.07823426]\n",
      "Loss in iteration 701: 0.5416821606914126\n",
      "Theta: [-0.38861075  0.24646962  0.0782272 ]\n",
      "Loss in iteration 702: 0.5416105402423076\n",
      "Theta: [-0.3891002   0.24675728  0.07822015]\n",
      "Loss in iteration 703: 0.5415389740908328\n",
      "Theta: [-0.38958946  0.24704482  0.0782131 ]\n",
      "Loss in iteration 704: 0.5414674621885078\n",
      "Theta: [-0.39007854  0.24733225  0.07820606]\n",
      "Loss in iteration 705: 0.5413960044868958\n",
      "Theta: [-0.39056743  0.24761958  0.07819902]\n",
      "Loss in iteration 706: 0.5413246009376027\n",
      "Theta: [-0.39105614  0.24790679  0.07819198]\n",
      "Loss in iteration 707: 0.5412532514922773\n",
      "Theta: [-0.39154466  0.2481939   0.07818495]\n",
      "Loss in iteration 708: 0.5411819561026115\n",
      "Theta: [-0.392033    0.24848089  0.07817793]\n",
      "Loss in iteration 709: 0.5411107147203402\n",
      "Theta: [-0.39252115  0.24876778  0.07817091]\n",
      "Loss in iteration 710: 0.541039527297241\n",
      "Theta: [-0.39300912  0.24905456  0.0781639 ]\n",
      "Loss in iteration 711: 0.5409683937851345\n",
      "Theta: [-0.39349691  0.24934123  0.07815689]\n",
      "Loss in iteration 712: 0.540897314135884\n",
      "Theta: [-0.39398451  0.24962778  0.07814988]\n",
      "Loss in iteration 713: 0.540826288301396\n",
      "Theta: [-0.39447192  0.24991423  0.07814288]\n",
      "Loss in iteration 714: 0.5407553162336195\n",
      "Theta: [-0.39495915  0.25020057  0.07813589]\n",
      "Loss in iteration 715: 0.540684397884546\n",
      "Theta: [-0.3954462   0.25048681  0.0781289 ]\n",
      "Loss in iteration 716: 0.5406135332062106\n",
      "Theta: [-0.39593307  0.25077293  0.07812191]\n",
      "Loss in iteration 717: 0.5405427221506904\n",
      "Theta: [-0.39641975  0.25105894  0.07811493]\n",
      "Loss in iteration 718: 0.5404719646701056\n",
      "Theta: [-0.39690624  0.25134485  0.07810796]\n",
      "Loss in iteration 719: 0.5404012607166188\n",
      "Theta: [-0.39739256  0.25163064  0.07810098]\n",
      "Loss in iteration 720: 0.5403306102424356\n",
      "Theta: [-0.39787868  0.25191633  0.07809402]\n",
      "Loss in iteration 721: 0.5402600131998041\n",
      "Theta: [-0.39836463  0.25220191  0.07808706]\n",
      "Loss in iteration 722: 0.5401894695410148\n",
      "Theta: [-0.39885039  0.25248738  0.0780801 ]\n",
      "Loss in iteration 723: 0.5401189792184011\n",
      "Theta: [-0.39933597  0.25277274  0.07807315]\n",
      "Loss in iteration 724: 0.540048542184339\n",
      "Theta: [-0.39982137  0.25305799  0.0780662 ]\n",
      "Loss in iteration 725: 0.5399781583912469\n",
      "Theta: [-0.40030658  0.25334314  0.07805926]\n",
      "Loss in iteration 726: 0.5399078277915854\n",
      "Theta: [-0.40079161  0.25362817  0.07805232]\n",
      "Loss in iteration 727: 0.5398375503378585\n",
      "Theta: [-0.40127646  0.2539131   0.07804539]\n",
      "Loss in iteration 728: 0.5397673259826119\n",
      "Theta: [-0.40176112  0.25419792  0.07803846]\n",
      "Loss in iteration 729: 0.5396971546784338\n",
      "Theta: [-0.4022456   0.25448263  0.07803154]\n",
      "Loss in iteration 730: 0.5396270363779554\n",
      "Theta: [-0.4027299   0.25476724  0.07802462]\n",
      "Loss in iteration 731: 0.5395569710338499\n",
      "Theta: [-0.40321401  0.25505173  0.0780177 ]\n",
      "Loss in iteration 732: 0.5394869585988327\n",
      "Theta: [-0.40369795  0.25533612  0.0780108 ]\n",
      "Loss in iteration 733: 0.5394169990256619\n",
      "Theta: [-0.4041817   0.2556204   0.07800389]\n",
      "Loss in iteration 734: 0.539347092267138\n",
      "Theta: [-0.40466527  0.25590457  0.07799699]\n",
      "Loss in iteration 735: 0.5392772382761032\n",
      "Theta: [-0.40514865  0.25618864  0.0779901 ]\n",
      "Loss in iteration 736: 0.5392074370054429\n",
      "Theta: [-0.40563186  0.25647259  0.07798321]\n",
      "Loss in iteration 737: 0.5391376884080841\n",
      "Theta: [-0.40611488  0.25675644  0.07797632]\n",
      "Loss in iteration 738: 0.5390679924369962\n",
      "Theta: [-0.40659772  0.25704018  0.07796944]\n",
      "Loss in iteration 739: 0.538998349045191\n",
      "Theta: [-0.40708038  0.25732382  0.07796256]\n",
      "Loss in iteration 740: 0.5389287581857223\n",
      "Theta: [-0.40756285  0.25760735  0.07795569]\n",
      "Loss in iteration 741: 0.5388592198116859\n",
      "Theta: [-0.40804515  0.25789077  0.07794883]\n",
      "Loss in iteration 742: 0.5387897338762202\n",
      "Theta: [-0.40852726  0.25817408  0.07794196]\n",
      "Loss in iteration 743: 0.5387203003325056\n",
      "Theta: [-0.40900919  0.25845728  0.07793511]\n",
      "Loss in iteration 744: 0.5386509191337641\n",
      "Theta: [-0.40949094  0.25874038  0.07792825]\n",
      "Loss in iteration 745: 0.5385815902332605\n",
      "Theta: [-0.40997251  0.25902337  0.0779214 ]\n",
      "Loss in iteration 746: 0.5385123135843011\n",
      "Theta: [-0.4104539   0.25930625  0.07791456]\n",
      "Loss in iteration 747: 0.5384430891402343\n",
      "Theta: [-0.4109351   0.25958903  0.07790772]\n",
      "Loss in iteration 748: 0.5383739168544509\n",
      "Theta: [-0.41141613  0.2598717   0.07790089]\n",
      "Loss in iteration 749: 0.5383047966803832\n",
      "Theta: [-0.41189697  0.26015426  0.07789406]\n",
      "Loss in iteration 750: 0.5382357285715059\n",
      "Theta: [-0.41237764  0.26043672  0.07788723]\n",
      "Loss in iteration 751: 0.538166712481335\n",
      "Theta: [-0.41285812  0.26071907  0.07788041]\n",
      "Loss in iteration 752: 0.5380977483634289\n",
      "Theta: [-0.41333842  0.26100131  0.0778736 ]\n",
      "Loss in iteration 753: 0.538028836171388\n",
      "Theta: [-0.41381854  0.26128345  0.07786678]\n",
      "Loss in iteration 754: 0.5379599758588537\n",
      "Theta: [-0.41429848  0.26156548  0.07785998]\n",
      "Loss in iteration 755: 0.5378911673795103\n",
      "Theta: [-0.41477824  0.2618474   0.07785317]\n",
      "Loss in iteration 756: 0.5378224106870833\n",
      "Theta: [-0.41525782  0.26212922  0.07784638]\n",
      "Loss in iteration 757: 0.53775370573534\n",
      "Theta: [-0.41573722  0.26241093  0.07783958]\n",
      "Loss in iteration 758: 0.5376850524780895\n",
      "Theta: [-0.41621644  0.26269253  0.0778328 ]\n",
      "Loss in iteration 759: 0.5376164508691827\n",
      "Theta: [-0.41669548  0.26297403  0.07782601]\n",
      "Loss in iteration 760: 0.5375479008625124\n",
      "Theta: [-0.41717433  0.26325542  0.07781923]\n",
      "Loss in iteration 761: 0.5374794024120123\n",
      "Theta: [-0.41765301  0.26353671  0.07781246]\n",
      "Loss in iteration 762: 0.5374109554716588\n",
      "Theta: [-0.41813151  0.26381789  0.07780569]\n",
      "Loss in iteration 763: 0.5373425599954691\n",
      "Theta: [-0.41860983  0.26409896  0.07779892]\n",
      "Loss in iteration 764: 0.5372742159375026\n",
      "Theta: [-0.41908797  0.26437993  0.07779216]\n",
      "Loss in iteration 765: 0.5372059232518596\n",
      "Theta: [-0.41956593  0.26466079  0.0777854 ]\n",
      "Loss in iteration 766: 0.5371376818926827\n",
      "Theta: [-0.42004371  0.26494155  0.07777865]\n",
      "Loss in iteration 767: 0.5370694918141554\n",
      "Theta: [-0.42052131  0.2652222   0.0777719 ]\n",
      "Loss in iteration 768: 0.5370013529705032\n",
      "Theta: [-0.42099873  0.26550275  0.07776516]\n",
      "Loss in iteration 769: 0.5369332653159925\n",
      "Theta: [-0.42147597  0.26578319  0.07775842]\n",
      "Loss in iteration 770: 0.5368652288049317\n",
      "Theta: [-0.42195304  0.26606352  0.07775169]\n",
      "Loss in iteration 771: 0.5367972433916706\n",
      "Theta: [-0.42242992  0.26634375  0.07774496]\n",
      "Loss in iteration 772: 0.5367293090305996\n",
      "Theta: [-0.42290663  0.26662387  0.07773823]\n",
      "Loss in iteration 773: 0.5366614256761516\n",
      "Theta: [-0.42338315  0.26690389  0.07773151]\n",
      "Loss in iteration 774: 0.5365935932828002\n",
      "Theta: [-0.4238595   0.2671838   0.07772479]\n",
      "Loss in iteration 775: 0.5365258118050604\n",
      "Theta: [-0.42433567  0.26746361  0.07771808]\n",
      "Loss in iteration 776: 0.5364580811974885\n",
      "Theta: [-0.42481166  0.26774331  0.07771137]\n",
      "Loss in iteration 777: 0.5363904014146823\n",
      "Theta: [-0.42528747  0.26802291  0.07770467]\n",
      "Loss in iteration 778: 0.5363227724112805\n",
      "Theta: [-0.4257631   0.2683024   0.07769797]\n",
      "Loss in iteration 779: 0.536255194141963\n",
      "Theta: [-0.42623856  0.26858179  0.07769128]\n",
      "Loss in iteration 780: 0.5361876665614514\n",
      "Theta: [-0.42671383  0.26886107  0.07768459]\n",
      "Loss in iteration 781: 0.536120189624508\n",
      "Theta: [-0.42718893  0.26914025  0.0776779 ]\n",
      "Loss in iteration 782: 0.5360527632859363\n",
      "Theta: [-0.42766385  0.26941932  0.07767122]\n",
      "Loss in iteration 783: 0.5359853875005811\n",
      "Theta: [-0.4281386   0.26969829  0.07766455]\n",
      "Loss in iteration 784: 0.535918062223328\n",
      "Theta: [-0.42861316  0.26997716  0.07765787]\n",
      "Loss in iteration 785: 0.5358507874091043\n",
      "Theta: [-0.42908755  0.27025591  0.07765121]\n",
      "Loss in iteration 786: 0.5357835630128776\n",
      "Theta: [-0.42956175  0.27053457  0.07764454]\n",
      "Loss in iteration 787: 0.5357163889896567\n",
      "Theta: [-0.43003578  0.27081312  0.07763789]\n",
      "Loss in iteration 788: 0.5356492652944915\n",
      "Theta: [-0.43050964  0.27109157  0.07763123]\n",
      "Loss in iteration 789: 0.535582191882473\n",
      "Theta: [-0.43098331  0.27136991  0.07762458]\n",
      "Loss in iteration 790: 0.5355151687087332\n",
      "Theta: [-0.43145681  0.27164814  0.07761793]\n",
      "Loss in iteration 791: 0.5354481957284443\n",
      "Theta: [-0.43193013  0.27192628  0.07761129]\n",
      "Loss in iteration 792: 0.5353812728968201\n",
      "Theta: [-0.43240328  0.27220431  0.07760466]\n",
      "Loss in iteration 793: 0.5353144001691152\n",
      "Theta: [-0.43287624  0.27248223  0.07759802]\n",
      "Loss in iteration 794: 0.5352475775006248\n",
      "Theta: [-0.43334903  0.27276005  0.0775914 ]\n",
      "Loss in iteration 795: 0.5351808048466848\n",
      "Theta: [-0.43382165  0.27303777  0.07758477]\n",
      "Loss in iteration 796: 0.5351140821626725\n",
      "Theta: [-0.43429408  0.27331538  0.07757815]\n",
      "Loss in iteration 797: 0.5350474094040049\n",
      "Theta: [-0.43476634  0.27359289  0.07757154]\n",
      "Loss in iteration 798: 0.5349807865261408\n",
      "Theta: [-0.43523842  0.2738703   0.07756493]\n",
      "Loss in iteration 799: 0.534914213484579\n",
      "Theta: [-0.43571033  0.2741476   0.07755832]\n",
      "Loss in iteration 800: 0.5348476902348593\n",
      "Theta: [-0.43618206  0.2744248   0.07755172]\n",
      "Loss in iteration 801: 0.5347812167325624\n",
      "Theta: [-0.43665361  0.27470189  0.07754512]\n",
      "Loss in iteration 802: 0.5347147929333087\n",
      "Theta: [-0.43712499  0.27497888  0.07753853]\n",
      "Loss in iteration 803: 0.53464841879276\n",
      "Theta: [-0.43759619  0.27525577  0.07753194]\n",
      "Loss in iteration 804: 0.5345820942666188\n",
      "Theta: [-0.43806721  0.27553255  0.07752535]\n",
      "Loss in iteration 805: 0.5345158193106275\n",
      "Theta: [-0.43853806  0.27580923  0.07751877]\n",
      "Loss in iteration 806: 0.5344495938805691\n",
      "Theta: [-0.43900873  0.27608581  0.07751219]\n",
      "Loss in iteration 807: 0.5343834179322677\n",
      "Theta: [-0.43947922  0.27636229  0.07750562]\n",
      "Loss in iteration 808: 0.5343172914215873\n",
      "Theta: [-0.43994954  0.27663866  0.07749905]\n",
      "Loss in iteration 809: 0.5342512143044327\n",
      "Theta: [-0.44041969  0.27691493  0.07749249]\n",
      "Loss in iteration 810: 0.5341851865367486\n",
      "Theta: [-0.44088966  0.27719109  0.07748593]\n",
      "Loss in iteration 811: 0.5341192080745206\n",
      "Theta: [-0.44135945  0.27746715  0.07747937]\n",
      "Loss in iteration 812: 0.5340532788737745\n",
      "Theta: [-0.44182907  0.27774311  0.07747282]\n",
      "Loss in iteration 813: 0.5339873988905763\n",
      "Theta: [-0.44229851  0.27801897  0.07746628]\n",
      "Loss in iteration 814: 0.5339215680810324\n",
      "Theta: [-0.44276777  0.27829472  0.07745973]\n",
      "Loss in iteration 815: 0.5338557864012895\n",
      "Theta: [-0.44323686  0.27857037  0.0774532 ]\n",
      "Loss in iteration 816: 0.5337900538075349\n",
      "Theta: [-0.44370578  0.27884592  0.07744666]\n",
      "Loss in iteration 817: 0.5337243702559951\n",
      "Theta: [-0.44417452  0.27912137  0.07744013]\n",
      "Loss in iteration 818: 0.5336587357029378\n",
      "Theta: [-0.44464309  0.27939671  0.07743361]\n",
      "Loss in iteration 819: 0.5335931501046706\n",
      "Theta: [-0.44511148  0.27967195  0.07742709]\n",
      "Loss in iteration 820: 0.5335276134175411\n",
      "Theta: [-0.44557969  0.27994709  0.07742057]\n",
      "Loss in iteration 821: 0.5334621255979372\n",
      "Theta: [-0.44604774  0.28022213  0.07741405]\n",
      "Loss in iteration 822: 0.5333966866022866\n",
      "Theta: [-0.4465156   0.28049706  0.07740755]\n",
      "Loss in iteration 823: 0.5333312963870573\n",
      "Theta: [-0.4469833   0.28077189  0.07740104]\n",
      "Loss in iteration 824: 0.5332659549087575\n",
      "Theta: [-0.44745081  0.28104662  0.07739454]\n",
      "Loss in iteration 825: 0.5332006621239348\n",
      "Theta: [-0.44791816  0.28132125  0.07738804]\n",
      "Loss in iteration 826: 0.5331354179891776\n",
      "Theta: [-0.44838533  0.28159578  0.07738155]\n",
      "Loss in iteration 827: 0.5330702224611137\n",
      "Theta: [-0.44885232  0.2818702   0.07737506]\n",
      "Loss in iteration 828: 0.533005075496411\n",
      "Theta: [-0.44931914  0.28214452  0.07736858]\n",
      "Loss in iteration 829: 0.532939977051777\n",
      "Theta: [-0.44978579  0.28241874  0.0773621 ]\n",
      "Loss in iteration 830: 0.5328749270839598\n",
      "Theta: [-0.45025226  0.28269286  0.07735563]\n",
      "Loss in iteration 831: 0.5328099255497469\n",
      "Theta: [-0.45071856  0.28296687  0.07734915]\n",
      "Loss in iteration 832: 0.5327449724059652\n",
      "Theta: [-0.45118468  0.28324079  0.07734269]\n",
      "Loss in iteration 833: 0.5326800676094823\n",
      "Theta: [-0.45165064  0.2835146   0.07733622]\n",
      "Loss in iteration 834: 0.5326152111172047\n",
      "Theta: [-0.45211641  0.28378831  0.07732976]\n",
      "Loss in iteration 835: 0.5325504028860792\n",
      "Theta: [-0.45258202  0.28406192  0.07732331]\n",
      "Loss in iteration 836: 0.5324856428730923\n",
      "Theta: [-0.45304745  0.28433543  0.07731686]\n",
      "Loss in iteration 837: 0.5324209310352699\n",
      "Theta: [-0.45351271  0.28460884  0.07731041]\n",
      "Loss in iteration 838: 0.5323562673296778\n",
      "Theta: [-0.45397779  0.28488214  0.07730397]\n",
      "Loss in iteration 839: 0.5322916517134211\n",
      "Theta: [-0.4544427   0.28515535  0.07729753]\n",
      "Loss in iteration 840: 0.5322270841436451\n",
      "Theta: [-0.45490744  0.28542845  0.0772911 ]\n",
      "Loss in iteration 841: 0.532162564577534\n",
      "Theta: [-0.455372    0.28570145  0.07728467]\n",
      "Loss in iteration 842: 0.5320980929723121\n",
      "Theta: [-0.4558364   0.28597435  0.07727824]\n",
      "Loss in iteration 843: 0.5320336692852429\n",
      "Theta: [-0.45630062  0.28624716  0.07727182]\n",
      "Loss in iteration 844: 0.5319692934736296\n",
      "Theta: [-0.45676466  0.28651985  0.0772654 ]\n",
      "Loss in iteration 845: 0.5319049654948147\n",
      "Theta: [-0.45722854  0.28679245  0.07725899]\n",
      "Loss in iteration 846: 0.5318406853061801\n",
      "Theta: [-0.45769224  0.28706495  0.07725258]\n",
      "Loss in iteration 847: 0.5317764528651474\n",
      "Theta: [-0.45815576  0.28733735  0.07724617]\n",
      "Loss in iteration 848: 0.5317122681291775\n",
      "Theta: [-0.45861912  0.28760964  0.07723977]\n",
      "Loss in iteration 849: 0.5316481310557701\n",
      "Theta: [-0.4590823   0.28788184  0.07723337]\n",
      "Loss in iteration 850: 0.5315840416024653\n",
      "Theta: [-0.45954532  0.28815393  0.07722698]\n",
      "Loss in iteration 851: 0.5315199997268418\n",
      "Theta: [-0.46000816  0.28842593  0.07722059]\n",
      "Loss in iteration 852: 0.5314560053865174\n",
      "Theta: [-0.46047082  0.28869782  0.0772142 ]\n",
      "Loss in iteration 853: 0.5313920585391496\n",
      "Theta: [-0.46093332  0.28896961  0.07720782]\n",
      "Loss in iteration 854: 0.5313281591424353\n",
      "Theta: [-0.46139564  0.28924131  0.07720144]\n",
      "Loss in iteration 855: 0.5312643071541097\n",
      "Theta: [-0.46185779  0.2895129   0.07719507]\n",
      "Loss in iteration 856: 0.5312005025319482\n",
      "Theta: [-0.46231977  0.28978439  0.0771887 ]\n",
      "Loss in iteration 857: 0.5311367452337644\n",
      "Theta: [-0.46278158  0.29005579  0.07718233]\n",
      "Loss in iteration 858: 0.5310730352174121\n",
      "Theta: [-0.46324322  0.29032708  0.07717597]\n",
      "Loss in iteration 859: 0.5310093724407832\n",
      "Theta: [-0.46370468  0.29059827  0.07716961]\n",
      "Loss in iteration 860: 0.530945756861809\n",
      "Theta: [-0.46416598  0.29086936  0.07716326]\n",
      "Loss in iteration 861: 0.5308821884384602\n",
      "Theta: [-0.4646271   0.29114035  0.07715691]\n",
      "Loss in iteration 862: 0.530818667128746\n",
      "Theta: [-0.46508805  0.29141125  0.07715056]\n",
      "Loss in iteration 863: 0.5307551928907148\n",
      "Theta: [-0.46554883  0.29168204  0.07714422]\n",
      "Loss in iteration 864: 0.5306917656824538\n",
      "Theta: [-0.46600944  0.29195273  0.07713788]\n",
      "Loss in iteration 865: 0.5306283854620891\n",
      "Theta: [-0.46646988  0.29222333  0.07713155]\n",
      "Loss in iteration 866: 0.5305650521877864\n",
      "Theta: [-0.46693014  0.29249382  0.07712522]\n",
      "Loss in iteration 867: 0.530501765817749\n",
      "Theta: [-0.46739024  0.29276421  0.07711889]\n",
      "Loss in iteration 868: 0.5304385263102201\n",
      "Theta: [-0.46785016  0.29303451  0.07711257]\n",
      "Loss in iteration 869: 0.5303753336234815\n",
      "Theta: [-0.46830992  0.2933047   0.07710625]\n",
      "Loss in iteration 870: 0.5303121877158532\n",
      "Theta: [-0.4687695   0.2935748   0.07709994]\n",
      "Loss in iteration 871: 0.5302490885456946\n",
      "Theta: [-0.46922892  0.2938448   0.07709363]\n",
      "Loss in iteration 872: 0.5301860360714037\n",
      "Theta: [-0.46968816  0.29411469  0.07708732]\n",
      "Loss in iteration 873: 0.5301230302514168\n",
      "Theta: [-0.47014723  0.29438449  0.07708102]\n",
      "Loss in iteration 874: 0.5300600710442095\n",
      "Theta: [-0.47060614  0.29465419  0.07707472]\n",
      "Loss in iteration 875: 0.5299971584082956\n",
      "Theta: [-0.47106487  0.29492379  0.07706843]\n",
      "Loss in iteration 876: 0.5299342923022277\n",
      "Theta: [-0.47152343  0.29519329  0.07706214]\n",
      "Loss in iteration 877: 0.5298714726845968\n",
      "Theta: [-0.47198182  0.29546269  0.07705585]\n",
      "Loss in iteration 878: 0.5298086995140326\n",
      "Theta: [-0.47244005  0.29573199  0.07704957]\n",
      "Loss in iteration 879: 0.5297459727492034\n",
      "Theta: [-0.4728981   0.2960012   0.07704329]\n",
      "Loss in iteration 880: 0.529683292348816\n",
      "Theta: [-0.47335598  0.2962703   0.07703701]\n",
      "Loss in iteration 881: 0.5296206582716154\n",
      "Theta: [-0.4738137   0.29653931  0.07703074]\n",
      "Loss in iteration 882: 0.5295580704763855\n",
      "Theta: [-0.47427124  0.29680822  0.07702447]\n",
      "Loss in iteration 883: 0.5294955289219482\n",
      "Theta: [-0.47472861  0.29707703  0.07701821]\n",
      "Loss in iteration 884: 0.529433033567164\n",
      "Theta: [-0.47518582  0.29734574  0.07701195]\n",
      "Loss in iteration 885: 0.5293705843709318\n",
      "Theta: [-0.47564285  0.29761435  0.07700569]\n",
      "Loss in iteration 886: 0.5293081812921886\n",
      "Theta: [-0.47609972  0.29788286  0.07699944]\n",
      "Loss in iteration 887: 0.5292458242899102\n",
      "Theta: [-0.47655642  0.29815128  0.07699319]\n",
      "Loss in iteration 888: 0.5291835133231101\n",
      "Theta: [-0.47701295  0.29841959  0.07698695]\n",
      "Loss in iteration 889: 0.5291212483508404\n",
      "Theta: [-0.47746931  0.29868781  0.07698071]\n",
      "Loss in iteration 890: 0.5290590293321914\n",
      "Theta: [-0.4779255   0.29895593  0.07697447]\n",
      "Loss in iteration 891: 0.5289968562262916\n",
      "Theta: [-0.47838152  0.29922396  0.07696824]\n",
      "Loss in iteration 892: 0.5289347289923075\n",
      "Theta: [-0.47883737  0.29949188  0.07696201]\n",
      "Loss in iteration 893: 0.5288726475894439\n",
      "Theta: [-0.47929306  0.29975971  0.07695578]\n",
      "Loss in iteration 894: 0.5288106119769437\n",
      "Theta: [-0.47974857  0.30002743  0.07694956]\n",
      "Loss in iteration 895: 0.5287486221140878\n",
      "Theta: [-0.48020392  0.30029506  0.07694334]\n",
      "Loss in iteration 896: 0.5286866779601953\n",
      "Theta: [-0.4806591   0.3005626   0.07693713]\n",
      "Loss in iteration 897: 0.528624779474623\n",
      "Theta: [-0.48111411  0.30083003  0.07693092]\n",
      "Loss in iteration 898: 0.5285629266167664\n",
      "Theta: [-0.48156895  0.30109737  0.07692471]\n",
      "Loss in iteration 899: 0.5285011193460581\n",
      "Theta: [-0.48202363  0.30136461  0.07691851]\n",
      "Loss in iteration 900: 0.5284393576219695\n",
      "Theta: [-0.48247813  0.30163175  0.07691231]\n",
      "Loss in iteration 901: 0.5283776414040089\n",
      "Theta: [-0.48293247  0.30189879  0.07690612]\n",
      "Loss in iteration 902: 0.5283159706517239\n",
      "Theta: [-0.48338664  0.30216574  0.07689993]\n",
      "Loss in iteration 903: 0.5282543453246984\n",
      "Theta: [-0.48384064  0.30243259  0.07689374]\n",
      "Loss in iteration 904: 0.5281927653825551\n",
      "Theta: [-0.48429448  0.30269934  0.07688755]\n",
      "Loss in iteration 905: 0.5281312307849544\n",
      "Theta: [-0.48474815  0.30296599  0.07688137]\n",
      "Loss in iteration 906: 0.5280697414915942\n",
      "Theta: [-0.48520165  0.30323255  0.0768752 ]\n",
      "Loss in iteration 907: 0.5280082974622105\n",
      "Theta: [-0.48565498  0.30349901  0.07686903]\n",
      "Loss in iteration 908: 0.5279468986565766\n",
      "Theta: [-0.48610814  0.30376537  0.07686286]\n",
      "Loss in iteration 909: 0.5278855450345038\n",
      "Theta: [-0.48656114  0.30403164  0.07685669]\n",
      "Loss in iteration 910: 0.5278242365558411\n",
      "Theta: [-0.48701397  0.30429781  0.07685053]\n",
      "Loss in iteration 911: 0.5277629731804748\n",
      "Theta: [-0.48746663  0.30456388  0.07684437]\n",
      "Loss in iteration 912: 0.5277017548683292\n",
      "Theta: [-0.48791913  0.30482985  0.07683822]\n",
      "Loss in iteration 913: 0.5276405815793661\n",
      "Theta: [-0.48837146  0.30509573  0.07683207]\n",
      "Loss in iteration 914: 0.5275794532735847\n",
      "Theta: [-0.48882362  0.30536151  0.07682592]\n",
      "Loss in iteration 915: 0.5275183699110213\n",
      "Theta: [-0.48927562  0.3056272   0.07681978]\n",
      "Loss in iteration 916: 0.5274573314517508\n",
      "Theta: [-0.48972744  0.30589278  0.07681364]\n",
      "Loss in iteration 917: 0.5273963378558847\n",
      "Theta: [-0.49017911  0.30615828  0.0768075 ]\n",
      "Loss in iteration 918: 0.5273353890835721\n",
      "Theta: [-0.4906306   0.30642367  0.07680137]\n",
      "Loss in iteration 919: 0.5272744850949997\n",
      "Theta: [-0.49108193  0.30668897  0.07679524]\n",
      "Loss in iteration 920: 0.5272136258503917\n",
      "Theta: [-0.49153309  0.30695417  0.07678912]\n",
      "Loss in iteration 921: 0.5271528113100089\n",
      "Theta: [-0.49198409  0.30721927  0.076783  ]\n",
      "Loss in iteration 922: 0.5270920414341504\n",
      "Theta: [-0.49243492  0.30748428  0.07677688]\n",
      "Loss in iteration 923: 0.5270313161831519\n",
      "Theta: [-0.49288558  0.30774919  0.07677077]\n",
      "Loss in iteration 924: 0.5269706355173867\n",
      "Theta: [-0.49333608  0.30801401  0.07676466]\n",
      "Loss in iteration 925: 0.5269099993972653\n",
      "Theta: [-0.49378641  0.30827873  0.07675855]\n",
      "Loss in iteration 926: 0.5268494077832353\n",
      "Theta: [-0.49423658  0.30854335  0.07675245]\n",
      "Loss in iteration 927: 0.5267888606357815\n",
      "Theta: [-0.49468658  0.30880788  0.07674635]\n",
      "Loss in iteration 928: 0.526728357915426\n",
      "Theta: [-0.49513641  0.30907231  0.07674025]\n",
      "Loss in iteration 929: 0.5266678995827279\n",
      "Theta: [-0.49558608  0.30933665  0.07673416]\n",
      "Loss in iteration 930: 0.5266074855982834\n",
      "Theta: [-0.49603559  0.30960089  0.07672807]\n",
      "Loss in iteration 931: 0.5265471159227257\n",
      "Theta: [-0.49648492  0.30986503  0.07672199]\n",
      "Loss in iteration 932: 0.5264867905167255\n",
      "Theta: [-0.4969341   0.31012908  0.07671591]\n",
      "Loss in iteration 933: 0.5264265093409899\n",
      "Theta: [-0.4973831   0.31039303  0.07670983]\n",
      "Loss in iteration 934: 0.5263662723562631\n",
      "Theta: [-0.49783194  0.31065689  0.07670376]\n",
      "Loss in iteration 935: 0.5263060795233268\n",
      "Theta: [-0.49828062  0.31092065  0.07669769]\n",
      "Loss in iteration 936: 0.5262459308029986\n",
      "Theta: [-0.49872913  0.31118432  0.07669162]\n",
      "Loss in iteration 937: 0.5261858261561344\n",
      "Theta: [-0.49917748  0.31144789  0.07668556]\n",
      "Loss in iteration 938: 0.5261257655436256\n",
      "Theta: [-0.49962566  0.31171136  0.0766795 ]\n",
      "Loss in iteration 939: 0.5260657489264012\n",
      "Theta: [-0.50007368  0.31197474  0.07667344]\n",
      "Loss in iteration 940: 0.526005776265427\n",
      "Theta: [-0.50052153  0.31223803  0.07666739]\n",
      "Loss in iteration 941: 0.5259458475217051\n",
      "Theta: [-0.50096922  0.31250121  0.07666134]\n",
      "Loss in iteration 942: 0.5258859626562749\n",
      "Theta: [-0.50141674  0.31276431  0.0766553 ]\n",
      "Loss in iteration 943: 0.5258261216302125\n",
      "Theta: [-0.5018641   0.31302731  0.07664926]\n",
      "Loss in iteration 944: 0.5257663244046302\n",
      "Theta: [-0.50231129  0.31329021  0.07664322]\n",
      "Loss in iteration 945: 0.5257065709406775\n",
      "Theta: [-0.50275832  0.31355302  0.07663718]\n",
      "Loss in iteration 946: 0.5256468611995403\n",
      "Theta: [-0.50320518  0.31381573  0.07663115]\n",
      "Loss in iteration 947: 0.5255871951424409\n",
      "Theta: [-0.50365188  0.31407835  0.07662513]\n",
      "Loss in iteration 948: 0.5255275727306389\n",
      "Theta: [-0.50409842  0.31434087  0.0766191 ]\n",
      "Loss in iteration 949: 0.5254679939254295\n",
      "Theta: [-0.50454479  0.3146033   0.07661308]\n",
      "Loss in iteration 950: 0.5254084586881451\n",
      "Theta: [-0.504991    0.31486564  0.07660706]\n",
      "Loss in iteration 951: 0.5253489669801547\n",
      "Theta: [-0.50543705  0.31512787  0.07660105]\n",
      "Loss in iteration 952: 0.5252895187628631\n",
      "Theta: [-0.50588293  0.31539002  0.07659504]\n",
      "Loss in iteration 953: 0.5252301139977122\n",
      "Theta: [-0.50632865  0.31565207  0.07658904]\n",
      "Loss in iteration 954: 0.52517075264618\n",
      "Theta: [-0.5067742   0.31591402  0.07658303]\n",
      "Loss in iteration 955: 0.5251114346697807\n",
      "Theta: [-0.50721959  0.31617589  0.07657703]\n",
      "Loss in iteration 956: 0.5250521600300655\n",
      "Theta: [-0.50766482  0.31643765  0.07657104]\n",
      "Loss in iteration 957: 0.5249929286886211\n",
      "Theta: [-0.50810988  0.31669932  0.07656505]\n",
      "Loss in iteration 958: 0.5249337406070713\n",
      "Theta: [-0.50855478  0.3169609   0.07655906]\n",
      "Loss in iteration 959: 0.5248745957470755\n",
      "Theta: [-0.50899952  0.31722239  0.07655307]\n",
      "Loss in iteration 960: 0.5248154940703298\n",
      "Theta: [-0.50944409  0.31748378  0.07654709]\n",
      "Loss in iteration 961: 0.5247564355385663\n",
      "Theta: [-0.5098885   0.31774507  0.07654111]\n",
      "Loss in iteration 962: 0.5246974201135535\n",
      "Theta: [-0.51033275  0.31800627  0.07653514]\n",
      "Loss in iteration 963: 0.5246384477570957\n",
      "Theta: [-0.51077684  0.31826738  0.07652917]\n",
      "Loss in iteration 964: 0.5245795184310335\n",
      "Theta: [-0.51122076  0.31852839  0.0765232 ]\n",
      "Loss in iteration 965: 0.5245206320972439\n",
      "Theta: [-0.51166452  0.31878931  0.07651723]\n",
      "Loss in iteration 966: 0.5244617887176394\n",
      "Theta: [-0.51210811  0.31905014  0.07651127]\n",
      "Loss in iteration 967: 0.5244029882541691\n",
      "Theta: [-0.51255155  0.31931087  0.07650531]\n",
      "Loss in iteration 968: 0.5243442306688174\n",
      "Theta: [-0.51299482  0.31957151  0.07649936]\n",
      "Loss in iteration 969: 0.5242855159236057\n",
      "Theta: [-0.51343793  0.31983205  0.07649341]\n",
      "Loss in iteration 970: 0.5242268439805907\n",
      "Theta: [-0.51388088  0.3200925   0.07648746]\n",
      "Loss in iteration 971: 0.524168214801865\n",
      "Theta: [-0.51432366  0.32035286  0.07648152]\n",
      "Loss in iteration 972: 0.5241096283495572\n",
      "Theta: [-0.51476628  0.32061312  0.07647558]\n",
      "Loss in iteration 973: 0.5240510845858318\n",
      "Theta: [-0.51520874  0.32087329  0.07646964]\n",
      "Loss in iteration 974: 0.523992583472889\n",
      "Theta: [-0.51565104  0.32113337  0.07646371]\n",
      "Loss in iteration 975: 0.5239341249729657\n",
      "Theta: [-0.51609318  0.32139335  0.07645778]\n",
      "Loss in iteration 976: 0.5238757090483329\n",
      "Theta: [-0.51653515  0.32165324  0.07645185]\n",
      "Loss in iteration 977: 0.5238173356612991\n",
      "Theta: [-0.51697697  0.32191304  0.07644593]\n",
      "Loss in iteration 978: 0.5237590047742069\n",
      "Theta: [-0.51741862  0.32217274  0.07644001]\n",
      "Loss in iteration 979: 0.5237007163494362\n",
      "Theta: [-0.51786011  0.32243235  0.07643409]\n",
      "Loss in iteration 980: 0.5236424703494014\n",
      "Theta: [-0.51830143  0.32269187  0.07642818]\n",
      "Loss in iteration 981: 0.5235842667365531\n",
      "Theta: [-0.5187426   0.32295129  0.07642227]\n",
      "Loss in iteration 982: 0.5235261054733775\n",
      "Theta: [-0.51918361  0.32321063  0.07641636]\n",
      "Loss in iteration 983: 0.5234679865223959\n",
      "Theta: [-0.51962445  0.32346986  0.07641046]\n",
      "Loss in iteration 984: 0.5234099098461658\n",
      "Theta: [-0.52006513  0.32372901  0.07640456]\n",
      "Loss in iteration 985: 0.5233518754072797\n",
      "Theta: [-0.52050566  0.32398806  0.07639866]\n",
      "Loss in iteration 986: 0.5232938831683659\n",
      "Theta: [-0.52094602  0.32424702  0.07639277]\n",
      "Loss in iteration 987: 0.5232359330920884\n",
      "Theta: [-0.52138622  0.32450589  0.07638688]\n",
      "Loss in iteration 988: 0.5231780251411459\n",
      "Theta: [-0.52182625  0.32476466  0.07638099]\n",
      "Loss in iteration 989: 0.5231201592782734\n",
      "Theta: [-0.52226613  0.32502335  0.07637511]\n",
      "Loss in iteration 990: 0.5230623354662405\n",
      "Theta: [-0.52270585  0.32528194  0.07636923]\n",
      "Loss in iteration 991: 0.5230045536678527\n",
      "Theta: [-0.52314541  0.32554043  0.07636335]\n",
      "Loss in iteration 992: 0.5229468138459503\n",
      "Theta: [-0.5235848   0.32579884  0.07635748]\n",
      "Loss in iteration 993: 0.5228891159634097\n",
      "Theta: [-0.52402404  0.32605715  0.07635161]\n",
      "Loss in iteration 994: 0.5228314599831421\n",
      "Theta: [-0.52446311  0.32631537  0.07634574]\n",
      "Loss in iteration 995: 0.5227738458680935\n",
      "Theta: [-0.52490203  0.3265735   0.07633988]\n",
      "Loss in iteration 996: 0.5227162735812458\n",
      "Theta: [-0.52534078  0.32683153  0.07633402]\n",
      "Loss in iteration 997: 0.5226587430856161\n",
      "Theta: [-0.52577938  0.32708948  0.07632816]\n",
      "Loss in iteration 998: 0.5226012543442559\n",
      "Theta: [-0.52621781  0.32734733  0.07632231]\n",
      "Loss in iteration 999: 0.5225438073202527\n",
      "Theta: [-0.52665609  0.32760509  0.07631646]\n",
      "Loss in iteration 1000: 0.5224864019767286\n",
      "Theta: [-0.5270942   0.32786275  0.07631061]\n",
      "Loss in iteration 1001: 0.522429038276841\n",
      "Theta: [-0.52753216  0.32812033  0.07630477]\n",
      "Loss in iteration 1002: 0.5223717161837821\n",
      "Theta: [-0.52796995  0.32837781  0.07629893]\n",
      "Loss in iteration 1003: 0.5223144356607792\n",
      "Theta: [-0.52840759  0.3286352   0.07629309]\n",
      "Loss in iteration 1004: 0.5222571966710947\n",
      "Theta: [-0.52884506  0.3288925   0.07628726]\n",
      "Loss in iteration 1005: 0.5221999991780261\n",
      "Theta: [-0.52928238  0.32914971  0.07628143]\n",
      "Loss in iteration 1006: 0.5221428431449052\n",
      "Theta: [-0.52971953  0.32940683  0.0762756 ]\n",
      "Loss in iteration 1007: 0.5220857285350995\n",
      "Theta: [-0.53015653  0.32966385  0.07626978]\n",
      "Loss in iteration 1008: 0.5220286553120108\n",
      "Theta: [-0.53059337  0.32992079  0.07626396]\n",
      "Loss in iteration 1009: 0.5219716234390759\n",
      "Theta: [-0.53103005  0.33017763  0.07625814]\n",
      "Loss in iteration 1010: 0.5219146328797667\n",
      "Theta: [-0.53146657  0.33043438  0.07625233]\n",
      "Loss in iteration 1011: 0.5218576835975892\n",
      "Theta: [-0.53190293  0.33069104  0.07624652]\n",
      "Loss in iteration 1012: 0.521800775556085\n",
      "Theta: [-0.53233913  0.33094761  0.07624071]\n",
      "Loss in iteration 1013: 0.5217439087188298\n",
      "Theta: [-0.53277517  0.33120408  0.07623491]\n",
      "Loss in iteration 1014: 0.521687083049434\n",
      "Theta: [-0.53321106  0.33146047  0.0762291 ]\n",
      "Loss in iteration 1015: 0.5216302985115431\n",
      "Theta: [-0.53364678  0.33171676  0.07622331]\n",
      "Loss in iteration 1016: 0.5215735550688373\n",
      "Theta: [-0.53408235  0.33197297  0.07621751]\n",
      "Loss in iteration 1017: 0.5215168526850303\n",
      "Theta: [-0.53451776  0.33222908  0.07621172]\n",
      "Loss in iteration 1018: 0.5214601913238721\n",
      "Theta: [-0.53495301  0.3324851   0.07620593]\n",
      "Loss in iteration 1019: 0.5214035709491458\n",
      "Theta: [-0.5353881   0.33274103  0.07620015]\n",
      "Loss in iteration 1020: 0.5213469915246699\n",
      "Theta: [-0.53582303  0.33299687  0.07619437]\n",
      "Loss in iteration 1021: 0.5212904530142969\n",
      "Theta: [-0.5362578   0.33325262  0.07618859]\n",
      "Loss in iteration 1022: 0.5212339553819141\n",
      "Theta: [-0.53669242  0.33350827  0.07618281]\n",
      "Loss in iteration 1023: 0.5211774985914427\n",
      "Theta: [-0.53712688  0.33376384  0.07617704]\n",
      "Loss in iteration 1024: 0.5211210826068392\n",
      "Theta: [-0.53756118  0.33401932  0.07617127]\n",
      "Loss in iteration 1025: 0.5210647073920938\n",
      "Theta: [-0.53799532  0.3342747   0.0761655 ]\n",
      "Loss in iteration 1026: 0.5210083729112313\n",
      "Theta: [-0.5384293   0.33453     0.07615974]\n",
      "Loss in iteration 1027: 0.5209520791283105\n",
      "Theta: [-0.53886313  0.3347852   0.07615398]\n",
      "Loss in iteration 1028: 0.520895826007425\n",
      "Theta: [-0.5392968   0.33504031  0.07614823]\n",
      "Loss in iteration 1029: 0.5208396135127024\n",
      "Theta: [-0.53973031  0.33529534  0.07614247]\n",
      "Loss in iteration 1030: 0.5207834416083046\n",
      "Theta: [-0.54016366  0.33555027  0.07613672]\n",
      "Loss in iteration 1031: 0.5207273102584277\n",
      "Theta: [-0.54059686  0.33580511  0.07613098]\n",
      "Loss in iteration 1032: 0.5206712194273018\n",
      "Theta: [-0.5410299   0.33605987  0.07612523]\n",
      "Loss in iteration 1033: 0.5206151690791915\n",
      "Theta: [-0.54146278  0.33631453  0.07611949]\n",
      "Loss in iteration 1034: 0.5205591591783952\n",
      "Theta: [-0.5418955   0.3365691   0.07611375]\n",
      "Loss in iteration 1035: 0.5205031896892457\n",
      "Theta: [-0.54232807  0.33682358  0.07610802]\n",
      "Loss in iteration 1036: 0.5204472605761097\n",
      "Theta: [-0.54276048  0.33707797  0.07610229]\n",
      "Loss in iteration 1037: 0.5203913718033878\n",
      "Theta: [-0.54319273  0.33733228  0.07609656]\n",
      "Loss in iteration 1038: 0.5203355233355147\n",
      "Theta: [-0.54362483  0.33758649  0.07609083]\n",
      "Loss in iteration 1039: 0.5202797151369594\n",
      "Theta: [-0.54405677  0.33784061  0.07608511]\n",
      "Loss in iteration 1040: 0.5202239471722245\n",
      "Theta: [-0.54448855  0.33809464  0.07607939]\n",
      "Loss in iteration 1041: 0.5201682194058466\n",
      "Theta: [-0.54492018  0.33834859  0.07607368]\n",
      "Loss in iteration 1042: 0.5201125318023962\n",
      "Theta: [-0.54535165  0.33860244  0.07606797]\n",
      "Loss in iteration 1043: 0.5200568843264778\n",
      "Theta: [-0.54578296  0.3388562   0.07606226]\n",
      "Loss in iteration 1044: 0.5200012769427294\n",
      "Theta: [-0.54621411  0.33910988  0.07605655]\n",
      "Loss in iteration 1045: 0.5199457096158233\n",
      "Theta: [-0.54664511  0.33936346  0.07605085]\n",
      "Loss in iteration 1046: 0.5198901823104651\n",
      "Theta: [-0.54707596  0.33961695  0.07604515]\n",
      "Loss in iteration 1047: 0.5198346949913946\n",
      "Theta: [-0.54750664  0.33987036  0.07603945]\n",
      "Loss in iteration 1048: 0.5197792476233848\n",
      "Theta: [-0.54793717  0.34012367  0.07603376]\n",
      "Loss in iteration 1049: 0.5197238401712431\n",
      "Theta: [-0.54836755  0.3403769   0.07602806]\n",
      "Loss in iteration 1050: 0.5196684725998096\n",
      "Theta: [-0.54879777  0.34063004  0.07602238]\n",
      "Loss in iteration 1051: 0.5196131448739593\n",
      "Theta: [-0.54922783  0.34088309  0.07601669]\n",
      "Loss in iteration 1052: 0.5195578569585996\n",
      "Theta: [-0.54965774  0.34113604  0.07601101]\n",
      "Loss in iteration 1053: 0.519502608818672\n",
      "Theta: [-0.55008749  0.34138891  0.07600533]\n",
      "Loss in iteration 1054: 0.5194474004191519\n",
      "Theta: [-0.55051708  0.34164169  0.07599966]\n",
      "Loss in iteration 1055: 0.5193922317250477\n",
      "Theta: [-0.55094652  0.34189439  0.07599398]\n",
      "Loss in iteration 1056: 0.5193371027014013\n",
      "Theta: [-0.55137581  0.34214699  0.07598831]\n",
      "Loss in iteration 1057: 0.5192820133132886\n",
      "Theta: [-0.55180494  0.3423995   0.07598265]\n",
      "Loss in iteration 1058: 0.5192269635258183\n",
      "Theta: [-0.55223391  0.34265193  0.07597698]\n",
      "Loss in iteration 1059: 0.5191719533041329\n",
      "Theta: [-0.55266273  0.34290426  0.07597132]\n",
      "Loss in iteration 1060: 0.5191169826134082\n",
      "Theta: [-0.55309139  0.34315651  0.07596567]\n",
      "Loss in iteration 1061: 0.5190620514188533\n",
      "Theta: [-0.5535199   0.34340867  0.07596001]\n",
      "Loss in iteration 1062: 0.5190071596857105\n",
      "Theta: [-0.55394825  0.34366074  0.07595436]\n",
      "Loss in iteration 1063: 0.5189523073792559\n",
      "Theta: [-0.55437645  0.34391272  0.07594871]\n",
      "Loss in iteration 1064: 0.5188974944647984\n",
      "Theta: [-0.55480449  0.34416461  0.07594307]\n",
      "Loss in iteration 1065: 0.5188427209076802\n",
      "Theta: [-0.55523238  0.34441641  0.07593742]\n",
      "Loss in iteration 1066: 0.5187879866732766\n",
      "Theta: [-0.55566012  0.34466813  0.07593178]\n",
      "Loss in iteration 1067: 0.5187332917269968\n",
      "Theta: [-0.55608769  0.34491976  0.07592615]\n",
      "Loss in iteration 1068: 0.518678636034282\n",
      "Theta: [-0.55651512  0.3451713   0.07592052]\n",
      "Loss in iteration 1069: 0.5186240195606077\n",
      "Theta: [-0.55694239  0.34542275  0.07591488]\n",
      "Loss in iteration 1070: 0.5185694422714815\n",
      "Theta: [-0.5573695   0.34567411  0.07590926]\n",
      "Loss in iteration 1071: 0.5185149041324447\n",
      "Theta: [-0.55779646  0.34592538  0.07590363]\n",
      "Loss in iteration 1072: 0.5184604051090714\n",
      "Theta: [-0.55822327  0.34617657  0.07589801]\n",
      "Loss in iteration 1073: 0.5184059451669689\n",
      "Theta: [-0.55864992  0.34642767  0.07589239]\n",
      "Loss in iteration 1074: 0.5183515242717773\n",
      "Theta: [-0.55907642  0.34667867  0.07588678]\n",
      "Loss in iteration 1075: 0.5182971423891697\n",
      "Theta: [-0.55950276  0.3469296   0.07588117]\n",
      "Loss in iteration 1076: 0.5182427994848521\n",
      "Theta: [-0.55992895  0.34718043  0.07587556]\n",
      "Loss in iteration 1077: 0.5181884955245635\n",
      "Theta: [-0.56035499  0.34743118  0.07586995]\n",
      "Loss in iteration 1078: 0.5181342304740756\n",
      "Theta: [-0.56078087  0.34768183  0.07586435]\n",
      "Loss in iteration 1079: 0.5180800042991932\n",
      "Theta: [-0.5612066   0.3479324   0.07585874]\n",
      "Loss in iteration 1080: 0.5180258169657537\n",
      "Theta: [-0.56163218  0.34818289  0.07585315]\n",
      "Loss in iteration 1081: 0.5179716684396273\n",
      "Theta: [-0.5620576   0.34843328  0.07584755]\n",
      "Loss in iteration 1082: 0.5179175586867173\n",
      "Theta: [-0.56248286  0.34868359  0.07584196]\n",
      "Loss in iteration 1083: 0.517863487672959\n",
      "Theta: [-0.56290798  0.34893381  0.07583637]\n",
      "Loss in iteration 1084: 0.5178094553643211\n",
      "Theta: [-0.56333294  0.34918394  0.07583079]\n",
      "Loss in iteration 1085: 0.5177554617268048\n",
      "Theta: [-0.56375775  0.34943399  0.0758252 ]\n",
      "Loss in iteration 1086: 0.5177015067264435\n",
      "Theta: [-0.5641824   0.34968394  0.07581962]\n",
      "Loss in iteration 1087: 0.517647590329304\n",
      "Theta: [-0.5646069   0.34993381  0.07581404]\n",
      "Loss in iteration 1088: 0.517593712501485\n",
      "Theta: [-0.56503125  0.3501836   0.07580847]\n",
      "Loss in iteration 1089: 0.5175398732091181\n",
      "Theta: [-0.56545544  0.35043329  0.0758029 ]\n",
      "Loss in iteration 1090: 0.5174860724183674\n",
      "Theta: [-0.56587949  0.3506829   0.07579733]\n",
      "Loss in iteration 1091: 0.5174323100954293\n",
      "Theta: [-0.56630338  0.35093242  0.07579176]\n",
      "Loss in iteration 1092: 0.5173785862065331\n",
      "Theta: [-0.56672711  0.35118185  0.0757862 ]\n",
      "Loss in iteration 1093: 0.51732490071794\n",
      "Theta: [-0.5671507   0.3514312   0.07578064]\n",
      "Loss in iteration 1094: 0.5172712535959442\n",
      "Theta: [-0.56757413  0.35168046  0.07577508]\n",
      "Loss in iteration 1095: 0.5172176448068716\n",
      "Theta: [-0.56799741  0.35192963  0.07576953]\n",
      "Loss in iteration 1096: 0.5171640743170811\n",
      "Theta: [-0.56842053  0.35217872  0.07576398]\n",
      "Loss in iteration 1097: 0.5171105420929636\n",
      "Theta: [-0.56884351  0.35242772  0.07575843]\n",
      "Loss in iteration 1098: 0.5170570481009424\n",
      "Theta: [-0.56926633  0.35267663  0.07575289]\n",
      "Loss in iteration 1099: 0.5170035923074732\n",
      "Theta: [-0.569689    0.35292545  0.07574734]\n",
      "Loss in iteration 1100: 0.5169501746790438\n",
      "Theta: [-0.57011151  0.35317419  0.0757418 ]\n",
      "Loss in iteration 1101: 0.5168967951821738\n",
      "Theta: [-0.57053388  0.35342285  0.07573627]\n",
      "Loss in iteration 1102: 0.5168434537834158\n",
      "Theta: [-0.57095609  0.35367141  0.07573073]\n",
      "Loss in iteration 1103: 0.5167901504493544\n",
      "Theta: [-0.57137815  0.35391989  0.0757252 ]\n",
      "Loss in iteration 1104: 0.5167368851466057\n",
      "Theta: [-0.57180006  0.35416828  0.07571967]\n",
      "Loss in iteration 1105: 0.5166836578418184\n",
      "Theta: [-0.57222182  0.35441659  0.07571415]\n",
      "Loss in iteration 1106: 0.5166304685016733\n",
      "Theta: [-0.57264342  0.35466481  0.07570862]\n",
      "Loss in iteration 1107: 0.5165773170928832\n",
      "Theta: [-0.57306488  0.35491294  0.07570311]\n",
      "Loss in iteration 1108: 0.5165242035821929\n",
      "Theta: [-0.57348618  0.35516099  0.07569759]\n",
      "Loss in iteration 1109: 0.516471127936379\n",
      "Theta: [-0.57390733  0.35540895  0.07569207]\n",
      "Loss in iteration 1110: 0.5164180901222504\n",
      "Theta: [-0.57432833  0.35565682  0.07568656]\n",
      "Loss in iteration 1111: 0.5163650901066476\n",
      "Theta: [-0.57474918  0.35590461  0.07568105]\n",
      "Loss in iteration 1112: 0.5163121278564434\n",
      "Theta: [-0.57516988  0.35615231  0.07567555]\n",
      "Loss in iteration 1113: 0.5162592033385424\n",
      "Theta: [-0.57559042  0.35639993  0.07567005]\n",
      "Loss in iteration 1114: 0.5162063165198805\n",
      "Theta: [-0.57601082  0.35664746  0.07566455]\n",
      "Loss in iteration 1115: 0.5161534673674261\n",
      "Theta: [-0.57643106  0.35689491  0.07565905]\n",
      "Loss in iteration 1116: 0.5161006558481792\n",
      "Theta: [-0.57685115  0.35714226  0.07565355]\n",
      "Loss in iteration 1117: 0.5160478819291714\n",
      "Theta: [-0.57727109  0.35738954  0.07564806]\n",
      "Loss in iteration 1118: 0.5159951455774664\n",
      "Theta: [-0.57769088  0.35763672  0.07564257]\n",
      "Loss in iteration 1119: 0.5159424467601591\n",
      "Theta: [-0.57811052  0.35788382  0.07563709]\n",
      "Loss in iteration 1120: 0.5158897854443765\n",
      "Theta: [-0.57853001  0.35813084  0.0756316 ]\n",
      "Loss in iteration 1121: 0.515837161597277\n",
      "Theta: [-0.57894935  0.35837777  0.07562612]\n",
      "Loss in iteration 1122: 0.5157845751860508\n",
      "Theta: [-0.57936854  0.35862461  0.07562065]\n",
      "Loss in iteration 1123: 0.5157320261779198\n",
      "Theta: [-0.57978758  0.35887137  0.07561517]\n",
      "Loss in iteration 1124: 0.5156795145401373\n",
      "Theta: [-0.58020647  0.35911805  0.0756097 ]\n",
      "Loss in iteration 1125: 0.515627040239988\n",
      "Theta: [-0.5806252   0.35936463  0.07560423]\n",
      "Loss in iteration 1126: 0.5155746032447882\n",
      "Theta: [-0.58104379  0.35961114  0.07559876]\n",
      "Loss in iteration 1127: 0.5155222035218862\n",
      "Theta: [-0.58146223  0.35985755  0.0755933 ]\n",
      "Loss in iteration 1128: 0.5154698410386609\n",
      "Theta: [-0.58188051  0.36010388  0.07558784]\n",
      "Loss in iteration 1129: 0.5154175157625233\n",
      "Theta: [-0.58229865  0.36035013  0.07558238]\n",
      "Loss in iteration 1130: 0.5153652276609155\n",
      "Theta: [-0.58271664  0.36059629  0.07557692]\n",
      "Loss in iteration 1131: 0.5153129767013113\n",
      "Theta: [-0.58313448  0.36084237  0.07557147]\n",
      "Loss in iteration 1132: 0.515260762851215\n",
      "Theta: [-0.58355216  0.36108836  0.07556602]\n",
      "Loss in iteration 1133: 0.5152085860781637\n",
      "Theta: [-0.5839697   0.36133426  0.07556057]\n",
      "Loss in iteration 1134: 0.5151564463497241\n",
      "Theta: [-0.58438709  0.36158009  0.07555513]\n",
      "Loss in iteration 1135: 0.5151043436334956\n",
      "Theta: [-0.58480433  0.36182582  0.07554968]\n",
      "Loss in iteration 1136: 0.5150522778971076\n",
      "Theta: [-0.58522142  0.36207147  0.07554425]\n",
      "Loss in iteration 1137: 0.5150002491082221\n",
      "Theta: [-0.58563836  0.36231704  0.07553881]\n",
      "Loss in iteration 1138: 0.5149482572345307\n",
      "Theta: [-0.58605515  0.36256252  0.07553337]\n",
      "Loss in iteration 1139: 0.5148963022437576\n",
      "Theta: [-0.58647179  0.36280792  0.07552794]\n",
      "Loss in iteration 1140: 0.5148443841036572\n",
      "Theta: [-0.58688828  0.36305323  0.07552252]\n",
      "Loss in iteration 1141: 0.5147925027820155\n",
      "Theta: [-0.58730462  0.36329846  0.07551709]\n",
      "Loss in iteration 1142: 0.5147406582466489\n",
      "Theta: [-0.58772082  0.3635436   0.07551167]\n",
      "Loss in iteration 1143: 0.5146888504654059\n",
      "Theta: [-0.58813686  0.36378866  0.07550625]\n",
      "Loss in iteration 1144: 0.5146370794061649\n",
      "Theta: [-0.58855276  0.36403363  0.07550083]\n",
      "Loss in iteration 1145: 0.5145853450368363\n",
      "Theta: [-0.58896851  0.36427852  0.07549541]\n",
      "Loss in iteration 1146: 0.5145336473253607\n",
      "Theta: [-0.5893841   0.36452333  0.07549   ]\n",
      "Loss in iteration 1147: 0.5144819862397099\n",
      "Theta: [-0.58979955  0.36476805  0.07548459]\n",
      "Loss in iteration 1148: 0.5144303617478865\n",
      "Theta: [-0.59021485  0.36501268  0.07547918]\n",
      "Loss in iteration 1149: 0.5143787738179243\n",
      "Theta: [-0.59063001  0.36525724  0.07547378]\n",
      "Loss in iteration 1150: 0.5143272224178876\n",
      "Theta: [-0.59104501  0.3655017   0.07546838]\n",
      "Loss in iteration 1151: 0.5142757075158717\n",
      "Theta: [-0.59145987  0.36574609  0.07546298]\n",
      "Loss in iteration 1152: 0.5142242290800028\n",
      "Theta: [-0.59187458  0.36599039  0.07545758]\n",
      "Loss in iteration 1153: 0.5141727870784374\n",
      "Theta: [-0.59228914  0.3662346   0.07545219]\n",
      "Loss in iteration 1154: 0.514121381479363\n",
      "Theta: [-0.59270355  0.36647873  0.0754468 ]\n",
      "Loss in iteration 1155: 0.5140700122509982\n",
      "Theta: [-0.59311781  0.36672278  0.07544141]\n",
      "Loss in iteration 1156: 0.5140186793615918\n",
      "Theta: [-0.59353193  0.36696675  0.07543602]\n",
      "Loss in iteration 1157: 0.5139673827794232\n",
      "Theta: [-0.59394589  0.36721063  0.07543064]\n",
      "Loss in iteration 1158: 0.5139161224728029\n",
      "Theta: [-0.59435971  0.36745442  0.07542526]\n",
      "Loss in iteration 1159: 0.5138648984100717\n",
      "Theta: [-0.59477338  0.36769813  0.07541988]\n",
      "Loss in iteration 1160: 0.5138137105596005\n",
      "Theta: [-0.59518691  0.36794176  0.07541451]\n",
      "Loss in iteration 1161: 0.5137625588897918\n",
      "Theta: [-0.59560028  0.36818531  0.07540914]\n",
      "Loss in iteration 1162: 0.5137114433690779\n",
      "Theta: [-0.59601351  0.36842877  0.07540377]\n",
      "Loss in iteration 1163: 0.5136603639659215\n",
      "Theta: [-0.5964266   0.36867215  0.0753984 ]\n",
      "Loss in iteration 1164: 0.5136093206488163\n",
      "Theta: [-0.59683953  0.36891544  0.07539303]\n",
      "Loss in iteration 1165: 0.5135583133862859\n",
      "Theta: [-0.59725232  0.36915865  0.07538767]\n",
      "Loss in iteration 1166: 0.5135073421468845\n",
      "Theta: [-0.59766496  0.36940178  0.07538231]\n",
      "Loss in iteration 1167: 0.513456406899197\n",
      "Theta: [-0.59807745  0.36964482  0.07537696]\n",
      "Loss in iteration 1168: 0.5134055076118382\n",
      "Theta: [-0.59848979  0.36988779  0.0753716 ]\n",
      "Loss in iteration 1169: 0.5133546442534533\n",
      "Theta: [-0.59890199  0.37013066  0.07536625]\n",
      "Loss in iteration 1170: 0.5133038167927179\n",
      "Theta: [-0.59931404  0.37037346  0.0753609 ]\n",
      "Loss in iteration 1171: 0.5132530251983379\n",
      "Theta: [-0.59972595  0.37061617  0.07535555]\n",
      "Loss in iteration 1172: 0.5132022694390495\n",
      "Theta: [-0.6001377   0.3708588   0.07535021]\n",
      "Loss in iteration 1173: 0.5131515494836186\n",
      "Theta: [-0.60054932  0.37110134  0.07534487]\n",
      "Loss in iteration 1174: 0.5131008653008421\n",
      "Theta: [-0.60096078  0.3713438   0.07533953]\n",
      "Loss in iteration 1175: 0.5130502168595465\n",
      "Theta: [-0.6013721   0.37158618  0.07533419]\n",
      "Loss in iteration 1176: 0.5129996041285887\n",
      "Theta: [-0.60178327  0.37182848  0.07532886]\n",
      "Loss in iteration 1177: 0.5129490270768553\n",
      "Theta: [-0.60219429  0.37207069  0.07532353]\n",
      "Loss in iteration 1178: 0.5128984856732635\n",
      "Theta: [-0.60260517  0.37231282  0.0753182 ]\n",
      "Loss in iteration 1179: 0.5128479798867599\n",
      "Theta: [-0.6030159   0.37255487  0.07531288]\n",
      "Loss in iteration 1180: 0.512797509686322\n",
      "Theta: [-0.60342649  0.37279683  0.07530755]\n",
      "Loss in iteration 1181: 0.5127470750409566\n",
      "Theta: [-0.60383693  0.37303872  0.07530223]\n",
      "Loss in iteration 1182: 0.5126966759197007\n",
      "Theta: [-0.60424722  0.37328052  0.07529691]\n",
      "Loss in iteration 1183: 0.512646312291621\n",
      "Theta: [-0.60465737  0.37352223  0.0752916 ]\n",
      "Loss in iteration 1184: 0.5125959841258148\n",
      "Theta: [-0.60506737  0.37376387  0.07528629]\n",
      "Loss in iteration 1185: 0.5125456913914084\n",
      "Theta: [-0.60547723  0.37400542  0.07528097]\n",
      "Loss in iteration 1186: 0.5124954340575585\n",
      "Theta: [-0.60588694  0.37424689  0.07527567]\n",
      "Loss in iteration 1187: 0.5124452120934514\n",
      "Theta: [-0.6062965   0.37448828  0.07527036]\n",
      "Loss in iteration 1188: 0.5123950254683034\n",
      "Theta: [-0.60670592  0.37472958  0.07526506]\n",
      "Loss in iteration 1189: 0.5123448741513605\n",
      "Theta: [-0.60711519  0.3749708   0.07525976]\n",
      "Loss in iteration 1190: 0.5122947581118984\n",
      "Theta: [-0.60752432  0.37521194  0.07525446]\n",
      "Loss in iteration 1191: 0.5122446773192224\n",
      "Theta: [-0.6079333   0.375453    0.07524916]\n",
      "Loss in iteration 1192: 0.5121946317426679\n",
      "Theta: [-0.60834214  0.37569398  0.07524387]\n",
      "Loss in iteration 1193: 0.5121446213515993\n",
      "Theta: [-0.60875083  0.37593487  0.07523858]\n",
      "Loss in iteration 1194: 0.5120946461154116\n",
      "Theta: [-0.60915937  0.37617568  0.07523329]\n",
      "Loss in iteration 1195: 0.512044706003528\n",
      "Theta: [-0.60956778  0.37641641  0.07522801]\n",
      "Loss in iteration 1196: 0.5119948009854031\n",
      "Theta: [-0.60997603  0.37665706  0.07522273]\n",
      "Loss in iteration 1197: 0.5119449310305194\n",
      "Theta: [-0.61038414  0.37689762  0.07521744]\n",
      "Loss in iteration 1198: 0.5118950961083898\n",
      "Theta: [-0.61079211  0.37713811  0.07521217]\n",
      "Loss in iteration 1199: 0.5118452961885565\n",
      "Theta: [-0.61119993  0.37737851  0.07520689]\n",
      "Loss in iteration 1200: 0.5117955312405913\n",
      "Theta: [-0.61160761  0.37761883  0.07520162]\n",
      "Loss in iteration 1201: 0.5117458012340952\n",
      "Theta: [-0.61201514  0.37785907  0.07519635]\n",
      "Loss in iteration 1202: 0.5116961061386989\n",
      "Theta: [-0.61242252  0.37809923  0.07519108]\n",
      "Loss in iteration 1203: 0.511646445924062\n",
      "Theta: [-0.61282977  0.3783393   0.07518582]\n",
      "Loss in iteration 1204: 0.5115968205598743\n",
      "Theta: [-0.61323686  0.3785793   0.07518055]\n",
      "Loss in iteration 1205: 0.511547230015854\n",
      "Theta: [-0.61364382  0.37881921  0.07517529]\n",
      "Loss in iteration 1206: 0.5114976742617494\n",
      "Theta: [-0.61405063  0.37905904  0.07517003]\n",
      "Loss in iteration 1207: 0.5114481532673377\n",
      "Theta: [-0.61445729  0.37929879  0.07516478]\n",
      "Loss in iteration 1208: 0.5113986670024254\n",
      "Theta: [-0.61486381  0.37953845  0.07515953]\n",
      "Loss in iteration 1209: 0.511349215436848\n",
      "Theta: [-0.61527019  0.37977804  0.07515427]\n",
      "Loss in iteration 1210: 0.5112997985404707\n",
      "Theta: [-0.61567642  0.38001755  0.07514903]\n",
      "Loss in iteration 1211: 0.5112504162831876\n",
      "Theta: [-0.61608251  0.38025697  0.07514378]\n",
      "Loss in iteration 1212: 0.5112010686349219\n",
      "Theta: [-0.61648845  0.38049631  0.07513854]\n",
      "Loss in iteration 1213: 0.5111517555656259\n",
      "Theta: [-0.61689426  0.38073557  0.0751333 ]\n",
      "Loss in iteration 1214: 0.5111024770452812\n",
      "Theta: [-0.61729991  0.38097475  0.07512806]\n",
      "Loss in iteration 1215: 0.5110532330438985\n",
      "Theta: [-0.61770543  0.38121385  0.07512282]\n",
      "Loss in iteration 1216: 0.5110040235315172\n",
      "Theta: [-0.61811079  0.38145287  0.07511759]\n",
      "Loss in iteration 1217: 0.5109548484782058\n",
      "Theta: [-0.61851602  0.38169181  0.07511236]\n",
      "Loss in iteration 1218: 0.5109057078540621\n",
      "Theta: [-0.6189211   0.38193067  0.07510713]\n",
      "Loss in iteration 1219: 0.5108566016292128\n",
      "Theta: [-0.61932604  0.38216944  0.0751019 ]\n",
      "Loss in iteration 1220: 0.510807529773813\n",
      "Theta: [-0.61973084  0.38240814  0.07509668]\n",
      "Loss in iteration 1221: 0.5107584922580475\n",
      "Theta: [-0.62013549  0.38264675  0.07509146]\n",
      "Loss in iteration 1222: 0.5107094890521292\n",
      "Theta: [-0.62054     0.38288528  0.07508624]\n",
      "Loss in iteration 1223: 0.5106605201263006\n",
      "Theta: [-0.62094437  0.38312374  0.07508102]\n",
      "Loss in iteration 1224: 0.5106115854508326\n",
      "Theta: [-0.62134859  0.38336211  0.07507581]\n",
      "Loss in iteration 1225: 0.5105626849960246\n",
      "Theta: [-0.62175267  0.3836004   0.0750706 ]\n",
      "Loss in iteration 1226: 0.5105138187322057\n",
      "Theta: [-0.62215661  0.38383861  0.07506539]\n",
      "Loss in iteration 1227: 0.5104649866297327\n",
      "Theta: [-0.6225604   0.38407674  0.07506018]\n",
      "Loss in iteration 1228: 0.5104161886589919\n",
      "Theta: [-0.62296405  0.38431479  0.07505498]\n",
      "Loss in iteration 1229: 0.5103674247903978\n",
      "Theta: [-0.62336756  0.38455276  0.07504977]\n",
      "Loss in iteration 1230: 0.5103186949943939\n",
      "Theta: [-0.62377093  0.38479065  0.07504457]\n",
      "Loss in iteration 1231: 0.5102699992414521\n",
      "Theta: [-0.62417415  0.38502846  0.07503938]\n",
      "Loss in iteration 1232: 0.5102213375020732\n",
      "Theta: [-0.62457723  0.38526618  0.07503418]\n",
      "Loss in iteration 1233: 0.5101727097467861\n",
      "Theta: [-0.62498017  0.38550383  0.07502899]\n",
      "Loss in iteration 1234: 0.5101241159461488\n",
      "Theta: [-0.62538297  0.3857414   0.0750238 ]\n",
      "Loss in iteration 1235: 0.5100755560707474\n",
      "Theta: [-0.62578562  0.38597889  0.07501861]\n",
      "Loss in iteration 1236: 0.510027030091197\n",
      "Theta: [-0.62618813  0.3862163   0.07501342]\n",
      "Loss in iteration 1237: 0.5099785379781405\n",
      "Theta: [-0.6265905   0.38645362  0.07500824]\n",
      "Loss in iteration 1238: 0.50993007970225\n",
      "Theta: [-0.62699273  0.38669087  0.07500306]\n",
      "Loss in iteration 1239: 0.5098816552342252\n",
      "Theta: [-0.62739481  0.38692804  0.07499788]\n",
      "Loss in iteration 1240: 0.509833264544795\n",
      "Theta: [-0.62779676  0.38716513  0.07499271]\n",
      "Loss in iteration 1241: 0.5097849076047164\n",
      "Theta: [-0.62819856  0.38740214  0.07498753]\n",
      "Loss in iteration 1242: 0.5097365843847745\n",
      "Theta: [-0.62860022  0.38763906  0.07498236]\n",
      "Loss in iteration 1243: 0.5096882948557828\n",
      "Theta: [-0.62900174  0.38787591  0.07497719]\n",
      "Loss in iteration 1244: 0.5096400389885835\n",
      "Theta: [-0.62940311  0.38811268  0.07497202]\n",
      "Loss in iteration 1245: 0.5095918167540464\n",
      "Theta: [-0.62980435  0.38834937  0.07496686]\n",
      "Loss in iteration 1246: 0.5095436281230699\n",
      "Theta: [-0.63020544  0.38858598  0.0749617 ]\n",
      "Loss in iteration 1247: 0.5094954730665808\n",
      "Theta: [-0.63060639  0.38882251  0.07495654]\n",
      "Loss in iteration 1248: 0.5094473515555338\n",
      "Theta: [-0.6310072   0.38905896  0.07495138]\n",
      "Loss in iteration 1249: 0.509399263560912\n",
      "Theta: [-0.63140787  0.38929533  0.07494622]\n",
      "Loss in iteration 1250: 0.5093512090537263\n",
      "Theta: [-0.6318084   0.38953162  0.07494107]\n",
      "Loss in iteration 1251: 0.509303188005016\n",
      "Theta: [-0.63220879  0.38976783  0.07493592]\n",
      "Loss in iteration 1252: 0.5092552003858483\n",
      "Theta: [-0.63260903  0.39000397  0.07493077]\n",
      "Loss in iteration 1253: 0.5092072461673183\n",
      "Theta: [-0.63300914  0.39024002  0.07492563]\n",
      "Loss in iteration 1254: 0.5091593253205497\n",
      "Theta: [-0.6334091   0.39047599  0.07492048]\n",
      "Loss in iteration 1255: 0.5091114378166939\n",
      "Theta: [-0.63380893  0.39071189  0.07491534]\n",
      "Loss in iteration 1256: 0.5090635836269299\n",
      "Theta: [-0.63420861  0.39094771  0.0749102 ]\n",
      "Loss in iteration 1257: 0.5090157627224654\n",
      "Theta: [-0.63460815  0.39118344  0.07490507]\n",
      "Loss in iteration 1258: 0.5089679750745352\n",
      "Theta: [-0.63500755  0.3914191   0.07489993]\n",
      "Loss in iteration 1259: 0.5089202206544026\n",
      "Theta: [-0.63540681  0.39165468  0.0748948 ]\n",
      "Loss in iteration 1260: 0.5088724994333585\n",
      "Theta: [-0.63580593  0.39189018  0.07488967]\n",
      "Loss in iteration 1261: 0.508824811382722\n",
      "Theta: [-0.63620491  0.3921256   0.07488454]\n",
      "Loss in iteration 1262: 0.5087771564738391\n",
      "Theta: [-0.63660375  0.39236094  0.07487942]\n",
      "Loss in iteration 1263: 0.508729534678085\n",
      "Theta: [-0.63700245  0.3925962   0.07487429]\n",
      "Loss in iteration 1264: 0.5086819459668613\n",
      "Theta: [-0.637401    0.39283139  0.07486917]\n",
      "Loss in iteration 1265: 0.5086343903115982\n",
      "Theta: [-0.63779942  0.39306649  0.07486406]\n",
      "Loss in iteration 1266: 0.5085868676837532\n",
      "Theta: [-0.6381977   0.39330152  0.07485894]\n",
      "Loss in iteration 1267: 0.5085393780548115\n",
      "Theta: [-0.63859584  0.39353647  0.07485383]\n",
      "Loss in iteration 1268: 0.5084919213962865\n",
      "Theta: [-0.63899384  0.39377134  0.07484871]\n",
      "Loss in iteration 1269: 0.5084444976797187\n",
      "Theta: [-0.63939169  0.39400613  0.0748436 ]\n",
      "Loss in iteration 1270: 0.5083971068766759\n",
      "Theta: [-0.63978941  0.39424084  0.0748385 ]\n",
      "Loss in iteration 1271: 0.5083497489587544\n",
      "Theta: [-0.64018699  0.39447547  0.07483339]\n",
      "Loss in iteration 1272: 0.5083024238975774\n",
      "Theta: [-0.64058443  0.39471003  0.07482829]\n",
      "Loss in iteration 1273: 0.5082551316647959\n",
      "Theta: [-0.64098173  0.39494451  0.07482319]\n",
      "Loss in iteration 1274: 0.5082078722320879\n",
      "Theta: [-0.64137889  0.3951789   0.07481809]\n",
      "Loss in iteration 1275: 0.5081606455711597\n",
      "Theta: [-0.64177591  0.39541322  0.07481299]\n",
      "Loss in iteration 1276: 0.5081134516537443\n",
      "Theta: [-0.64217279  0.39564747  0.0748079 ]\n",
      "Loss in iteration 1277: 0.5080662904516028\n",
      "Theta: [-0.64256953  0.39588163  0.07480281]\n",
      "Loss in iteration 1278: 0.5080191619365231\n",
      "Theta: [-0.64296613  0.39611572  0.07479772]\n",
      "Loss in iteration 1279: 0.5079720660803209\n",
      "Theta: [-0.64336259  0.39634972  0.07479263]\n",
      "Loss in iteration 1280: 0.5079250028548388\n",
      "Theta: [-0.64375892  0.39658365  0.07478755]\n",
      "Loss in iteration 1281: 0.5078779722319474\n",
      "Theta: [-0.6441551   0.3968175   0.07478247]\n",
      "Loss in iteration 1282: 0.5078309741835436\n",
      "Theta: [-0.64455115  0.39705128  0.07477739]\n",
      "Loss in iteration 1283: 0.5077840086815527\n",
      "Theta: [-0.64494705  0.39728497  0.07477231]\n",
      "Loss in iteration 1284: 0.5077370756979263\n",
      "Theta: [-0.64534282  0.39751859  0.07476723]\n",
      "Loss in iteration 1285: 0.5076901752046438\n",
      "Theta: [-0.64573845  0.39775213  0.07476216]\n",
      "Loss in iteration 1286: 0.5076433071737118\n",
      "Theta: [-0.64613394  0.39798559  0.07475709]\n",
      "Loss in iteration 1287: 0.5075964715771635\n",
      "Theta: [-0.64652929  0.39821898  0.07475202]\n",
      "Loss in iteration 1288: 0.5075496683870598\n",
      "Theta: [-0.64692451  0.39845228  0.07474695]\n",
      "Loss in iteration 1289: 0.5075028975754886\n",
      "Theta: [-0.64731958  0.39868551  0.07474188]\n",
      "Loss in iteration 1290: 0.5074561591145647\n",
      "Theta: [-0.64771452  0.39891866  0.07473682]\n",
      "Loss in iteration 1291: 0.5074094529764298\n",
      "Theta: [-0.64810931  0.39915174  0.07473176]\n",
      "Loss in iteration 1292: 0.5073627791332534\n",
      "Theta: [-0.64850397  0.39938473  0.0747267 ]\n",
      "Loss in iteration 1293: 0.5073161375572314\n",
      "Theta: [-0.64889849  0.39961765  0.07472165]\n",
      "Loss in iteration 1294: 0.5072695282205866\n",
      "Theta: [-0.64929288  0.39985049  0.07471659]\n",
      "Loss in iteration 1295: 0.5072229510955691\n",
      "Theta: [-0.64968712  0.40008326  0.07471154]\n",
      "Loss in iteration 1296: 0.5071764061544557\n",
      "Theta: [-0.65008123  0.40031594  0.07470649]\n",
      "Loss in iteration 1297: 0.5071298933695503\n",
      "Theta: [-0.6504752   0.40054855  0.07470144]\n",
      "Loss in iteration 1298: 0.5070834127131836\n",
      "Theta: [-0.65086903  0.40078108  0.0746964 ]\n",
      "Loss in iteration 1299: 0.5070369641577129\n",
      "Theta: [-0.65126272  0.40101354  0.07469135]\n",
      "Loss in iteration 1300: 0.5069905476755231\n",
      "Theta: [-0.65165627  0.40124591  0.07468631]\n",
      "Loss in iteration 1301: 0.5069441632390247\n",
      "Theta: [-0.65204969  0.40147821  0.07468127]\n",
      "Loss in iteration 1302: 0.5068978108206561\n",
      "Theta: [-0.65244297  0.40171044  0.07467624]\n",
      "Loss in iteration 1303: 0.5068514903928819\n",
      "Theta: [-0.65283611  0.40194258  0.0746712 ]\n",
      "Loss in iteration 1304: 0.5068052019281937\n",
      "Theta: [-0.65322912  0.40217465  0.07466617]\n",
      "Loss in iteration 1305: 0.5067589453991093\n",
      "Theta: [-0.65362199  0.40240664  0.07466114]\n",
      "Loss in iteration 1306: 0.5067127207781738\n",
      "Theta: [-0.65401472  0.40263856  0.07465611]\n",
      "Loss in iteration 1307: 0.5066665280379584\n",
      "Theta: [-0.65440731  0.4028704   0.07465109]\n",
      "Loss in iteration 1308: 0.5066203671510613\n",
      "Theta: [-0.65479976  0.40310216  0.07464606]\n",
      "Loss in iteration 1309: 0.5065742380901073\n",
      "Theta: [-0.65519208  0.40333384  0.07464104]\n",
      "Loss in iteration 1310: 0.5065281408277474\n",
      "Theta: [-0.65558426  0.40356545  0.07463602]\n",
      "Loss in iteration 1311: 0.5064820753366599\n",
      "Theta: [-0.65597631  0.40379698  0.074631  ]\n",
      "Loss in iteration 1312: 0.5064360415895487\n",
      "Theta: [-0.65636821  0.40402844  0.07462599]\n",
      "Loss in iteration 1313: 0.5063900395591449\n",
      "Theta: [-0.65675999  0.40425981  0.07462098]\n",
      "Loss in iteration 1314: 0.5063440692182053\n",
      "Theta: [-0.65715162  0.40449112  0.07461596]\n",
      "Loss in iteration 1315: 0.5062981305395143\n",
      "Theta: [-0.65754312  0.40472234  0.07461095]\n",
      "Loss in iteration 1316: 0.5062522234958816\n",
      "Theta: [-0.65793448  0.40495349  0.07460595]\n",
      "Loss in iteration 1317: 0.506206348060144\n",
      "Theta: [-0.6583257   0.40518456  0.07460094]\n",
      "Loss in iteration 1318: 0.5061605042051645\n",
      "Theta: [-0.65871679  0.40541556  0.07459594]\n",
      "Loss in iteration 1319: 0.5061146919038323\n",
      "Theta: [-0.65910774  0.40564648  0.07459094]\n",
      "Loss in iteration 1320: 0.5060689111290628\n",
      "Theta: [-0.65949855  0.40587732  0.07458594]\n",
      "Loss in iteration 1321: 0.5060231618537983\n",
      "Theta: [-0.65988923  0.40610809  0.07458095]\n",
      "Loss in iteration 1322: 0.5059774440510065\n",
      "Theta: [-0.66027977  0.40633878  0.07457595]\n",
      "Loss in iteration 1323: 0.5059317576936823\n",
      "Theta: [-0.66067017  0.40656939  0.07457096]\n",
      "Loss in iteration 1324: 0.5058861027548459\n",
      "Theta: [-0.66106044  0.40679993  0.07456597]\n",
      "Loss in iteration 1325: 0.5058404792075444\n",
      "Theta: [-0.66145058  0.40703039  0.07456098]\n",
      "Loss in iteration 1326: 0.5057948870248505\n",
      "Theta: [-0.66184057  0.40726078  0.07455599]\n",
      "Loss in iteration 1327: 0.5057493261798638\n",
      "Theta: [-0.66223043  0.40749109  0.07455101]\n",
      "Loss in iteration 1328: 0.5057037966457094\n",
      "Theta: [-0.66262016  0.40772132  0.07454603]\n",
      "Loss in iteration 1329: 0.5056582983955383\n",
      "Theta: [-0.66300975  0.40795148  0.07454105]\n",
      "Loss in iteration 1330: 0.5056128314025282\n",
      "Theta: [-0.6633992   0.40818156  0.07453607]\n",
      "Loss in iteration 1331: 0.5055673956398826\n",
      "Theta: [-0.66378852  0.40841157  0.0745311 ]\n",
      "Loss in iteration 1332: 0.5055219910808308\n",
      "Theta: [-0.6641777   0.4086415   0.07452612]\n",
      "Loss in iteration 1333: 0.5054766176986283\n",
      "Theta: [-0.66456675  0.40887135  0.07452115]\n",
      "Loss in iteration 1334: 0.5054312754665565\n",
      "Theta: [-0.66495566  0.40910113  0.07451618]\n",
      "Loss in iteration 1335: 0.505385964357923\n",
      "Theta: [-0.66534444  0.40933083  0.07451121]\n",
      "Loss in iteration 1336: 0.5053406843460609\n",
      "Theta: [-0.66573308  0.40956046  0.07450625]\n",
      "Loss in iteration 1337: 0.5052954354043293\n",
      "Theta: [-0.66612158  0.40979001  0.07450129]\n",
      "Loss in iteration 1338: 0.5052502175061135\n",
      "Theta: [-0.66650995  0.41001949  0.07449632]\n",
      "Loss in iteration 1339: 0.5052050306248242\n",
      "Theta: [-0.66689819  0.41024889  0.07449136]\n",
      "Loss in iteration 1340: 0.5051598747338982\n",
      "Theta: [-0.66728629  0.41047822  0.07448641]\n",
      "Loss in iteration 1341: 0.5051147498067978\n",
      "Theta: [-0.66767425  0.41070747  0.07448145]\n",
      "Loss in iteration 1342: 0.5050696558170116\n",
      "Theta: [-0.66806208  0.41093664  0.0744765 ]\n",
      "Loss in iteration 1343: 0.5050245927380531\n",
      "Theta: [-0.66844978  0.41116574  0.07447155]\n",
      "Loss in iteration 1344: 0.5049795605434625\n",
      "Theta: [-0.66883734  0.41139477  0.0744666 ]\n",
      "Loss in iteration 1345: 0.5049345592068051\n",
      "Theta: [-0.66922476  0.41162372  0.07446165]\n",
      "Loss in iteration 1346: 0.5048895887016719\n",
      "Theta: [-0.66961205  0.41185259  0.07445671]\n",
      "Loss in iteration 1347: 0.5048446490016795\n",
      "Theta: [-0.66999921  0.41208139  0.07445176]\n",
      "Loss in iteration 1348: 0.5047997400804703\n",
      "Theta: [-0.67038623  0.41231011  0.07444682]\n",
      "Loss in iteration 1349: 0.5047548619117125\n",
      "Theta: [-0.67077312  0.41253876  0.07444188]\n",
      "Loss in iteration 1350: 0.5047100144690992\n",
      "Theta: [-0.67115987  0.41276734  0.07443695]\n",
      "Loss in iteration 1351: 0.5046651977263497\n",
      "Theta: [-0.67154649  0.41299583  0.07443201]\n",
      "Loss in iteration 1352: 0.5046204116572084\n",
      "Theta: [-0.67193297  0.41322426  0.07442708]\n",
      "Loss in iteration 1353: 0.5045756562354454\n",
      "Theta: [-0.67231932  0.41345261  0.07442215]\n",
      "Loss in iteration 1354: 0.5045309314348564\n",
      "Theta: [-0.67270554  0.41368088  0.07441722]\n",
      "Loss in iteration 1355: 0.5044862372292621\n",
      "Theta: [-0.67309162  0.41390908  0.07441229]\n",
      "Loss in iteration 1356: 0.504441573592509\n",
      "Theta: [-0.67347757  0.41413721  0.07440737]\n",
      "Loss in iteration 1357: 0.5043969404984686\n",
      "Theta: [-0.67386338  0.41436525  0.07440245]\n",
      "Loss in iteration 1358: 0.5043523379210385\n",
      "Theta: [-0.67424906  0.41459323  0.07439752]\n",
      "Loss in iteration 1359: 0.5043077658341408\n",
      "Theta: [-0.67463461  0.41482113  0.07439261]\n",
      "Loss in iteration 1360: 0.5042632242117236\n",
      "Theta: [-0.67502002  0.41504896  0.07438769]\n",
      "Loss in iteration 1361: 0.5042187130277598\n",
      "Theta: [-0.6754053   0.41527671  0.07438277]\n",
      "Loss in iteration 1362: 0.5041742322562478\n",
      "Theta: [-0.67579044  0.41550438  0.07437786]\n",
      "Loss in iteration 1363: 0.5041297818712112\n",
      "Theta: [-0.67617546  0.41573199  0.07437295]\n",
      "Loss in iteration 1364: 0.5040853618466989\n",
      "Theta: [-0.67656033  0.41595952  0.07436804]\n",
      "Loss in iteration 1365: 0.5040409721567848\n",
      "Theta: [-0.67694508  0.41618697  0.07436313]\n",
      "Loss in iteration 1366: 0.5039966127755683\n",
      "Theta: [-0.67732969  0.41641435  0.07435823]\n",
      "Loss in iteration 1367: 0.5039522836771736\n",
      "Theta: [-0.67771417  0.41664165  0.07435332]\n",
      "Loss in iteration 1368: 0.5039079848357502\n",
      "Theta: [-0.67809851  0.41686888  0.07434842]\n",
      "Loss in iteration 1369: 0.5038637162254725\n",
      "Theta: [-0.67848272  0.41709604  0.07434352]\n",
      "Loss in iteration 1370: 0.5038194778205407\n",
      "Theta: [-0.6788668   0.41732312  0.07433863]\n",
      "Loss in iteration 1371: 0.5037752695951788\n",
      "Theta: [-0.67925075  0.41755013  0.07433373]\n",
      "Loss in iteration 1372: 0.503731091523637\n",
      "Theta: [-0.67963456  0.41777707  0.07432884]\n",
      "Loss in iteration 1373: 0.5036869435801897\n",
      "Theta: [-0.68001824  0.41800393  0.07432395]\n",
      "Loss in iteration 1374: 0.5036428257391369\n",
      "Theta: [-0.68040179  0.41823071  0.07431906]\n",
      "Loss in iteration 1375: 0.5035987379748029\n",
      "Theta: [-0.6807852   0.41845742  0.07431417]\n",
      "Loss in iteration 1376: 0.5035546802615376\n",
      "Theta: [-0.68116848  0.41868406  0.07430928]\n",
      "Loss in iteration 1377: 0.5035106525737154\n",
      "Theta: [-0.68155163  0.41891063  0.0743044 ]\n",
      "Loss in iteration 1378: 0.5034666548857356\n",
      "Theta: [-0.68193465  0.41913712  0.07429952]\n",
      "Loss in iteration 1379: 0.5034226871720222\n",
      "Theta: [-0.68231753  0.41936353  0.07429464]\n",
      "Loss in iteration 1380: 0.5033787494070244\n",
      "Theta: [-0.68270028  0.41958988  0.07428976]\n",
      "Loss in iteration 1381: 0.5033348415652165\n",
      "Theta: [-0.6830829   0.41981615  0.07428489]\n",
      "Loss in iteration 1382: 0.5032909636210963\n",
      "Theta: [-0.68346539  0.42004234  0.07428001]\n",
      "Loss in iteration 1383: 0.5032471155491877\n",
      "Theta: [-0.68384774  0.42026846  0.07427514]\n",
      "Loss in iteration 1384: 0.5032032973240386\n",
      "Theta: [-0.68422997  0.42049451  0.07427027]\n",
      "Loss in iteration 1385: 0.503159508920222\n",
      "Theta: [-0.68461206  0.42072049  0.0742654 ]\n",
      "Loss in iteration 1386: 0.5031157503123354\n",
      "Theta: [-0.68499401  0.42094639  0.07426053]\n",
      "Loss in iteration 1387: 0.5030720214750007\n",
      "Theta: [-0.68537584  0.42117222  0.07425567]\n",
      "Loss in iteration 1388: 0.503028322382865\n",
      "Theta: [-0.68575754  0.42139797  0.07425081]\n",
      "Loss in iteration 1389: 0.5029846530105997\n",
      "Theta: [-0.6861391   0.42162365  0.07424595]\n",
      "Loss in iteration 1390: 0.5029410133329006\n",
      "Theta: [-0.68652053  0.42184926  0.07424109]\n",
      "Loss in iteration 1391: 0.5028974033244884\n",
      "Theta: [-0.68690183  0.4220748   0.07423623]\n",
      "Loss in iteration 1392: 0.5028538229601082\n",
      "Theta: [-0.687283    0.42230026  0.07423138]\n",
      "Loss in iteration 1393: 0.5028102722145296\n",
      "Theta: [-0.68766403  0.42252565  0.07422652]\n",
      "Loss in iteration 1394: 0.5027667510625465\n",
      "Theta: [-0.68804494  0.42275096  0.07422167]\n",
      "Loss in iteration 1395: 0.5027232594789777\n",
      "Theta: [-0.68842571  0.4229762   0.07421682]\n",
      "Loss in iteration 1396: 0.5026797974386663\n",
      "Theta: [-0.68880635  0.42320137  0.07421197]\n",
      "Loss in iteration 1397: 0.5026363649164796\n",
      "Theta: [-0.68918686  0.42342647  0.07420713]\n",
      "Loss in iteration 1398: 0.5025929618873095\n",
      "Theta: [-0.68956724  0.42365149  0.07420229]\n",
      "Loss in iteration 1399: 0.5025495883260721\n",
      "Theta: [-0.68994749  0.42387644  0.07419744]\n",
      "Loss in iteration 1400: 0.502506244207708\n",
      "Theta: [-0.6903276   0.42410132  0.0741926 ]\n",
      "Loss in iteration 1401: 0.5024629295071822\n",
      "Theta: [-0.69070759  0.42432612  0.07418777]\n",
      "Loss in iteration 1402: 0.5024196441994837\n",
      "Theta: [-0.69108744  0.42455085  0.07418293]\n",
      "Loss in iteration 1403: 0.5023763882596258\n",
      "Theta: [-0.69146717  0.42477551  0.07417809]\n",
      "Loss in iteration 1404: 0.5023331616626467\n",
      "Theta: [-0.69184676  0.4250001   0.07417326]\n",
      "Loss in iteration 1405: 0.5022899643836081\n",
      "Theta: [-0.69222622  0.42522461  0.07416843]\n",
      "Loss in iteration 1406: 0.5022467963975957\n",
      "Theta: [-0.69260555  0.42544905  0.0741636 ]\n",
      "Loss in iteration 1407: 0.5022036576797205\n",
      "Theta: [-0.69298475  0.42567342  0.07415878]\n",
      "Loss in iteration 1408: 0.5021605482051166\n",
      "Theta: [-0.69336382  0.42589771  0.07415395]\n",
      "Loss in iteration 1409: 0.5021174679489425\n",
      "Theta: [-0.69374276  0.42612193  0.07414913]\n",
      "Loss in iteration 1410: 0.5020744168863811\n",
      "Theta: [-0.69412157  0.42634608  0.07414431]\n",
      "Loss in iteration 1411: 0.5020313949926392\n",
      "Theta: [-0.69450025  0.42657016  0.07413949]\n",
      "Loss in iteration 1412: 0.5019884022429474\n",
      "Theta: [-0.6948788   0.42679417  0.07413467]\n",
      "Loss in iteration 1413: 0.501945438612561\n",
      "Theta: [-0.69525722  0.4270181   0.07412985]\n",
      "Loss in iteration 1414: 0.5019025040767584\n",
      "Theta: [-0.6956355   0.42724196  0.07412504]\n",
      "Loss in iteration 1415: 0.5018595986108432\n",
      "Theta: [-0.69601366  0.42746575  0.07412023]\n",
      "Loss in iteration 1416: 0.5018167221901415\n",
      "Theta: [-0.69639169  0.42768946  0.07411542]\n",
      "Loss in iteration 1417: 0.5017738747900045\n",
      "Theta: [-0.69676958  0.42791311  0.07411061]\n",
      "Loss in iteration 1418: 0.501731056385807\n",
      "Theta: [-0.69714735  0.42813668  0.0741058 ]\n",
      "Loss in iteration 1419: 0.5016882669529472\n",
      "Theta: [-0.69752499  0.42836018  0.074101  ]\n",
      "Loss in iteration 1420: 0.5016455064668479\n",
      "Theta: [-0.6979025   0.4285836   0.07409619]\n",
      "Loss in iteration 1421: 0.5016027749029555\n",
      "Theta: [-0.69827988  0.42880696  0.07409139]\n",
      "Loss in iteration 1422: 0.5015600722367399\n",
      "Theta: [-0.69865712  0.42903024  0.07408659]\n",
      "Loss in iteration 1423: 0.5015173984436953\n",
      "Theta: [-0.69903424  0.42925345  0.0740818 ]\n",
      "Loss in iteration 1424: 0.5014747534993392\n",
      "Theta: [-0.69941123  0.42947659  0.074077  ]\n",
      "Loss in iteration 1425: 0.5014321373792132\n",
      "Theta: [-0.69978809  0.42969966  0.07407221]\n",
      "Loss in iteration 1426: 0.5013895500588827\n",
      "Theta: [-0.70016482  0.42992266  0.07406741]\n",
      "Loss in iteration 1427: 0.5013469915139364\n",
      "Theta: [-0.70054142  0.43014558  0.07406262]\n",
      "Loss in iteration 1428: 0.5013044617199868\n",
      "Theta: [-0.70091789  0.43036843  0.07405783]\n",
      "Loss in iteration 1429: 0.5012619606526706\n",
      "Theta: [-0.70129423  0.43059121  0.07405305]\n",
      "Loss in iteration 1430: 0.5012194882876472\n",
      "Theta: [-0.70167045  0.43081392  0.07404826]\n",
      "Loss in iteration 1431: 0.5011770446006003\n",
      "Theta: [-0.70204653  0.43103656  0.07404348]\n",
      "Loss in iteration 1432: 0.5011346295672372\n",
      "Theta: [-0.70242248  0.43125912  0.0740387 ]\n",
      "Loss in iteration 1433: 0.5010922431632884\n",
      "Theta: [-0.70279831  0.43148161  0.07403392]\n",
      "Loss in iteration 1434: 0.5010498853645082\n",
      "Theta: [-0.70317401  0.43170404  0.07402914]\n",
      "Loss in iteration 1435: 0.5010075561466742\n",
      "Theta: [-0.70354957  0.43192639  0.07402436]\n",
      "Loss in iteration 1436: 0.5009652554855878\n",
      "Theta: [-0.70392501  0.43214867  0.07401959]\n",
      "Loss in iteration 1437: 0.5009229833570736\n",
      "Theta: [-0.70430032  0.43237087  0.07401482]\n",
      "Loss in iteration 1438: 0.5008807397369796\n",
      "Theta: [-0.7046755   0.43259301  0.07401005]\n",
      "Loss in iteration 1439: 0.5008385246011777\n",
      "Theta: [-0.70505056  0.43281507  0.07400528]\n",
      "Loss in iteration 1440: 0.5007963379255627\n",
      "Theta: [-0.70542548  0.43303707  0.07400051]\n",
      "Loss in iteration 1441: 0.500754179686053\n",
      "Theta: [-0.70580028  0.43325899  0.07399575]\n",
      "Loss in iteration 1442: 0.5007120498585902\n",
      "Theta: [-0.70617494  0.43348084  0.07399098]\n",
      "Loss in iteration 1443: 0.5006699484191396\n",
      "Theta: [-0.70654948  0.43370262  0.07398622]\n",
      "Loss in iteration 1444: 0.5006278753436894\n",
      "Theta: [-0.70692389  0.43392433  0.07398146]\n",
      "Loss in iteration 1445: 0.5005858306082512\n",
      "Theta: [-0.70729818  0.43414597  0.0739767 ]\n",
      "Loss in iteration 1446: 0.5005438141888602\n",
      "Theta: [-0.70767233  0.43436753  0.07397194]\n",
      "Loss in iteration 1447: 0.5005018260615741\n",
      "Theta: [-0.70804636  0.43458903  0.07396719]\n",
      "Loss in iteration 1448: 0.5004598662024747\n",
      "Theta: [-0.70842025  0.43481046  0.07396244]\n",
      "Loss in iteration 1449: 0.5004179345876661\n",
      "Theta: [-0.70879402  0.43503181  0.07395769]\n",
      "Loss in iteration 1450: 0.5003760311932767\n",
      "Theta: [-0.70916767  0.43525309  0.07395294]\n",
      "Loss in iteration 1451: 0.5003341559954567\n",
      "Theta: [-0.70954118  0.4354743   0.07394819]\n",
      "Loss in iteration 1452: 0.5002923089703807\n",
      "Theta: [-0.70991457  0.43569544  0.07394344]\n",
      "Loss in iteration 1453: 0.5002504900942454\n",
      "Theta: [-0.71028783  0.43591652  0.0739387 ]\n",
      "Loss in iteration 1454: 0.5002086993432711\n",
      "Theta: [-0.71066096  0.43613751  0.07393395]\n",
      "Loss in iteration 1455: 0.5001669366937009\n",
      "Theta: [-0.71103396  0.43635844  0.07392921]\n",
      "Loss in iteration 1456: 0.5001252021218014\n",
      "Theta: [-0.71140684  0.4365793   0.07392447]\n",
      "Loss in iteration 1457: 0.5000834956038621\n",
      "Theta: [-0.71177958  0.43680009  0.07391974]\n",
      "Loss in iteration 1458: 0.5000418171161946\n",
      "Theta: [-0.7121522   0.43702081  0.073915  ]\n",
      "Loss in iteration 1459: 0.5000001666351347\n",
      "Theta: [-0.7125247   0.43724145  0.07391027]\n",
      "Loss in iteration 1460: 0.4999585441370402\n",
      "Theta: [-0.71289706  0.43746203  0.07390553]\n",
      "Loss in iteration 1461: 0.49991694959829247\n",
      "Theta: [-0.7132693   0.43768253  0.0739008 ]\n",
      "Loss in iteration 1462: 0.4998753829952955\n",
      "Theta: [-0.71364141  0.43790297  0.07389608]\n",
      "Loss in iteration 1463: 0.499833844304476\n",
      "Theta: [-0.7140134   0.43812333  0.07389135]\n",
      "Loss in iteration 1464: 0.4997923335022839\n",
      "Theta: [-0.71438526  0.43834363  0.07388662]\n",
      "Loss in iteration 1465: 0.4997508505651917\n",
      "Theta: [-0.71475699  0.43856385  0.0738819 ]\n",
      "Loss in iteration 1466: 0.4997093954696946\n",
      "Theta: [-0.71512859  0.43878401  0.07387718]\n",
      "Loss in iteration 1467: 0.4996679681923111\n",
      "Theta: [-0.71550007  0.43900409  0.07387246]\n",
      "Loss in iteration 1468: 0.4996265687095818\n",
      "Theta: [-0.71587142  0.4392241   0.07386774]\n",
      "Loss in iteration 1469: 0.49958519699807025\n",
      "Theta: [-0.71624264  0.43944405  0.07386302]\n",
      "Loss in iteration 1470: 0.49954385303436316\n",
      "Theta: [-0.71661374  0.43966392  0.07385831]\n",
      "Loss in iteration 1471: 0.49950253679506945\n",
      "Theta: [-0.71698471  0.43988372  0.07385359]\n",
      "Loss in iteration 1472: 0.4994612482568205\n",
      "Theta: [-0.71735555  0.44010346  0.07384888]\n",
      "Loss in iteration 1473: 0.4994199873962712\n",
      "Theta: [-0.71772627  0.44032312  0.07384417]\n",
      "Loss in iteration 1474: 0.49937875419009825\n",
      "Theta: [-0.71809686  0.44054271  0.07383946]\n",
      "Loss in iteration 1475: 0.49933754861500135\n",
      "Theta: [-0.71846732  0.44076224  0.07383475]\n",
      "Loss in iteration 1476: 0.4992963706477027\n",
      "Theta: [-0.71883766  0.44098169  0.07383005]\n",
      "Loss in iteration 1477: 0.49925522026494673\n",
      "Theta: [-0.71920787  0.44120107  0.07382535]\n",
      "Loss in iteration 1478: 0.49921409744350087\n",
      "Theta: [-0.71957796  0.44142039  0.07382064]\n",
      "Loss in iteration 1479: 0.4991730021601549\n",
      "Theta: [-0.71994791  0.44163963  0.07381594]\n",
      "Loss in iteration 1480: 0.4991319343917212\n",
      "Theta: [-0.72031775  0.4418588   0.07381124]\n",
      "Loss in iteration 1481: 0.4990908941150344\n",
      "Theta: [-0.72068745  0.44207791  0.07380655]\n",
      "Loss in iteration 1482: 0.4990498813069516\n",
      "Theta: [-0.72105704  0.44229694  0.07380185]\n",
      "Loss in iteration 1483: 0.49900889594435244\n",
      "Theta: [-0.72142649  0.44251591  0.07379716]\n",
      "Loss in iteration 1484: 0.4989679380041389\n",
      "Theta: [-0.72179582  0.44273481  0.07379247]\n",
      "Loss in iteration 1485: 0.4989270074632352\n",
      "Theta: [-0.72216502  0.44295363  0.07378778]\n",
      "Loss in iteration 1486: 0.4988861042985883\n",
      "Theta: [-0.7225341   0.44317239  0.07378309]\n",
      "Loss in iteration 1487: 0.4988452284871671\n",
      "Theta: [-0.72290305  0.44339108  0.0737784 ]\n",
      "Loss in iteration 1488: 0.49880438000596294\n",
      "Theta: [-0.72327188  0.44360969  0.07377372]\n",
      "Loss in iteration 1489: 0.49876355883198953\n",
      "Theta: [-0.72364058  0.44382824  0.07376903]\n",
      "Loss in iteration 1490: 0.4987227649422827\n",
      "Theta: [-0.72400916  0.44404672  0.07376435]\n",
      "Loss in iteration 1491: 0.49868199831390064\n",
      "Theta: [-0.72437761  0.44426513  0.07375967]\n",
      "Loss in iteration 1492: 0.49864125892392364\n",
      "Theta: [-0.72474593  0.44448347  0.07375499]\n",
      "Loss in iteration 1493: 0.4986005467494545\n",
      "Theta: [-0.72511413  0.44470174  0.07375032]\n",
      "Loss in iteration 1494: 0.49855986176761763\n",
      "Theta: [-0.72548221  0.44491994  0.07374564]\n",
      "Loss in iteration 1495: 0.4985192039555602\n",
      "Theta: [-0.72585016  0.44513808  0.07374097]\n",
      "Loss in iteration 1496: 0.49847857329045114\n",
      "Theta: [-0.72621798  0.44535614  0.07373629]\n",
      "Loss in iteration 1497: 0.4984379697494814\n",
      "Theta: [-0.72658568  0.44557414  0.07373162]\n",
      "Loss in iteration 1498: 0.4983973933098643\n",
      "Theta: [-0.72695326  0.44579206  0.07372695]\n",
      "Loss in iteration 1499: 0.49835684394883534\n",
      "Theta: [-0.72732071  0.44600992  0.07372229]\n",
      "Loss in iteration 1500: 0.4983163216436518\n",
      "Theta: [-0.72768803  0.44622771  0.07371762]\n",
      "Loss in iteration 1501: 0.4982758263715926\n",
      "Theta: [-0.72805523  0.44644543  0.07371296]\n",
      "Loss in iteration 1502: 0.4982353581099596\n",
      "Theta: [-0.72842231  0.44666308  0.0737083 ]\n",
      "Loss in iteration 1503: 0.49819491683607575\n",
      "Theta: [-0.72878926  0.44688066  0.07370363]\n",
      "Loss in iteration 1504: 0.49815450252728655\n",
      "Theta: [-0.72915608  0.44709817  0.07369898]\n",
      "Loss in iteration 1505: 0.4981141151609589\n",
      "Theta: [-0.72952278  0.44731561  0.07369432]\n",
      "Loss in iteration 1506: 0.4980737547144824\n",
      "Theta: [-0.72988936  0.44753299  0.07368966]\n",
      "Loss in iteration 1507: 0.49803342116526766\n",
      "Theta: [-0.73025581  0.4477503   0.07368501]\n",
      "Loss in iteration 1508: 0.49799311449074757\n",
      "Theta: [-0.73062214  0.44796753  0.07368036]\n",
      "Loss in iteration 1509: 0.497952834668377\n",
      "Theta: [-0.73098835  0.4481847   0.0736757 ]\n",
      "Loss in iteration 1510: 0.49791258167563235\n",
      "Theta: [-0.73135443  0.4484018   0.07367105]\n",
      "Loss in iteration 1511: 0.49787235549001196\n",
      "Theta: [-0.73172038  0.44861883  0.07366641]\n",
      "Loss in iteration 1512: 0.49783215608903597\n",
      "Theta: [-0.73208621  0.4488358   0.07366176]\n",
      "Loss in iteration 1513: 0.49779198345024656\n",
      "Theta: [-0.73245192  0.44905269  0.07365712]\n",
      "Loss in iteration 1514: 0.4977518375512067\n",
      "Theta: [-0.7328175   0.44926952  0.07365247]\n",
      "Loss in iteration 1515: 0.49771171836950195\n",
      "Theta: [-0.73318296  0.44948628  0.07364783]\n",
      "Loss in iteration 1516: 0.49767162588273955\n",
      "Theta: [-0.7335483   0.44970297  0.07364319]\n",
      "Loss in iteration 1517: 0.49763156006854786\n",
      "Theta: [-0.73391351  0.44991959  0.07363855]\n",
      "Loss in iteration 1518: 0.49759152090457737\n",
      "Theta: [-0.7342786   0.45013614  0.07363392]\n",
      "Loss in iteration 1519: 0.49755150836850004\n",
      "Theta: [-0.73464356  0.45035263  0.07362928]\n",
      "Loss in iteration 1520: 0.4975115224380092\n",
      "Theta: [-0.7350084   0.45056904  0.07362465]\n",
      "Loss in iteration 1521: 0.4974715630908201\n",
      "Theta: [-0.73537312  0.45078539  0.07362002]\n",
      "Loss in iteration 1522: 0.49743163030466947\n",
      "Theta: [-0.73573772  0.45100167  0.07361539]\n",
      "Loss in iteration 1523: 0.4973917240573155\n",
      "Theta: [-0.73610219  0.45121789  0.07361076]\n",
      "Loss in iteration 1524: 0.4973518443265381\n",
      "Theta: [-0.73646653  0.45143403  0.07360613]\n",
      "Loss in iteration 1525: 0.497311991090138\n",
      "Theta: [-0.73683076  0.45165011  0.0736015 ]\n",
      "Loss in iteration 1526: 0.4972721643259385\n",
      "Theta: [-0.73719486  0.45186612  0.07359688]\n",
      "Loss in iteration 1527: 0.4972323640117833\n",
      "Theta: [-0.73755883  0.45208206  0.07359226]\n",
      "Loss in iteration 1528: 0.4971925901255381\n",
      "Theta: [-0.73792269  0.45229793  0.07358764]\n",
      "Loss in iteration 1529: 0.49715284264509\n",
      "Theta: [-0.73828642  0.45251373  0.07358302]\n",
      "Loss in iteration 1530: 0.4971131215483474\n",
      "Theta: [-0.73865003  0.45272947  0.0735784 ]\n",
      "Loss in iteration 1531: 0.49707342681324\n",
      "Theta: [-0.73901351  0.45294514  0.07357378]\n",
      "Loss in iteration 1532: 0.4970337584177188\n",
      "Theta: [-0.73937687  0.45316074  0.07356917]\n",
      "Loss in iteration 1533: 0.4969941163397562\n",
      "Theta: [-0.73974011  0.45337628  0.07356455]\n",
      "Loss in iteration 1534: 0.496954500557346\n",
      "Theta: [-0.74010323  0.45359174  0.07355994]\n",
      "Loss in iteration 1535: 0.49691491104850327\n",
      "Theta: [-0.74046622  0.45380714  0.07355533]\n",
      "Loss in iteration 1536: 0.496875347791264\n",
      "Theta: [-0.7408291   0.45402247  0.07355072]\n",
      "Loss in iteration 1537: 0.496835810763686\n",
      "Theta: [-0.74119184  0.45423773  0.07354612]\n",
      "Loss in iteration 1538: 0.49679629994384755\n",
      "Theta: [-0.74155447  0.45445293  0.07354151]\n",
      "Loss in iteration 1539: 0.4967568153098489\n",
      "Theta: [-0.74191697  0.45466806  0.07353691]\n",
      "Loss in iteration 1540: 0.49671735683981105\n",
      "Theta: [-0.74227936  0.45488312  0.0735323 ]\n",
      "Loss in iteration 1541: 0.49667792451187603\n",
      "Theta: [-0.74264161  0.45509811  0.0735277 ]\n",
      "Loss in iteration 1542: 0.4966385183042073\n",
      "Theta: [-0.74300375  0.45531304  0.0735231 ]\n",
      "Loss in iteration 1543: 0.4965991381949894\n",
      "Theta: [-0.74336577  0.4555279   0.0735185 ]\n",
      "Loss in iteration 1544: 0.4965597841624277\n",
      "Theta: [-0.74372766  0.45574269  0.07351391]\n",
      "Loss in iteration 1545: 0.4965204561847487\n",
      "Theta: [-0.74408943  0.45595741  0.07350931]\n",
      "Loss in iteration 1546: 0.49648115424020034\n",
      "Theta: [-0.74445108  0.45617207  0.07350472]\n",
      "Loss in iteration 1547: 0.49644187830705105\n",
      "Theta: [-0.7448126   0.45638666  0.07350013]\n",
      "Loss in iteration 1548: 0.49640262836359056\n",
      "Theta: [-0.74517401  0.45660118  0.07349554]\n",
      "Loss in iteration 1549: 0.49636340438812965\n",
      "Theta: [-0.74553529  0.45681564  0.07349095]\n",
      "Loss in iteration 1550: 0.4963242063589998\n",
      "Theta: [-0.74589645  0.45703003  0.07348636]\n",
      "Loss in iteration 1551: 0.4962850342545533\n",
      "Theta: [-0.74625749  0.45724435  0.07348178]\n",
      "Loss in iteration 1552: 0.49624588805316416\n",
      "Theta: [-0.7466184   0.4574586   0.07347719]\n",
      "Loss in iteration 1553: 0.4962067677332261\n",
      "Theta: [-0.7469792   0.45767279  0.07347261]\n",
      "Loss in iteration 1554: 0.4961676732731549\n",
      "Theta: [-0.74733987  0.45788691  0.07346803]\n",
      "Loss in iteration 1555: 0.49612860465138636\n",
      "Theta: [-0.74770043  0.45810096  0.07346345]\n",
      "Loss in iteration 1556: 0.49608956184637754\n",
      "Theta: [-0.74806086  0.45831495  0.07345887]\n",
      "Loss in iteration 1557: 0.49605054483660593\n",
      "Theta: [-0.74842117  0.45852887  0.07345429]\n",
      "Loss in iteration 1558: 0.49601155360057014\n",
      "Theta: [-0.74878135  0.45874272  0.07344972]\n",
      "Loss in iteration 1559: 0.49597258811678957\n",
      "Theta: [-0.74914142  0.45895651  0.07344514]\n",
      "Loss in iteration 1560: 0.49593364836380405\n",
      "Theta: [-0.74950137  0.45917023  0.07344057]\n",
      "Loss in iteration 1561: 0.49589473432017445\n",
      "Theta: [-0.74986119  0.45938388  0.073436  ]\n",
      "Loss in iteration 1562: 0.49585584596448223\n",
      "Theta: [-0.75022089  0.45959747  0.07343143]\n",
      "Loss in iteration 1563: 0.4958169832753294\n",
      "Theta: [-0.75058048  0.45981099  0.07342686]\n",
      "Loss in iteration 1564: 0.495778146231339\n",
      "Theta: [-0.75093994  0.46002444  0.0734223 ]\n",
      "Loss in iteration 1565: 0.49573933481115423\n",
      "Theta: [-0.75129928  0.46023783  0.07341773]\n",
      "Loss in iteration 1566: 0.4957005489934393\n",
      "Theta: [-0.7516585   0.46045115  0.07341317]\n",
      "Loss in iteration 1567: 0.4956617887568789\n",
      "Theta: [-0.7520176   0.4606644   0.07340861]\n",
      "Loss in iteration 1568: 0.49562305408017804\n",
      "Theta: [-0.75237657  0.46087759  0.07340405]\n",
      "Loss in iteration 1569: 0.49558434494206294\n",
      "Theta: [-0.75273543  0.46109071  0.07339949]\n",
      "Loss in iteration 1570: 0.49554566132127953\n",
      "Theta: [-0.75309417  0.46130377  0.07339493]\n",
      "Loss in iteration 1571: 0.4955070031965951\n",
      "Theta: [-0.75345278  0.46151676  0.07339037]\n",
      "Loss in iteration 1572: 0.4954683705467965\n",
      "Theta: [-0.75381128  0.46172968  0.07338582]\n",
      "Loss in iteration 1573: 0.49542976335069205\n",
      "Theta: [-0.75416965  0.46194253  0.07338126]\n",
      "Loss in iteration 1574: 0.4953911815871097\n",
      "Theta: [-0.75452791  0.46215532  0.07337671]\n",
      "Loss in iteration 1575: 0.4953526252348982\n",
      "Theta: [-0.75488604  0.46236805  0.07337216]\n",
      "Loss in iteration 1576: 0.49531409427292694\n",
      "Theta: [-0.75524406  0.4625807   0.07336761]\n",
      "Loss in iteration 1577: 0.4952755886800854\n",
      "Theta: [-0.75560195  0.46279329  0.07336307]\n",
      "Loss in iteration 1578: 0.4952371084352831\n",
      "Theta: [-0.75595972  0.46300582  0.07335852]\n",
      "Loss in iteration 1579: 0.4951986535174509\n",
      "Theta: [-0.75631738  0.46321828  0.07335398]\n",
      "Loss in iteration 1580: 0.49516022390553877\n",
      "Theta: [-0.75667491  0.46343067  0.07334943]\n",
      "Loss in iteration 1581: 0.49512181957851803\n",
      "Theta: [-0.75703232  0.463643    0.07334489]\n",
      "Loss in iteration 1582: 0.49508344051537967\n",
      "Theta: [-0.75738962  0.46385526  0.07334035]\n",
      "Loss in iteration 1583: 0.4950450866951354\n",
      "Theta: [-0.75774679  0.46406746  0.07333581]\n",
      "Loss in iteration 1584: 0.49500675809681643\n",
      "Theta: [-0.75810385  0.46427959  0.07333128]\n",
      "Loss in iteration 1585: 0.49496845469947504\n",
      "Theta: [-0.75846078  0.46449165  0.07332674]\n",
      "Loss in iteration 1586: 0.49493017648218335\n",
      "Theta: [-0.75881759  0.46470365  0.07332221]\n",
      "Loss in iteration 1587: 0.4948919234240337\n",
      "Theta: [-0.75917429  0.46491558  0.07331767]\n",
      "Loss in iteration 1588: 0.49485369550413855\n",
      "Theta: [-0.75953086  0.46512745  0.07331314]\n",
      "Loss in iteration 1589: 0.4948154927016304\n",
      "Theta: [-0.75988732  0.46533925  0.07330861]\n",
      "Loss in iteration 1590: 0.494777314995662\n",
      "Theta: [-0.76024366  0.46555098  0.07330408]\n",
      "Loss in iteration 1591: 0.49473916236540644\n",
      "Theta: [-0.76059987  0.46576265  0.07329956]\n",
      "Loss in iteration 1592: 0.4947010347900565\n",
      "Theta: [-0.76095597  0.46597426  0.07329503]\n",
      "Loss in iteration 1593: 0.4946629322488254\n",
      "Theta: [-0.76131195  0.4661858   0.07329051]\n",
      "Loss in iteration 1594: 0.49462485472094586\n",
      "Theta: [-0.76166781  0.46639727  0.07328598]\n",
      "Loss in iteration 1595: 0.49458680218567125\n",
      "Theta: [-0.76202355  0.46660868  0.07328146]\n",
      "Loss in iteration 1596: 0.49454877462227437\n",
      "Theta: [-0.76237917  0.46682002  0.07327694]\n",
      "Loss in iteration 1597: 0.4945107720100485\n",
      "Theta: [-0.76273467  0.4670313   0.07327242]\n",
      "Loss in iteration 1598: 0.49447279432830654\n",
      "Theta: [-0.76309005  0.46724251  0.0732679 ]\n",
      "Loss in iteration 1599: 0.49443484155638173\n",
      "Theta: [-0.76344532  0.46745365  0.07326339]\n",
      "Loss in iteration 1600: 0.49439691367362654\n",
      "Theta: [-0.76380046  0.46766474  0.07325887]\n",
      "Loss in iteration 1601: 0.49435901065941407\n",
      "Theta: [-0.76415549  0.46787575  0.07325436]\n",
      "Loss in iteration 1602: 0.4943211324931369\n",
      "Theta: [-0.76451039  0.4680867   0.07324985]\n",
      "Loss in iteration 1603: 0.4942832791542075\n",
      "Theta: [-0.76486518  0.46829759  0.07324534]\n",
      "Loss in iteration 1604: 0.4942454506220583\n",
      "Theta: [-0.76521985  0.46850841  0.07324083]\n",
      "Loss in iteration 1605: 0.49420764687614155\n",
      "Theta: [-0.7655744   0.46871916  0.07323632]\n",
      "Loss in iteration 1606: 0.4941698678959288\n",
      "Theta: [-0.76592884  0.46892985  0.07323182]\n",
      "Loss in iteration 1607: 0.4941321136609125\n",
      "Theta: [-0.76628315  0.46914048  0.07322731]\n",
      "Loss in iteration 1608: 0.4940943841506038\n",
      "Theta: [-0.76663735  0.46935104  0.07322281]\n",
      "Loss in iteration 1609: 0.49405667934453396\n",
      "Theta: [-0.76699142  0.46956153  0.07321831]\n",
      "Loss in iteration 1610: 0.4940189992222542\n",
      "Theta: [-0.76734538  0.46977197  0.07321381]\n",
      "Loss in iteration 1611: 0.49398134376333486\n",
      "Theta: [-0.76769922  0.46998233  0.07320931]\n",
      "Loss in iteration 1612: 0.49394371294736655\n",
      "Theta: [-0.76805295  0.47019263  0.07320481]\n",
      "Loss in iteration 1613: 0.49390610675395924\n",
      "Theta: [-0.76840655  0.47040287  0.07320031]\n",
      "Loss in iteration 1614: 0.4938685251627426\n",
      "Theta: [-0.76876004  0.47061304  0.07319582]\n",
      "Loss in iteration 1615: 0.493830968153366\n",
      "Theta: [-0.76911341  0.47082314  0.07319132]\n",
      "Loss in iteration 1616: 0.493793435705498\n",
      "Theta: [-0.76946666  0.47103319  0.07318683]\n",
      "Loss in iteration 1617: 0.4937559277988274\n",
      "Theta: [-0.76981979  0.47124316  0.07318234]\n",
      "Loss in iteration 1618: 0.49371844441306195\n",
      "Theta: [-0.77017281  0.47145308  0.07317785]\n",
      "Loss in iteration 1619: 0.49368098552792966\n",
      "Theta: [-0.7705257   0.47166292  0.07317336]\n",
      "Loss in iteration 1620: 0.4936435511231771\n",
      "Theta: [-0.77087848  0.47187271  0.07316888]\n",
      "Loss in iteration 1621: 0.4936061411785711\n",
      "Theta: [-0.77123114  0.47208242  0.07316439]\n",
      "Loss in iteration 1622: 0.4935687556738977\n",
      "Theta: [-0.77158369  0.47229208  0.07315991]\n",
      "Loss in iteration 1623: 0.4935313945889623\n",
      "Theta: [-0.77193611  0.47250167  0.07315543]\n",
      "Loss in iteration 1624: 0.49349405790359\n",
      "Theta: [-0.77228842  0.47271119  0.07315094]\n",
      "Loss in iteration 1625: 0.49345674559762515\n",
      "Theta: [-0.77264061  0.47292065  0.07314646]\n",
      "Loss in iteration 1626: 0.4934194576509314\n",
      "Theta: [-0.77299269  0.47313005  0.07314199]\n",
      "Loss in iteration 1627: 0.4933821940433921\n",
      "Theta: [-0.77334465  0.47333938  0.07313751]\n",
      "Loss in iteration 1628: 0.49334495475490947\n",
      "Theta: [-0.77369648  0.47354865  0.07313303]\n",
      "Loss in iteration 1629: 0.493307739765406\n",
      "Theta: [-0.77404821  0.47375786  0.07312856]\n",
      "Loss in iteration 1630: 0.4932705490548219\n",
      "Theta: [-0.77439981  0.47396699  0.07312408]\n",
      "Loss in iteration 1631: 0.49323338260311844\n",
      "Theta: [-0.7747513   0.47417607  0.07311961]\n",
      "Loss in iteration 1632: 0.4931962403902752\n",
      "Theta: [-0.77510267  0.47438508  0.07311514]\n",
      "Loss in iteration 1633: 0.4931591223962911\n",
      "Theta: [-0.77545393  0.47459403  0.07311067]\n",
      "Loss in iteration 1634: 0.49312202860118437\n",
      "Theta: [-0.77580506  0.47480291  0.07310621]\n",
      "Loss in iteration 1635: 0.4930849589849927\n",
      "Theta: [-0.77615608  0.47501173  0.07310174]\n",
      "Loss in iteration 1636: 0.49304791352777255\n",
      "Theta: [-0.77650699  0.47522048  0.07309727]\n",
      "Loss in iteration 1637: 0.49301089220959987\n",
      "Theta: [-0.77685777  0.47542918  0.07309281]\n",
      "Loss in iteration 1638: 0.4929738950105696\n",
      "Theta: [-0.77720844  0.4756378   0.07308835]\n",
      "Loss in iteration 1639: 0.49293692191079636\n",
      "Theta: [-0.777559    0.47584637  0.07308389]\n",
      "Loss in iteration 1640: 0.4928999728904129\n",
      "Theta: [-0.77790943  0.47605486  0.07307943]\n",
      "Loss in iteration 1641: 0.4928630479295718\n",
      "Theta: [-0.77825975  0.4762633   0.07307497]\n",
      "Loss in iteration 1642: 0.4928261470084447\n",
      "Theta: [-0.77860996  0.47647167  0.07307051]\n",
      "Loss in iteration 1643: 0.49278927010722207\n",
      "Theta: [-0.77896004  0.47667998  0.07306605]\n",
      "Loss in iteration 1644: 0.49275241720611357\n",
      "Theta: [-0.77931001  0.47688822  0.0730616 ]\n",
      "Loss in iteration 1645: 0.4927155882853477\n",
      "Theta: [-0.77965987  0.4770964   0.07305715]\n",
      "Loss in iteration 1646: 0.49267878332517234\n",
      "Theta: [-0.78000961  0.47730452  0.0730527 ]\n",
      "Loss in iteration 1647: 0.4926420023058538\n",
      "Theta: [-0.78035923  0.47751257  0.07304824]\n",
      "Loss in iteration 1648: 0.4926052452076779\n",
      "Theta: [-0.78070874  0.47772056  0.0730438 ]\n",
      "Loss in iteration 1649: 0.49256851201094926\n",
      "Theta: [-0.78105813  0.47792849  0.07303935]\n",
      "Loss in iteration 1650: 0.4925318026959912\n",
      "Theta: [-0.7814074   0.47813635  0.0730349 ]\n",
      "Loss in iteration 1651: 0.492495117243146\n",
      "Theta: [-0.78175656  0.47834415  0.07303046]\n",
      "Loss in iteration 1652: 0.4924584556327752\n",
      "Theta: [-0.7821056   0.47855189  0.07302601]\n",
      "Loss in iteration 1653: 0.49242181784525874\n",
      "Theta: [-0.78245452  0.47875956  0.07302157]\n",
      "Loss in iteration 1654: 0.4923852038609957\n",
      "Theta: [-0.78280334  0.47896717  0.07301713]\n",
      "Loss in iteration 1655: 0.4923486136604041\n",
      "Theta: [-0.78315203  0.47917471  0.07301269]\n",
      "Loss in iteration 1656: 0.49231204722392036\n",
      "Theta: [-0.78350061  0.47938219  0.07300825]\n",
      "Loss in iteration 1657: 0.492275504532\n",
      "Theta: [-0.78384907  0.47958961  0.07300381]\n",
      "Loss in iteration 1658: 0.4922389855651172\n",
      "Theta: [-0.78419742  0.47979697  0.07299937]\n",
      "Loss in iteration 1659: 0.49220249030376495\n",
      "Theta: [-0.78454565  0.48000426  0.07299494]\n",
      "Loss in iteration 1660: 0.49216601872845495\n",
      "Theta: [-0.78489377  0.48021149  0.07299051]\n",
      "Loss in iteration 1661: 0.49212957081971775\n",
      "Theta: [-0.78524177  0.48041865  0.07298607]\n",
      "Loss in iteration 1662: 0.4920931465581023\n",
      "Theta: [-0.78558966  0.48062576  0.07298164]\n",
      "Loss in iteration 1663: 0.4920567459241766\n",
      "Theta: [-0.78593743  0.4808328   0.07297721]\n",
      "Loss in iteration 1664: 0.49202036889852685\n",
      "Theta: [-0.78628508  0.48103977  0.07297278]\n",
      "Loss in iteration 1665: 0.49198401546175835\n",
      "Theta: [-0.78663262  0.48124669  0.07296836]\n",
      "Loss in iteration 1666: 0.49194768559449487\n",
      "Theta: [-0.78698005  0.48145354  0.07296393]\n",
      "Loss in iteration 1667: 0.4919113792773788\n",
      "Theta: [-0.78732736  0.48166033  0.07295951]\n",
      "Loss in iteration 1668: 0.4918750964910707\n",
      "Theta: [-0.78767455  0.48186705  0.07295508]\n",
      "Loss in iteration 1669: 0.4918388372162505\n",
      "Theta: [-0.78802163  0.48207371  0.07295066]\n",
      "Loss in iteration 1670: 0.491802601433616\n",
      "Theta: [-0.7883686   0.48228031  0.07294624]\n",
      "Loss in iteration 1671: 0.49176638912388376\n",
      "Theta: [-0.78871545  0.48248685  0.07294182]\n",
      "Loss in iteration 1672: 0.49173020026778863\n",
      "Theta: [-0.78906218  0.48269332  0.0729374 ]\n",
      "Loss in iteration 1673: 0.49169403484608465\n",
      "Theta: [-0.7894088   0.48289973  0.07293299]\n",
      "Loss in iteration 1674: 0.4916578928395437\n",
      "Theta: [-0.78975531  0.48310608  0.07292857]\n",
      "Loss in iteration 1675: 0.49162177422895587\n",
      "Theta: [-0.7901017   0.48331237  0.07292415]\n",
      "Loss in iteration 1676: 0.4915856789951305\n",
      "Theta: [-0.79044798  0.48351859  0.07291974]\n",
      "Loss in iteration 1677: 0.4915496071188948\n",
      "Theta: [-0.79079414  0.48372475  0.07291533]\n",
      "Loss in iteration 1678: 0.49151355858109425\n",
      "Theta: [-0.79114019  0.48393085  0.07291092]\n",
      "Loss in iteration 1679: 0.49147753336259314\n",
      "Theta: [-0.79148612  0.48413688  0.07290651]\n",
      "Loss in iteration 1680: 0.491441531444274\n",
      "Theta: [-0.79183194  0.48434285  0.0729021 ]\n",
      "Loss in iteration 1681: 0.49140555280703757\n",
      "Theta: [-0.79217764  0.48454876  0.07289769]\n",
      "Loss in iteration 1682: 0.49136959743180275\n",
      "Theta: [-0.79252323  0.48475461  0.07289329]\n",
      "Loss in iteration 1683: 0.4913336652995072\n",
      "Theta: [-0.79286871  0.48496039  0.07288888]\n",
      "Loss in iteration 1684: 0.4912977563911064\n",
      "Theta: [-0.79321407  0.48516612  0.07288448]\n",
      "Loss in iteration 1685: 0.49126187068757443\n",
      "Theta: [-0.79355932  0.48537178  0.07288008]\n",
      "Loss in iteration 1686: 0.4912260081699036\n",
      "Theta: [-0.79390445  0.48557738  0.07287568]\n",
      "Loss in iteration 1687: 0.4911901688191039\n",
      "Theta: [-0.79424947  0.48578291  0.07287128]\n",
      "Loss in iteration 1688: 0.49115435261620427\n",
      "Theta: [-0.79459438  0.48598839  0.07286688]\n",
      "Loss in iteration 1689: 0.4911185595422515\n",
      "Theta: [-0.79493917  0.4861938   0.07286248]\n",
      "Loss in iteration 1690: 0.4910827895783105\n",
      "Theta: [-0.79528385  0.48639915  0.07285809]\n",
      "Loss in iteration 1691: 0.4910470427054644\n",
      "Theta: [-0.79562842  0.48660443  0.07285369]\n",
      "Loss in iteration 1692: 0.49101131890481475\n",
      "Theta: [-0.79597287  0.48680966  0.0728493 ]\n",
      "Loss in iteration 1693: 0.49097561815748036\n",
      "Theta: [-0.7963172   0.48701482  0.07284491]\n",
      "Loss in iteration 1694: 0.4909399404445991\n",
      "Theta: [-0.79666143  0.48721992  0.07284052]\n",
      "Loss in iteration 1695: 0.4909042857473264\n",
      "Theta: [-0.79700554  0.48742496  0.07283613]\n",
      "Loss in iteration 1696: 0.4908686540468358\n",
      "Theta: [-0.79734954  0.48762994  0.07283174]\n",
      "Loss in iteration 1697: 0.49083304532431926\n",
      "Theta: [-0.79769342  0.48783485  0.07282735]\n",
      "Loss in iteration 1698: 0.4907974595609859\n",
      "Theta: [-0.79803719  0.4880397   0.07282297]\n",
      "Loss in iteration 1699: 0.4907618967380638\n",
      "Theta: [-0.79838085  0.4882445   0.07281858]\n",
      "Loss in iteration 1700: 0.49072635683679855\n",
      "Theta: [-0.79872439  0.48844922  0.0728142 ]\n",
      "Loss in iteration 1701: 0.4906908398384536\n",
      "Theta: [-0.79906782  0.48865389  0.07280982]\n",
      "Loss in iteration 1702: 0.4906553457243106\n",
      "Theta: [-0.79941114  0.4888585   0.07280543]\n",
      "Loss in iteration 1703: 0.4906198744756691\n",
      "Theta: [-0.79975434  0.48906304  0.07280105]\n",
      "Loss in iteration 1704: 0.49058442607384634\n",
      "Theta: [-0.80009743  0.48926752  0.07279668]\n",
      "Loss in iteration 1705: 0.49054900050017786\n",
      "Theta: [-0.80044041  0.48947194  0.0727923 ]\n",
      "Loss in iteration 1706: 0.49051359773601666\n",
      "Theta: [-0.80078327  0.4896763   0.07278792]\n",
      "Loss in iteration 1707: 0.4904782177627336\n",
      "Theta: [-0.80112603  0.4898806   0.07278355]\n",
      "Loss in iteration 1708: 0.4904428605617177\n",
      "Theta: [-0.80146867  0.49008484  0.07277917]\n",
      "Loss in iteration 1709: 0.4904075261143756\n",
      "Theta: [-0.80181119  0.49028901  0.0727748 ]\n",
      "Loss in iteration 1710: 0.49037221440213175\n",
      "Theta: [-0.80215361  0.49049312  0.07277043]\n",
      "Loss in iteration 1711: 0.4903369254064285\n",
      "Theta: [-0.80249591  0.49069717  0.07276606]\n",
      "Loss in iteration 1712: 0.49030165910872575\n",
      "Theta: [-0.8028381   0.49090116  0.07276169]\n",
      "Loss in iteration 1713: 0.4902664154905013\n",
      "Theta: [-0.80318017  0.49110509  0.07275732]\n",
      "Loss in iteration 1714: 0.49023119453325054\n",
      "Theta: [-0.80352214  0.49130896  0.07275296]\n",
      "Loss in iteration 1715: 0.4901959962184867\n",
      "Theta: [-0.80386399  0.49151276  0.07274859]\n",
      "Loss in iteration 1716: 0.4901608205277409\n",
      "Theta: [-0.80420573  0.49171651  0.07274423]\n",
      "Loss in iteration 1717: 0.49012566744256136\n",
      "Theta: [-0.80454735  0.49192019  0.07273986]\n",
      "Loss in iteration 1718: 0.4900905369445144\n",
      "Theta: [-0.80488887  0.49212381  0.0727355 ]\n",
      "Loss in iteration 1719: 0.4900554290151839\n",
      "Theta: [-0.80523027  0.49232737  0.07273114]\n",
      "Loss in iteration 1720: 0.490020343636171\n",
      "Theta: [-0.80557156  0.49253087  0.07272678]\n",
      "Loss in iteration 1721: 0.4899852807890953\n",
      "Theta: [-0.80591274  0.49273431  0.07272242]\n",
      "Loss in iteration 1722: 0.4899502404555931\n",
      "Theta: [-0.8062538   0.49293768  0.07271807]\n",
      "Loss in iteration 1723: 0.48991522261731874\n",
      "Theta: [-0.80659475  0.493141    0.07271371]\n",
      "Loss in iteration 1724: 0.4898802272559438\n",
      "Theta: [-0.8069356   0.49334425  0.07270936]\n",
      "Loss in iteration 1725: 0.4898452543531577\n",
      "Theta: [-0.80727633  0.49354745  0.072705  ]\n",
      "Loss in iteration 1726: 0.48981030389066704\n",
      "Theta: [-0.80761694  0.49375058  0.07270065]\n",
      "Loss in iteration 1727: 0.4897753758501963\n",
      "Theta: [-0.80795745  0.49395365  0.0726963 ]\n",
      "Loss in iteration 1728: 0.48974047021348704\n",
      "Theta: [-0.80829784  0.49415666  0.07269195]\n",
      "Loss in iteration 1729: 0.4897055869622987\n",
      "Theta: [-0.80863813  0.49435961  0.0726876 ]\n",
      "Loss in iteration 1730: 0.4896707260784076\n",
      "Theta: [-0.8089783   0.4945625   0.07268325]\n",
      "Loss in iteration 1731: 0.48963588754360815\n",
      "Theta: [-0.80931836  0.49476533  0.07267891]\n",
      "Loss in iteration 1732: 0.4896010713397114\n",
      "Theta: [-0.8096583   0.4949681   0.07267456]\n",
      "Loss in iteration 1733: 0.4895662774485466\n",
      "Theta: [-0.80999814  0.4951708   0.07267022]\n",
      "Loss in iteration 1734: 0.4895315058519595\n",
      "Theta: [-0.81033787  0.49537345  0.07266587]\n",
      "Loss in iteration 1735: 0.489496756531814\n",
      "Theta: [-0.81067748  0.49557603  0.07266153]\n",
      "Loss in iteration 1736: 0.489462029469991\n",
      "Theta: [-0.81101698  0.49577856  0.07265719]\n",
      "Loss in iteration 1737: 0.4894273246483884\n",
      "Theta: [-0.81135637  0.49598102  0.07265285]\n",
      "Loss in iteration 1738: 0.4893926420489219\n",
      "Theta: [-0.81169565  0.49618343  0.07264851]\n",
      "Loss in iteration 1739: 0.48935798165352423\n",
      "Theta: [-0.81203482  0.49638577  0.07264418]\n",
      "Loss in iteration 1740: 0.48932334344414535\n",
      "Theta: [-0.81237388  0.49658805  0.07263984]\n",
      "Loss in iteration 1741: 0.48928872740275237\n",
      "Theta: [-0.81271283  0.49679027  0.0726355 ]\n",
      "Loss in iteration 1742: 0.4892541335113302\n",
      "Theta: [-0.81305166  0.49699243  0.07263117]\n",
      "Loss in iteration 1743: 0.4892195617518802\n",
      "Theta: [-0.81339039  0.49719453  0.07262684]\n",
      "Loss in iteration 1744: 0.4891850121064213\n",
      "Theta: [-0.813729    0.49739657  0.07262251]\n",
      "Loss in iteration 1745: 0.4891504845569895\n",
      "Theta: [-0.8140675   0.49759855  0.07261818]\n",
      "Loss in iteration 1746: 0.4891159790856381\n",
      "Theta: [-0.8144059   0.49780047  0.07261385]\n",
      "Loss in iteration 1747: 0.4890814956744373\n",
      "Theta: [-0.81474418  0.49800233  0.07260952]\n",
      "Loss in iteration 1748: 0.4890470343054746\n",
      "Theta: [-0.81508235  0.49820413  0.07260519]\n",
      "Loss in iteration 1749: 0.4890125949608546\n",
      "Theta: [-0.81542041  0.49840587  0.07260087]\n",
      "Loss in iteration 1750: 0.4889781776226988\n",
      "Theta: [-0.81575836  0.49860755  0.07259654]\n",
      "Loss in iteration 1751: 0.4889437822731459\n",
      "Theta: [-0.8160962   0.49880917  0.07259222]\n",
      "Loss in iteration 1752: 0.4889094088943519\n",
      "Theta: [-0.81643393  0.49901072  0.0725879 ]\n",
      "Loss in iteration 1753: 0.48887505746848914\n",
      "Theta: [-0.81677154  0.49921222  0.07258357]\n",
      "Loss in iteration 1754: 0.48884072797774764\n",
      "Theta: [-0.81710905  0.49941366  0.07257925]\n",
      "Loss in iteration 1755: 0.4888064204043341\n",
      "Theta: [-0.81744645  0.49961504  0.07257494]\n",
      "Loss in iteration 1756: 0.48877213473047226\n",
      "Theta: [-0.81778374  0.49981635  0.07257062]\n",
      "Loss in iteration 1757: 0.48873787093840293\n",
      "Theta: [-0.81812091  0.50001761  0.0725663 ]\n",
      "Loss in iteration 1758: 0.48870362901038367\n",
      "Theta: [-0.81845798  0.50021881  0.07256198]\n",
      "Loss in iteration 1759: 0.4886694089286889\n",
      "Theta: [-0.81879494  0.50041995  0.07255767]\n",
      "Loss in iteration 1760: 0.48863521067561033\n",
      "Theta: [-0.81913178  0.50062102  0.07255336]\n",
      "Loss in iteration 1761: 0.48860103423345613\n",
      "Theta: [-0.81946852  0.50082204  0.07254904]\n",
      "Loss in iteration 1762: 0.48856687958455153\n",
      "Theta: [-0.81980515  0.501023    0.07254473]\n",
      "Loss in iteration 1763: 0.48853274671123864\n",
      "Theta: [-0.82014167  0.5012239   0.07254042]\n",
      "Loss in iteration 1764: 0.4884986355958765\n",
      "Theta: [-0.82047807  0.50142474  0.07253611]\n",
      "Loss in iteration 1765: 0.48846454622084073\n",
      "Theta: [-0.82081437  0.50162551  0.07253181]\n",
      "Loss in iteration 1766: 0.48843047856852384\n",
      "Theta: [-0.82115056  0.50182623  0.0725275 ]\n",
      "Loss in iteration 1767: 0.48839643262133514\n",
      "Theta: [-0.82148664  0.50202689  0.07252319]\n",
      "Loss in iteration 1768: 0.4883624083617009\n",
      "Theta: [-0.8218226   0.50222749  0.07251889]\n",
      "Loss in iteration 1769: 0.4883284057720637\n",
      "Theta: [-0.82215846  0.50242803  0.07251459]\n",
      "Loss in iteration 1770: 0.48829442483488333\n",
      "Theta: [-0.82249421  0.50262851  0.07251028]\n",
      "Loss in iteration 1771: 0.48826046553263597\n",
      "Theta: [-0.82282985  0.50282893  0.07250598]\n",
      "Loss in iteration 1772: 0.48822652784781445\n",
      "Theta: [-0.82316538  0.50302929  0.07250168]\n",
      "Loss in iteration 1773: 0.48819261176292855\n",
      "Theta: [-0.82350081  0.5032296   0.07249738]\n",
      "Loss in iteration 1774: 0.48815871726050475\n",
      "Theta: [-0.82383612  0.50342984  0.07249309]\n",
      "Loss in iteration 1775: 0.48812484432308595\n",
      "Theta: [-0.82417132  0.50363002  0.07248879]\n",
      "Loss in iteration 1776: 0.48809099293323166\n",
      "Theta: [-0.82450641  0.50383014  0.07248449]\n",
      "Loss in iteration 1777: 0.4880571630735181\n",
      "Theta: [-0.8248414   0.50403021  0.0724802 ]\n",
      "Loss in iteration 1778: 0.488023354726538\n",
      "Theta: [-0.82517627  0.50423021  0.07247591]\n",
      "Loss in iteration 1779: 0.487989567874901\n",
      "Theta: [-0.82551104  0.50443016  0.07247161]\n",
      "Loss in iteration 1780: 0.48795580250123277\n",
      "Theta: [-0.8258457   0.50463004  0.07246732]\n",
      "Loss in iteration 1781: 0.48792205858817594\n",
      "Theta: [-0.82618025  0.50482987  0.07246303]\n",
      "Loss in iteration 1782: 0.4878883361183896\n",
      "Theta: [-0.82651468  0.50502964  0.07245874]\n",
      "Loss in iteration 1783: 0.4878546350745491\n",
      "Theta: [-0.82684902  0.50522935  0.07245445]\n",
      "Loss in iteration 1784: 0.4878209554393465\n",
      "Theta: [-0.82718324  0.505429    0.07245017]\n",
      "Loss in iteration 1785: 0.48778729719549024\n",
      "Theta: [-0.82751735  0.50562859  0.07244588]\n",
      "Loss in iteration 1786: 0.4877536603257054\n",
      "Theta: [-0.82785136  0.50582812  0.0724416 ]\n",
      "Loss in iteration 1787: 0.4877200448127333\n",
      "Theta: [-0.82818525  0.50602759  0.07243731]\n",
      "Loss in iteration 1788: 0.4876864506393317\n",
      "Theta: [-0.82851904  0.506227    0.07243303]\n",
      "Loss in iteration 1789: 0.48765287778827504\n",
      "Theta: [-0.82885272  0.50642635  0.07242875]\n",
      "Loss in iteration 1790: 0.48761932624235355\n",
      "Theta: [-0.82918629  0.50662565  0.07242447]\n",
      "Loss in iteration 1791: 0.48758579598437457\n",
      "Theta: [-0.82951975  0.50682489  0.07242019]\n",
      "Loss in iteration 1792: 0.48755228699716135\n",
      "Theta: [-0.8298531   0.50702406  0.07241591]\n",
      "Loss in iteration 1793: 0.48751879926355346\n",
      "Theta: [-0.83018635  0.50722318  0.07241163]\n",
      "Loss in iteration 1794: 0.4874853327664069\n",
      "Theta: [-0.83051949  0.50742224  0.07240736]\n",
      "Loss in iteration 1795: 0.4874518874885939\n",
      "Theta: [-0.83085251  0.50762124  0.07240308]\n",
      "Loss in iteration 1796: 0.4874184634130034\n",
      "Theta: [-0.83118543  0.50782018  0.07239881]\n",
      "Loss in iteration 1797: 0.48738506052253994\n",
      "Theta: [-0.83151825  0.50801906  0.07239454]\n",
      "Loss in iteration 1798: 0.4873516788001248\n",
      "Theta: [-0.83185095  0.50821789  0.07239026]\n",
      "Loss in iteration 1799: 0.48731831822869537\n",
      "Theta: [-0.83218355  0.50841665  0.07238599]\n",
      "Loss in iteration 1800: 0.487284978791205\n",
      "Theta: [-0.83251604  0.50861536  0.07238172]\n",
      "Loss in iteration 1801: 0.48725166047062374\n",
      "Theta: [-0.83284842  0.50881401  0.07237745]\n",
      "Loss in iteration 1802: 0.4872183632499375\n",
      "Theta: [-0.83318069  0.5090126   0.07237319]\n",
      "Loss in iteration 1803: 0.48718508711214836\n",
      "Theta: [-0.83351286  0.50921113  0.07236892]\n",
      "Loss in iteration 1804: 0.48715183204027457\n",
      "Theta: [-0.83384491  0.5094096   0.07236465]\n",
      "Loss in iteration 1805: 0.48711859801735075\n",
      "Theta: [-0.83417686  0.50960801  0.07236039]\n",
      "Loss in iteration 1806: 0.48708538502642734\n",
      "Theta: [-0.8345087   0.50980637  0.07235613]\n",
      "Loss in iteration 1807: 0.48705219305057107\n",
      "Theta: [-0.83484044  0.51000467  0.07235186]\n",
      "Loss in iteration 1808: 0.4870190220728645\n",
      "Theta: [-0.83517207  0.51020291  0.0723476 ]\n",
      "Loss in iteration 1809: 0.4869858720764067\n",
      "Theta: [-0.83550359  0.51040109  0.07234334]\n",
      "Loss in iteration 1810: 0.48695274304431235\n",
      "Theta: [-0.835835    0.51059921  0.07233908]\n",
      "Loss in iteration 1811: 0.48691963495971274\n",
      "Theta: [-0.8361663   0.51079727  0.07233482]\n",
      "Loss in iteration 1812: 0.48688654780575435\n",
      "Theta: [-0.8364975   0.51099528  0.07233057]\n",
      "Loss in iteration 1813: 0.48685348156560054\n",
      "Theta: [-0.83682859  0.51119322  0.07232631]\n",
      "Loss in iteration 1814: 0.48682043622242976\n",
      "Theta: [-0.83715957  0.51139111  0.07232206]\n",
      "Loss in iteration 1815: 0.48678741175943735\n",
      "Theta: [-0.83749045  0.51158894  0.0723178 ]\n",
      "Loss in iteration 1816: 0.4867544081598341\n",
      "Theta: [-0.83782122  0.51178671  0.07231355]\n",
      "Loss in iteration 1817: 0.48672142540684654\n",
      "Theta: [-0.83815188  0.51198443  0.0723093 ]\n",
      "Loss in iteration 1818: 0.4866884634837176\n",
      "Theta: [-0.83848243  0.51218208  0.07230504]\n",
      "Loss in iteration 1819: 0.4866555223737059\n",
      "Theta: [-0.83881288  0.51237968  0.07230079]\n",
      "Loss in iteration 1820: 0.48662260206008595\n",
      "Theta: [-0.83914322  0.51257722  0.07229655]\n",
      "Loss in iteration 1821: 0.4865897025261482\n",
      "Theta: [-0.83947345  0.5127747   0.0722923 ]\n",
      "Loss in iteration 1822: 0.4865568237551988\n",
      "Theta: [-0.83980358  0.51297212  0.07228805]\n",
      "Loss in iteration 1823: 0.48652396573055995\n",
      "Theta: [-0.8401336   0.51316949  0.07228381]\n",
      "Loss in iteration 1824: 0.4864911284355694\n",
      "Theta: [-0.84046351  0.5133668   0.07227956]\n",
      "Loss in iteration 1825: 0.48645831185358096\n",
      "Theta: [-0.84079332  0.51356405  0.07227532]\n",
      "Loss in iteration 1826: 0.4864255159679641\n",
      "Theta: [-0.84112302  0.51376124  0.07227107]\n",
      "Loss in iteration 1827: 0.48639274076210426\n",
      "Theta: [-0.84145261  0.51395837  0.07226683]\n",
      "Loss in iteration 1828: 0.4863599862194024\n",
      "Theta: [-0.8417821   0.51415545  0.07226259]\n",
      "Loss in iteration 1829: 0.4863272523232752\n",
      "Theta: [-0.84211148  0.51435247  0.07225835]\n",
      "Loss in iteration 1830: 0.48629453905715536\n",
      "Theta: [-0.84244076  0.51454943  0.07225411]\n",
      "Loss in iteration 1831: 0.486261846404491\n",
      "Theta: [-0.84276992  0.51474633  0.07224987]\n",
      "Loss in iteration 1832: 0.48622917434874613\n",
      "Theta: [-0.84309898  0.51494318  0.07224564]\n",
      "Loss in iteration 1833: 0.48619652287340004\n",
      "Theta: [-0.84342794  0.51513996  0.0722414 ]\n",
      "Loss in iteration 1834: 0.4861638919619484\n",
      "Theta: [-0.84375679  0.51533669  0.07223717]\n",
      "Loss in iteration 1835: 0.4861312815979021\n",
      "Theta: [-0.84408553  0.51553337  0.07223293]\n",
      "Loss in iteration 1836: 0.48609869176478726\n",
      "Theta: [-0.84441417  0.51572998  0.0722287 ]\n",
      "Loss in iteration 1837: 0.48606612244614633\n",
      "Theta: [-0.8447427   0.51592654  0.07222447]\n",
      "Loss in iteration 1838: 0.486033573625537\n",
      "Theta: [-0.84507112  0.51612304  0.07222024]\n",
      "Loss in iteration 1839: 0.4860010452865326\n",
      "Theta: [-0.84539944  0.51631948  0.07221601]\n",
      "Loss in iteration 1840: 0.485968537412722\n",
      "Theta: [-0.84572766  0.51651586  0.07221178]\n",
      "Loss in iteration 1841: 0.48593604998770973\n",
      "Theta: [-0.84605576  0.51671219  0.07220755]\n",
      "Loss in iteration 1842: 0.4859035829951155\n",
      "Theta: [-0.84638376  0.51690846  0.07220333]\n",
      "Loss in iteration 1843: 0.485871136418575\n",
      "Theta: [-0.84671166  0.51710467  0.0721991 ]\n",
      "Loss in iteration 1844: 0.4858387102417391\n",
      "Theta: [-0.84703945  0.51730083  0.07219488]\n",
      "Loss in iteration 1845: 0.48580630444827455\n",
      "Theta: [-0.84736713  0.51749693  0.07219065]\n",
      "Loss in iteration 1846: 0.4857739190218629\n",
      "Theta: [-0.84769471  0.51769297  0.07218643]\n",
      "Loss in iteration 1847: 0.48574155394620194\n",
      "Theta: [-0.84802218  0.51788895  0.07218221]\n",
      "Loss in iteration 1848: 0.48570920920500404\n",
      "Theta: [-0.84834955  0.51808488  0.07217799]\n",
      "Loss in iteration 1849: 0.4856768847819977\n",
      "Theta: [-0.84867681  0.51828074  0.07217377]\n",
      "Loss in iteration 1850: 0.4856445806609267\n",
      "Theta: [-0.84900397  0.51847656  0.07216955]\n",
      "Loss in iteration 1851: 0.48561229682554957\n",
      "Theta: [-0.84933102  0.51867231  0.07216533]\n",
      "Loss in iteration 1852: 0.4855800332596414\n",
      "Theta: [-0.84965797  0.51886801  0.07216111]\n",
      "Loss in iteration 1853: 0.48554778994699144\n",
      "Theta: [-0.84998481  0.51906365  0.0721569 ]\n",
      "Loss in iteration 1854: 0.48551556687140507\n",
      "Theta: [-0.85031154  0.51925923  0.07215268]\n",
      "Loss in iteration 1855: 0.48548336401670256\n",
      "Theta: [-0.85063817  0.51945476  0.07214847]\n",
      "Loss in iteration 1856: 0.4854511813667196\n",
      "Theta: [-0.8509647   0.51965023  0.07214426]\n",
      "Loss in iteration 1857: 0.4854190189053073\n",
      "Theta: [-0.85129112  0.51984564  0.07214004]\n",
      "Loss in iteration 1858: 0.4853868766163322\n",
      "Theta: [-0.85161743  0.52004099  0.07213583]\n",
      "Loss in iteration 1859: 0.4853547544836755\n",
      "Theta: [-0.85194364  0.52023629  0.07213162]\n",
      "Loss in iteration 1860: 0.4853226524912342\n",
      "Theta: [-0.85226975  0.52043153  0.07212741]\n",
      "Loss in iteration 1861: 0.4852905706229205\n",
      "Theta: [-0.85259575  0.52062672  0.07212321]\n",
      "Loss in iteration 1862: 0.4852585088626612\n",
      "Theta: [-0.85292165  0.52082185  0.072119  ]\n",
      "Loss in iteration 1863: 0.48522646719439927\n",
      "Theta: [-0.85324744  0.52101692  0.07211479]\n",
      "Loss in iteration 1864: 0.48519444560209185\n",
      "Theta: [-0.85357312  0.52121193  0.07211059]\n",
      "Loss in iteration 1865: 0.48516244406971204\n",
      "Theta: [-0.8538987   0.52140689  0.07210638]\n",
      "Loss in iteration 1866: 0.4851304625812478\n",
      "Theta: [-0.85422418  0.52160179  0.07210218]\n",
      "Loss in iteration 1867: 0.4850985011207022\n",
      "Theta: [-0.85454955  0.52179663  0.07209798]\n",
      "Loss in iteration 1868: 0.4850665596720933\n",
      "Theta: [-0.85487482  0.52199142  0.07209378]\n",
      "Loss in iteration 1869: 0.48503463821945464\n",
      "Theta: [-0.85519998  0.52218615  0.07208958]\n",
      "Loss in iteration 1870: 0.4850027367468346\n",
      "Theta: [-0.85552504  0.52238083  0.07208538]\n",
      "Loss in iteration 1871: 0.4849708552382965\n",
      "Theta: [-0.85585     0.52257544  0.07208118]\n",
      "Loss in iteration 1872: 0.484938993677919\n",
      "Theta: [-0.85617485  0.52277001  0.07207698]\n",
      "Loss in iteration 1873: 0.48490715204979556\n",
      "Theta: [-0.85649959  0.52296451  0.07207279]\n",
      "Loss in iteration 1874: 0.4848753303380348\n",
      "Theta: [-0.85682424  0.52315896  0.07206859]\n",
      "Loss in iteration 1875: 0.4848435285267605\n",
      "Theta: [-0.85714877  0.52335335  0.0720644 ]\n",
      "Loss in iteration 1876: 0.48481174660011106\n",
      "Theta: [-0.85747321  0.52354769  0.0720602 ]\n",
      "Loss in iteration 1877: 0.48477998454224014\n",
      "Theta: [-0.85779754  0.52374197  0.07205601]\n",
      "Loss in iteration 1878: 0.4847482423373164\n",
      "Theta: [-0.85812176  0.52393619  0.07205182]\n",
      "Loss in iteration 1879: 0.4847165199695231\n",
      "Theta: [-0.85844589  0.52413035  0.07204763]\n",
      "Loss in iteration 1880: 0.48468481742305886\n",
      "Theta: [-0.8587699   0.52432446  0.07204344]\n",
      "Loss in iteration 1881: 0.48465313468213705\n",
      "Theta: [-0.85909382  0.52451852  0.07203925]\n",
      "Loss in iteration 1882: 0.4846214717309858\n",
      "Theta: [-0.85941763  0.52471252  0.07203506]\n",
      "Loss in iteration 1883: 0.48458982855384825\n",
      "Theta: [-0.85974133  0.52490646  0.07203087]\n",
      "Loss in iteration 1884: 0.48455820513498254\n",
      "Theta: [-0.86006494  0.52510034  0.07202669]\n",
      "Loss in iteration 1885: 0.48452660145866133\n",
      "Theta: [-0.86038843  0.52529417  0.0720225 ]\n",
      "Loss in iteration 1886: 0.48449501750917245\n",
      "Theta: [-0.86071183  0.52548794  0.07201832]\n",
      "Loss in iteration 1887: 0.48446345327081836\n",
      "Theta: [-0.86103512  0.52568166  0.07201413]\n",
      "Loss in iteration 1888: 0.4844319087279166\n",
      "Theta: [-0.86135831  0.52587532  0.07200995]\n",
      "Loss in iteration 1889: 0.484400383864799\n",
      "Theta: [-0.86168139  0.52606893  0.07200577]\n",
      "Loss in iteration 1890: 0.48436887866581285\n",
      "Theta: [-0.86200438  0.52626247  0.07200159]\n",
      "Loss in iteration 1891: 0.48433739311531937\n",
      "Theta: [-0.86232725  0.52645597  0.07199741]\n",
      "Loss in iteration 1892: 0.48430592719769544\n",
      "Theta: [-0.86265003  0.5266494   0.07199323]\n",
      "Loss in iteration 1893: 0.4842744808973318\n",
      "Theta: [-0.8629727   0.52684278  0.07198906]\n",
      "Loss in iteration 1894: 0.48424305419863467\n",
      "Theta: [-0.86329527  0.52703611  0.07198488]\n",
      "Loss in iteration 1895: 0.4842116470860244\n",
      "Theta: [-0.86361773  0.52722938  0.0719807 ]\n",
      "Loss in iteration 1896: 0.48418025954393634\n",
      "Theta: [-0.86394009  0.52742259  0.07197653]\n",
      "Loss in iteration 1897: 0.4841488915568206\n",
      "Theta: [-0.86426235  0.52761575  0.07197235]\n",
      "Loss in iteration 1898: 0.4841175431091414\n",
      "Theta: [-0.86458451  0.52780885  0.07196818]\n",
      "Loss in iteration 1899: 0.48408621418537817\n",
      "Theta: [-0.86490656  0.5280019   0.07196401]\n",
      "Loss in iteration 1900: 0.48405490477002483\n",
      "Theta: [-0.86522851  0.52819489  0.07195984]\n",
      "Loss in iteration 1901: 0.4840236148475898\n",
      "Theta: [-0.86555036  0.52838782  0.07195567]\n",
      "Loss in iteration 1902: 0.48399234440259625\n",
      "Theta: [-0.8658721  0.5285807  0.0719515]\n",
      "Loss in iteration 1903: 0.4839610934195817\n",
      "Theta: [-0.86619374  0.52877352  0.07194733]\n",
      "Loss in iteration 1904: 0.48392986188309833\n",
      "Theta: [-0.86651528  0.52896629  0.07194316]\n",
      "Loss in iteration 1905: 0.48389864977771324\n",
      "Theta: [-0.86683672  0.529159    0.071939  ]\n",
      "Loss in iteration 1906: 0.48386745708800727\n",
      "Theta: [-0.86715805  0.52935166  0.07193483]\n",
      "Loss in iteration 1907: 0.48383628379857646\n",
      "Theta: [-0.86747928  0.52954426  0.07193067]\n",
      "Loss in iteration 1908: 0.48380512989403124\n",
      "Theta: [-0.86780041  0.52973681  0.0719265 ]\n",
      "Loss in iteration 1909: 0.4837739953589964\n",
      "Theta: [-0.86812144  0.5299293   0.07192234]\n",
      "Loss in iteration 1910: 0.4837428801781112\n",
      "Theta: [-0.86844236  0.53012173  0.07191818]\n",
      "Loss in iteration 1911: 0.4837117843360293\n",
      "Theta: [-0.86876318  0.53031411  0.07191402]\n",
      "Loss in iteration 1912: 0.4836807078174189\n",
      "Theta: [-0.8690839   0.53050643  0.07190986]\n",
      "Loss in iteration 1913: 0.4836496506069631\n",
      "Theta: [-0.86940452  0.5306987   0.0719057 ]\n",
      "Loss in iteration 1914: 0.48361861268935824\n",
      "Theta: [-0.86972503  0.53089091  0.07190154]\n",
      "Loss in iteration 1915: 0.48358759404931634\n",
      "Theta: [-0.87004544  0.53108307  0.07189738]\n",
      "Loss in iteration 1916: 0.48355659467156287\n",
      "Theta: [-0.87036575  0.53127517  0.07189322]\n",
      "Loss in iteration 1917: 0.4835256145408383\n",
      "Theta: [-0.87068596  0.53146722  0.07188907]\n",
      "Loss in iteration 1918: 0.48349465364189725\n",
      "Theta: [-0.87100606  0.53165921  0.07188491]\n",
      "Loss in iteration 1919: 0.48346371195950844\n",
      "Theta: [-0.87132607  0.53185115  0.07188076]\n",
      "Loss in iteration 1920: 0.4834327894784549\n",
      "Theta: [-0.87164597  0.53204303  0.07187661]\n",
      "Loss in iteration 1921: 0.4834018861835348\n",
      "Theta: [-0.87196577  0.53223486  0.07187245]\n",
      "Loss in iteration 1922: 0.48337100205955963\n",
      "Theta: [-0.87228547  0.53242663  0.0718683 ]\n",
      "Loss in iteration 1923: 0.48334013709135526\n",
      "Theta: [-0.87260506  0.53261835  0.07186415]\n",
      "Loss in iteration 1924: 0.4833092912637626\n",
      "Theta: [-0.87292456  0.53281001  0.07186   ]\n",
      "Loss in iteration 1925: 0.48327846456163615\n",
      "Theta: [-0.87324395  0.53300161  0.07185585]\n",
      "Loss in iteration 1926: 0.48324765696984445\n",
      "Theta: [-0.87356324  0.53319316  0.07185171]\n",
      "Loss in iteration 1927: 0.4832168684732709\n",
      "Theta: [-0.87388243  0.53338466  0.07184756]\n",
      "Loss in iteration 1928: 0.48318609905681287\n",
      "Theta: [-0.87420152  0.5335761   0.07184341]\n",
      "Loss in iteration 1929: 0.4831553487053818\n",
      "Theta: [-0.8745205   0.53376749  0.07183927]\n",
      "Loss in iteration 1930: 0.48312461740390333\n",
      "Theta: [-0.87483939  0.53395882  0.07183513]\n",
      "Loss in iteration 1931: 0.4830939051373174\n",
      "Theta: [-0.87515817  0.5341501   0.07183098]\n",
      "Loss in iteration 1932: 0.48306321189057805\n",
      "Theta: [-0.87547685  0.53434132  0.07182684]\n",
      "Loss in iteration 1933: 0.4830325376486534\n",
      "Theta: [-0.87579543  0.53453249  0.0718227 ]\n",
      "Loss in iteration 1934: 0.4830018823965255\n",
      "Theta: [-0.87611391  0.5347236   0.07181856]\n",
      "Loss in iteration 1935: 0.48297124611919096\n",
      "Theta: [-0.87643229  0.53491466  0.07181442]\n",
      "Loss in iteration 1936: 0.48294062880166033\n",
      "Theta: [-0.87675057  0.53510566  0.07181028]\n",
      "Loss in iteration 1937: 0.48291003042895786\n",
      "Theta: [-0.87706874  0.53529661  0.07180614]\n",
      "Loss in iteration 1938: 0.4828794509861225\n",
      "Theta: [-0.87738682  0.5354875   0.071802  ]\n",
      "Loss in iteration 1939: 0.48284889045820634\n",
      "Theta: [-0.87770479  0.53567834  0.07179787]\n",
      "Loss in iteration 1940: 0.4828183488302766\n",
      "Theta: [-0.87802266  0.53586912  0.07179373]\n",
      "Loss in iteration 1941: 0.4827878260874137\n",
      "Theta: [-0.87834043  0.53605985  0.0717896 ]\n",
      "Loss in iteration 1942: 0.4827573222147125\n",
      "Theta: [-0.8786581   0.53625053  0.07178546]\n",
      "Loss in iteration 1943: 0.48272683719728177\n",
      "Theta: [-0.87897567  0.53644115  0.07178133]\n",
      "Loss in iteration 1944: 0.4826963710202438\n",
      "Theta: [-0.87929314  0.53663171  0.0717772 ]\n",
      "Loss in iteration 1945: 0.48266592366873545\n",
      "Theta: [-0.87961051  0.53682223  0.07177307]\n",
      "Loss in iteration 1946: 0.48263549512790754\n",
      "Theta: [-0.87992778  0.53701268  0.07176894]\n",
      "Loss in iteration 1947: 0.4826050853829241\n",
      "Theta: [-0.88024494  0.53720309  0.07176481]\n",
      "Loss in iteration 1948: 0.48257469441896383\n",
      "Theta: [-0.88056201  0.53739343  0.07176068]\n",
      "Loss in iteration 1949: 0.48254432222121907\n",
      "Theta: [-0.88087898  0.53758373  0.07175655]\n",
      "Loss in iteration 1950: 0.48251396877489583\n",
      "Theta: [-0.88119584  0.53777397  0.07175243]\n",
      "Loss in iteration 1951: 0.48248363406521455\n",
      "Theta: [-0.8815126   0.53796415  0.0717483 ]\n",
      "Loss in iteration 1952: 0.48245331807740877\n",
      "Theta: [-0.88182927  0.53815429  0.07174418]\n",
      "Loss in iteration 1953: 0.48242302079672655\n",
      "Theta: [-0.88214583  0.53834436  0.07174005]\n",
      "Loss in iteration 1954: 0.48239274220842954\n",
      "Theta: [-0.8824623   0.53853439  0.07173593]\n",
      "Loss in iteration 1955: 0.4823624822977928\n",
      "Theta: [-0.88277866  0.53872435  0.07173181]\n",
      "Loss in iteration 1956: 0.4823322410501061\n",
      "Theta: [-0.88309492  0.53891427  0.07172768]\n",
      "Loss in iteration 1957: 0.48230201845067205\n",
      "Theta: [-0.88341108  0.53910413  0.07172356]\n",
      "Loss in iteration 1958: 0.48227181448480766\n",
      "Theta: [-0.88372715  0.53929393  0.07171944]\n",
      "Loss in iteration 1959: 0.48224162913784363\n",
      "Theta: [-0.88404311  0.53948369  0.07171532]\n",
      "Loss in iteration 1960: 0.4822114623951238\n",
      "Theta: [-0.88435897  0.53967338  0.07171121]\n",
      "Loss in iteration 1961: 0.4821813142420066\n",
      "Theta: [-0.88467473  0.53986303  0.07170709]\n",
      "Loss in iteration 1962: 0.48215118466386386\n",
      "Theta: [-0.8849904   0.54005262  0.07170297]\n",
      "Loss in iteration 1963: 0.48212107364608076\n",
      "Theta: [-0.88530596  0.54024215  0.07169886]\n",
      "Loss in iteration 1964: 0.4820909811740565\n",
      "Theta: [-0.88562142  0.54043164  0.07169474]\n",
      "Loss in iteration 1965: 0.48206090723320416\n",
      "Theta: [-0.88593678  0.54062106  0.07169063]\n",
      "Loss in iteration 1966: 0.4820308518089497\n",
      "Theta: [-0.88625205  0.54081044  0.07168652]\n",
      "Loss in iteration 1967: 0.4820008148867339\n",
      "Theta: [-0.88656721  0.54099976  0.0716824 ]\n",
      "Loss in iteration 1968: 0.48197079645200985\n",
      "Theta: [-0.88688227  0.54118903  0.07167829]\n",
      "Loss in iteration 1969: 0.48194079649024535\n",
      "Theta: [-0.88719724  0.54137824  0.07167418]\n",
      "Loss in iteration 1970: 0.48191081498692157\n",
      "Theta: [-0.8875121   0.5415674   0.07167007]\n",
      "Loss in iteration 1971: 0.48188085192753255\n",
      "Theta: [-0.88782687  0.5417565   0.07166596]\n",
      "Loss in iteration 1972: 0.4818509072975866\n",
      "Theta: [-0.88814153  0.54194555  0.07166185]\n",
      "Loss in iteration 1973: 0.4818209810826056\n",
      "Theta: [-0.8884561   0.54213455  0.07165775]\n",
      "Loss in iteration 1974: 0.48179107326812476\n",
      "Theta: [-0.88877056  0.54232349  0.07165364]\n",
      "Loss in iteration 1975: 0.48176118383969274\n",
      "Theta: [-0.88908493  0.54251239  0.07164953]\n",
      "Loss in iteration 1976: 0.481731312782872\n",
      "Theta: [-0.8893992   0.54270122  0.07164543]\n",
      "Loss in iteration 1977: 0.4817014600832381\n",
      "Theta: [-0.88971337  0.54289001  0.07164133]\n",
      "Loss in iteration 1978: 0.4816716257263808\n",
      "Theta: [-0.89002744  0.54307873  0.07163722]\n",
      "Loss in iteration 1979: 0.4816418096979023\n",
      "Theta: [-0.89034141  0.54326741  0.07163312]\n",
      "Loss in iteration 1980: 0.4816120119834193\n",
      "Theta: [-0.89065528  0.54345603  0.07162902]\n",
      "Loss in iteration 1981: 0.48158223256856125\n",
      "Theta: [-0.89096905  0.5436446   0.07162492]\n",
      "Loss in iteration 1982: 0.4815524714389714\n",
      "Theta: [-0.89128272  0.54383312  0.07162082]\n",
      "Loss in iteration 1983: 0.48152272858030615\n",
      "Theta: [-0.8915963   0.54402158  0.07161672]\n",
      "Loss in iteration 1984: 0.4814930039782357\n",
      "Theta: [-0.89190977  0.54420999  0.07161262]\n",
      "Loss in iteration 1985: 0.48146329761844314\n",
      "Theta: [-0.89222315  0.54439834  0.07160852]\n",
      "Loss in iteration 1986: 0.48143360948662534\n",
      "Theta: [-0.89253643  0.54458665  0.07160443]\n",
      "Loss in iteration 1987: 0.4814039395684923\n",
      "Theta: [-0.8928496   0.54477489  0.07160033]\n",
      "Loss in iteration 1988: 0.4813742878497677\n",
      "Theta: [-0.89316268  0.54496309  0.07159624]\n",
      "Loss in iteration 1989: 0.4813446543161881\n",
      "Theta: [-0.89347566  0.54515123  0.07159214]\n",
      "Loss in iteration 1990: 0.4813150389535036\n",
      "Theta: [-0.89378855  0.54533932  0.07158805]\n",
      "Loss in iteration 1991: 0.4812854417474777\n",
      "Theta: [-0.89410133  0.54552736  0.07158396]\n",
      "Loss in iteration 1992: 0.48125586268388704\n",
      "Theta: [-0.89441402  0.54571534  0.07157987]\n",
      "Loss in iteration 1993: 0.4812263017485218\n",
      "Theta: [-0.8947266   0.54590327  0.07157577]\n",
      "Loss in iteration 1994: 0.48119675892718516\n",
      "Theta: [-0.89503909  0.54609114  0.07157168]\n",
      "Loss in iteration 1995: 0.48116723420569363\n",
      "Theta: [-0.89535148  0.54627897  0.07156759]\n",
      "Loss in iteration 1996: 0.48113772756987694\n",
      "Theta: [-0.89566377  0.54646674  0.07156351]\n",
      "Loss in iteration 1997: 0.4811082390055782\n",
      "Theta: [-0.89597597  0.54665445  0.07155942]\n",
      "Loss in iteration 1998: 0.48107876849865344\n",
      "Theta: [-0.89628806  0.54684212  0.07155533]\n",
      "Loss in iteration 1999: 0.4810493160349722\n",
      "Theta: [-0.89660006  0.54702973  0.07155125]\n",
      "Loss in iteration 2000: 0.48101988160041714\n",
      "Theta: [-0.89691196  0.54721729  0.07154716]\n",
      "Loss in iteration 2001: 0.48099046518088395\n",
      "Theta: [-0.89722376  0.54740479  0.07154308]\n",
      "Loss in iteration 2002: 0.4809610667622814\n",
      "Theta: [-0.89753546  0.54759224  0.07153899]\n",
      "Loss in iteration 2003: 0.4809316863305319\n",
      "Theta: [-0.89784706  0.54777964  0.07153491]\n",
      "Loss in iteration 2004: 0.4809023238715703\n",
      "Theta: [-0.89815857  0.54796699  0.07153083]\n",
      "Loss in iteration 2005: 0.48087297937134543\n",
      "Theta: [-0.89846998  0.54815428  0.07152675]\n",
      "Loss in iteration 2006: 0.4808436528158182\n",
      "Theta: [-0.89878129  0.54834152  0.07152267]\n",
      "Loss in iteration 2007: 0.4808143441909634\n",
      "Theta: [-0.8990925   0.54852871  0.07151859]\n",
      "Loss in iteration 2008: 0.4807850534827687\n",
      "Theta: [-0.89940361  0.54871585  0.07151451]\n",
      "Loss in iteration 2009: 0.48075578067723446\n",
      "Theta: [-0.89971463  0.54890293  0.07151043]\n",
      "Loss in iteration 2010: 0.48072652576037483\n",
      "Theta: [-0.90002555  0.54908996  0.07150635]\n",
      "Loss in iteration 2011: 0.4806972887182164\n",
      "Theta: [-0.90033637  0.54927693  0.07150228]\n",
      "Loss in iteration 2012: 0.48066806953679875\n",
      "Theta: [-0.90064709  0.54946386  0.0714982 ]\n",
      "Loss in iteration 2013: 0.4806388682021748\n",
      "Theta: [-0.90095772  0.54965073  0.07149413]\n",
      "Loss in iteration 2014: 0.48060968470041066\n",
      "Theta: [-0.90126825  0.54983755  0.07149005]\n",
      "Loss in iteration 2015: 0.4805805190175845\n",
      "Theta: [-0.90157868  0.55002431  0.07148598]\n",
      "Loss in iteration 2016: 0.4805513711397885\n",
      "Theta: [-0.90188901  0.55021103  0.07148191]\n",
      "Loss in iteration 2017: 0.4805222410531274\n",
      "Theta: [-0.90219925  0.55039769  0.07147783]\n",
      "Loss in iteration 2018: 0.4804931287437185\n",
      "Theta: [-0.90250939  0.5505843   0.07147376]\n",
      "Loss in iteration 2019: 0.4804640341976928\n",
      "Theta: [-0.90281943  0.55077085  0.07146969]\n",
      "Loss in iteration 2020: 0.4804349574011935\n",
      "Theta: [-0.90312937  0.55095736  0.07146562]\n",
      "Loss in iteration 2021: 0.48040589834037706\n",
      "Theta: [-0.90343922  0.55114381  0.07146155]\n",
      "Loss in iteration 2022: 0.4803768570014127\n",
      "Theta: [-0.90374897  0.55133021  0.07145749]\n",
      "Loss in iteration 2023: 0.4803478333704828\n",
      "Theta: [-0.90405862  0.55151655  0.07145342]\n",
      "Loss in iteration 2024: 0.48031882743378235\n",
      "Theta: [-0.90436818  0.55170285  0.07144935]\n",
      "Loss in iteration 2025: 0.4802898391775191\n",
      "Theta: [-0.90467764  0.55188909  0.07144529]\n",
      "Loss in iteration 2026: 0.4802608685879138\n",
      "Theta: [-0.904987    0.55207528  0.07144122]\n",
      "Loss in iteration 2027: 0.4802319156512\n",
      "Theta: [-0.90529626  0.55226142  0.07143716]\n",
      "Loss in iteration 2028: 0.48020298035362413\n",
      "Theta: [-0.90560543  0.5524475   0.0714331 ]\n",
      "Loss in iteration 2029: 0.48017406268144514\n",
      "Theta: [-0.9059145   0.55263353  0.07142903]\n",
      "Loss in iteration 2030: 0.48014516262093515\n",
      "Theta: [-0.90622347  0.55281951  0.07142497]\n",
      "Loss in iteration 2031: 0.4801162801583789\n",
      "Theta: [-0.90653235  0.55300544  0.07142091]\n",
      "Loss in iteration 2032: 0.4800874152800737\n",
      "Theta: [-0.90684113  0.55319132  0.07141685]\n",
      "Loss in iteration 2033: 0.4800585679723298\n",
      "Theta: [-0.90714982  0.55337714  0.07141279]\n",
      "Loss in iteration 2034: 0.4800297382214702\n",
      "Theta: [-0.9074584   0.55356291  0.07140873]\n",
      "Loss in iteration 2035: 0.48000092601383054\n",
      "Theta: [-0.90776689  0.55374863  0.07140467]\n",
      "Loss in iteration 2036: 0.479972131335759\n",
      "Theta: [-0.90807529  0.5539343   0.07140062]\n",
      "Loss in iteration 2037: 0.47994335417361694\n",
      "Theta: [-0.90838358  0.55411992  0.07139656]\n",
      "Loss in iteration 2038: 0.47991459451377794\n",
      "Theta: [-0.90869178  0.55430548  0.07139251]\n",
      "Loss in iteration 2039: 0.4798858523426281\n",
      "Theta: [-0.90899989  0.55449099  0.07138845]\n",
      "Loss in iteration 2040: 0.4798571276465669\n",
      "Theta: [-0.9093079   0.55467645  0.0713844 ]\n",
      "Loss in iteration 2041: 0.47982842041200613\n",
      "Theta: [-0.90961581  0.55486186  0.07138034]\n",
      "Loss in iteration 2042: 0.4797997306253694\n",
      "Theta: [-0.90992362  0.55504722  0.07137629]\n",
      "Loss in iteration 2043: 0.47977105827309435\n",
      "Theta: [-0.91023134  0.55523252  0.07137224]\n",
      "Loss in iteration 2044: 0.47974240334163004\n",
      "Theta: [-0.91053897  0.55541777  0.07136819]\n",
      "Loss in iteration 2045: 0.47971376581743896\n",
      "Theta: [-0.91084649  0.55560297  0.07136414]\n",
      "Loss in iteration 2046: 0.47968514568699555\n",
      "Theta: [-0.91115392  0.55578812  0.07136009]\n",
      "Loss in iteration 2047: 0.47965654293678694\n",
      "Theta: [-0.91146126  0.55597322  0.07135604]\n",
      "Loss in iteration 2048: 0.4796279575533133\n",
      "Theta: [-0.9117685   0.55615827  0.07135199]\n",
      "Loss in iteration 2049: 0.47959938952308667\n",
      "Theta: [-0.91207564  0.55634326  0.07134794]\n",
      "Loss in iteration 2050: 0.479570838832632\n",
      "Theta: [-0.91238269  0.5565282   0.0713439 ]\n",
      "Loss in iteration 2051: 0.4795423054684865\n",
      "Theta: [-0.91268964  0.55671309  0.07133985]\n",
      "Loss in iteration 2052: 0.4795137894172003\n",
      "Theta: [-0.91299649  0.55689793  0.07133581]\n",
      "Loss in iteration 2053: 0.4794852906653355\n",
      "Theta: [-0.91330325  0.55708272  0.07133176]\n",
      "Loss in iteration 2054: 0.47945680919946726\n",
      "Theta: [-0.91360992  0.55726745  0.07132772]\n",
      "Loss in iteration 2055: 0.4794283450061823\n",
      "Theta: [-0.91391648  0.55745214  0.07132368]\n",
      "Loss in iteration 2056: 0.4793998980720808\n",
      "Theta: [-0.91422296  0.55763677  0.07131963]\n",
      "Loss in iteration 2057: 0.4793714683837744\n",
      "Theta: [-0.91452933  0.55782135  0.07131559]\n",
      "Loss in iteration 2058: 0.47934305592788823\n",
      "Theta: [-0.91483561  0.55800588  0.07131155]\n",
      "Loss in iteration 2059: 0.479314660691059\n",
      "Theta: [-0.9151418   0.55819036  0.07130751]\n",
      "Loss in iteration 2060: 0.4792862826599361\n",
      "Theta: [-0.91544789  0.55837478  0.07130347]\n",
      "Loss in iteration 2061: 0.4792579218211812\n",
      "Theta: [-0.91575388  0.55855916  0.07129944]\n",
      "Loss in iteration 2062: 0.4792295781614684\n",
      "Theta: [-0.91605978  0.55874348  0.0712954 ]\n",
      "Loss in iteration 2063: 0.4792012516674843\n",
      "Theta: [-0.91636559  0.55892775  0.07129136]\n",
      "Loss in iteration 2064: 0.47917294232592766\n",
      "Theta: [-0.91667129  0.55911198  0.07128733]\n",
      "Loss in iteration 2065: 0.47914465012350954\n",
      "Theta: [-0.91697691  0.55929614  0.07128329]\n",
      "Loss in iteration 2066: 0.4791163750469534\n",
      "Theta: [-0.91728243  0.55948026  0.07127926]\n",
      "Loss in iteration 2067: 0.47908811708299504\n",
      "Theta: [-0.91758785  0.55966433  0.07127522]\n",
      "Loss in iteration 2068: 0.47905987621838236\n",
      "Theta: [-0.91789318  0.55984835  0.07127119]\n",
      "Loss in iteration 2069: 0.479031652439876\n",
      "Theta: [-0.91819841  0.56003231  0.07126716]\n",
      "Loss in iteration 2070: 0.4790034457342482\n",
      "Theta: [-0.91850355  0.56021622  0.07126312]\n",
      "Loss in iteration 2071: 0.478975256088284\n",
      "Theta: [-0.91880859  0.56040009  0.07125909]\n",
      "Loss in iteration 2072: 0.47894708348878057\n",
      "Theta: [-0.91911354  0.5605839   0.07125506]\n",
      "Loss in iteration 2073: 0.47891892792254687\n",
      "Theta: [-0.91941839  0.56076766  0.07125103]\n",
      "Loss in iteration 2074: 0.4788907893764048\n",
      "Theta: [-0.91972315  0.56095137  0.071247  ]\n",
      "Loss in iteration 2075: 0.4788626678371877\n",
      "Theta: [-0.92002781  0.56113502  0.07124298]\n",
      "Loss in iteration 2076: 0.47883456329174195\n",
      "Theta: [-0.92033238  0.56131863  0.07123895]\n",
      "Loss in iteration 2077: 0.4788064757269252\n",
      "Theta: [-0.92063685  0.56150219  0.07123492]\n",
      "Loss in iteration 2078: 0.4787784051296082\n",
      "Theta: [-0.92094123  0.56168569  0.0712309 ]\n",
      "Loss in iteration 2079: 0.4787503514866728\n",
      "Theta: [-0.92124552  0.56186915  0.07122687]\n",
      "Loss in iteration 2080: 0.4787223147850138\n",
      "Theta: [-0.92154971  0.56205255  0.07122285]\n",
      "Loss in iteration 2081: 0.478694295011538\n",
      "Theta: [-0.9218538   0.5622359   0.07121882]\n",
      "Loss in iteration 2082: 0.47866629215316403\n",
      "Theta: [-0.9221578  0.5624192  0.0712148]\n",
      "Loss in iteration 2083: 0.47863830619682274\n",
      "Theta: [-0.92246171  0.56260245  0.07121078]\n",
      "Loss in iteration 2084: 0.47861033712945733\n",
      "Theta: [-0.92276552  0.56278565  0.07120676]\n",
      "Loss in iteration 2085: 0.4785823849380227\n",
      "Theta: [-0.92306924  0.5629688   0.07120274]\n",
      "Loss in iteration 2086: 0.47855444960948595\n",
      "Theta: [-0.92337286  0.5631519   0.07119872]\n",
      "Loss in iteration 2087: 0.4785265311308263\n",
      "Theta: [-0.92367639  0.56333495  0.0711947 ]\n",
      "Loss in iteration 2088: 0.47849862948903493\n",
      "Theta: [-0.92397982  0.56351794  0.07119068]\n",
      "Loss in iteration 2089: 0.47847074467111517\n",
      "Theta: [-0.92428316  0.56370089  0.07118666]\n",
      "Loss in iteration 2090: 0.4784428766640822\n",
      "Theta: [-0.92458641  0.56388378  0.07118264]\n",
      "Loss in iteration 2091: 0.4784150254549633\n",
      "Theta: [-0.92488956  0.56406663  0.07117863]\n",
      "Loss in iteration 2092: 0.4783871910307975\n",
      "Theta: [-0.92519262  0.56424942  0.07117461]\n",
      "Loss in iteration 2093: 0.4783593733786365\n",
      "Theta: [-0.92549558  0.56443217  0.07117059]\n",
      "Loss in iteration 2094: 0.47833157248554303\n",
      "Theta: [-0.92579845  0.56461486  0.07116658]\n",
      "Loss in iteration 2095: 0.47830378833859244\n",
      "Theta: [-0.92610123  0.5647975   0.07116257]\n",
      "Loss in iteration 2096: 0.4782760209248718\n",
      "Theta: [-0.92640391  0.56498009  0.07115855]\n",
      "Loss in iteration 2097: 0.4782482702314802\n",
      "Theta: [-0.9267065   0.56516263  0.07115454]\n",
      "Loss in iteration 2098: 0.47822053624552835\n",
      "Theta: [-0.92700899  0.56534512  0.07115053]\n",
      "Loss in iteration 2099: 0.47819281895413923\n",
      "Theta: [-0.92731139  0.56552756  0.07114652]\n",
      "Loss in iteration 2100: 0.4781651183444474\n",
      "Theta: [-0.9276137   0.56570995  0.07114251]\n",
      "Loss in iteration 2101: 0.47813743440359974\n",
      "Theta: [-0.92791591  0.56589229  0.0711385 ]\n",
      "Loss in iteration 2102: 0.4781097671187544\n",
      "Theta: [-0.92821803  0.56607458  0.07113449]\n",
      "Loss in iteration 2103: 0.47808211647708193\n",
      "Theta: [-0.92852006  0.56625682  0.07113048]\n",
      "Loss in iteration 2104: 0.47805448246576426\n",
      "Theta: [-0.92882199  0.56643901  0.07112647]\n",
      "Loss in iteration 2105: 0.4780268650719956\n",
      "Theta: [-0.92912383  0.56662115  0.07112247]\n",
      "Loss in iteration 2106: 0.47799926428298173\n",
      "Theta: [-0.92942558  0.56680323  0.07111846]\n",
      "Loss in iteration 2107: 0.47797168008594015\n",
      "Theta: [-0.92972723  0.56698527  0.07111446]\n",
      "Loss in iteration 2108: 0.4779441124681002\n",
      "Theta: [-0.93002879  0.56716726  0.07111045]\n",
      "Loss in iteration 2109: 0.47791656141670324\n",
      "Theta: [-0.93033025  0.56734919  0.07110645]\n",
      "Loss in iteration 2110: 0.47788902691900226\n",
      "Theta: [-0.93063162  0.56753108  0.07110244]\n",
      "Loss in iteration 2111: 0.4778615089622618\n",
      "Theta: [-0.9309329   0.56771292  0.07109844]\n",
      "Loss in iteration 2112: 0.4778340075337585\n",
      "Theta: [-0.93123409  0.5678947   0.07109444]\n",
      "Loss in iteration 2113: 0.4778065226207802\n",
      "Theta: [-0.93153518  0.56807644  0.07109044]\n",
      "Loss in iteration 2114: 0.47777905421062733\n",
      "Theta: [-0.93183618  0.56825813  0.07108644]\n",
      "Loss in iteration 2115: 0.477751602290611\n",
      "Theta: [-0.93213709  0.56843976  0.07108244]\n",
      "Loss in iteration 2116: 0.47772416684805485\n",
      "Theta: [-0.9324379   0.56862135  0.07107844]\n",
      "Loss in iteration 2117: 0.47769674787029376\n",
      "Theta: [-0.93273862  0.56880288  0.07107444]\n",
      "Loss in iteration 2118: 0.4776693453446743\n",
      "Theta: [-0.93303925  0.56898437  0.07107044]\n",
      "Loss in iteration 2119: 0.47764195925855496\n",
      "Theta: [-0.93333978  0.56916581  0.07106644]\n",
      "Loss in iteration 2120: 0.4776145895993056\n",
      "Theta: [-0.93364022  0.56934719  0.07106245]\n",
      "Loss in iteration 2121: 0.477587236354308\n",
      "Theta: [-0.93394057  0.56952853  0.07105845]\n",
      "Loss in iteration 2122: 0.47755989951095507\n",
      "Theta: [-0.93424083  0.56970981  0.07105446]\n",
      "Loss in iteration 2123: 0.4775325790566521\n",
      "Theta: [-0.93454099  0.56989105  0.07105046]\n",
      "Loss in iteration 2124: 0.4775052749788151\n",
      "Theta: [-0.93484106  0.57007224  0.07104647]\n",
      "Loss in iteration 2125: 0.4774779872648724\n",
      "Theta: [-0.93514104  0.57025337  0.07104248]\n",
      "Loss in iteration 2126: 0.47745071590226346\n",
      "Theta: [-0.93544092  0.57043446  0.07103848]\n",
      "Loss in iteration 2127: 0.4774234608784396\n",
      "Theta: [-0.93574072  0.5706155   0.07103449]\n",
      "Loss in iteration 2128: 0.47739622218086325\n",
      "Theta: [-0.93604042  0.57079649  0.0710305 ]\n",
      "Loss in iteration 2129: 0.47736899979700914\n",
      "Theta: [-0.93634002  0.57097742  0.07102651]\n",
      "Loss in iteration 2130: 0.47734179371436264\n",
      "Theta: [-0.93663954  0.57115831  0.07102252]\n",
      "Loss in iteration 2131: 0.4773146039204212\n",
      "Theta: [-0.93693896  0.57133915  0.07101853]\n",
      "Loss in iteration 2132: 0.47728743040269356\n",
      "Theta: [-0.93723829  0.57151994  0.07101454]\n",
      "Loss in iteration 2133: 0.4772602731487002\n",
      "Theta: [-0.93753753  0.57170068  0.07101056]\n",
      "Loss in iteration 2134: 0.4772331321459729\n",
      "Theta: [-0.93783668  0.57188137  0.07100657]\n",
      "Loss in iteration 2135: 0.4772060073820547\n",
      "Theta: [-0.93813573  0.57206201  0.07100258]\n",
      "Loss in iteration 2136: 0.47717889884450054\n",
      "Theta: [-0.93843469  0.5722426   0.0709986 ]\n",
      "Loss in iteration 2137: 0.4771518065208763\n",
      "Theta: [-0.93873356  0.57242314  0.07099461]\n",
      "Loss in iteration 2138: 0.47712473039876\n",
      "Theta: [-0.93903234  0.57260363  0.07099063]\n",
      "Loss in iteration 2139: 0.4770976704657403\n",
      "Theta: [-0.93933102  0.57278407  0.07098664]\n",
      "Loss in iteration 2140: 0.4770706267094177\n",
      "Theta: [-0.93962962  0.57296446  0.07098266]\n",
      "Loss in iteration 2141: 0.4770435991174042\n",
      "Theta: [-0.93992812  0.5731448   0.07097868]\n",
      "Loss in iteration 2142: 0.4770165876773227\n",
      "Theta: [-0.94022653  0.5733251   0.0709747 ]\n",
      "Loss in iteration 2143: 0.47698959237680794\n",
      "Theta: [-0.94052484  0.57350534  0.07097072]\n",
      "Loss in iteration 2144: 0.4769626132035059\n",
      "Theta: [-0.94082307  0.57368554  0.07096674]\n",
      "Loss in iteration 2145: 0.47693565014507383\n",
      "Theta: [-0.9411212   0.57386568  0.07096276]\n",
      "Loss in iteration 2146: 0.4769087031891804\n",
      "Theta: [-0.94141925  0.57404578  0.07095878]\n",
      "Loss in iteration 2147: 0.4768817723235055\n",
      "Theta: [-0.9417172   0.57422582  0.0709548 ]\n",
      "Loss in iteration 2148: 0.4768548575357406\n",
      "Theta: [-0.94201505  0.57440582  0.07095082]\n",
      "Loss in iteration 2149: 0.47682795881358786\n",
      "Theta: [-0.94231282  0.57458577  0.07094684]\n",
      "Loss in iteration 2150: 0.4768010761447616\n",
      "Theta: [-0.9426105   0.57476567  0.07094287]\n",
      "Loss in iteration 2151: 0.4767742095169868\n",
      "Theta: [-0.94290808  0.57494552  0.07093889]\n",
      "Loss in iteration 2152: 0.47674735891799985\n",
      "Theta: [-0.94320557  0.57512532  0.07093492]\n",
      "Loss in iteration 2153: 0.47672052433554846\n",
      "Theta: [-0.94350297  0.57530507  0.07093094]\n",
      "Loss in iteration 2154: 0.47669370575739156\n",
      "Theta: [-0.94380028  0.57548477  0.07092697]\n",
      "Loss in iteration 2155: 0.4766669031712994\n",
      "Theta: [-0.9440975   0.57566442  0.070923  ]\n",
      "Loss in iteration 2156: 0.47664011656505323\n",
      "Theta: [-0.94439463  0.57584403  0.07091902]\n",
      "Loss in iteration 2157: 0.4766133459264457\n",
      "Theta: [-0.94469166  0.57602358  0.07091505]\n",
      "Loss in iteration 2158: 0.4765865912432807\n",
      "Theta: [-0.94498861  0.57620309  0.07091108]\n",
      "Loss in iteration 2159: 0.47655985250337307\n",
      "Theta: [-0.94528546  0.57638254  0.07090711]\n",
      "Loss in iteration 2160: 0.47653312969454886\n",
      "Theta: [-0.94558222  0.57656195  0.07090314]\n",
      "Loss in iteration 2161: 0.47650642280464584\n",
      "Theta: [-0.94587889  0.57674131  0.07089917]\n",
      "Loss in iteration 2162: 0.4764797318215122\n",
      "Theta: [-0.94617547  0.57692062  0.0708952 ]\n",
      "Loss in iteration 2163: 0.4764530567330075\n",
      "Theta: [-0.94647196  0.57709988  0.07089123]\n",
      "Loss in iteration 2164: 0.4764263975270026\n",
      "Theta: [-0.94676836  0.57727909  0.07088727]\n",
      "Loss in iteration 2165: 0.4763997541913793\n",
      "Theta: [-0.94706467  0.57745826  0.0708833 ]\n",
      "Loss in iteration 2166: 0.4763731267140308\n",
      "Theta: [-0.94736088  0.57763737  0.07087934]\n",
      "Loss in iteration 2167: 0.476346515082861\n",
      "Theta: [-0.94765701  0.57781644  0.07087537]\n",
      "Loss in iteration 2168: 0.4763199192857849\n",
      "Theta: [-0.94795304  0.57799545  0.07087141]\n",
      "Loss in iteration 2169: 0.4762933393107291\n",
      "Theta: [-0.94824899  0.57817442  0.07086744]\n",
      "Loss in iteration 2170: 0.4762667751456307\n",
      "Theta: [-0.94854484  0.57835334  0.07086348]\n",
      "Loss in iteration 2171: 0.47624022677843797\n",
      "Theta: [-0.9488406   0.57853221  0.07085951]\n",
      "Loss in iteration 2172: 0.47621369419711057\n",
      "Theta: [-0.94913627  0.57871103  0.07085555]\n",
      "Loss in iteration 2173: 0.4761871773896186\n",
      "Theta: [-0.94943185  0.57888981  0.07085159]\n",
      "Loss in iteration 2174: 0.4761606763439437\n",
      "Theta: [-0.94972734  0.57906853  0.07084763]\n",
      "Loss in iteration 2175: 0.47613419104807825\n",
      "Theta: [-0.95002274  0.57924721  0.07084367]\n",
      "Loss in iteration 2176: 0.4761077214900257\n",
      "Theta: [-0.95031805  0.57942583  0.07083971]\n",
      "Loss in iteration 2177: 0.4760812676578003\n",
      "Theta: [-0.95061327  0.57960441  0.07083575]\n",
      "Loss in iteration 2178: 0.47605482953942774\n",
      "Theta: [-0.9509084   0.57978294  0.07083179]\n",
      "Loss in iteration 2179: 0.4760284071229443\n",
      "Theta: [-0.95120343  0.57996142  0.07082784]\n",
      "Loss in iteration 2180: 0.4760020003963972\n",
      "Theta: [-0.95149838  0.58013986  0.07082388]\n",
      "Loss in iteration 2181: 0.47597560934784444\n",
      "Theta: [-0.95179324  0.58031824  0.07081992]\n",
      "Loss in iteration 2182: 0.47594923396535566\n",
      "Theta: [-0.95208801  0.58049658  0.07081597]\n",
      "Loss in iteration 2183: 0.4759228742370105\n",
      "Theta: [-0.95238268  0.58067486  0.07081201]\n",
      "Loss in iteration 2184: 0.47589653015090017\n",
      "Theta: [-0.95267727  0.5808531   0.07080806]\n",
      "Loss in iteration 2185: 0.4758702016951265\n",
      "Theta: [-0.95297177  0.58103129  0.0708041 ]\n",
      "Loss in iteration 2186: 0.47584388885780243\n",
      "Theta: [-0.95326617  0.58120943  0.07080015]\n",
      "Loss in iteration 2187: 0.4758175916270512\n",
      "Theta: [-0.95356049  0.58138753  0.0707962 ]\n",
      "Loss in iteration 2188: 0.4757913099910074\n",
      "Theta: [-0.95385471  0.58156557  0.07079224]\n",
      "Loss in iteration 2189: 0.47576504393781655\n",
      "Theta: [-0.95414885  0.58174357  0.07078829]\n",
      "Loss in iteration 2190: 0.4757387934556347\n",
      "Theta: [-0.9544429   0.58192152  0.07078434]\n",
      "Loss in iteration 2191: 0.47571255853262867\n",
      "Theta: [-0.95473685  0.58209942  0.07078039]\n",
      "Loss in iteration 2192: 0.4756863391569766\n",
      "Theta: [-0.95503072  0.58227727  0.07077644]\n",
      "Loss in iteration 2193: 0.47566013531686707\n",
      "Theta: [-0.9553245   0.58245508  0.07077249]\n",
      "Loss in iteration 2194: 0.4756339470004992\n",
      "Theta: [-0.95561818  0.58263283  0.07076855]\n",
      "Loss in iteration 2195: 0.4756077741960834\n",
      "Theta: [-0.95591178  0.58281054  0.0707646 ]\n",
      "Loss in iteration 2196: 0.47558161689184053\n",
      "Theta: [-0.95620529  0.5829882   0.07076065]\n",
      "Loss in iteration 2197: 0.4755554750760023\n",
      "Theta: [-0.95649871  0.58316581  0.0707567 ]\n",
      "Loss in iteration 2198: 0.4755293487368113\n",
      "Theta: [-0.95679204  0.58334337  0.07075276]\n",
      "Loss in iteration 2199: 0.4755032378625204\n",
      "Theta: [-0.95708528  0.58352089  0.07074881]\n",
      "Loss in iteration 2200: 0.475477142441394\n",
      "Theta: [-0.95737842  0.58369836  0.07074487]\n",
      "Loss in iteration 2201: 0.47545106246170626\n",
      "Theta: [-0.95767148  0.58387578  0.07074092]\n",
      "Loss in iteration 2202: 0.4754249979117427\n",
      "Theta: [-0.95796446  0.58405315  0.07073698]\n",
      "Loss in iteration 2203: 0.4753989487797995\n",
      "Theta: [-0.95825734  0.58423047  0.07073304]\n",
      "Loss in iteration 2204: 0.47537291505418316\n",
      "Theta: [-0.95855013  0.58440775  0.0707291 ]\n",
      "Loss in iteration 2205: 0.4753468967232113\n",
      "Theta: [-0.95884283  0.58458497  0.07072516]\n",
      "Loss in iteration 2206: 0.4753208937752116\n",
      "Theta: [-0.95913544  0.58476215  0.07072121]\n",
      "Loss in iteration 2207: 0.47529490619852305\n",
      "Theta: [-0.95942797  0.58493928  0.07071727]\n",
      "Loss in iteration 2208: 0.47526893398149495\n",
      "Theta: [-0.9597204   0.58511637  0.07071333]\n",
      "Loss in iteration 2209: 0.4752429771124873\n",
      "Theta: [-0.96001275  0.5852934   0.0707094 ]\n",
      "Loss in iteration 2210: 0.4752170355798704\n",
      "Theta: [-0.96030501  0.58547039  0.07070546]\n",
      "Loss in iteration 2211: 0.4751911093720257\n",
      "Theta: [-0.96059717  0.58564733  0.07070152]\n",
      "Loss in iteration 2212: 0.4751651984773448\n",
      "Theta: [-0.96088925  0.58582422  0.07069758]\n",
      "Loss in iteration 2213: 0.4751393028842301\n",
      "Theta: [-0.96118124  0.58600107  0.07069364]\n",
      "Loss in iteration 2214: 0.47511342258109457\n",
      "Theta: [-0.96147314  0.58617786  0.07068971]\n",
      "Loss in iteration 2215: 0.4750875575563617\n",
      "Theta: [-0.96176495  0.58635461  0.07068577]\n",
      "Loss in iteration 2216: 0.4750617077984655\n",
      "Theta: [-0.96205668  0.58653131  0.07068184]\n",
      "Loss in iteration 2217: 0.4750358732958506\n",
      "Theta: [-0.96234831  0.58670797  0.0706779 ]\n",
      "Loss in iteration 2218: 0.47501005403697194\n",
      "Theta: [-0.96263986  0.58688457  0.07067397]\n",
      "Loss in iteration 2219: 0.4749842500102953\n",
      "Theta: [-0.96293131  0.58706113  0.07067004]\n",
      "Loss in iteration 2220: 0.4749584612042968\n",
      "Theta: [-0.96322268  0.58723764  0.07066611]\n",
      "Loss in iteration 2221: 0.47493268760746316\n",
      "Theta: [-0.96351396  0.5874141   0.07066217]\n",
      "Loss in iteration 2222: 0.4749069292082912\n",
      "Theta: [-0.96380515  0.58759052  0.07065824]\n",
      "Loss in iteration 2223: 0.4748811859952886\n",
      "Theta: [-0.96409625  0.58776689  0.07065431]\n",
      "Loss in iteration 2224: 0.4748554579569737\n",
      "Theta: [-0.96438727  0.58794321  0.07065038]\n",
      "Loss in iteration 2225: 0.4748297450818747\n",
      "Theta: [-0.96467819  0.58811948  0.07064645]\n",
      "Loss in iteration 2226: 0.4748040473585307\n",
      "Theta: [-0.96496903  0.58829571  0.07064252]\n",
      "Loss in iteration 2227: 0.47477836477549085\n",
      "Theta: [-0.96525978  0.58847188  0.07063859]\n",
      "Loss in iteration 2228: 0.4747526973213153\n",
      "Theta: [-0.96555044  0.58864801  0.07063467]\n",
      "Loss in iteration 2229: 0.474727044984574\n",
      "Theta: [-0.96584101  0.5888241   0.07063074]\n",
      "Loss in iteration 2230: 0.4747014077538478\n",
      "Theta: [-0.96613149  0.58900013  0.07062681]\n",
      "Loss in iteration 2231: 0.4746757856177274\n",
      "Theta: [-0.96642189  0.58917612  0.07062289]\n",
      "Loss in iteration 2232: 0.4746501785648142\n",
      "Theta: [-0.96671219  0.58935206  0.07061896]\n",
      "Loss in iteration 2233: 0.4746245865837202\n",
      "Theta: [-0.96700241  0.58952796  0.07061504]\n",
      "Loss in iteration 2234: 0.4745990096630674\n",
      "Theta: [-0.96729254  0.5897038   0.07061111]\n",
      "Loss in iteration 2235: 0.47457344779148825\n",
      "Theta: [-0.96758259  0.5898796   0.07060719]\n",
      "Loss in iteration 2236: 0.4745479009576254\n",
      "Theta: [-0.96787254  0.59005535  0.07060327]\n",
      "Loss in iteration 2237: 0.4745223691501322\n",
      "Theta: [-0.96816241  0.59023106  0.07059934]\n",
      "Loss in iteration 2238: 0.47449685235767186\n",
      "Theta: [-0.96845218  0.59040672  0.07059542]\n",
      "Loss in iteration 2239: 0.47447135056891815\n",
      "Theta: [-0.96874187  0.59058233  0.0705915 ]\n",
      "Loss in iteration 2240: 0.47444586377255527\n",
      "Theta: [-0.96903148  0.59075789  0.07058758]\n",
      "Loss in iteration 2241: 0.47442039195727725\n",
      "Theta: [-0.96932099  0.59093341  0.07058366]\n",
      "Loss in iteration 2242: 0.4743949351117888\n",
      "Theta: [-0.96961042  0.59110887  0.07057974]\n",
      "Loss in iteration 2243: 0.4743694932248048\n",
      "Theta: [-0.96989976  0.5912843   0.07057582]\n",
      "Loss in iteration 2244: 0.47434406628505044\n",
      "Theta: [-0.97018901  0.59145967  0.0705719 ]\n",
      "Loss in iteration 2245: 0.4743186542812607\n",
      "Theta: [-0.97047817  0.591635    0.07056799]\n",
      "Loss in iteration 2246: 0.47429325720218146\n",
      "Theta: [-0.97076725  0.59181028  0.07056407]\n",
      "Loss in iteration 2247: 0.4742678750365683\n",
      "Theta: [-0.97105624  0.59198551  0.07056015]\n",
      "Loss in iteration 2248: 0.4742425077731875\n",
      "Theta: [-0.97134514  0.5921607   0.07055624]\n",
      "Loss in iteration 2249: 0.47421715540081494\n",
      "Theta: [-0.97163395  0.59233584  0.07055232]\n",
      "Loss in iteration 2250: 0.47419181790823706\n",
      "Theta: [-0.97192268  0.59251093  0.07054841]\n",
      "Loss in iteration 2251: 0.47416649528425053\n",
      "Theta: [-0.97221132  0.59268598  0.07054449]\n",
      "Loss in iteration 2252: 0.4741411875176621\n",
      "Theta: [-0.97249987  0.59286098  0.07054058]\n",
      "Loss in iteration 2253: 0.4741158945972884\n",
      "Theta: [-0.97278833  0.59303593  0.07053667]\n",
      "Loss in iteration 2254: 0.4740906165119568\n",
      "Theta: [-0.97307671  0.59321083  0.07053275]\n",
      "Loss in iteration 2255: 0.4740653532505042\n",
      "Theta: [-0.973365    0.59338569  0.07052884]\n",
      "Loss in iteration 2256: 0.4740401048017777\n",
      "Theta: [-0.9736532   0.5935605   0.07052493]\n",
      "Loss in iteration 2257: 0.47401487115463536\n",
      "Theta: [-0.97394131  0.59373527  0.07052102]\n",
      "Loss in iteration 2258: 0.47398965229794415\n",
      "Theta: [-0.97422934  0.59390999  0.07051711]\n",
      "Loss in iteration 2259: 0.4739644482205817\n",
      "Theta: [-0.97451728  0.59408466  0.0705132 ]\n",
      "Loss in iteration 2260: 0.4739392589114361\n",
      "Theta: [-0.97480514  0.59425928  0.07050929]\n",
      "Loss in iteration 2261: 0.47391408435940463\n",
      "Theta: [-0.9750929   0.59443386  0.07050538]\n",
      "Loss in iteration 2262: 0.4738889245533953\n",
      "Theta: [-0.97538058  0.59460839  0.07050147]\n",
      "Loss in iteration 2263: 0.473863779482326\n",
      "Theta: [-0.97566817  0.59478287  0.07049757]\n",
      "Loss in iteration 2264: 0.4738386491351247\n",
      "Theta: [-0.97595568  0.59495731  0.07049366]\n",
      "Loss in iteration 2265: 0.4738135335007292\n",
      "Theta: [-0.9762431   0.5951317   0.07048975]\n",
      "Loss in iteration 2266: 0.4737884325680877\n",
      "Theta: [-0.97653043  0.59530605  0.07048585]\n",
      "Loss in iteration 2267: 0.4737633463261581\n",
      "Theta: [-0.97681767  0.59548035  0.07048194]\n",
      "Loss in iteration 2268: 0.4737382747639083\n",
      "Theta: [-0.97710483  0.5956546   0.07047804]\n",
      "Loss in iteration 2269: 0.4737132178703163\n",
      "Theta: [-0.9773919   0.5958288   0.07047413]\n",
      "Loss in iteration 2270: 0.47368817563437005\n",
      "Theta: [-0.97767889  0.59600296  0.07047023]\n",
      "Loss in iteration 2271: 0.4736631480450676\n",
      "Theta: [-0.97796578  0.59617707  0.07046633]\n",
      "Loss in iteration 2272: 0.4736381350914168\n",
      "Theta: [-0.9782526   0.59635114  0.07046243]\n",
      "Loss in iteration 2273: 0.4736131367624353\n",
      "Theta: [-0.97853932  0.59652516  0.07045852]\n",
      "Loss in iteration 2274: 0.47358815304715113\n",
      "Theta: [-0.97882596  0.59669913  0.07045462]\n",
      "Loss in iteration 2275: 0.47356318393460206\n",
      "Theta: [-0.97911251  0.59687306  0.07045072]\n",
      "Loss in iteration 2276: 0.4735382294138355\n",
      "Theta: [-0.97939898  0.59704694  0.07044682]\n",
      "Loss in iteration 2277: 0.473513289473909\n",
      "Theta: [-0.97968535  0.59722077  0.07044292]\n",
      "Loss in iteration 2278: 0.47348836410389017\n",
      "Theta: [-0.97997165  0.59739456  0.07043902]\n",
      "Loss in iteration 2279: 0.4734634532928564\n",
      "Theta: [-0.98025785  0.5975683   0.07043513]\n",
      "Loss in iteration 2280: 0.4734385570298945\n",
      "Theta: [-0.98054397  0.59774199  0.07043123]\n",
      "Loss in iteration 2281: 0.4734136753041021\n",
      "Theta: [-0.98083001  0.59791564  0.07042733]\n",
      "Loss in iteration 2282: 0.4733888081045858\n",
      "Theta: [-0.98111595  0.59808924  0.07042343]\n",
      "Loss in iteration 2283: 0.47336395542046233\n",
      "Theta: [-0.98140181  0.5982628   0.07041954]\n",
      "Loss in iteration 2284: 0.47333911724085853\n",
      "Theta: [-0.98168759  0.59843631  0.07041564]\n",
      "Loss in iteration 2285: 0.47331429355491084\n",
      "Theta: [-0.98197328  0.59860977  0.07041175]\n",
      "Loss in iteration 2286: 0.47328948435176543\n",
      "Theta: [-0.98225888  0.59878319  0.07040785]\n",
      "Loss in iteration 2287: 0.4732646896205784\n",
      "Theta: [-0.9825444   0.59895656  0.07040396]\n",
      "Loss in iteration 2288: 0.47323990935051574\n",
      "Theta: [-0.98282983  0.59912989  0.07040007]\n",
      "Loss in iteration 2289: 0.473215143530753\n",
      "Theta: [-0.98311517  0.59930317  0.07039617]\n",
      "Loss in iteration 2290: 0.47319039215047565\n",
      "Theta: [-0.98340043  0.5994764   0.07039228]\n",
      "Loss in iteration 2291: 0.47316565519887915\n",
      "Theta: [-0.98368561  0.59964959  0.07038839]\n",
      "Loss in iteration 2292: 0.47314093266516827\n",
      "Theta: [-0.98397069  0.59982273  0.0703845 ]\n",
      "Loss in iteration 2293: 0.4731162245385577\n",
      "Theta: [-0.98425569  0.59999582  0.07038061]\n",
      "Loss in iteration 2294: 0.47309153080827193\n",
      "Theta: [-0.98454061  0.60016887  0.07037672]\n",
      "Loss in iteration 2295: 0.47306685146354527\n",
      "Theta: [-0.98482544  0.60034187  0.07037283]\n",
      "Loss in iteration 2296: 0.4730421864936215\n",
      "Theta: [-0.98511018  0.60051483  0.07036894]\n",
      "Loss in iteration 2297: 0.47301753588775447\n",
      "Theta: [-0.98539484  0.60068774  0.07036505]\n",
      "Loss in iteration 2298: 0.4729928996352072\n",
      "Theta: [-0.98567942  0.60086061  0.07036116]\n",
      "Loss in iteration 2299: 0.4729682777252531\n",
      "Theta: [-0.9859639   0.60103342  0.07035728]\n",
      "Loss in iteration 2300: 0.47294367014717437\n",
      "Theta: [-0.98624831  0.6012062   0.07035339]\n",
      "Loss in iteration 2301: 0.4729190768902637\n",
      "Theta: [-0.98653262  0.60137893  0.0703495 ]\n",
      "Loss in iteration 2302: 0.47289449794382316\n",
      "Theta: [-0.98681685  0.60155161  0.07034562]\n",
      "Loss in iteration 2303: 0.47286993329716415\n",
      "Theta: [-0.987101    0.60172424  0.07034173]\n",
      "Loss in iteration 2304: 0.4728453829396082\n",
      "Theta: [-0.98738506  0.60189683  0.07033785]\n",
      "Loss in iteration 2305: 0.47282084686048637\n",
      "Theta: [-0.98766903  0.60206938  0.07033396]\n",
      "Loss in iteration 2306: 0.47279632504913877\n",
      "Theta: [-0.98795292  0.60224188  0.07033008]\n",
      "Loss in iteration 2307: 0.472771817494916\n",
      "Theta: [-0.98823673  0.60241433  0.0703262 ]\n",
      "Loss in iteration 2308: 0.47274732418717763\n",
      "Theta: [-0.98852045  0.60258674  0.07032231]\n",
      "Loss in iteration 2309: 0.472722845115293\n",
      "Theta: [-0.98880408  0.6027591   0.07031843]\n",
      "Loss in iteration 2310: 0.47269838026864114\n",
      "Theta: [-0.98908763  0.60293141  0.07031455]\n",
      "Loss in iteration 2311: 0.4726739296366106\n",
      "Theta: [-0.98937109  0.60310368  0.07031067]\n",
      "Loss in iteration 2312: 0.4726494932085995\n",
      "Theta: [-0.98965447  0.60327591  0.07030679]\n",
      "Loss in iteration 2313: 0.4726250709740154\n",
      "Theta: [-0.98993777  0.60344809  0.07030291]\n",
      "Loss in iteration 2314: 0.47260066292227504\n",
      "Theta: [-0.99022097  0.60362022  0.07029903]\n",
      "Loss in iteration 2315: 0.472576269042806\n",
      "Theta: [-0.9905041   0.60379231  0.07029515]\n",
      "Loss in iteration 2316: 0.4725518893250438\n",
      "Theta: [-0.99078714  0.60396435  0.07029127]\n",
      "Loss in iteration 2317: 0.4725275237584344\n",
      "Theta: [-0.99107009  0.60413635  0.0702874 ]\n",
      "Loss in iteration 2318: 0.4725031723324331\n",
      "Theta: [-0.99135296  0.6043083   0.07028352]\n",
      "Loss in iteration 2319: 0.47247883503650456\n",
      "Theta: [-0.99163574  0.60448021  0.07027964]\n",
      "Loss in iteration 2320: 0.4724545118601228\n",
      "Theta: [-0.99191844  0.60465207  0.07027577]\n",
      "Loss in iteration 2321: 0.47243020279277187\n",
      "Theta: [-0.99220106  0.60482388  0.07027189]\n",
      "Loss in iteration 2322: 0.4724059078239447\n",
      "Theta: [-0.99248359  0.60499565  0.07026801]\n",
      "Loss in iteration 2323: 0.4723816269431441\n",
      "Theta: [-0.99276603  0.60516738  0.07026414]\n",
      "Loss in iteration 2324: 0.4723573601398819\n",
      "Theta: [-0.9930484   0.60533906  0.07026027]\n",
      "Loss in iteration 2325: 0.47233310740367945\n",
      "Theta: [-0.99333067  0.60551069  0.07025639]\n",
      "Loss in iteration 2326: 0.4723088687240681\n",
      "Theta: [-0.99361286  0.60568228  0.07025252]\n",
      "Loss in iteration 2327: 0.4722846440905878\n",
      "Theta: [-0.99389497  0.60585382  0.07024865]\n",
      "Loss in iteration 2328: 0.4722604334927884\n",
      "Theta: [-0.99417699  0.60602532  0.07024478]\n",
      "Loss in iteration 2329: 0.47223623692022926\n",
      "Theta: [-0.99445893  0.60619677  0.0702409 ]\n",
      "Loss in iteration 2330: 0.4722120543624785\n",
      "Theta: [-0.99474079  0.60636818  0.07023703]\n",
      "Loss in iteration 2331: 0.4721878858091142\n",
      "Theta: [-0.99502256  0.60653954  0.07023316]\n",
      "Loss in iteration 2332: 0.47216373124972366\n",
      "Theta: [-0.99530424  0.60671086  0.07022929]\n",
      "Loss in iteration 2333: 0.4721395906739033\n",
      "Theta: [-0.99558584  0.60688213  0.07022542]\n",
      "Loss in iteration 2334: 0.4721154640712594\n",
      "Theta: [-0.99586736  0.60705336  0.07022156]\n",
      "Loss in iteration 2335: 0.4720913514314071\n",
      "Theta: [-0.99614879  0.60722454  0.07021769]\n",
      "Loss in iteration 2336: 0.47206725274397093\n",
      "Theta: [-0.99643014  0.60739568  0.07021382]\n",
      "Loss in iteration 2337: 0.472043167998585\n",
      "Theta: [-0.99671141  0.60756677  0.07020995]\n",
      "Loss in iteration 2338: 0.4720190971848924\n",
      "Theta: [-0.99699259  0.60773782  0.07020609]\n",
      "Loss in iteration 2339: 0.4719950402925459\n",
      "Theta: [-0.99727368  0.60790882  0.07020222]\n",
      "Loss in iteration 2340: 0.4719709973112074\n",
      "Theta: [-0.9975547   0.60807977  0.07019835]\n",
      "Loss in iteration 2341: 0.4719469682305477\n",
      "Theta: [-0.99783562  0.60825068  0.07019449]\n",
      "Loss in iteration 2342: 0.47192295304024756\n",
      "Theta: [-0.99811647  0.60842155  0.07019062]\n",
      "Loss in iteration 2343: 0.4718989517299963\n",
      "Theta: [-0.99839723  0.60859237  0.07018676]\n",
      "Loss in iteration 2344: 0.4718749642894933\n",
      "Theta: [-0.99867791  0.60876315  0.0701829 ]\n",
      "Loss in iteration 2345: 0.4718509907084464\n",
      "Theta: [-0.9989585   0.60893388  0.07017903]\n",
      "Loss in iteration 2346: 0.47182703097657297\n",
      "Theta: [-0.99923901  0.60910457  0.07017517]\n",
      "Loss in iteration 2347: 0.47180308508359986\n",
      "Theta: [-0.99951944  0.60927521  0.07017131]\n",
      "Loss in iteration 2348: 0.4717791530192627\n",
      "Theta: [-0.99979978  0.60944581  0.07016745]\n",
      "Loss in iteration 2349: 0.4717552347733067\n",
      "Theta: [-1.00008004  0.60961636  0.07016359]\n",
      "Loss in iteration 2350: 0.47173133033548614\n",
      "Theta: [-1.00036021  0.60978687  0.07015973]\n",
      "Loss in iteration 2351: 0.4717074396955645\n",
      "Theta: [-1.0006403   0.60995733  0.07015587]\n",
      "Loss in iteration 2352: 0.47168356284331403\n",
      "Theta: [-1.00092031  0.61012775  0.07015201]\n",
      "Loss in iteration 2353: 0.47165969976851696\n",
      "Theta: [-1.00120023  0.61029812  0.07014815]\n",
      "Loss in iteration 2354: 0.47163585046096385\n",
      "Theta: [-1.00148007  0.61046845  0.07014429]\n",
      "Loss in iteration 2355: 0.4716120149104552\n",
      "Theta: [-1.00175983  0.61063873  0.07014043]\n",
      "Loss in iteration 2356: 0.4715881931067999\n",
      "Theta: [-1.0020395   0.61080897  0.07013657]\n",
      "Loss in iteration 2357: 0.47156438503981646\n",
      "Theta: [-1.00231909  0.61097916  0.07013272]\n",
      "Loss in iteration 2358: 0.47154059069933246\n",
      "Theta: [-1.0025986   0.61114931  0.07012886]\n",
      "Loss in iteration 2359: 0.4715168100751844\n",
      "Theta: [-1.00287803  0.61131942  0.07012501]\n",
      "Loss in iteration 2360: 0.4714930431572179\n",
      "Theta: [-1.00315737  0.61148948  0.07012115]\n",
      "Loss in iteration 2361: 0.4714692899352878\n",
      "Theta: [-1.00343662  0.61165949  0.07011729]\n",
      "Loss in iteration 2362: 0.4714455503992582\n",
      "Theta: [-1.0037158   0.61182947  0.07011344]\n",
      "Loss in iteration 2363: 0.4714218245390018\n",
      "Theta: [-1.00399489  0.61199939  0.07010959]\n",
      "Loss in iteration 2364: 0.47139811234440065\n",
      "Theta: [-1.0042739   0.61216927  0.07010573]\n",
      "Loss in iteration 2365: 0.47137441380534606\n",
      "Theta: [-1.00455282  0.61233911  0.07010188]\n",
      "Loss in iteration 2366: 0.471350728911738\n",
      "Theta: [-1.00483166  0.61250891  0.07009803]\n",
      "Loss in iteration 2367: 0.4713270576534855\n",
      "Theta: [-1.00511042  0.61267865  0.07009418]\n",
      "Loss in iteration 2368: 0.4713034000205071\n",
      "Theta: [-1.0053891   0.61284836  0.07009032]\n",
      "Loss in iteration 2369: 0.47127975600272975\n",
      "Theta: [-1.00566769  0.61301802  0.07008647]\n",
      "Loss in iteration 2370: 0.4712561255900897\n",
      "Theta: [-1.0059462   0.61318763  0.07008262]\n",
      "Loss in iteration 2371: 0.4712325087725324\n",
      "Theta: [-1.00622463  0.61335721  0.07007877]\n",
      "Loss in iteration 2372: 0.47120890554001177\n",
      "Theta: [-1.00650297  0.61352673  0.07007492]\n",
      "Loss in iteration 2373: 0.4711853158824914\n",
      "Theta: [-1.00678124  0.61369621  0.07007108]\n",
      "Loss in iteration 2374: 0.47116173978994325\n",
      "Theta: [-1.00705941  0.61386565  0.07006723]\n",
      "Loss in iteration 2375: 0.4711381772523483\n",
      "Theta: [-1.00733751  0.61403505  0.07006338]\n",
      "Loss in iteration 2376: 0.4711146282596971\n",
      "Theta: [-1.00761552  0.6142044   0.07005953]\n",
      "Loss in iteration 2377: 0.47109109280198835\n",
      "Theta: [-1.00789346  0.6143737   0.07005568]\n",
      "Loss in iteration 2378: 0.4710675708692301\n",
      "Theta: [-1.0081713   0.61454296  0.07005184]\n",
      "Loss in iteration 2379: 0.47104406245143965\n",
      "Theta: [-1.00844907  0.61471218  0.07004799]\n",
      "Loss in iteration 2380: 0.4710205675386422\n",
      "Theta: [-1.00872675  0.61488135  0.07004415]\n",
      "Loss in iteration 2381: 0.47099708612087293\n",
      "Theta: [-1.00900436  0.61505048  0.0700403 ]\n",
      "Loss in iteration 2382: 0.4709736181881754\n",
      "Theta: [-1.00928187  0.61521956  0.07003646]\n",
      "Loss in iteration 2383: 0.4709501637306023\n",
      "Theta: [-1.00955931  0.6153886   0.07003261]\n",
      "Loss in iteration 2384: 0.47092672273821473\n",
      "Theta: [-1.00983666  0.6155576   0.07002877]\n",
      "Loss in iteration 2385: 0.47090329520108326\n",
      "Theta: [-1.01011394  0.61572655  0.07002493]\n",
      "Loss in iteration 2386: 0.47087988110928697\n",
      "Theta: [-1.01039113  0.61589546  0.07002109]\n",
      "Loss in iteration 2387: 0.4708564804529141\n",
      "Theta: [-1.01066823  0.61606432  0.07001724]\n",
      "Loss in iteration 2388: 0.47083309322206124\n",
      "Theta: [-1.01094526  0.61623314  0.0700134 ]\n",
      "Loss in iteration 2389: 0.47080971940683425\n",
      "Theta: [-1.0112222   0.61640192  0.07000956]\n",
      "Loss in iteration 2390: 0.4707863589973476\n",
      "Theta: [-1.01149906  0.61657065  0.07000572]\n",
      "Loss in iteration 2391: 0.4707630119837248\n",
      "Theta: [-1.01177584  0.61673934  0.07000188]\n",
      "Loss in iteration 2392: 0.4707396783560979\n",
      "Theta: [-1.01205254  0.61690798  0.06999804]\n",
      "Loss in iteration 2393: 0.4707163581046079\n",
      "Theta: [-1.01232915  0.61707658  0.0699942 ]\n",
      "Loss in iteration 2394: 0.4706930512194047\n",
      "Theta: [-1.01260568  0.61724514  0.06999036]\n",
      "Loss in iteration 2395: 0.4706697576906467\n",
      "Theta: [-1.01288213  0.61741365  0.06998652]\n",
      "Loss in iteration 2396: 0.47064647750850136\n",
      "Theta: [-1.0131585   0.61758212  0.06998269]\n",
      "Loss in iteration 2397: 0.47062321066314455\n",
      "Theta: [-1.01343479  0.61775054  0.06997885]\n",
      "Loss in iteration 2398: 0.4705999571447615\n",
      "Theta: [-1.01371099  0.61791892  0.06997501]\n",
      "Loss in iteration 2399: 0.4705767169435456\n",
      "Theta: [-1.01398712  0.61808726  0.06997118]\n",
      "Loss in iteration 2400: 0.4705534900496992\n",
      "Theta: [-1.01426316  0.61825555  0.06996734]\n",
      "Loss in iteration 2401: 0.4705302764534335\n",
      "Theta: [-1.01453912  0.6184238   0.06996351]\n",
      "Loss in iteration 2402: 0.47050707614496823\n",
      "Theta: [-1.014815    0.618592    0.06995967]\n",
      "Loss in iteration 2403: 0.4704838891145319\n",
      "Theta: [-1.01509079  0.61876017  0.06995584]\n",
      "Loss in iteration 2404: 0.4704607153523615\n",
      "Theta: [-1.01536651  0.61892828  0.069952  ]\n",
      "Loss in iteration 2405: 0.47043755484870353\n",
      "Theta: [-1.01564214  0.61909636  0.06994817]\n",
      "Loss in iteration 2406: 0.47041440759381203\n",
      "Theta: [-1.01591769  0.61926439  0.06994434]\n",
      "Loss in iteration 2407: 0.4703912735779507\n",
      "Theta: [-1.01619316  0.61943237  0.06994051]\n",
      "Loss in iteration 2408: 0.47036815279139127\n",
      "Theta: [-1.01646855  0.61960032  0.06993667]\n",
      "Loss in iteration 2409: 0.4703450452244143\n",
      "Theta: [-1.01674386  0.61976822  0.06993284]\n",
      "Loss in iteration 2410: 0.4703219508673093\n",
      "Theta: [-1.01701908  0.61993607  0.06992901]\n",
      "Loss in iteration 2411: 0.470298869710374\n",
      "Theta: [-1.01729423  0.62010389  0.06992518]\n",
      "Loss in iteration 2412: 0.47027580174391503\n",
      "Theta: [-1.01756929  0.62027165  0.06992135]\n",
      "Loss in iteration 2413: 0.4702527469582475\n",
      "Theta: [-1.01784427  0.62043938  0.06991752]\n",
      "Loss in iteration 2414: 0.4702297053436953\n",
      "Theta: [-1.01811917  0.62060706  0.06991369]\n",
      "Loss in iteration 2415: 0.4702066768905906\n",
      "Theta: [-1.01839399  0.6207747   0.06990986]\n",
      "Loss in iteration 2416: 0.47018366158927466\n",
      "Theta: [-1.01866873  0.62094229  0.06990604]\n",
      "Loss in iteration 2417: 0.470160659430097\n",
      "Theta: [-1.01894339  0.62110984  0.06990221]\n",
      "Loss in iteration 2418: 0.47013767040341564\n",
      "Theta: [-1.01921796  0.62127735  0.06989838]\n",
      "Loss in iteration 2419: 0.4701146944995975\n",
      "Theta: [-1.01949246  0.62144482  0.06989455]\n",
      "Loss in iteration 2420: 0.4700917317090178\n",
      "Theta: [-1.01976687  0.62161224  0.06989073]\n",
      "Loss in iteration 2421: 0.47006878202206037\n",
      "Theta: [-1.0200412   0.62177961  0.0698869 ]\n",
      "Loss in iteration 2422: 0.47004584542911787\n",
      "Theta: [-1.02031546  0.62194695  0.06988308]\n",
      "Loss in iteration 2423: 0.4700229219205909\n",
      "Theta: [-1.02058963  0.62211424  0.06987925]\n",
      "Loss in iteration 2424: 0.4700000114868891\n",
      "Theta: [-1.02086372  0.62228149  0.06987543]\n",
      "Loss in iteration 2425: 0.4699771141184305\n",
      "Theta: [-1.02113773  0.62244869  0.06987161]\n",
      "Loss in iteration 2426: 0.46995422980564167\n",
      "Theta: [-1.02141165  0.62261585  0.06986778]\n",
      "Loss in iteration 2427: 0.4699313585389575\n",
      "Theta: [-1.0216855   0.62278297  0.06986396]\n",
      "Loss in iteration 2428: 0.4699085003088214\n",
      "Theta: [-1.02195927  0.62295004  0.06986014]\n",
      "Loss in iteration 2429: 0.4698856551056855\n",
      "Theta: [-1.02223295  0.62311708  0.06985631]\n",
      "Loss in iteration 2430: 0.4698628229200105\n",
      "Theta: [-1.02250656  0.62328406  0.06985249]\n",
      "Loss in iteration 2431: 0.46984000374226503\n",
      "Theta: [-1.02278008  0.62345101  0.06984867]\n",
      "Loss in iteration 2432: 0.4698171975629265\n",
      "Theta: [-1.02305353  0.62361791  0.06984485]\n",
      "Loss in iteration 2433: 0.469794404372481\n",
      "Theta: [-1.02332689  0.62378477  0.06984103]\n",
      "Loss in iteration 2434: 0.46977162416142254\n",
      "Theta: [-1.02360017  0.62395158  0.06983721]\n",
      "Loss in iteration 2435: 0.46974885692025414\n",
      "Theta: [-1.02387338  0.62411836  0.06983339]\n",
      "Loss in iteration 2436: 0.46972610263948683\n",
      "Theta: [-1.0241465   0.62428508  0.06982957]\n",
      "Loss in iteration 2437: 0.46970336130964013\n",
      "Theta: [-1.02441954  0.62445177  0.06982576]\n",
      "Loss in iteration 2438: 0.4696806329212423\n",
      "Theta: [-1.0246925   0.62461841  0.06982194]\n",
      "Loss in iteration 2439: 0.4696579174648292\n",
      "Theta: [-1.02496538  0.62478501  0.06981812]\n",
      "Loss in iteration 2440: 0.46963521493094634\n",
      "Theta: [-1.02523818  0.62495157  0.0698143 ]\n",
      "Loss in iteration 2441: 0.46961252531014624\n",
      "Theta: [-1.0255109   0.62511808  0.06981049]\n",
      "Loss in iteration 2442: 0.4695898485929908\n",
      "Theta: [-1.02578354  0.62528456  0.06980667]\n",
      "Loss in iteration 2443: 0.4695671847700497\n",
      "Theta: [-1.0260561   0.62545098  0.06980286]\n",
      "Loss in iteration 2444: 0.46954453383190153\n",
      "Theta: [-1.02632858  0.62561737  0.06979904]\n",
      "Loss in iteration 2445: 0.4695218957691327\n",
      "Theta: [-1.02660098  0.62578371  0.06979523]\n",
      "Loss in iteration 2446: 0.4694992705723382\n",
      "Theta: [-1.0268733   0.62595001  0.06979141]\n",
      "Loss in iteration 2447: 0.4694766582321212\n",
      "Theta: [-1.02714554  0.62611627  0.0697876 ]\n",
      "Loss in iteration 2448: 0.4694540587390936\n",
      "Theta: [-1.0274177   0.62628248  0.06978379]\n",
      "Loss in iteration 2449: 0.4694314720838752\n",
      "Theta: [-1.02768978  0.62644865  0.06977997]\n",
      "Loss in iteration 2450: 0.4694088982570942\n",
      "Theta: [-1.02796178  0.62661478  0.06977616]\n",
      "Loss in iteration 2451: 0.4693863372493873\n",
      "Theta: [-1.0282337   0.62678086  0.06977235]\n",
      "Loss in iteration 2452: 0.4693637890513991\n",
      "Theta: [-1.02850554  0.62694691  0.06976854]\n",
      "Loss in iteration 2453: 0.46934125365378276\n",
      "Theta: [-1.0287773   0.6271129   0.06976473]\n",
      "Loss in iteration 2454: 0.46931873104719984\n",
      "Theta: [-1.02904898  0.62727886  0.06976092]\n",
      "Loss in iteration 2455: 0.4692962212223199\n",
      "Theta: [-1.02932058  0.62744478  0.06975711]\n",
      "Loss in iteration 2456: 0.4692737241698207\n",
      "Theta: [-1.0295921   0.62761065  0.0697533 ]\n",
      "Loss in iteration 2457: 0.46925123988038886\n",
      "Theta: [-1.02986354  0.62777648  0.06974949]\n",
      "Loss in iteration 2458: 0.46922876834471827\n",
      "Theta: [-1.0301349   0.62794226  0.06974568]\n",
      "Loss in iteration 2459: 0.46920630955351184\n",
      "Theta: [-1.03040618  0.628108    0.06974187]\n",
      "Loss in iteration 2460: 0.4691838634974805\n",
      "Theta: [-1.03067738  0.6282737   0.06973806]\n",
      "Loss in iteration 2461: 0.4691614301673431\n",
      "Theta: [-1.03094851  0.62843936  0.06973426]\n",
      "Loss in iteration 2462: 0.46913900955382704\n",
      "Theta: [-1.03121955  0.62860498  0.06973045]\n",
      "Loss in iteration 2463: 0.4691166016476678\n",
      "Theta: [-1.03149051  0.62877055  0.06972664]\n",
      "Loss in iteration 2464: 0.469094206439609\n",
      "Theta: [-1.0317614   0.62893608  0.06972284]\n",
      "Loss in iteration 2465: 0.46907182392040264\n",
      "Theta: [-1.0320322   0.62910157  0.06971903]\n",
      "Loss in iteration 2466: 0.4690494540808086\n",
      "Theta: [-1.03230292  0.62926701  0.06971523]\n",
      "Loss in iteration 2467: 0.4690270969115952\n",
      "Theta: [-1.03257357  0.62943242  0.06971142]\n",
      "Loss in iteration 2468: 0.46900475240353884\n",
      "Theta: [-1.03284414  0.62959778  0.06970762]\n",
      "Loss in iteration 2469: 0.4689824205474238\n",
      "Theta: [-1.03311462  0.6297631   0.06970381]\n",
      "Loss in iteration 2470: 0.46896010133404303\n",
      "Theta: [-1.03338503  0.62992837  0.06970001]\n",
      "Loss in iteration 2471: 0.4689377947541969\n",
      "Theta: [-1.03365536  0.6300936   0.06969621]\n",
      "Loss in iteration 2472: 0.46891550079869476\n",
      "Theta: [-1.03392561  0.63025879  0.06969241]\n",
      "Loss in iteration 2473: 0.4688932194583533\n",
      "Theta: [-1.03419578  0.63042394  0.0696886 ]\n",
      "Loss in iteration 2474: 0.4688709507239978\n",
      "Theta: [-1.03446587  0.63058905  0.0696848 ]\n",
      "Loss in iteration 2475: 0.46884869458646156\n",
      "Theta: [-1.03473588  0.63075411  0.069681  ]\n",
      "Loss in iteration 2476: 0.46882645103658577\n",
      "Theta: [-1.03500581  0.63091913  0.0696772 ]\n",
      "Loss in iteration 2477: 0.46880422006522005\n",
      "Theta: [-1.03527567  0.63108411  0.0696734 ]\n",
      "Loss in iteration 2478: 0.4687820016632214\n",
      "Theta: [-1.03554544  0.63124905  0.0696696 ]\n",
      "Loss in iteration 2479: 0.468759795821456\n",
      "Theta: [-1.03581514  0.63141394  0.0696658 ]\n",
      "Loss in iteration 2480: 0.4687376025307971\n",
      "Theta: [-1.03608476  0.63157879  0.069662  ]\n",
      "Loss in iteration 2481: 0.4687154217821263\n",
      "Theta: [-1.03635429  0.6317436   0.0696582 ]\n",
      "Loss in iteration 2482: 0.46869325356633346\n",
      "Theta: [-1.03662375  0.63190837  0.06965441]\n",
      "Loss in iteration 2483: 0.4686710978743164\n",
      "Theta: [-1.03689313  0.6320731   0.06965061]\n",
      "Loss in iteration 2484: 0.46864895469698065\n",
      "Theta: [-1.03716243  0.63223778  0.06964681]\n",
      "Loss in iteration 2485: 0.46862682402524025\n",
      "Theta: [-1.03743166  0.63240242  0.06964302]\n",
      "Loss in iteration 2486: 0.46860470585001657\n",
      "Theta: [-1.0377008   0.63256702  0.06963922]\n",
      "Loss in iteration 2487: 0.46858260016224\n",
      "Theta: [-1.03796987  0.63273158  0.06963542]\n",
      "Loss in iteration 2488: 0.468560506952848\n",
      "Theta: [-1.03823885  0.63289609  0.06963163]\n",
      "Loss in iteration 2489: 0.46853842621278635\n",
      "Theta: [-1.03850776  0.63306056  0.06962783]\n",
      "Loss in iteration 2490: 0.4685163579330088\n",
      "Theta: [-1.03877659  0.63322499  0.06962404]\n",
      "Loss in iteration 2491: 0.46849430210447723\n",
      "Theta: [-1.03904534  0.63338938  0.06962025]\n",
      "Loss in iteration 2492: 0.46847225871816134\n",
      "Theta: [-1.03931402  0.63355373  0.06961645]\n",
      "Loss in iteration 2493: 0.46845022776503853\n",
      "Theta: [-1.03958261  0.63371803  0.06961266]\n",
      "Loss in iteration 2494: 0.4684282092360945\n",
      "Theta: [-1.03985113  0.6338823   0.06960887]\n",
      "Loss in iteration 2495: 0.46840620312232284\n",
      "Theta: [-1.04011957  0.63404652  0.06960507]\n",
      "Loss in iteration 2496: 0.4683842094147251\n",
      "Theta: [-1.04038792  0.63421069  0.06960128]\n",
      "Loss in iteration 2497: 0.46836222810431055\n",
      "Theta: [-1.04065621  0.63437483  0.06959749]\n",
      "Loss in iteration 2498: 0.46834025918209643\n",
      "Theta: [-1.04092441  0.63453893  0.0695937 ]\n",
      "Loss in iteration 2499: 0.468318302639108\n",
      "Theta: [-1.04119253  0.63470298  0.06958991]\n",
      "Loss in iteration 2500: 0.46829635846637835\n",
      "Theta: [-1.04146058  0.63486699  0.06958612]\n",
      "Loss in iteration 2501: 0.46827442665494856\n",
      "Theta: [-1.04172855  0.63503096  0.06958233]\n",
      "Loss in iteration 2502: 0.46825250719586764\n",
      "Theta: [-1.04199644  0.63519489  0.06957854]\n",
      "Loss in iteration 2503: 0.4682306000801919\n",
      "Theta: [-1.04226425  0.63535877  0.06957475]\n",
      "Loss in iteration 2504: 0.4682087052989861\n",
      "Theta: [-1.04253198  0.63552261  0.06957096]\n",
      "Loss in iteration 2505: 0.468186822843323\n",
      "Theta: [-1.04279964  0.63568642  0.06956717]\n",
      "Loss in iteration 2506: 0.46816495270428277\n",
      "Theta: [-1.04306722  0.63585018  0.06956339]\n",
      "Loss in iteration 2507: 0.4681430948729535\n",
      "Theta: [-1.04333472  0.63601389  0.0695596 ]\n",
      "Loss in iteration 2508: 0.4681212493404313\n",
      "Theta: [-1.04360214  0.63617757  0.06955581]\n",
      "Loss in iteration 2509: 0.46809941609782\n",
      "Theta: [-1.04386948  0.63634121  0.06955203]\n",
      "Loss in iteration 2510: 0.4680775951362311\n",
      "Theta: [-1.04413675  0.6365048   0.06954824]\n",
      "Loss in iteration 2511: 0.46805578644678414\n",
      "Theta: [-1.04440393  0.63666835  0.06954446]\n",
      "Loss in iteration 2512: 0.4680339900206064\n",
      "Theta: [-1.04467105  0.63683186  0.06954067]\n",
      "Loss in iteration 2513: 0.468012205848833\n",
      "Theta: [-1.04493808  0.63699533  0.06953689]\n",
      "Loss in iteration 2514: 0.4679904339226067\n",
      "Theta: [-1.04520503  0.63715875  0.0695331 ]\n",
      "Loss in iteration 2515: 0.4679686742330784\n",
      "Theta: [-1.04547191  0.63732214  0.06952932]\n",
      "Loss in iteration 2516: 0.46794692677140604\n",
      "Theta: [-1.04573871  0.63748548  0.06952554]\n",
      "Loss in iteration 2517: 0.467925191528756\n",
      "Theta: [-1.04600543  0.63764878  0.06952175]\n",
      "Loss in iteration 2518: 0.4679034684963024\n",
      "Theta: [-1.04627208  0.63781204  0.06951797]\n",
      "Loss in iteration 2519: 0.4678817576652265\n",
      "Theta: [-1.04653864  0.63797526  0.06951419]\n",
      "Loss in iteration 2520: 0.4678600590267181\n",
      "Theta: [-1.04680513  0.63813844  0.06951041]\n",
      "Loss in iteration 2521: 0.46783837257197397\n",
      "Theta: [-1.04707154  0.63830158  0.06950663]\n",
      "Loss in iteration 2522: 0.46781669829219935\n",
      "Theta: [-1.04733788  0.63846467  0.06950284]\n",
      "Loss in iteration 2523: 0.4677950361786066\n",
      "Theta: [-1.04760413  0.63862772  0.06949906]\n",
      "Loss in iteration 2524: 0.467773386222416\n",
      "Theta: [-1.04787031  0.63879073  0.06949528]\n",
      "Loss in iteration 2525: 0.46775174841485573\n",
      "Theta: [-1.04813642  0.6389537   0.0694915 ]\n",
      "Loss in iteration 2526: 0.46773012274716136\n",
      "Theta: [-1.04840244  0.63911663  0.06948773]\n",
      "Loss in iteration 2527: 0.46770850921057616\n",
      "Theta: [-1.04866839  0.63927952  0.06948395]\n",
      "Loss in iteration 2528: 0.46768690779635136\n",
      "Theta: [-1.04893426  0.63944237  0.06948017]\n",
      "Loss in iteration 2529: 0.4676653184957458\n",
      "Theta: [-1.04920005  0.63960517  0.06947639]\n",
      "Loss in iteration 2530: 0.46764374130002545\n",
      "Theta: [-1.04946577  0.63976793  0.06947261]\n",
      "Loss in iteration 2531: 0.46762217620046465\n",
      "Theta: [-1.04973141  0.63993065  0.06946884]\n",
      "Loss in iteration 2532: 0.46760062318834505\n",
      "Theta: [-1.04999697  0.64009334  0.06946506]\n",
      "Loss in iteration 2533: 0.46757908225495604\n",
      "Theta: [-1.05026245  0.64025597  0.06946128]\n",
      "Loss in iteration 2534: 0.4675575533915945\n",
      "Theta: [-1.05052786  0.64041857  0.06945751]\n",
      "Loss in iteration 2535: 0.467536036589565\n",
      "Theta: [-1.05079319  0.64058113  0.06945373]\n",
      "Loss in iteration 2536: 0.46751453184017977\n",
      "Theta: [-1.05105844  0.64074364  0.06944996]\n",
      "Loss in iteration 2537: 0.46749303913475865\n",
      "Theta: [-1.05132362  0.64090612  0.06944618]\n",
      "Loss in iteration 2538: 0.4674715584646291\n",
      "Theta: [-1.05158872  0.64106855  0.06944241]\n",
      "Loss in iteration 2539: 0.46745008982112607\n",
      "Theta: [-1.05185374  0.64123094  0.06943864]\n",
      "Loss in iteration 2540: 0.4674286331955922\n",
      "Theta: [-1.05211869  0.64139329  0.06943486]\n",
      "Loss in iteration 2541: 0.4674071885793776\n",
      "Theta: [-1.05238356  0.6415556   0.06943109]\n",
      "Loss in iteration 2542: 0.46738575596384\n",
      "Theta: [-1.05264835  0.64171787  0.06942732]\n",
      "Loss in iteration 2543: 0.4673643353403449\n",
      "Theta: [-1.05291306  0.6418801   0.06942355]\n",
      "Loss in iteration 2544: 0.46734292670026484\n",
      "Theta: [-1.0531777   0.64204229  0.06941977]\n",
      "Loss in iteration 2545: 0.4673215300349805\n",
      "Theta: [-1.05344227  0.64220443  0.069416  ]\n",
      "Loss in iteration 2546: 0.4673001453358799\n",
      "Theta: [-1.05370675  0.64236654  0.06941223]\n",
      "Loss in iteration 2547: 0.46727877259435824\n",
      "Theta: [-1.05397116  0.6425286   0.06940846]\n",
      "Loss in iteration 2548: 0.4672574118018188\n",
      "Theta: [-1.05423549  0.64269062  0.06940469]\n",
      "Loss in iteration 2549: 0.46723606294967185\n",
      "Theta: [-1.05449975  0.6428526   0.06940092]\n",
      "Loss in iteration 2550: 0.4672147260293358\n",
      "Theta: [-1.05476393  0.64301454  0.06939715]\n",
      "Loss in iteration 2551: 0.4671934010322359\n",
      "Theta: [-1.05502803  0.64317644  0.06939338]\n",
      "Loss in iteration 2552: 0.46717208794980514\n",
      "Theta: [-1.05529206  0.6433383   0.06938962]\n",
      "Loss in iteration 2553: 0.46715078677348454\n",
      "Theta: [-1.05555601  0.64350012  0.06938585]\n",
      "Loss in iteration 2554: 0.46712949749472144\n",
      "Theta: [-1.05581988  0.6436619   0.06938208]\n",
      "Loss in iteration 2555: 0.4671082201049719\n",
      "Theta: [-1.05608368  0.64382363  0.06937831]\n",
      "Loss in iteration 2556: 0.4670869545956984\n",
      "Theta: [-1.0563474   0.64398533  0.06937455]\n",
      "Loss in iteration 2557: 0.4670657009583718\n",
      "Theta: [-1.05661104  0.64414698  0.06937078]\n",
      "Loss in iteration 2558: 0.4670444591844695\n",
      "Theta: [-1.05687461  0.64430859  0.06936702]\n",
      "Loss in iteration 2559: 0.467023229265477\n",
      "Theta: [-1.0571381   0.64447017  0.06936325]\n",
      "Loss in iteration 2560: 0.46700201119288726\n",
      "Theta: [-1.05740152  0.6446317   0.06935948]\n",
      "Loss in iteration 2561: 0.46698080495820016\n",
      "Theta: [-1.05766486  0.64479319  0.06935572]\n",
      "Loss in iteration 2562: 0.46695961055292345\n",
      "Theta: [-1.05792812  0.64495464  0.06935196]\n",
      "Loss in iteration 2563: 0.46693842796857205\n",
      "Theta: [-1.05819131  0.64511605  0.06934819]\n",
      "Loss in iteration 2564: 0.4669172571966682\n",
      "Theta: [-1.05845442  0.64527742  0.06934443]\n",
      "Loss in iteration 2565: 0.4668960982287422\n",
      "Theta: [-1.05871746  0.64543874  0.06934067]\n",
      "Loss in iteration 2566: 0.4668749510563307\n",
      "Theta: [-1.05898042  0.64560003  0.0693369 ]\n",
      "Loss in iteration 2567: 0.46685381567097844\n",
      "Theta: [-1.0592433   0.64576128  0.06933314]\n",
      "Loss in iteration 2568: 0.46683269206423744\n",
      "Theta: [-1.05950611  0.64592248  0.06932938]\n",
      "Loss in iteration 2569: 0.46681158022766717\n",
      "Theta: [-1.05976884  0.64608365  0.06932562]\n",
      "Loss in iteration 2570: 0.466790480152834\n",
      "Theta: [-1.0600315   0.64624477  0.06932186]\n",
      "Loss in iteration 2571: 0.4667693918313121\n",
      "Theta: [-1.06029408  0.64640586  0.0693181 ]\n",
      "Loss in iteration 2572: 0.4667483152546831\n",
      "Theta: [-1.06055658  0.6465669   0.06931434]\n",
      "Loss in iteration 2573: 0.46672725041453533\n",
      "Theta: [-1.06081901  0.6467279   0.06931058]\n",
      "Loss in iteration 2574: 0.46670619730246476\n",
      "Theta: [-1.06108136  0.64688887  0.06930682]\n",
      "Loss in iteration 2575: 0.4666851559100754\n",
      "Theta: [-1.06134364  0.64704979  0.06930306]\n",
      "Loss in iteration 2576: 0.46666412622897746\n",
      "Theta: [-1.06160584  0.64721067  0.0692993 ]\n",
      "Loss in iteration 2577: 0.4666431082507889\n",
      "Theta: [-1.06186797  0.64737151  0.06929554]\n",
      "Loss in iteration 2578: 0.4666221019671354\n",
      "Theta: [-1.06213002  0.64753231  0.06929178]\n",
      "Loss in iteration 2579: 0.46660110736964916\n",
      "Theta: [-1.062392    0.64769307  0.06928802]\n",
      "Loss in iteration 2580: 0.4665801244499703\n",
      "Theta: [-1.0626539   0.64785379  0.06928427]\n",
      "Loss in iteration 2581: 0.4665591531997461\n",
      "Theta: [-1.06291572  0.64801447  0.06928051]\n",
      "Loss in iteration 2582: 0.4665381936106306\n",
      "Theta: [-1.06317747  0.64817511  0.06927675]\n",
      "Loss in iteration 2583: 0.46651724567428604\n",
      "Theta: [-1.06343914  0.64833571  0.069273  ]\n",
      "Loss in iteration 2584: 0.46649630938238085\n",
      "Theta: [-1.06370074  0.64849627  0.06926924]\n",
      "Loss in iteration 2585: 0.46647538472659156\n",
      "Theta: [-1.06396226  0.64865678  0.06926549]\n",
      "Loss in iteration 2586: 0.46645447169860155\n",
      "Theta: [-1.06422371  0.64881726  0.06926173]\n",
      "Loss in iteration 2587: 0.4664335702901017\n",
      "Theta: [-1.06448508  0.6489777   0.06925798]\n",
      "Loss in iteration 2588: 0.46641268049278983\n",
      "Theta: [-1.06474638  0.64913809  0.06925423]\n",
      "Loss in iteration 2589: 0.46639180229837085\n",
      "Theta: [-1.0650076   0.64929845  0.06925047]\n",
      "Loss in iteration 2590: 0.4663709356985574\n",
      "Theta: [-1.06526875  0.64945877  0.06924672]\n",
      "Loss in iteration 2591: 0.4663500806850691\n",
      "Theta: [-1.06552982  0.64961904  0.06924297]\n",
      "Loss in iteration 2592: 0.46632923724963254\n",
      "Theta: [-1.06579081  0.64977928  0.06923921]\n",
      "Loss in iteration 2593: 0.4663084053839818\n",
      "Theta: [-1.06605173  0.64993947  0.06923546]\n",
      "Loss in iteration 2594: 0.46628758507985807\n",
      "Theta: [-1.06631258  0.65009963  0.06923171]\n",
      "Loss in iteration 2595: 0.46626677632900965\n",
      "Theta: [-1.06657335  0.65025975  0.06922796]\n",
      "Loss in iteration 2596: 0.4662459791231919\n",
      "Theta: [-1.06683405  0.65041982  0.06922421]\n",
      "Loss in iteration 2597: 0.46622519345416774\n",
      "Theta: [-1.06709467  0.65057985  0.06922046]\n",
      "Loss in iteration 2598: 0.46620441931370676\n",
      "Theta: [-1.06735521  0.65073985  0.06921671]\n",
      "Loss in iteration 2599: 0.46618365669358625\n",
      "Theta: [-1.06761568  0.6508998   0.06921296]\n",
      "Loss in iteration 2600: 0.4661629055855899\n",
      "Theta: [-1.06787608  0.65105972  0.06920921]\n",
      "Loss in iteration 2601: 0.46614216598150954\n",
      "Theta: [-1.0681364   0.65121959  0.06920546]\n",
      "Loss in iteration 2602: 0.46612143787314314\n",
      "Theta: [-1.06839665  0.65137943  0.06920171]\n",
      "Loss in iteration 2603: 0.4661007212522961\n",
      "Theta: [-1.06865682  0.65153922  0.06919796]\n",
      "Loss in iteration 2604: 0.4660800161107816\n",
      "Theta: [-1.06891692  0.65169898  0.06919422]\n",
      "Loss in iteration 2605: 0.4660593224404188\n",
      "Theta: [-1.06917694  0.65185869  0.06919047]\n",
      "Loss in iteration 2606: 0.46603864023303493\n",
      "Theta: [-1.06943689  0.65201837  0.06918672]\n",
      "Loss in iteration 2607: 0.46601796948046365\n",
      "Theta: [-1.06969676  0.652178    0.06918298]\n",
      "Loss in iteration 2608: 0.46599731017454604\n",
      "Theta: [-1.06995656  0.65233759  0.06917923]\n",
      "Loss in iteration 2609: 0.46597666230713053\n",
      "Theta: [-1.07021628  0.65249715  0.06917548]\n",
      "Loss in iteration 2610: 0.46595602587007173\n",
      "Theta: [-1.07047593  0.65265666  0.06917174]\n",
      "Loss in iteration 2611: 0.4659354008552322\n",
      "Theta: [-1.07073551  0.65281614  0.06916799]\n",
      "Loss in iteration 2612: 0.4659147872544811\n",
      "Theta: [-1.07099501  0.65297557  0.06916425]\n",
      "Loss in iteration 2613: 0.46589418505969504\n",
      "Theta: [-1.07125443  0.65313497  0.06916051]\n",
      "Loss in iteration 2614: 0.4658735942627572\n",
      "Theta: [-1.07151379  0.65329432  0.06915676]\n",
      "Loss in iteration 2615: 0.4658530148555579\n",
      "Theta: [-1.07177306  0.65345364  0.06915302]\n",
      "Loss in iteration 2616: 0.4658324468299947\n",
      "Theta: [-1.07203227  0.65361291  0.06914928]\n",
      "Loss in iteration 2617: 0.4658118901779722\n",
      "Theta: [-1.07229139  0.65377215  0.06914553]\n",
      "Loss in iteration 2618: 0.4657913448914018\n",
      "Theta: [-1.07255045  0.65393135  0.06914179]\n",
      "Loss in iteration 2619: 0.46577081096220196\n",
      "Theta: [-1.07280943  0.6540905   0.06913805]\n",
      "Loss in iteration 2620: 0.46575028838229804\n",
      "Theta: [-1.07306834  0.65424962  0.06913431]\n",
      "Loss in iteration 2621: 0.46572977714362274\n",
      "Theta: [-1.07332717  0.6544087   0.06913057]\n",
      "Loss in iteration 2622: 0.46570927723811567\n",
      "Theta: [-1.07358592  0.65456773  0.06912682]\n",
      "Loss in iteration 2623: 0.46568878865772306\n",
      "Theta: [-1.07384461  0.65472673  0.06912308]\n",
      "Loss in iteration 2624: 0.4656683113943983\n",
      "Theta: [-1.07410322  0.65488569  0.06911934]\n",
      "Loss in iteration 2625: 0.46564784544010207\n",
      "Theta: [-1.07436175  0.65504461  0.0691156 ]\n",
      "Loss in iteration 2626: 0.46562739078680154\n",
      "Theta: [-1.07462021  0.65520348  0.06911187]\n",
      "Loss in iteration 2627: 0.465606947426471\n",
      "Theta: [-1.0748786   0.65536232  0.06910813]\n",
      "Loss in iteration 2628: 0.4655865153510918\n",
      "Theta: [-1.07513692  0.65552112  0.06910439]\n",
      "Loss in iteration 2629: 0.46556609455265224\n",
      "Theta: [-1.07539516  0.65567988  0.06910065]\n",
      "Loss in iteration 2630: 0.4655456850231473\n",
      "Theta: [-1.07565332  0.6558386   0.06909691]\n",
      "Loss in iteration 2631: 0.46552528675457905\n",
      "Theta: [-1.07591141  0.65599728  0.06909318]\n",
      "Loss in iteration 2632: 0.4655048997389566\n",
      "Theta: [-1.07616943  0.65615592  0.06908944]\n",
      "Loss in iteration 2633: 0.46548452396829587\n",
      "Theta: [-1.07642738  0.65631453  0.0690857 ]\n",
      "Loss in iteration 2634: 0.46546415943461944\n",
      "Theta: [-1.07668525  0.65647309  0.06908197]\n",
      "Loss in iteration 2635: 0.4654438061299571\n",
      "Theta: [-1.07694304  0.65663161  0.06907823]\n",
      "Loss in iteration 2636: 0.46542346404634555\n",
      "Theta: [-1.07720077  0.65679009  0.06907449]\n",
      "Loss in iteration 2637: 0.46540313317582815\n",
      "Theta: [-1.07745841  0.65694854  0.06907076]\n",
      "Loss in iteration 2638: 0.46538281351045535\n",
      "Theta: [-1.07771599  0.65710694  0.06906702]\n",
      "Loss in iteration 2639: 0.4653625050422842\n",
      "Theta: [-1.07797349  0.65726531  0.06906329]\n",
      "Loss in iteration 2640: 0.465342207763379\n",
      "Theta: [-1.07823092  0.65742363  0.06905956]\n",
      "Loss in iteration 2641: 0.46532192166581043\n",
      "Theta: [-1.07848828  0.65758192  0.06905582]\n",
      "Loss in iteration 2642: 0.4653016467416565\n",
      "Theta: [-1.07874556  0.65774016  0.06905209]\n",
      "Loss in iteration 2643: 0.46528138298300176\n",
      "Theta: [-1.07900277  0.65789837  0.06904836]\n",
      "Loss in iteration 2644: 0.46526113038193784\n",
      "Theta: [-1.0792599   0.65805654  0.06904462]\n",
      "Loss in iteration 2645: 0.4652408889305626\n",
      "Theta: [-1.07951696  0.65821467  0.06904089]\n",
      "Loss in iteration 2646: 0.46522065862098166\n",
      "Theta: [-1.07977395  0.65837276  0.06903716]\n",
      "Loss in iteration 2647: 0.46520043944530687\n",
      "Theta: [-1.08003086  0.65853081  0.06903343]\n",
      "Loss in iteration 2648: 0.4651802313956566\n",
      "Theta: [-1.08028771  0.65868882  0.0690297 ]\n",
      "Loss in iteration 2649: 0.4651600344641569\n",
      "Theta: [-1.08054447  0.65884679  0.06902597]\n",
      "Loss in iteration 2650: 0.4651398486429397\n",
      "Theta: [-1.08080117  0.65900472  0.06902224]\n",
      "Loss in iteration 2651: 0.46511967392414433\n",
      "Theta: [-1.08105779  0.65916261  0.06901851]\n",
      "Loss in iteration 2652: 0.4650995102999169\n",
      "Theta: [-1.08131434  0.65932047  0.06901478]\n",
      "Loss in iteration 2653: 0.46507935776240955\n",
      "Theta: [-1.08157081  0.65947828  0.06901105]\n",
      "Loss in iteration 2654: 0.46505921630378233\n",
      "Theta: [-1.08182722  0.65963606  0.06900732]\n",
      "Loss in iteration 2655: 0.4650390859162012\n",
      "Theta: [-1.08208354  0.65979379  0.06900359]\n",
      "Loss in iteration 2656: 0.465018966591839\n",
      "Theta: [-1.0823398   0.65995149  0.06899986]\n",
      "Loss in iteration 2657: 0.4649988583228758\n",
      "Theta: [-1.08259598  0.66010915  0.06899614]\n",
      "Loss in iteration 2658: 0.4649787611014978\n",
      "Theta: [-1.08285209  0.66026677  0.06899241]\n",
      "Loss in iteration 2659: 0.4649586749198981\n",
      "Theta: [-1.08310813  0.66042435  0.06898868]\n",
      "Loss in iteration 2660: 0.464938599770277\n",
      "Theta: [-1.08336409  0.66058189  0.06898496]\n",
      "Loss in iteration 2661: 0.46491853564484104\n",
      "Theta: [-1.08361999  0.66073939  0.06898123]\n",
      "Loss in iteration 2662: 0.46489848253580335\n",
      "Theta: [-1.0838758   0.66089685  0.0689775 ]\n",
      "Loss in iteration 2663: 0.4648784404353842\n",
      "Theta: [-1.08413155  0.66105428  0.06897378]\n",
      "Loss in iteration 2664: 0.46485840933581046\n",
      "Theta: [-1.08438722  0.66121166  0.06897005]\n",
      "Loss in iteration 2665: 0.46483838922931525\n",
      "Theta: [-1.08464282  0.66136901  0.06896633]\n",
      "Loss in iteration 2666: 0.46481838010813903\n",
      "Theta: [-1.08489835  0.66152631  0.0689626 ]\n",
      "Loss in iteration 2667: 0.46479838196452866\n",
      "Theta: [-1.0851538   0.66168358  0.06895888]\n",
      "Loss in iteration 2668: 0.4647783947907375\n",
      "Theta: [-1.08540919  0.66184081  0.06895516]\n",
      "Loss in iteration 2669: 0.4647584185790258\n",
      "Theta: [-1.08566449  0.661998    0.06895143]\n",
      "Loss in iteration 2670: 0.4647384533216604\n",
      "Theta: [-1.08591973  0.66215515  0.06894771]\n",
      "Loss in iteration 2671: 0.4647184990109149\n",
      "Theta: [-1.08617489  0.66231226  0.06894399]\n",
      "Loss in iteration 2672: 0.4646985556390692\n",
      "Theta: [-1.08642999  0.66246934  0.06894026]\n",
      "Loss in iteration 2673: 0.46467862319841047\n",
      "Theta: [-1.086685    0.66262637  0.06893654]\n",
      "Loss in iteration 2674: 0.4646587016812316\n",
      "Theta: [-1.08693995  0.66278337  0.06893282]\n",
      "Loss in iteration 2675: 0.46463879107983325\n",
      "Theta: [-1.08719482  0.66294032  0.0689291 ]\n",
      "Loss in iteration 2676: 0.4646188913865217\n",
      "Theta: [-1.08744963  0.66309724  0.06892538]\n",
      "Loss in iteration 2677: 0.4645990025936104\n",
      "Theta: [-1.08770436  0.66325412  0.06892166]\n",
      "Loss in iteration 2678: 0.464579124693419\n",
      "Theta: [-1.08795901  0.66341096  0.06891794]\n",
      "Loss in iteration 2679: 0.4645592576782745\n",
      "Theta: [-1.0882136   0.66356776  0.06891422]\n",
      "Loss in iteration 2680: 0.4645394015405096\n",
      "Theta: [-1.08846811  0.66372453  0.0689105 ]\n",
      "Loss in iteration 2681: 0.46451955627246405\n",
      "Theta: [-1.08872255  0.66388125  0.06890678]\n",
      "Loss in iteration 2682: 0.46449972186648414\n",
      "Theta: [-1.08897692  0.66403794  0.06890306]\n",
      "Loss in iteration 2683: 0.4644798983149229\n",
      "Theta: [-1.08923121  0.66419458  0.06889934]\n",
      "Loss in iteration 2684: 0.46446008561013946\n",
      "Theta: [-1.08948543  0.66435119  0.06889563]\n",
      "Loss in iteration 2685: 0.4644402837445002\n",
      "Theta: [-1.08973958  0.66450776  0.06889191]\n",
      "Loss in iteration 2686: 0.46442049271037716\n",
      "Theta: [-1.08999366  0.66466429  0.06888819]\n",
      "Loss in iteration 2687: 0.46440071250014986\n",
      "Theta: [-1.09024767  0.66482079  0.06888448]\n",
      "Loss in iteration 2688: 0.4643809431062036\n",
      "Theta: [-1.09050161  0.66497724  0.06888076]\n",
      "Loss in iteration 2689: 0.4643611845209308\n",
      "Theta: [-1.09075547  0.66513365  0.06887704]\n",
      "Loss in iteration 2690: 0.46434143673673\n",
      "Theta: [-1.09100926  0.66529003  0.06887333]\n",
      "Loss in iteration 2691: 0.4643216997460064\n",
      "Theta: [-1.09126298  0.66544637  0.06886961]\n",
      "Loss in iteration 2692: 0.464301973541172\n",
      "Theta: [-1.09151662  0.66560267  0.0688659 ]\n",
      "Loss in iteration 2693: 0.4642822581146448\n",
      "Theta: [-1.0917702   0.66575893  0.06886218]\n",
      "Loss in iteration 2694: 0.4642625534588496\n",
      "Theta: [-1.0920237   0.66591515  0.06885847]\n",
      "Loss in iteration 2695: 0.4642428595662178\n",
      "Theta: [-1.09227713  0.66607134  0.06885475]\n",
      "Loss in iteration 2696: 0.4642231764291871\n",
      "Theta: [-1.09253049  0.66622748  0.06885104]\n",
      "Loss in iteration 2697: 0.4642035040402014\n",
      "Theta: [-1.09278378  0.66638359  0.06884733]\n",
      "Loss in iteration 2698: 0.4641838423917119\n",
      "Theta: [-1.093037    0.66653966  0.06884361]\n",
      "Loss in iteration 2699: 0.4641641914761754\n",
      "Theta: [-1.09329014  0.66669569  0.0688399 ]\n",
      "Loss in iteration 2700: 0.464144551286056\n",
      "Theta: [-1.09354321  0.66685168  0.06883619]\n",
      "Loss in iteration 2701: 0.4641249218138234\n",
      "Theta: [-1.09379621  0.66700763  0.06883248]\n",
      "Loss in iteration 2702: 0.46410530305195424\n",
      "Theta: [-1.09404914  0.66716355  0.06882877]\n",
      "Loss in iteration 2703: 0.46408569499293173\n",
      "Theta: [-1.094302    0.66731942  0.06882506]\n",
      "Loss in iteration 2704: 0.4640660976292452\n",
      "Theta: [-1.09455479  0.66747526  0.06882135]\n",
      "Loss in iteration 2705: 0.4640465109533905\n",
      "Theta: [-1.0948075   0.66763106  0.06881763]\n",
      "Loss in iteration 2706: 0.4640269349578699\n",
      "Theta: [-1.09506014  0.66778682  0.06881392]\n",
      "Loss in iteration 2707: 0.46400736963519235\n",
      "Theta: [-1.09531272  0.66794255  0.06881021]\n",
      "Loss in iteration 2708: 0.46398781497787267\n",
      "Theta: [-1.09556522  0.66809823  0.06880651]\n",
      "Loss in iteration 2709: 0.4639682709784328\n",
      "Theta: [-1.09581765  0.66825388  0.0688028 ]\n",
      "Loss in iteration 2710: 0.4639487376294004\n",
      "Theta: [-1.09607     0.66840949  0.06879909]\n",
      "Loss in iteration 2711: 0.46392921492331013\n",
      "Theta: [-1.09632229  0.66856506  0.06879538]\n",
      "Loss in iteration 2712: 0.46390970285270244\n",
      "Theta: [-1.0965745   0.66872059  0.06879167]\n",
      "Loss in iteration 2713: 0.46389020141012466\n",
      "Theta: [-1.09682665  0.66887608  0.06878796]\n",
      "Loss in iteration 2714: 0.46387071058813034\n",
      "Theta: [-1.09707872  0.66903154  0.06878426]\n",
      "Loss in iteration 2715: 0.463851230379279\n",
      "Theta: [-1.09733072  0.66918696  0.06878055]\n",
      "Loss in iteration 2716: 0.4638317607761372\n",
      "Theta: [-1.09758265  0.66934234  0.06877684]\n",
      "Loss in iteration 2717: 0.46381230177127747\n",
      "Theta: [-1.09783451  0.66949768  0.06877314]\n",
      "Loss in iteration 2718: 0.46379285335727893\n",
      "Theta: [-1.0980863   0.66965298  0.06876943]\n",
      "Loss in iteration 2719: 0.4637734155267265\n",
      "Theta: [-1.09833801  0.66980825  0.06876573]\n",
      "Loss in iteration 2720: 0.46375398827221226\n",
      "Theta: [-1.09858966  0.66996347  0.06876202]\n",
      "Loss in iteration 2721: 0.46373457158633385\n",
      "Theta: [-1.09884123  0.67011866  0.06875832]\n",
      "Loss in iteration 2722: 0.4637151654616957\n",
      "Theta: [-1.09909274  0.67027381  0.06875461]\n",
      "Loss in iteration 2723: 0.46369576989090855\n",
      "Theta: [-1.09934417  0.67042893  0.06875091]\n",
      "Loss in iteration 2724: 0.4636763848665892\n",
      "Theta: [-1.09959553  0.670584    0.0687472 ]\n",
      "Loss in iteration 2725: 0.46365701038136076\n",
      "Theta: [-1.09984682  0.67073904  0.0687435 ]\n",
      "Loss in iteration 2726: 0.463637646427853\n",
      "Theta: [-1.10009804  0.67089404  0.0687398 ]\n",
      "Loss in iteration 2727: 0.4636182929987017\n",
      "Theta: [-1.10034919  0.671049    0.06873609]\n",
      "Loss in iteration 2728: 0.463598950086549\n",
      "Theta: [-1.10060027  0.67120392  0.06873239]\n",
      "Loss in iteration 2729: 0.4635796176840433\n",
      "Theta: [-1.10085127  0.67135881  0.06872869]\n",
      "Loss in iteration 2730: 0.4635602957838392\n",
      "Theta: [-1.10110221  0.67151365  0.06872499]\n",
      "Loss in iteration 2731: 0.46354098437859775\n",
      "Theta: [-1.10135307  0.67166846  0.06872129]\n",
      "Loss in iteration 2732: 0.4635216834609864\n",
      "Theta: [-1.10160387  0.67182323  0.06871759]\n",
      "Loss in iteration 2733: 0.4635023930236782\n",
      "Theta: [-1.10185459  0.67197797  0.06871389]\n",
      "Loss in iteration 2734: 0.46348311305935325\n",
      "Theta: [-1.10210525  0.67213266  0.06871019]\n",
      "Loss in iteration 2735: 0.46346384356069725\n",
      "Theta: [-1.10235583  0.67228732  0.06870649]\n",
      "Loss in iteration 2736: 0.46344458452040266\n",
      "Theta: [-1.10260634  0.67244194  0.06870279]\n",
      "Loss in iteration 2737: 0.46342533593116786\n",
      "Theta: [-1.10285678  0.67259652  0.06869909]\n",
      "Loss in iteration 2738: 0.4634060977856975\n",
      "Theta: [-1.10310716  0.67275107  0.06869539]\n",
      "Loss in iteration 2739: 0.46338687007670243\n",
      "Theta: [-1.10335746  0.67290557  0.06869169]\n",
      "Loss in iteration 2740: 0.4633676527968999\n",
      "Theta: [-1.10360769  0.67306004  0.06868799]\n",
      "Loss in iteration 2741: 0.4633484459390133\n",
      "Theta: [-1.10385785  0.67321447  0.06868429]\n",
      "Loss in iteration 2742: 0.463329249495772\n",
      "Theta: [-1.10410794  0.67336887  0.0686806 ]\n",
      "Loss in iteration 2743: 0.4633100634599118\n",
      "Theta: [-1.10435795  0.67352322  0.0686769 ]\n",
      "Loss in iteration 2744: 0.4632908878241745\n",
      "Theta: [-1.1046079   0.67367754  0.0686732 ]\n",
      "Loss in iteration 2745: 0.46327172258130844\n",
      "Theta: [-1.10485778  0.67383182  0.0686695 ]\n",
      "Loss in iteration 2746: 0.4632525677240678\n",
      "Theta: [-1.10510759  0.67398606  0.06866581]\n",
      "Loss in iteration 2747: 0.463233423245213\n",
      "Theta: [-1.10535733  0.67414027  0.06866211]\n",
      "Loss in iteration 2748: 0.4632142891375108\n",
      "Theta: [-1.105607    0.67429444  0.06865842]\n",
      "Loss in iteration 2749: 0.4631951653937337\n",
      "Theta: [-1.10585659  0.67444856  0.06865472]\n",
      "Loss in iteration 2750: 0.46317605200666095\n",
      "Theta: [-1.10610612  0.67460266  0.06865103]\n",
      "Loss in iteration 2751: 0.46315694896907744\n",
      "Theta: [-1.10635558  0.67475671  0.06864733]\n",
      "Loss in iteration 2752: 0.46313785627377463\n",
      "Theta: [-1.10660497  0.67491073  0.06864364]\n",
      "Loss in iteration 2753: 0.4631187739135496\n",
      "Theta: [-1.10685428  0.67506471  0.06863994]\n",
      "Loss in iteration 2754: 0.463099701881206\n",
      "Theta: [-1.10710353  0.67521865  0.06863625]\n",
      "Loss in iteration 2755: 0.4630806401695534\n",
      "Theta: [-1.10735271  0.67537255  0.06863256]\n",
      "Loss in iteration 2756: 0.4630615887714077\n",
      "Theta: [-1.10760181  0.67552642  0.06862886]\n",
      "Loss in iteration 2757: 0.4630425476795905\n",
      "Theta: [-1.10785085  0.67568025  0.06862517]\n",
      "Loss in iteration 2758: 0.4630235168869299\n",
      "Theta: [-1.10809982  0.67583404  0.06862148]\n",
      "Loss in iteration 2759: 0.46300449638625985\n",
      "Theta: [-1.10834871  0.67598779  0.06861779]\n",
      "Loss in iteration 2760: 0.4629854861704208\n",
      "Theta: [-1.10859754  0.67614151  0.0686141 ]\n",
      "Loss in iteration 2761: 0.4629664862322586\n",
      "Theta: [-1.1088463   0.67629519  0.06861041]\n",
      "Loss in iteration 2762: 0.46294749656462586\n",
      "Theta: [-1.10909499  0.67644883  0.06860671]\n",
      "Loss in iteration 2763: 0.462928517160381\n",
      "Theta: [-1.10934361  0.67660244  0.06860302]\n",
      "Loss in iteration 2764: 0.46290954801238804\n",
      "Theta: [-1.10959215  0.676756    0.06859933]\n",
      "Loss in iteration 2765: 0.462890589113518\n",
      "Theta: [-1.10984063  0.67690953  0.06859564]\n",
      "Loss in iteration 2766: 0.46287164045664736\n",
      "Theta: [-1.11008904  0.67706303  0.06859195]\n",
      "Loss in iteration 2767: 0.4628527020346586\n",
      "Theta: [-1.11033738  0.67721648  0.06858827]\n",
      "Loss in iteration 2768: 0.4628337738404406\n",
      "Theta: [-1.11058565  0.6773699   0.06858458]\n",
      "Loss in iteration 2769: 0.462814855866888\n",
      "Theta: [-1.11083385  0.67752328  0.06858089]\n",
      "Loss in iteration 2770: 0.46279594810690133\n",
      "Theta: [-1.11108198  0.67767662  0.0685772 ]\n",
      "Loss in iteration 2771: 0.46277705055338786\n",
      "Theta: [-1.11133004  0.67782993  0.06857351]\n",
      "Loss in iteration 2772: 0.4627581631992601\n",
      "Theta: [-1.11157803  0.6779832   0.06856983]\n",
      "Loss in iteration 2773: 0.4627392860374369\n",
      "Theta: [-1.11182595  0.67813643  0.06856614]\n",
      "Loss in iteration 2774: 0.4627204190608431\n",
      "Theta: [-1.11207381  0.67828962  0.06856245]\n",
      "Loss in iteration 2775: 0.46270156226240966\n",
      "Theta: [-1.11232159  0.67844278  0.06855876]\n",
      "Loss in iteration 2776: 0.46268271563507324\n",
      "Theta: [-1.1125693   0.6785959   0.06855508]\n",
      "Loss in iteration 2777: 0.4626638791717768\n",
      "Theta: [-1.11281695  0.67874898  0.06855139]\n",
      "Loss in iteration 2778: 0.4626450528654692\n",
      "Theta: [-1.11306452  0.67890203  0.06854771]\n",
      "Loss in iteration 2779: 0.46262623670910513\n",
      "Theta: [-1.11331203  0.67905503  0.06854402]\n",
      "Loss in iteration 2780: 0.46260743069564547\n",
      "Theta: [-1.11355947  0.67920801  0.06854034]\n",
      "Loss in iteration 2781: 0.4625886348180569\n",
      "Theta: [-1.11380683  0.67936094  0.06853665]\n",
      "Loss in iteration 2782: 0.4625698490693121\n",
      "Theta: [-1.11405413  0.67951384  0.06853297]\n",
      "Loss in iteration 2783: 0.46255107344238977\n",
      "Theta: [-1.11430136  0.6796667   0.06852928]\n",
      "Loss in iteration 2784: 0.4625323079302747\n",
      "Theta: [-1.11454852  0.67981952  0.0685256 ]\n",
      "Loss in iteration 2785: 0.4625135525259572\n",
      "Theta: [-1.11479561  0.6799723   0.06852192]\n",
      "Loss in iteration 2786: 0.46249480722243397\n",
      "Theta: [-1.11504263  0.68012505  0.06851824]\n",
      "Loss in iteration 2787: 0.4624760720127074\n",
      "Theta: [-1.11528958  0.68027776  0.06851455]\n",
      "Loss in iteration 2788: 0.4624573468897857\n",
      "Theta: [-1.11553647  0.68043044  0.06851087]\n",
      "Loss in iteration 2789: 0.46243863184668316\n",
      "Theta: [-1.11578328  0.68058308  0.06850719]\n",
      "Loss in iteration 2790: 0.46241992687642025\n",
      "Theta: [-1.11603003  0.68073568  0.06850351]\n",
      "Loss in iteration 2791: 0.462401231972023\n",
      "Theta: [-1.1162767   0.68088824  0.06849983]\n",
      "Loss in iteration 2792: 0.4623825471265233\n",
      "Theta: [-1.11652331  0.68104077  0.06849615]\n",
      "Loss in iteration 2793: 0.46236387233295945\n",
      "Theta: [-1.11676985  0.68119326  0.06849246]\n",
      "Loss in iteration 2794: 0.4623452075843747\n",
      "Theta: [-1.11701632  0.68134571  0.06848878]\n",
      "Loss in iteration 2795: 0.4623265528738192\n",
      "Theta: [-1.11726272  0.68149812  0.0684851 ]\n",
      "Loss in iteration 2796: 0.46230790819434814\n",
      "Theta: [-1.11750905  0.6816505   0.06848142]\n",
      "Loss in iteration 2797: 0.46228927353902344\n",
      "Theta: [-1.11775531  0.68180284  0.06847775]\n",
      "Loss in iteration 2798: 0.46227064890091213\n",
      "Theta: [-1.11800151  0.68195515  0.06847407]\n",
      "Loss in iteration 2799: 0.4622520342730875\n",
      "Theta: [-1.11824763  0.68210742  0.06847039]\n",
      "Loss in iteration 2800: 0.46223342964862857\n",
      "Theta: [-1.11849369  0.68225965  0.06846671]\n",
      "Loss in iteration 2801: 0.4622148350206202\n",
      "Theta: [-1.11873968  0.68241184  0.06846303]\n",
      "Loss in iteration 2802: 0.46219625038215334\n",
      "Theta: [-1.1189856   0.682564    0.06845935]\n",
      "Loss in iteration 2803: 0.4621776757263246\n",
      "Theta: [-1.11923145  0.68271612  0.06845568]\n",
      "Loss in iteration 2804: 0.46215911104623614\n",
      "Theta: [-1.11947723  0.68286821  0.068452  ]\n",
      "Loss in iteration 2805: 0.46214055633499646\n",
      "Theta: [-1.11972295  0.68302025  0.06844832]\n",
      "Loss in iteration 2806: 0.4621220115857196\n",
      "Theta: [-1.11996859  0.68317226  0.06844465]\n",
      "Loss in iteration 2807: 0.4621034767915252\n",
      "Theta: [-1.12021417  0.68332424  0.06844097]\n",
      "Loss in iteration 2808: 0.46208495194553945\n",
      "Theta: [-1.12045968  0.68347618  0.0684373 ]\n",
      "Loss in iteration 2809: 0.4620664370408935\n",
      "Theta: [-1.12070512  0.68362808  0.06843362]\n",
      "Loss in iteration 2810: 0.46204793207072486\n",
      "Theta: [-1.12095049  0.68377994  0.06842994]\n",
      "Loss in iteration 2811: 0.4620294370281766\n",
      "Theta: [-1.1211958   0.68393177  0.06842627]\n",
      "Loss in iteration 2812: 0.46201095190639785\n",
      "Theta: [-1.12144103  0.68408356  0.0684226 ]\n",
      "Loss in iteration 2813: 0.46199247669854304\n",
      "Theta: [-1.1216862   0.68423531  0.06841892]\n",
      "Loss in iteration 2814: 0.4619740113977726\n",
      "Theta: [-1.1219313   0.68438703  0.06841525]\n",
      "Loss in iteration 2815: 0.4619555559972531\n",
      "Theta: [-1.12217633  0.68453871  0.06841157]\n",
      "Loss in iteration 2816: 0.46193711049015623\n",
      "Theta: [-1.12242129  0.68469035  0.0684079 ]\n",
      "Loss in iteration 2817: 0.4619186748696601\n",
      "Theta: [-1.12266618  0.68484196  0.06840423]\n",
      "Loss in iteration 2818: 0.4619002491289479\n",
      "Theta: [-1.12291101  0.68499353  0.06840056]\n",
      "Loss in iteration 2819: 0.4618818332612092\n",
      "Theta: [-1.12315577  0.68514507  0.06839688]\n",
      "Loss in iteration 2820: 0.46186342725963897\n",
      "Theta: [-1.12340046  0.68529656  0.06839321]\n",
      "Loss in iteration 2821: 0.46184503111743797\n",
      "Theta: [-1.12364508  0.68544803  0.06838954]\n",
      "Loss in iteration 2822: 0.4618266448278127\n",
      "Theta: [-1.12388963  0.68559945  0.06838587]\n",
      "Loss in iteration 2823: 0.46180826838397526\n",
      "Theta: [-1.12413412  0.68575084  0.0683822 ]\n",
      "Loss in iteration 2824: 0.46178990177914386\n",
      "Theta: [-1.12437853  0.68590219  0.06837853]\n",
      "Loss in iteration 2825: 0.46177154500654205\n",
      "Theta: [-1.12462288  0.68605351  0.06837486]\n",
      "Loss in iteration 2826: 0.46175319805939913\n",
      "Theta: [-1.12486717  0.68620479  0.06837119]\n",
      "Loss in iteration 2827: 0.46173486093095034\n",
      "Theta: [-1.12511138  0.68635603  0.06836752]\n",
      "Loss in iteration 2828: 0.46171653361443665\n",
      "Theta: [-1.12535553  0.68650723  0.06836385]\n",
      "Loss in iteration 2829: 0.4616982161031041\n",
      "Theta: [-1.1255996   0.6866584   0.06836018]\n",
      "Loss in iteration 2830: 0.4616799083902052\n",
      "Theta: [-1.12584361  0.68680954  0.06835651]\n",
      "Loss in iteration 2831: 0.4616616104689977\n",
      "Theta: [-1.12608756  0.68696063  0.06835284]\n",
      "Loss in iteration 2832: 0.46164332233274513\n",
      "Theta: [-1.12633143  0.6871117   0.06834918]\n",
      "Loss in iteration 2833: 0.46162504397471665\n",
      "Theta: [-1.12657524  0.68726272  0.06834551]\n",
      "Loss in iteration 2834: 0.46160677538818734\n",
      "Theta: [-1.12681898  0.68741371  0.06834184]\n",
      "Loss in iteration 2835: 0.4615885165664376\n",
      "Theta: [-1.12706265  0.68756466  0.06833817]\n",
      "Loss in iteration 2836: 0.46157026750275354\n",
      "Theta: [-1.12730625  0.68771557  0.06833451]\n",
      "Loss in iteration 2837: 0.46155202819042723\n",
      "Theta: [-1.12754979  0.68786645  0.06833084]\n",
      "Loss in iteration 2838: 0.46153379862275606\n",
      "Theta: [-1.12779326  0.6880173   0.06832717]\n",
      "Loss in iteration 2839: 0.4615155787930431\n",
      "Theta: [-1.12803666  0.6881681   0.06832351]\n",
      "Loss in iteration 2840: 0.46149736869459723\n",
      "Theta: [-1.12827999  0.68831887  0.06831984]\n",
      "Loss in iteration 2841: 0.46147916832073277\n",
      "Theta: [-1.12852326  0.68846961  0.06831618]\n",
      "Loss in iteration 2842: 0.46146097766476984\n",
      "Theta: [-1.12876646  0.68862031  0.06831251]\n",
      "Loss in iteration 2843: 0.4614427967200338\n",
      "Theta: [-1.12900959  0.68877097  0.06830885]\n",
      "Loss in iteration 2844: 0.46142462547985624\n",
      "Theta: [-1.12925265  0.68892159  0.06830518]\n",
      "Loss in iteration 2845: 0.46140646393757373\n",
      "Theta: [-1.12949565  0.68907218  0.06830152]\n",
      "Loss in iteration 2846: 0.461388312086529\n",
      "Theta: [-1.12973858  0.68922274  0.06829786]\n",
      "Loss in iteration 2847: 0.4613701699200698\n",
      "Theta: [-1.12998144  0.68937325  0.06829419]\n",
      "Loss in iteration 2848: 0.46135203743154984\n",
      "Theta: [-1.13022423  0.68952373  0.06829053]\n",
      "Loss in iteration 2849: 0.46133391461432866\n",
      "Theta: [-1.13046696  0.68967418  0.06828687]\n",
      "Loss in iteration 2850: 0.4613158014617708\n",
      "Theta: [-1.13070962  0.68982459  0.06828321]\n",
      "Loss in iteration 2851: 0.46129769796724657\n",
      "Theta: [-1.13095221  0.68997496  0.06827954]\n",
      "Loss in iteration 2852: 0.46127960412413205\n",
      "Theta: [-1.13119474  0.6901253   0.06827588]\n",
      "Loss in iteration 2853: 0.4612615199258086\n",
      "Theta: [-1.1314372   0.6902756   0.06827222]\n",
      "Loss in iteration 2854: 0.4612434453656635\n",
      "Theta: [-1.13167959  0.69042586  0.06826856]\n",
      "Loss in iteration 2855: 0.46122538043708905\n",
      "Theta: [-1.13192191  0.69057609  0.0682649 ]\n",
      "Loss in iteration 2856: 0.46120732513348395\n",
      "Theta: [-1.13216417  0.69072628  0.06826124]\n",
      "Loss in iteration 2857: 0.4611892794482512\n",
      "Theta: [-1.13240636  0.69087644  0.06825758]\n",
      "Loss in iteration 2858: 0.46117124337480064\n",
      "Theta: [-1.13264848  0.69102656  0.06825392]\n",
      "Loss in iteration 2859: 0.4611532169065468\n",
      "Theta: [-1.13289054  0.69117665  0.06825026]\n",
      "Loss in iteration 2860: 0.4611352000369099\n",
      "Theta: [-1.13313253  0.69132669  0.0682466 ]\n",
      "Loss in iteration 2861: 0.4611171927593159\n",
      "Theta: [-1.13337445  0.69147671  0.06824294]\n",
      "Loss in iteration 2862: 0.46109919506719604\n",
      "Theta: [-1.1336163   0.69162668  0.06823928]\n",
      "Loss in iteration 2863: 0.4610812069539872\n",
      "Theta: [-1.13385809  0.69177663  0.06823562]\n",
      "Loss in iteration 2864: 0.4610632284131316\n",
      "Theta: [-1.13409981  0.69192653  0.06823197]\n",
      "Loss in iteration 2865: 0.4610452594380772\n",
      "Theta: [-1.13434147  0.6920764   0.06822831]\n",
      "Loss in iteration 2866: 0.4610273000222773\n",
      "Theta: [-1.13458306  0.69222623  0.06822465]\n",
      "Loss in iteration 2867: 0.46100935015919076\n",
      "Theta: [-1.13482458  0.69237603  0.06822099]\n",
      "Loss in iteration 2868: 0.4609914098422819\n",
      "Theta: [-1.13506603  0.69252579  0.06821734]\n",
      "Loss in iteration 2869: 0.4609734790650204\n",
      "Theta: [-1.13530742  0.69267552  0.06821368]\n",
      "Loss in iteration 2870: 0.4609555578208815\n",
      "Theta: [-1.13554874  0.69282521  0.06821002]\n",
      "Loss in iteration 2871: 0.460937646103346\n",
      "Theta: [-1.13578999  0.69297486  0.06820637]\n",
      "Loss in iteration 2872: 0.46091974390589996\n",
      "Theta: [-1.13603118  0.69312448  0.06820271]\n",
      "Loss in iteration 2873: 0.4609018512220351\n",
      "Theta: [-1.1362723   0.69327406  0.06819906]\n",
      "Loss in iteration 2874: 0.4608839680452485\n",
      "Theta: [-1.13651336  0.69342361  0.0681954 ]\n",
      "Loss in iteration 2875: 0.4608660943690427\n",
      "Theta: [-1.13675435  0.69357312  0.06819175]\n",
      "Loss in iteration 2876: 0.46084823018692556\n",
      "Theta: [-1.13699527  0.6937226   0.06818809]\n",
      "Loss in iteration 2877: 0.4608303754924106\n",
      "Theta: [-1.13723612  0.69387204  0.06818444]\n",
      "Loss in iteration 2878: 0.46081253027901636\n",
      "Theta: [-1.13747691  0.69402144  0.06818079]\n",
      "Loss in iteration 2879: 0.4607946945402677\n",
      "Theta: [-1.13771763  0.69417081  0.06817713]\n",
      "Loss in iteration 2880: 0.4607768682696937\n",
      "Theta: [-1.13795829  0.69432015  0.06817348]\n",
      "Loss in iteration 2881: 0.4607590514608295\n",
      "Theta: [-1.13819888  0.69446944  0.06816983]\n",
      "Loss in iteration 2882: 0.46074124410721606\n",
      "Theta: [-1.1384394   0.6946187   0.06816617]\n",
      "Loss in iteration 2883: 0.46072344620239875\n",
      "Theta: [-1.13867986  0.69476793  0.06816252]\n",
      "Loss in iteration 2884: 0.46070565773992905\n",
      "Theta: [-1.13892025  0.69491712  0.06815887]\n",
      "Loss in iteration 2885: 0.46068787871336364\n",
      "Theta: [-1.13916057  0.69506628  0.06815522]\n",
      "Loss in iteration 2886: 0.4606701091162645\n",
      "Theta: [-1.13940083  0.6952154   0.06815157]\n",
      "Loss in iteration 2887: 0.46065234894219936\n",
      "Theta: [-1.13964102  0.69536448  0.06814792]\n",
      "Loss in iteration 2888: 0.46063459818474084\n",
      "Theta: [-1.13988115  0.69551353  0.06814427]\n",
      "Loss in iteration 2889: 0.460616856837467\n",
      "Theta: [-1.14012121  0.69566254  0.06814062]\n",
      "Loss in iteration 2890: 0.4605991248939617\n",
      "Theta: [-1.1403612   0.69581152  0.06813697]\n",
      "Loss in iteration 2891: 0.4605814023478135\n",
      "Theta: [-1.14060113  0.69596046  0.06813332]\n",
      "Loss in iteration 2892: 0.46056368919261703\n",
      "Theta: [-1.14084099  0.69610937  0.06812967]\n",
      "Loss in iteration 2893: 0.46054598542197167\n",
      "Theta: [-1.14108078  0.69625824  0.06812602]\n",
      "Loss in iteration 2894: 0.46052829102948273\n",
      "Theta: [-1.14132051  0.69640707  0.06812237]\n",
      "Loss in iteration 2895: 0.4605106060087599\n",
      "Theta: [-1.14156017  0.69655587  0.06811872]\n",
      "Loss in iteration 2896: 0.4604929303534195\n",
      "Theta: [-1.14179977  0.69670464  0.06811507]\n",
      "Loss in iteration 2897: 0.4604752640570821\n",
      "Theta: [-1.1420393   0.69685337  0.06811142]\n",
      "Loss in iteration 2898: 0.4604576071133741\n",
      "Theta: [-1.14227877  0.69700206  0.06810778]\n",
      "Loss in iteration 2899: 0.46043995951592726\n",
      "Theta: [-1.14251817  0.69715072  0.06810413]\n",
      "Loss in iteration 2900: 0.46042232125837823\n",
      "Theta: [-1.1427575   0.69729934  0.06810048]\n",
      "Loss in iteration 2901: 0.46040469233436954\n",
      "Theta: [-1.14299677  0.69744793  0.06809684]\n",
      "Loss in iteration 2902: 0.4603870727375485\n",
      "Theta: [-1.14323597  0.69759648  0.06809319]\n",
      "Loss in iteration 2903: 0.460369462461568\n",
      "Theta: [-1.14347511  0.697745    0.06808954]\n",
      "Loss in iteration 2904: 0.46035186150008633\n",
      "Theta: [-1.14371418  0.69789348  0.0680859 ]\n",
      "Loss in iteration 2905: 0.46033426984676673\n",
      "Theta: [-1.14395318  0.69804193  0.06808225]\n",
      "Loss in iteration 2906: 0.46031668749527804\n",
      "Theta: [-1.14419212  0.69819034  0.06807861]\n",
      "Loss in iteration 2907: 0.46029911443929417\n",
      "Theta: [-1.14443099  0.69833872  0.06807496]\n",
      "Loss in iteration 2908: 0.46028155067249443\n",
      "Theta: [-1.1446698   0.69848706  0.06807132]\n",
      "Loss in iteration 2909: 0.4602639961885634\n",
      "Theta: [-1.14490854  0.69863536  0.06806767]\n",
      "Loss in iteration 2910: 0.4602464509811906\n",
      "Theta: [-1.14514722  0.69878363  0.06806403]\n",
      "Loss in iteration 2911: 0.4602289150440713\n",
      "Theta: [-1.14538583  0.69893187  0.06806039]\n",
      "Loss in iteration 2912: 0.4602113883709058\n",
      "Theta: [-1.14562438  0.69908007  0.06805674]\n",
      "Loss in iteration 2913: 0.46019387095539976\n",
      "Theta: [-1.14586286  0.69922823  0.0680531 ]\n",
      "Loss in iteration 2914: 0.4601763627912635\n",
      "Theta: [-1.14610127  0.69937636  0.06804946]\n",
      "Loss in iteration 2915: 0.46015886387221366\n",
      "Theta: [-1.14633962  0.69952446  0.06804581]\n",
      "Loss in iteration 2916: 0.46014137419197093\n",
      "Theta: [-1.14657791  0.69967251  0.06804217]\n",
      "Loss in iteration 2917: 0.4601238937442622\n",
      "Theta: [-1.14681612  0.69982054  0.06803853]\n",
      "Loss in iteration 2918: 0.46010642252281897\n",
      "Theta: [-1.14705428  0.69996853  0.06803489]\n",
      "Loss in iteration 2919: 0.46008896052137827\n",
      "Theta: [-1.14729236  0.70011648  0.06803125]\n",
      "Loss in iteration 2920: 0.4600715077336821\n",
      "Theta: [-1.14753039  0.7002644   0.06802761]\n",
      "Loss in iteration 2921: 0.460054064153478\n",
      "Theta: [-1.14776834  0.70041228  0.06802396]\n",
      "Loss in iteration 2922: 0.4600366297745183\n",
      "Theta: [-1.14800624  0.70056013  0.06802032]\n",
      "Loss in iteration 2923: 0.4600192045905609\n",
      "Theta: [-1.14824406  0.70070795  0.06801668]\n",
      "Loss in iteration 2924: 0.46000178859536867\n",
      "Theta: [-1.14848182  0.70085573  0.06801304]\n",
      "Loss in iteration 2925: 0.45998438178270973\n",
      "Theta: [-1.14871952  0.70100347  0.06800941]\n",
      "Loss in iteration 2926: 0.4599669841463572\n",
      "Theta: [-1.14895715  0.70115118  0.06800577]\n",
      "Loss in iteration 2927: 0.4599495956800899\n",
      "Theta: [-1.14919472  0.70129885  0.06800213]\n",
      "Loss in iteration 2928: 0.4599322163776913\n",
      "Theta: [-1.14943222  0.70144649  0.06799849]\n",
      "Loss in iteration 2929: 0.4599148462329501\n",
      "Theta: [-1.14966965  0.70159409  0.06799485]\n",
      "Loss in iteration 2930: 0.4598974852396605\n",
      "Theta: [-1.14990703  0.70174166  0.06799121]\n",
      "Loss in iteration 2931: 0.45988013339162137\n",
      "Theta: [-1.15014433  0.7018892   0.06798757]\n",
      "Loss in iteration 2932: 0.4598627906826372\n",
      "Theta: [-1.15038157  0.7020367   0.06798394]\n",
      "Loss in iteration 2933: 0.45984545710651736\n",
      "Theta: [-1.15061875  0.70218416  0.0679803 ]\n",
      "Loss in iteration 2934: 0.45982813265707656\n",
      "Theta: [-1.15085586  0.70233159  0.06797666]\n",
      "Loss in iteration 2935: 0.4598108173281342\n",
      "Theta: [-1.15109291  0.70247898  0.06797303]\n",
      "Loss in iteration 2936: 0.45979351111351535\n",
      "Theta: [-1.15132989  0.70262634  0.06796939]\n",
      "Loss in iteration 2937: 0.45977621400704977\n",
      "Theta: [-1.1515668   0.70277367  0.06796575]\n",
      "Loss in iteration 2938: 0.4597589260025729\n",
      "Theta: [-1.15180365  0.70292096  0.06796212]\n",
      "Loss in iteration 2939: 0.45974164709392457\n",
      "Theta: [-1.15204044  0.70306821  0.06795848]\n",
      "Loss in iteration 2940: 0.45972437727495025\n",
      "Theta: [-1.15227716  0.70321543  0.06795485]\n",
      "Loss in iteration 2941: 0.45970711653950047\n",
      "Theta: [-1.15251382  0.70336262  0.06795121]\n",
      "Loss in iteration 2942: 0.45968986488143043\n",
      "Theta: [-1.15275041  0.70350977  0.06794758]\n",
      "Loss in iteration 2943: 0.45967262229460126\n",
      "Theta: [-1.15298694  0.70365689  0.06794394]\n",
      "Loss in iteration 2944: 0.4596553887728782\n",
      "Theta: [-1.15322341  0.70380397  0.06794031]\n",
      "Loss in iteration 2945: 0.4596381643101324\n",
      "Theta: [-1.1534598   0.70395101  0.06793668]\n",
      "Loss in iteration 2946: 0.45962094890023936\n",
      "Theta: [-1.15369614  0.70409802  0.06793304]\n",
      "Loss in iteration 2947: 0.4596037425370804\n",
      "Theta: [-1.15393241  0.704245    0.06792941]\n",
      "Loss in iteration 2948: 0.4595865452145413\n",
      "Theta: [-1.15416861  0.70439194  0.06792578]\n",
      "Loss in iteration 2949: 0.45956935692651335\n",
      "Theta: [-1.15440475  0.70453885  0.06792215]\n",
      "Loss in iteration 2950: 0.4595521776668926\n",
      "Theta: [-1.15464083  0.70468573  0.06791851]\n",
      "Loss in iteration 2951: 0.4595350074295802\n",
      "Theta: [-1.15487684  0.70483256  0.06791488]\n",
      "Loss in iteration 2952: 0.4595178462084825\n",
      "Theta: [-1.15511279  0.70497937  0.06791125]\n",
      "Loss in iteration 2953: 0.4595006939975109\n",
      "Theta: [-1.15534867  0.70512614  0.06790762]\n",
      "Loss in iteration 2954: 0.4594835507905819\n",
      "Theta: [-1.15558449  0.70527287  0.06790399]\n",
      "Loss in iteration 2955: 0.45946641658161647\n",
      "Theta: [-1.15582024  0.70541957  0.06790036]\n",
      "Loss in iteration 2956: 0.4594492913645414\n",
      "Theta: [-1.15605593  0.70556624  0.06789673]\n",
      "Loss in iteration 2957: 0.4594321751332878\n",
      "Theta: [-1.15629156  0.70571287  0.0678931 ]\n",
      "Loss in iteration 2958: 0.45941506788179254\n",
      "Theta: [-1.15652712  0.70585946  0.06788947]\n",
      "Loss in iteration 2959: 0.45939796960399704\n",
      "Theta: [-1.15676262  0.70600603  0.06788584]\n",
      "Loss in iteration 2960: 0.4593808802938477\n",
      "Theta: [-1.15699805  0.70615255  0.06788221]\n",
      "Loss in iteration 2961: 0.459363799945296\n",
      "Theta: [-1.15723342  0.70629905  0.06787858]\n",
      "Loss in iteration 2962: 0.45934672855229874\n",
      "Theta: [-1.15746872  0.7064455   0.06787495]\n",
      "Loss in iteration 2963: 0.4593296661088172\n",
      "Theta: [-1.15770396  0.70659193  0.06787132]\n",
      "Loss in iteration 2964: 0.45931261260881806\n",
      "Theta: [-1.15793914  0.70673832  0.06786769]\n",
      "Loss in iteration 2965: 0.4592955680462727\n",
      "Theta: [-1.15817425  0.70688467  0.06786407]\n",
      "Loss in iteration 2966: 0.45927853241515776\n",
      "Theta: [-1.1584093   0.70703099  0.06786044]\n",
      "Loss in iteration 2967: 0.4592615057094546\n",
      "Theta: [-1.15864428  0.70717728  0.06785681]\n",
      "Loss in iteration 2968: 0.4592444879231498\n",
      "Theta: [-1.1588792   0.70732353  0.06785318]\n",
      "Loss in iteration 2969: 0.45922747905023464\n",
      "Theta: [-1.15911406  0.70746975  0.06784956]\n",
      "Loss in iteration 2970: 0.45921047908470564\n",
      "Theta: [-1.15934885  0.70761593  0.06784593]\n",
      "Loss in iteration 2971: 0.45919348802056403\n",
      "Theta: [-1.15958358  0.70776208  0.06784231]\n",
      "Loss in iteration 2972: 0.4591765058518164\n",
      "Theta: [-1.15981824  0.70790819  0.06783868]\n",
      "Loss in iteration 2973: 0.45915953257247366\n",
      "Theta: [-1.16005284  0.70805427  0.06783505]\n",
      "Loss in iteration 2974: 0.45914256817655213\n",
      "Theta: [-1.16028738  0.70820032  0.06783143]\n",
      "Loss in iteration 2975: 0.45912561265807306\n",
      "Theta: [-1.16052185  0.70834633  0.0678278 ]\n",
      "Loss in iteration 2976: 0.45910866601106265\n",
      "Theta: [-1.16075626  0.7084923   0.06782418]\n",
      "Loss in iteration 2977: 0.4590917282295516\n",
      "Theta: [-1.16099061  0.70863825  0.06782056]\n",
      "Loss in iteration 2978: 0.45907479930757605\n",
      "Theta: [-1.16122489  0.70878416  0.06781693]\n",
      "Loss in iteration 2979: 0.45905787923917685\n",
      "Theta: [-1.16145911  0.70893003  0.06781331]\n",
      "Loss in iteration 2980: 0.4590409680183996\n",
      "Theta: [-1.16169326  0.70907587  0.06780968]\n",
      "Loss in iteration 2981: 0.45902406563929543\n",
      "Theta: [-1.16192735  0.70922167  0.06780606]\n",
      "Loss in iteration 2982: 0.4590071720959197\n",
      "Theta: [-1.16216138  0.70936745  0.06780244]\n",
      "Loss in iteration 2983: 0.4589902873823328\n",
      "Theta: [-1.16239534  0.70951318  0.06779882]\n",
      "Loss in iteration 2984: 0.45897341149260035\n",
      "Theta: [-1.16262924  0.70965889  0.06779519]\n",
      "Loss in iteration 2985: 0.45895654442079253\n",
      "Theta: [-1.16286308  0.70980455  0.06779157]\n",
      "Loss in iteration 2986: 0.4589396861609847\n",
      "Theta: [-1.16309685  0.70995019  0.06778795]\n",
      "Loss in iteration 2987: 0.4589228367072568\n",
      "Theta: [-1.16333056  0.71009579  0.06778433]\n",
      "Loss in iteration 2988: 0.45890599605369364\n",
      "Theta: [-1.1635642   0.71024135  0.06778071]\n",
      "Loss in iteration 2989: 0.4588891641943855\n",
      "Theta: [-1.16379779  0.71038689  0.06777709]\n",
      "Loss in iteration 2990: 0.45887234112342673\n",
      "Theta: [-1.1640313   0.71053238  0.06777347]\n",
      "Loss in iteration 2991: 0.4588555268349171\n",
      "Theta: [-1.16426476  0.71067785  0.06776984]\n",
      "Loss in iteration 2992: 0.4588387213229609\n",
      "Theta: [-1.16449815  0.71082328  0.06776622]\n",
      "Loss in iteration 2993: 0.4588219245816677\n",
      "Theta: [-1.16473148  0.71096867  0.06776261]\n",
      "Loss in iteration 2994: 0.45880513660515126\n",
      "Theta: [-1.16496475  0.71111404  0.06775899]\n",
      "Loss in iteration 2995: 0.458788357387531\n",
      "Theta: [-1.16519795  0.71125936  0.06775537]\n",
      "Loss in iteration 2996: 0.4587715869229303\n",
      "Theta: [-1.16543109  0.71140466  0.06775175]\n",
      "Loss in iteration 2997: 0.4587548252054781\n",
      "Theta: [-1.16566416  0.71154992  0.06774813]\n",
      "Loss in iteration 2998: 0.458738072229308\n",
      "Theta: [-1.16589717  0.71169514  0.06774451]\n",
      "Loss in iteration 2999: 0.4587213279885583\n",
      "Theta: [-1.16613012  0.71184033  0.06774089]\n",
      "Loss in iteration 3000: 0.45870459247737194\n",
      "Theta: [-1.16636301  0.71198549  0.06773727]\n",
      "Loss in iteration 3001: 0.45868786568989706\n",
      "Theta: [-1.16659583  0.71213061  0.06773366]\n",
      "Loss in iteration 3002: 0.45867114762028655\n",
      "Theta: [-1.16682859  0.7122757   0.06773004]\n",
      "Loss in iteration 3003: 0.45865443826269797\n",
      "Theta: [-1.16706129  0.71242076  0.06772642]\n",
      "Loss in iteration 3004: 0.4586377376112935\n",
      "Theta: [-1.16729392  0.71256578  0.06772281]\n",
      "Loss in iteration 3005: 0.4586210456602407\n",
      "Theta: [-1.16752649  0.71271077  0.06771919]\n",
      "Loss in iteration 3006: 0.4586043624037115\n",
      "Theta: [-1.167759    0.71285572  0.06771557]\n",
      "Loss in iteration 3007: 0.45858768783588266\n",
      "Theta: [-1.16799144  0.71300064  0.06771196]\n",
      "Loss in iteration 3008: 0.4585710219509358\n",
      "Theta: [-1.16822382  0.71314553  0.06770834]\n",
      "Loss in iteration 3009: 0.4585543647430571\n",
      "Theta: [-1.16845614  0.71329038  0.06770473]\n",
      "Loss in iteration 3010: 0.45853771620643813\n",
      "Theta: [-1.1686884   0.7134352   0.06770111]\n",
      "Loss in iteration 3011: 0.4585210763352744\n",
      "Theta: [-1.16892059  0.71357999  0.0676975 ]\n",
      "Loss in iteration 3012: 0.4585044451237668\n",
      "Theta: [-1.16915272  0.71372474  0.06769388]\n",
      "Loss in iteration 3013: 0.4584878225661209\n",
      "Theta: [-1.16938479  0.71386945  0.06769027]\n",
      "Loss in iteration 3014: 0.4584712086565469\n",
      "Theta: [-1.16961679  0.71401414  0.06768666]\n",
      "Loss in iteration 3015: 0.4584546033892595\n",
      "Theta: [-1.16984873  0.71415879  0.06768304]\n",
      "Loss in iteration 3016: 0.4584380067584787\n",
      "Theta: [-1.17008061  0.7143034   0.06767943]\n",
      "Loss in iteration 3017: 0.45842141875842884\n",
      "Theta: [-1.17031243  0.71444798  0.06767582]\n",
      "Loss in iteration 3018: 0.4584048393833393\n",
      "Theta: [-1.17054418  0.71459253  0.0676722 ]\n",
      "Loss in iteration 3019: 0.4583882686274439\n",
      "Theta: [-1.17077587  0.71473705  0.06766859]\n",
      "Loss in iteration 3020: 0.4583717064849814\n",
      "Theta: [-1.1710075   0.71488153  0.06766498]\n",
      "Loss in iteration 3021: 0.45835515295019513\n",
      "Theta: [-1.17123907  0.71502597  0.06766137]\n",
      "Loss in iteration 3022: 0.4583386080173334\n",
      "Theta: [-1.17147057  0.71517039  0.06765776]\n",
      "Loss in iteration 3023: 0.45832207168064876\n",
      "Theta: [-1.17170201  0.71531477  0.06765414]\n",
      "Loss in iteration 3024: 0.45830554393439926\n",
      "Theta: [-1.17193339  0.71545911  0.06765053]\n",
      "Loss in iteration 3025: 0.4582890247728467\n",
      "Theta: [-1.1721647   0.71560343  0.06764692]\n",
      "Loss in iteration 3026: 0.45827251419025844\n",
      "Theta: [-1.17239596  0.71574771  0.06764331]\n",
      "Loss in iteration 3027: 0.4582560121809059\n",
      "Theta: [-1.17262715  0.71589195  0.0676397 ]\n",
      "Loss in iteration 3028: 0.45823951873906554\n",
      "Theta: [-1.17285827  0.71603616  0.06763609]\n",
      "Loss in iteration 3029: 0.45822303385901864\n",
      "Theta: [-1.17308934  0.71618034  0.06763248]\n",
      "Loss in iteration 3030: 0.45820655753505063\n",
      "Theta: [-1.17332034  0.71632448  0.06762887]\n",
      "Loss in iteration 3031: 0.45819008976145226\n",
      "Theta: [-1.17355128  0.7164686   0.06762526]\n",
      "Loss in iteration 3032: 0.4581736305325185\n",
      "Theta: [-1.17378216  0.71661267  0.06762165]\n",
      "Loss in iteration 3033: 0.45815717984254933\n",
      "Theta: [-1.17401298  0.71675672  0.06761805]\n",
      "Loss in iteration 3034: 0.45814073768584895\n",
      "Theta: [-1.17424373  0.71690073  0.06761444]\n",
      "Loss in iteration 3035: 0.4581243040567267\n",
      "Theta: [-1.17447442  0.7170447   0.06761083]\n",
      "Loss in iteration 3036: 0.4581078789494964\n",
      "Theta: [-1.17470505  0.71718865  0.06760722]\n",
      "Loss in iteration 3037: 0.4580914623584762\n",
      "Theta: [-1.17493562  0.71733256  0.06760362]\n",
      "Loss in iteration 3038: 0.45807505427798967\n",
      "Theta: [-1.17516613  0.71747643  0.06760001]\n",
      "Loss in iteration 3039: 0.4580586547023643\n",
      "Theta: [-1.17539657  0.71762028  0.0675964 ]\n",
      "Loss in iteration 3040: 0.4580422636259324\n",
      "Theta: [-1.17562695  0.71776408  0.06759279]\n",
      "Loss in iteration 3041: 0.45802588104303127\n",
      "Theta: [-1.17585727  0.71790786  0.06758919]\n",
      "Loss in iteration 3042: 0.4580095069480023\n",
      "Theta: [-1.17608752  0.7180516   0.06758558]\n",
      "Loss in iteration 3043: 0.4579931413351921\n",
      "Theta: [-1.17631772  0.71819531  0.06758198]\n",
      "Loss in iteration 3044: 0.4579767841989513\n",
      "Theta: [-1.17654785  0.71833899  0.06757837]\n",
      "Loss in iteration 3045: 0.45796043553363547\n",
      "Theta: [-1.17677792  0.71848263  0.06757477]\n",
      "Loss in iteration 3046: 0.4579440953336051\n",
      "Theta: [-1.17700793  0.71862624  0.06757116]\n",
      "Loss in iteration 3047: 0.4579277635932246\n",
      "Theta: [-1.17723788  0.71876981  0.06756756]\n",
      "Loss in iteration 3048: 0.45791144030686354\n",
      "Theta: [-1.17746776  0.71891336  0.06756395]\n",
      "Loss in iteration 3049: 0.4578951254688958\n",
      "Theta: [-1.17769758  0.71905687  0.06756035]\n",
      "Loss in iteration 3050: 0.45787881907370015\n",
      "Theta: [-1.17792734  0.71920034  0.06755674]\n",
      "Loss in iteration 3051: 0.45786252111565967\n",
      "Theta: [-1.17815704  0.71934378  0.06755314]\n",
      "Loss in iteration 3052: 0.45784623158916204\n",
      "Theta: [-1.17838668  0.71948719  0.06754954]\n",
      "Loss in iteration 3053: 0.4578299504885996\n",
      "Theta: [-1.17861626  0.71963057  0.06754593]\n",
      "Loss in iteration 3054: 0.4578136778083694\n",
      "Theta: [-1.17884577  0.71977391  0.06754233]\n",
      "Loss in iteration 3055: 0.457797413542873\n",
      "Theta: [-1.17907522  0.71991722  0.06753873]\n",
      "Loss in iteration 3056: 0.4577811576865164\n",
      "Theta: [-1.17930461  0.7200605   0.06753513]\n",
      "Loss in iteration 3057: 0.45776491023371\n",
      "Theta: [-1.17953394  0.72020374  0.06753153]\n",
      "Loss in iteration 3058: 0.4577486711788696\n",
      "Theta: [-1.17976321  0.72034695  0.06752792]\n",
      "Loss in iteration 3059: 0.4577324405164145\n",
      "Theta: [-1.17999241  0.72049012  0.06752432]\n",
      "Loss in iteration 3060: 0.4577162182407692\n",
      "Theta: [-1.18022156  0.72063327  0.06752072]\n",
      "Loss in iteration 3061: 0.4577000043463626\n",
      "Theta: [-1.18045064  0.72077638  0.06751712]\n",
      "Loss in iteration 3062: 0.457683798827628\n",
      "Theta: [-1.18067966  0.72091945  0.06751352]\n",
      "Loss in iteration 3063: 0.4576676016790035\n",
      "Theta: [-1.18090862  0.7210625   0.06750992]\n",
      "Loss in iteration 3064: 0.45765141289493144\n",
      "Theta: [-1.18113751  0.72120551  0.06750632]\n",
      "Loss in iteration 3065: 0.4576352324698592\n",
      "Theta: [-1.18136635  0.72134849  0.06750272]\n",
      "Loss in iteration 3066: 0.4576190603982383\n",
      "Theta: [-1.18159512  0.72149143  0.06749912]\n",
      "Loss in iteration 3067: 0.4576028966745242\n",
      "Theta: [-1.18182384  0.72163434  0.06749552]\n",
      "Loss in iteration 3068: 0.4575867412931782\n",
      "Theta: [-1.18205249  0.72177722  0.06749192]\n",
      "Loss in iteration 3069: 0.45757059424866525\n",
      "Theta: [-1.18228108  0.72192006  0.06748832]\n",
      "Loss in iteration 3070: 0.45755445553545504\n",
      "Theta: [-1.18250961  0.72206288  0.06748473]\n",
      "Loss in iteration 3071: 0.45753832514802156\n",
      "Theta: [-1.18273807  0.72220565  0.06748113]\n",
      "Loss in iteration 3072: 0.4575222030808436\n",
      "Theta: [-1.18296648  0.7223484   0.06747753]\n",
      "Loss in iteration 3073: 0.4575060893284042\n",
      "Theta: [-1.18319483  0.72249111  0.06747393]\n",
      "Loss in iteration 3074: 0.45748998388519124\n",
      "Theta: [-1.18342311  0.72263379  0.06747034]\n",
      "Loss in iteration 3075: 0.45747388674569656\n",
      "Theta: [-1.18365133  0.72277644  0.06746674]\n",
      "Loss in iteration 3076: 0.4574577979044169\n",
      "Theta: [-1.18387949  0.72291905  0.06746314]\n",
      "Loss in iteration 3077: 0.45744171735585354\n",
      "Theta: [-1.18410759  0.72306163  0.06745955]\n",
      "Loss in iteration 3078: 0.4574256450945117\n",
      "Theta: [-1.18433563  0.72320418  0.06745595]\n",
      "Loss in iteration 3079: 0.4574095811149017\n",
      "Theta: [-1.18456361  0.7233467   0.06745235]\n",
      "Loss in iteration 3080: 0.457393525411538\n",
      "Theta: [-1.18479153  0.72348918  0.06744876]\n",
      "Loss in iteration 3081: 0.4573774779789397\n",
      "Theta: [-1.18501938  0.72363163  0.06744516]\n",
      "Loss in iteration 3082: 0.4573614388116301\n",
      "Theta: [-1.18524717  0.72377405  0.06744157]\n",
      "Loss in iteration 3083: 0.4573454079041372\n",
      "Theta: [-1.18547491  0.72391643  0.06743797]\n",
      "Loss in iteration 3084: 0.45732938525099326\n",
      "Theta: [-1.18570258  0.72405878  0.06743438]\n",
      "Loss in iteration 3085: 0.4573133708467351\n",
      "Theta: [-1.18593019  0.7242011   0.06743078]\n",
      "Loss in iteration 3086: 0.45729736468590415\n",
      "Theta: [-1.18615774  0.72434338  0.06742719]\n",
      "Loss in iteration 3087: 0.4572813667630459\n",
      "Theta: [-1.18638523  0.72448563  0.0674236 ]\n",
      "Loss in iteration 3088: 0.45726537707271064\n",
      "Theta: [-1.18661266  0.72462785  0.06742   ]\n",
      "Loss in iteration 3089: 0.45724939560945266\n",
      "Theta: [-1.18684003  0.72477004  0.06741641]\n",
      "Loss in iteration 3090: 0.4572334223678313\n",
      "Theta: [-1.18706733  0.72491219  0.06741282]\n",
      "Loss in iteration 3091: 0.45721745734240954\n",
      "Theta: [-1.18729458  0.72505431  0.06740922]\n",
      "Loss in iteration 3092: 0.45720150052775566\n",
      "Theta: [-1.18752176  0.7251964   0.06740563]\n",
      "Loss in iteration 3093: 0.4571855519184416\n",
      "Theta: [-1.18774889  0.72533846  0.06740204]\n",
      "Loss in iteration 3094: 0.45716961150904395\n",
      "Theta: [-1.18797595  0.72548048  0.06739845]\n",
      "Loss in iteration 3095: 0.4571536792941441\n",
      "Theta: [-1.18820296  0.72562247  0.06739486]\n",
      "Loss in iteration 3096: 0.4571377552683272\n",
      "Theta: [-1.1884299   0.72576442  0.06739126]\n",
      "Loss in iteration 3097: 0.45712183942618323\n",
      "Theta: [-1.18865678  0.72590635  0.06738767]\n",
      "Loss in iteration 3098: 0.45710593176230646\n",
      "Theta: [-1.1888836   0.72604824  0.06738408]\n",
      "Loss in iteration 3099: 0.4570900322712954\n",
      "Theta: [-1.18911036  0.7261901   0.06738049]\n",
      "Loss in iteration 3100: 0.45707414094775317\n",
      "Theta: [-1.18933706  0.72633192  0.0673769 ]\n",
      "Loss in iteration 3101: 0.4570582577862872\n",
      "Theta: [-1.1895637   0.72647372  0.06737331]\n",
      "Loss in iteration 3102: 0.45704238278150916\n",
      "Theta: [-1.18979028  0.72661548  0.06736972]\n",
      "Loss in iteration 3103: 0.45702651592803534\n",
      "Theta: [-1.19001679  0.72675721  0.06736613]\n",
      "Loss in iteration 3104: 0.45701065722048606\n",
      "Theta: [-1.19024325  0.7268989   0.06736254]\n",
      "Loss in iteration 3105: 0.45699480665348624\n",
      "Theta: [-1.19046965  0.72704057  0.06735896]\n",
      "Loss in iteration 3106: 0.45697896422166523\n",
      "Theta: [-1.19069598  0.7271822   0.06735537]\n",
      "Loss in iteration 3107: 0.4569631299196566\n",
      "Theta: [-1.19092226  0.72732379  0.06735178]\n",
      "Loss in iteration 3108: 0.45694730374209824\n",
      "Theta: [-1.19114847  0.72746536  0.06734819]\n",
      "Loss in iteration 3109: 0.4569314856836326\n",
      "Theta: [-1.19137463  0.72760689  0.0673446 ]\n",
      "Loss in iteration 3110: 0.4569156757389062\n",
      "Theta: [-1.19160072  0.72774839  0.06734101]\n",
      "Loss in iteration 3111: 0.45689987390257003\n",
      "Theta: [-1.19182676  0.72788986  0.06733743]\n",
      "Loss in iteration 3112: 0.4568840801692792\n",
      "Theta: [-1.19205273  0.72803129  0.06733384]\n",
      "Loss in iteration 3113: 0.4568682945336937\n",
      "Theta: [-1.19227865  0.7281727   0.06733025]\n",
      "Loss in iteration 3114: 0.45685251699047735\n",
      "Theta: [-1.1925045   0.72831407  0.06732667]\n",
      "Loss in iteration 3115: 0.4568367475342984\n",
      "Theta: [-1.19273029  0.7284554   0.06732308]\n",
      "Loss in iteration 3116: 0.45682098615982947\n",
      "Theta: [-1.19295603  0.72859671  0.0673195 ]\n",
      "Loss in iteration 3117: 0.45680523286174746\n",
      "Theta: [-1.1931817   0.72873798  0.06731591]\n",
      "Loss in iteration 3118: 0.4567894876347338\n",
      "Theta: [-1.19340731  0.72887922  0.06731232]\n",
      "Loss in iteration 3119: 0.4567737504734739\n",
      "Theta: [-1.19363286  0.72902043  0.06730874]\n",
      "Loss in iteration 3120: 0.45675802137265753\n",
      "Theta: [-1.19385835  0.7291616   0.06730515]\n",
      "Loss in iteration 3121: 0.4567423003269788\n",
      "Theta: [-1.19408379  0.72930275  0.06730157]\n",
      "Loss in iteration 3122: 0.4567265873311365\n",
      "Theta: [-1.19430916  0.72944386  0.06729799]\n",
      "Loss in iteration 3123: 0.45671088237983304\n",
      "Theta: [-1.19453447  0.72958493  0.0672944 ]\n",
      "Loss in iteration 3124: 0.45669518546777543\n",
      "Theta: [-1.19475972  0.72972598  0.06729082]\n",
      "Loss in iteration 3125: 0.45667949658967516\n",
      "Theta: [-1.19498491  0.72986699  0.06728723]\n",
      "Loss in iteration 3126: 0.45666381574024745\n",
      "Theta: [-1.19521005  0.73000797  0.06728365]\n",
      "Loss in iteration 3127: 0.45664814291421263\n",
      "Theta: [-1.19543512  0.73014892  0.06728007]\n",
      "Loss in iteration 3128: 0.4566324781062944\n",
      "Theta: [-1.19566013  0.73028984  0.06727648]\n",
      "Loss in iteration 3129: 0.4566168213112214\n",
      "Theta: [-1.19588508  0.73043072  0.0672729 ]\n",
      "Loss in iteration 3130: 0.4566011725237263\n",
      "Theta: [-1.19610998  0.73057157  0.06726932]\n",
      "Loss in iteration 3131: 0.45658553173854577\n",
      "Theta: [-1.19633481  0.73071239  0.06726574]\n",
      "Loss in iteration 3132: 0.4565698989504211\n",
      "Theta: [-1.19655958  0.73085318  0.06726216]\n",
      "Loss in iteration 3133: 0.4565542741540976\n",
      "Theta: [-1.19678429  0.73099393  0.06725858]\n",
      "Loss in iteration 3134: 0.45653865734432514\n",
      "Theta: [-1.19700895  0.73113466  0.06725499]\n",
      "Loss in iteration 3135: 0.4565230485158574\n",
      "Theta: [-1.19723354  0.73127535  0.06725141]\n",
      "Loss in iteration 3136: 0.4565074476634527\n",
      "Theta: [-1.19745807  0.73141601  0.06724783]\n",
      "Loss in iteration 3137: 0.4564918547818732\n",
      "Theta: [-1.19768255  0.73155663  0.06724425]\n",
      "Loss in iteration 3138: 0.4564762698658857\n",
      "Theta: [-1.19790696  0.73169722  0.06724067]\n",
      "Loss in iteration 3139: 0.4564606929102608\n",
      "Theta: [-1.19813132  0.73183779  0.06723709]\n",
      "Loss in iteration 3140: 0.4564451239097738\n",
      "Theta: [-1.19835561  0.73197832  0.06723351]\n",
      "Loss in iteration 3141: 0.4564295628592037\n",
      "Theta: [-1.19857985  0.73211881  0.06722993]\n",
      "Loss in iteration 3142: 0.456414009753334\n",
      "Theta: [-1.19880402  0.73225928  0.06722635]\n",
      "Loss in iteration 3143: 0.45639846458695277\n",
      "Theta: [-1.19902814  0.73239971  0.06722278]\n",
      "Loss in iteration 3144: 0.4563829273548514\n",
      "Theta: [-1.19925219  0.73254011  0.0672192 ]\n",
      "Loss in iteration 3145: 0.45636739805182613\n",
      "Theta: [-1.19947619  0.73268048  0.06721562]\n",
      "Loss in iteration 3146: 0.45635187667267735\n",
      "Theta: [-1.19970013  0.73282082  0.06721204]\n",
      "Loss in iteration 3147: 0.45633636321220955\n",
      "Theta: [-1.19992401  0.73296112  0.06720846]\n",
      "Loss in iteration 3148: 0.45632085766523134\n",
      "Theta: [-1.20014783  0.73310139  0.06720489]\n",
      "Loss in iteration 3149: 0.4563053600265556\n",
      "Theta: [-1.20037158  0.73324163  0.06720131]\n",
      "Loss in iteration 3150: 0.45628987029099916\n",
      "Theta: [-1.20059528  0.73338184  0.06719773]\n",
      "Loss in iteration 3151: 0.4562743884533836\n",
      "Theta: [-1.20081892  0.73352202  0.06719416]\n",
      "Loss in iteration 3152: 0.456258914508534\n",
      "Theta: [-1.20104251  0.73366216  0.06719058]\n",
      "Loss in iteration 3153: 0.4562434484512803\n",
      "Theta: [-1.20126603  0.73380227  0.067187  ]\n",
      "Loss in iteration 3154: 0.4562279902764557\n",
      "Theta: [-1.20148949  0.73394235  0.06718343]\n",
      "Loss in iteration 3155: 0.45621253997889843\n",
      "Theta: [-1.20171289  0.7340824   0.06717985]\n",
      "Loss in iteration 3156: 0.45619709755345056\n",
      "Theta: [-1.20193624  0.73422242  0.06717628]\n",
      "Loss in iteration 3157: 0.45618166299495805\n",
      "Theta: [-1.20215952  0.7343624   0.0671727 ]\n",
      "Loss in iteration 3158: 0.4561662362982716\n",
      "Theta: [-1.20238275  0.73450235  0.06716913]\n",
      "Loss in iteration 3159: 0.4561508174582454\n",
      "Theta: [-1.20260591  0.73464227  0.06716555]\n",
      "Loss in iteration 3160: 0.45613540646973827\n",
      "Theta: [-1.20282902  0.73478216  0.06716198]\n",
      "Loss in iteration 3161: 0.456120003327613\n",
      "Theta: [-1.20305207  0.73492202  0.0671584 ]\n",
      "Loss in iteration 3162: 0.45610460802673614\n",
      "Theta: [-1.20327506  0.73506184  0.06715483]\n",
      "Loss in iteration 3163: 0.4560892205619793\n",
      "Theta: [-1.20349799  0.73520163  0.06715126]\n",
      "Loss in iteration 3164: 0.45607384092821734\n",
      "Theta: [-1.20372086  0.73534139  0.06714768]\n",
      "Loss in iteration 3165: 0.45605846912032943\n",
      "Theta: [-1.20394367  0.73548112  0.06714411]\n",
      "Loss in iteration 3166: 0.4560431051331993\n",
      "Theta: [-1.20416642  0.73562082  0.06714054]\n",
      "Loss in iteration 3167: 0.4560277489617143\n",
      "Theta: [-1.20438912  0.73576048  0.06713696]\n",
      "Loss in iteration 3168: 0.45601240060076614\n",
      "Theta: [-1.20461175  0.73590012  0.06713339]\n",
      "Loss in iteration 3169: 0.4559970600452505\n",
      "Theta: [-1.20483433  0.73603972  0.06712982]\n",
      "Loss in iteration 3170: 0.45598172729006725\n",
      "Theta: [-1.20505684  0.73617929  0.06712625]\n",
      "Loss in iteration 3171: 0.45596640233012037\n",
      "Theta: [-1.2052793   0.73631883  0.06712268]\n",
      "Loss in iteration 3172: 0.45595108516031785\n",
      "Theta: [-1.2055017   0.73645833  0.06711911]\n",
      "Loss in iteration 3173: 0.455935775775572\n",
      "Theta: [-1.20572404  0.73659781  0.06711553]\n",
      "Loss in iteration 3174: 0.45592047417079873\n",
      "Theta: [-1.20594632  0.73673725  0.06711196]\n",
      "Loss in iteration 3175: 0.4559051803409187\n",
      "Theta: [-1.20616855  0.73687666  0.06710839]\n",
      "Loss in iteration 3176: 0.455889894280856\n",
      "Theta: [-1.20639071  0.73701604  0.06710482]\n",
      "Loss in iteration 3177: 0.45587461598553936\n",
      "Theta: [-1.20661281  0.73715539  0.06710125]\n",
      "Loss in iteration 3178: 0.45585934544990125\n",
      "Theta: [-1.20683486  0.7372947   0.06709768]\n",
      "Loss in iteration 3179: 0.4558440826688781\n",
      "Theta: [-1.20705685  0.73743398  0.06709411]\n",
      "Loss in iteration 3180: 0.45582882763741084\n",
      "Theta: [-1.20727878  0.73757324  0.06709055]\n",
      "Loss in iteration 3181: 0.455813580350444\n",
      "Theta: [-1.20750065  0.73771246  0.06708698]\n",
      "Loss in iteration 3182: 0.4557983408029266\n",
      "Theta: [-1.20772246  0.73785165  0.06708341]\n",
      "Loss in iteration 3183: 0.45578310898981117\n",
      "Theta: [-1.20794421  0.7379908   0.06707984]\n",
      "Loss in iteration 3184: 0.45576788490605497\n",
      "Theta: [-1.20816591  0.73812993  0.06707627]\n",
      "Loss in iteration 3185: 0.4557526685466186\n",
      "Theta: [-1.20838754  0.73826902  0.0670727 ]\n",
      "Loss in iteration 3186: 0.4557374599064674\n",
      "Theta: [-1.20860912  0.73840808  0.06706914]\n",
      "Loss in iteration 3187: 0.4557222589805702\n",
      "Theta: [-1.20883064  0.73854711  0.06706557]\n",
      "Loss in iteration 3188: 0.45570706576389997\n",
      "Theta: [-1.2090521   0.73868611  0.067062  ]\n",
      "Loss in iteration 3189: 0.4556918802514339\n",
      "Theta: [-1.2092735   0.73882508  0.06705844]\n",
      "Loss in iteration 3190: 0.4556767024381533\n",
      "Theta: [-1.20949485  0.73896402  0.06705487]\n",
      "Loss in iteration 3191: 0.455661532319043\n",
      "Theta: [-1.20971613  0.73910292  0.0670513 ]\n",
      "Loss in iteration 3192: 0.4556463698890923\n",
      "Theta: [-1.20993736  0.73924179  0.06704774]\n",
      "Loss in iteration 3193: 0.45563121514329447\n",
      "Theta: [-1.21015853  0.73938063  0.06704417]\n",
      "Loss in iteration 3194: 0.45561606807664645\n",
      "Theta: [-1.21037964  0.73951944  0.06704061]\n",
      "Loss in iteration 3195: 0.4556009286841497\n",
      "Theta: [-1.21060069  0.73965822  0.06703704]\n",
      "Loss in iteration 3196: 0.4555857969608094\n",
      "Theta: [-1.21082168  0.73979697  0.06703348]\n",
      "Loss in iteration 3197: 0.4555706729016345\n",
      "Theta: [-1.21104262  0.73993568  0.06702991]\n",
      "Loss in iteration 3198: 0.4555555565016385\n",
      "Theta: [-1.21126349  0.74007437  0.06702635]\n",
      "Loss in iteration 3199: 0.4555404477558384\n",
      "Theta: [-1.21148431  0.74021302  0.06702278]\n",
      "Loss in iteration 3200: 0.4555253466592555\n",
      "Theta: [-1.21170507  0.74035164  0.06701922]\n",
      "Loss in iteration 3201: 0.4555102532069148\n",
      "Theta: [-1.21192577  0.74049023  0.06701565]\n",
      "Loss in iteration 3202: 0.4554951673938456\n",
      "Theta: [-1.21214642  0.74062879  0.06701209]\n",
      "Loss in iteration 3203: 0.455480089215081\n",
      "Theta: [-1.212367    0.74076731  0.06700853]\n",
      "Loss in iteration 3204: 0.4554650186656579\n",
      "Theta: [-1.21258753  0.74090581  0.06700496]\n",
      "Loss in iteration 3205: 0.45544995574061786\n",
      "Theta: [-1.212808    0.74104427  0.0670014 ]\n",
      "Loss in iteration 3206: 0.4554349004350056\n",
      "Theta: [-1.21302841  0.7411827   0.06699784]\n",
      "Loss in iteration 3207: 0.4554198527438701\n",
      "Theta: [-1.21324877  0.7413211   0.06699428]\n",
      "Loss in iteration 3208: 0.45540481266226435\n",
      "Theta: [-1.21346906  0.74145947  0.06699072]\n",
      "Loss in iteration 3209: 0.45538978018524534\n",
      "Theta: [-1.2136893   0.74159781  0.06698715]\n",
      "Loss in iteration 3210: 0.4553747553078738\n",
      "Theta: [-1.21390948  0.74173612  0.06698359]\n",
      "Loss in iteration 3211: 0.45535973802521473\n",
      "Theta: [-1.2141296   0.74187439  0.06698003]\n",
      "Loss in iteration 3212: 0.45534472833233686\n",
      "Theta: [-1.21434966  0.74201264  0.06697647]\n",
      "Loss in iteration 3213: 0.4553297262243127\n",
      "Theta: [-1.21456967  0.74215085  0.06697291]\n",
      "Loss in iteration 3214: 0.4553147316962191\n",
      "Theta: [-1.21478962  0.74228903  0.06696935]\n",
      "Loss in iteration 3215: 0.45529974474313667\n",
      "Theta: [-1.21500951  0.74242718  0.06696579]\n",
      "Loss in iteration 3216: 0.4552847653601497\n",
      "Theta: [-1.21522934  0.7425653   0.06696223]\n",
      "Loss in iteration 3217: 0.4552697935423468\n",
      "Theta: [-1.21544911  0.74270339  0.06695867]\n",
      "Loss in iteration 3218: 0.4552548292848202\n",
      "Theta: [-1.21566883  0.74284145  0.06695511]\n",
      "Loss in iteration 3219: 0.4552398725826663\n",
      "Theta: [-1.21588849  0.74297947  0.06695155]\n",
      "Loss in iteration 3220: 0.4552249234309852\n",
      "Theta: [-1.21610809  0.74311747  0.06694799]\n",
      "Loss in iteration 3221: 0.4552099818248812\n",
      "Theta: [-1.21632763  0.74325543  0.06694443]\n",
      "Loss in iteration 3222: 0.455195047759462\n",
      "Theta: [-1.21654712  0.74339336  0.06694088]\n",
      "Loss in iteration 3223: 0.45518012122983975\n",
      "Theta: [-1.21676655  0.74353126  0.06693732]\n",
      "Loss in iteration 3224: 0.45516520223113005\n",
      "Theta: [-1.21698592  0.74366913  0.06693376]\n",
      "Loss in iteration 3225: 0.45515029075845276\n",
      "Theta: [-1.21720523  0.74380697  0.0669302 ]\n",
      "Loss in iteration 3226: 0.45513538680693144\n",
      "Theta: [-1.21742449  0.74394478  0.06692665]\n",
      "Loss in iteration 3227: 0.4551204903716938\n",
      "Theta: [-1.21764368  0.74408255  0.06692309]\n",
      "Loss in iteration 3228: 0.4551056014478707\n",
      "Theta: [-1.21786282  0.7442203   0.06691953]\n",
      "Loss in iteration 3229: 0.4550907200305979\n",
      "Theta: [-1.21808191  0.74435801  0.06691598]\n",
      "Loss in iteration 3230: 0.45507584611501445\n",
      "Theta: [-1.21830093  0.74449569  0.06691242]\n",
      "Loss in iteration 3231: 0.4550609796962632\n",
      "Theta: [-1.2185199   0.74463334  0.06690886]\n",
      "Loss in iteration 3232: 0.4550461207694911\n",
      "Theta: [-1.21873881  0.74477096  0.06690531]\n",
      "Loss in iteration 3233: 0.45503126932984883\n",
      "Theta: [-1.21895766  0.74490855  0.06690175]\n",
      "Loss in iteration 3234: 0.4550164253724912\n",
      "Theta: [-1.21917646  0.74504611  0.0668982 ]\n",
      "Loss in iteration 3235: 0.4550015888925767\n",
      "Theta: [-1.21939519  0.74518364  0.06689464]\n",
      "Loss in iteration 3236: 0.4549867598852673\n",
      "Theta: [-1.21961388  0.74532113  0.06689109]\n",
      "Loss in iteration 3237: 0.45497193834572974\n",
      "Theta: [-1.2198325   0.7454586   0.06688753]\n",
      "Loss in iteration 3238: 0.45495712426913365\n",
      "Theta: [-1.22005106  0.74559603  0.06688398]\n",
      "Loss in iteration 3239: 0.45494231765065307\n",
      "Theta: [-1.22026957  0.74573344  0.06688042]\n",
      "Loss in iteration 3240: 0.4549275184854656\n",
      "Theta: [-1.22048802  0.74587081  0.06687687]\n",
      "Loss in iteration 3241: 0.45491272676875305\n",
      "Theta: [-1.22070642  0.74600815  0.06687332]\n",
      "Loss in iteration 3242: 0.4548979424957005\n",
      "Theta: [-1.22092475  0.74614546  0.06686976]\n",
      "Loss in iteration 3243: 0.45488316566149756\n",
      "Theta: [-1.22114303  0.74628274  0.06686621]\n",
      "Loss in iteration 3244: 0.454868396261337\n",
      "Theta: [-1.22136126  0.74641999  0.06686266]\n",
      "Loss in iteration 3245: 0.4548536342904157\n",
      "Theta: [-1.22157942  0.74655721  0.06685911]\n",
      "Loss in iteration 3246: 0.45483887974393467\n",
      "Theta: [-1.22179753  0.74669439  0.06685555]\n",
      "Loss in iteration 3247: 0.45482413261709814\n",
      "Theta: [-1.22201558  0.74683155  0.066852  ]\n",
      "Loss in iteration 3248: 0.45480939290511463\n",
      "Theta: [-1.22223357  0.74696867  0.06684845]\n",
      "Loss in iteration 3249: 0.45479466060319623\n",
      "Theta: [-1.22245151  0.74710577  0.0668449 ]\n",
      "Loss in iteration 3250: 0.45477993570655895\n",
      "Theta: [-1.22266939  0.74724283  0.06684135]\n",
      "Loss in iteration 3251: 0.4547652182104223\n",
      "Theta: [-1.22288721  0.74737986  0.0668378 ]\n",
      "Loss in iteration 3252: 0.45475050811001017\n",
      "Theta: [-1.22310498  0.74751686  0.06683425]\n",
      "Loss in iteration 3253: 0.45473580540054975\n",
      "Theta: [-1.22332269  0.74765383  0.0668307 ]\n",
      "Loss in iteration 3254: 0.4547211100772721\n",
      "Theta: [-1.22354034  0.74779077  0.06682715]\n",
      "Loss in iteration 3255: 0.4547064221354126\n",
      "Theta: [-1.22375793  0.74792768  0.0668236 ]\n",
      "Loss in iteration 3256: 0.4546917415702094\n",
      "Theta: [-1.22397547  0.74806456  0.06682005]\n",
      "Loss in iteration 3257: 0.45467706837690536\n",
      "Theta: [-1.22419295  0.74820141  0.0668165 ]\n",
      "Loss in iteration 3258: 0.4546624025507465\n",
      "Theta: [-1.22441038  0.74833822  0.06681295]\n",
      "Loss in iteration 3259: 0.45464774408698333\n",
      "Theta: [-1.22462774  0.74847501  0.0668094 ]\n",
      "Loss in iteration 3260: 0.4546330929808692\n",
      "Theta: [-1.22484505  0.74861176  0.06680585]\n",
      "Loss in iteration 3261: 0.45461844922766204\n",
      "Theta: [-1.22506231  0.74874849  0.0668023 ]\n",
      "Loss in iteration 3262: 0.454603812822623\n",
      "Theta: [-1.2252795   0.74888518  0.06679875]\n",
      "Loss in iteration 3263: 0.4545891837610174\n",
      "Theta: [-1.22549664  0.74902184  0.06679521]\n",
      "Loss in iteration 3264: 0.4545745620381139\n",
      "Theta: [-1.22571373  0.74915847  0.06679166]\n",
      "Loss in iteration 3265: 0.4545599476491853\n",
      "Theta: [-1.22593075  0.74929508  0.06678811]\n",
      "Loss in iteration 3266: 0.4545453405895079\n",
      "Theta: [-1.22614772  0.74943165  0.06678456]\n",
      "Loss in iteration 3267: 0.454530740854362\n",
      "Theta: [-1.22636464  0.74956819  0.06678102]\n",
      "Loss in iteration 3268: 0.4545161484390314\n",
      "Theta: [-1.22658149  0.7497047   0.06677747]\n",
      "Loss in iteration 3269: 0.4545015633388034\n",
      "Theta: [-1.22679829  0.74984117  0.06677392]\n",
      "Loss in iteration 3270: 0.45448698554896994\n",
      "Theta: [-1.22701504  0.74997762  0.06677038]\n",
      "Loss in iteration 3271: 0.4544724150648257\n",
      "Theta: [-1.22723172  0.75011404  0.06676683]\n",
      "Loss in iteration 3272: 0.45445785188166954\n",
      "Theta: [-1.22744835  0.75025043  0.06676329]\n",
      "Loss in iteration 3273: 0.45444329599480404\n",
      "Theta: [-1.22766493  0.75038678  0.06675974]\n",
      "Loss in iteration 3274: 0.45442874739953554\n",
      "Theta: [-1.22788144  0.75052311  0.06675619]\n",
      "Loss in iteration 3275: 0.45441420609117394\n",
      "Theta: [-1.2280979   0.7506594   0.06675265]\n",
      "Loss in iteration 3276: 0.45439967206503296\n",
      "Theta: [-1.22831431  0.75079567  0.06674911]\n",
      "Loss in iteration 3277: 0.45438514531643004\n",
      "Theta: [-1.22853066  0.7509319   0.06674556]\n",
      "Loss in iteration 3278: 0.45437062584068644\n",
      "Theta: [-1.22874695  0.7510681   0.06674202]\n",
      "Loss in iteration 3279: 0.4543561136331267\n",
      "Theta: [-1.22896318  0.75120428  0.06673847]\n",
      "Loss in iteration 3280: 0.45434160868907947\n",
      "Theta: [-1.22917936  0.75134042  0.06673493]\n",
      "Loss in iteration 3281: 0.4543271110038769\n",
      "Theta: [-1.22939548  0.75147653  0.06673139]\n",
      "Loss in iteration 3282: 0.45431262057285515\n",
      "Theta: [-1.22961155  0.75161261  0.06672784]\n",
      "Loss in iteration 3283: 0.4542981373913537\n",
      "Theta: [-1.22982756  0.75174866  0.0667243 ]\n",
      "Loss in iteration 3284: 0.45428366145471566\n",
      "Theta: [-1.23004351  0.75188468  0.06672076]\n",
      "Loss in iteration 3285: 0.45426919275828836\n",
      "Theta: [-1.23025941  0.75202067  0.06671722]\n",
      "Loss in iteration 3286: 0.45425473129742217\n",
      "Theta: [-1.23047525  0.75215663  0.06671367]\n",
      "Loss in iteration 3287: 0.4542402770674718\n",
      "Theta: [-1.23069103  0.75229256  0.06671013]\n",
      "Loss in iteration 3288: 0.45422583006379486\n",
      "Theta: [-1.23090676  0.75242846  0.06670659]\n",
      "Loss in iteration 3289: 0.4542113902817533\n",
      "Theta: [-1.23112243  0.75256433  0.06670305]\n",
      "Loss in iteration 3290: 0.4541969577167123\n",
      "Theta: [-1.23133805  0.75270016  0.06669951]\n",
      "Loss in iteration 3291: 0.45418253236404105\n",
      "Theta: [-1.23155361  0.75283597  0.06669597]\n",
      "Loss in iteration 3292: 0.45416811421911213\n",
      "Theta: [-1.23176911  0.75297175  0.06669243]\n",
      "Loss in iteration 3293: 0.4541537032773019\n",
      "Theta: [-1.23198456  0.75310749  0.06668889]\n",
      "Loss in iteration 3294: 0.45413929953399035\n",
      "Theta: [-1.23219995  0.75324321  0.06668534]\n",
      "Loss in iteration 3295: 0.4541249029845612\n",
      "Theta: [-1.23241529  0.75337889  0.06668181]\n",
      "Loss in iteration 3296: 0.45411051362440163\n",
      "Theta: [-1.23263057  0.75351455  0.06667827]\n",
      "Loss in iteration 3297: 0.4540961314489027\n",
      "Theta: [-1.23284579  0.75365017  0.06667473]\n",
      "Loss in iteration 3298: 0.45408175645345894\n",
      "Theta: [-1.23306096  0.75378577  0.06667119]\n",
      "Loss in iteration 3299: 0.45406738863346857\n",
      "Theta: [-1.23327607  0.75392133  0.06666765]\n",
      "Loss in iteration 3300: 0.4540530279843333\n",
      "Theta: [-1.23349113  0.75405687  0.06666411]\n",
      "Loss in iteration 3301: 0.4540386745014588\n",
      "Theta: [-1.23370613  0.75419237  0.06666057]\n",
      "Loss in iteration 3302: 0.454024328180254\n",
      "Theta: [-1.23392107  0.75432784  0.06665703]\n",
      "Loss in iteration 3303: 0.45400998901613177\n",
      "Theta: [-1.23413596  0.75446329  0.06665349]\n",
      "Loss in iteration 3304: 0.4539956570045085\n",
      "Theta: [-1.23435079  0.7545987   0.06664996]\n",
      "Loss in iteration 3305: 0.45398133214080394\n",
      "Theta: [-1.23456557  0.75473408  0.06664642]\n",
      "Loss in iteration 3306: 0.45396701442044196\n",
      "Theta: [-1.23478029  0.75486944  0.06664288]\n",
      "Loss in iteration 3307: 0.4539527038388495\n",
      "Theta: [-1.23499496  0.75500476  0.06663935]\n",
      "Loss in iteration 3308: 0.4539384003914573\n",
      "Theta: [-1.23520956  0.75514005  0.06663581]\n",
      "Loss in iteration 3309: 0.45392410407370015\n",
      "Theta: [-1.23542412  0.75527531  0.06663227]\n",
      "Loss in iteration 3310: 0.4539098148810156\n",
      "Theta: [-1.23563862  0.75541054  0.06662874]\n",
      "Loss in iteration 3311: 0.4538955328088454\n",
      "Theta: [-1.23585306  0.75554574  0.0666252 ]\n",
      "Loss in iteration 3312: 0.4538812578526349\n",
      "Theta: [-1.23606744  0.75568092  0.06662167]\n",
      "Loss in iteration 3313: 0.4538669900078328\n",
      "Theta: [-1.23628177  0.75581606  0.06661813]\n",
      "Loss in iteration 3314: 0.45385272926989145\n",
      "Theta: [-1.23649605  0.75595117  0.06661459]\n",
      "Loss in iteration 3315: 0.4538384756342667\n",
      "Theta: [-1.23671027  0.75608625  0.06661106]\n",
      "Loss in iteration 3316: 0.4538242290964182\n",
      "Theta: [-1.23692443  0.7562213   0.06660753]\n",
      "Loss in iteration 3317: 0.453809989651809\n",
      "Theta: [-1.23713854  0.75635632  0.06660399]\n",
      "Loss in iteration 3318: 0.4537957572959057\n",
      "Theta: [-1.2373526   0.75649131  0.06660046]\n",
      "Loss in iteration 3319: 0.45378153202417887\n",
      "Theta: [-1.23756659  0.75662627  0.06659692]\n",
      "Loss in iteration 3320: 0.4537673138321019\n",
      "Theta: [-1.23778053  0.7567612   0.06659339]\n",
      "Loss in iteration 3321: 0.4537531027151524\n",
      "Theta: [-1.23799442  0.7568961   0.06658986]\n",
      "Loss in iteration 3322: 0.45373889866881145\n",
      "Theta: [-1.23820825  0.75703097  0.06658632]\n",
      "Loss in iteration 3323: 0.45372470168856316\n",
      "Theta: [-1.23842203  0.75716581  0.06658279]\n",
      "Loss in iteration 3324: 0.453710511769896\n",
      "Theta: [-1.23863575  0.75730062  0.06657926]\n",
      "Loss in iteration 3325: 0.45369632890830125\n",
      "Theta: [-1.23884941  0.7574354   0.06657572]\n",
      "Loss in iteration 3326: 0.4536821530992741\n",
      "Theta: [-1.23906302  0.75757015  0.06657219]\n",
      "Loss in iteration 3327: 0.45366798433831357\n",
      "Theta: [-1.23927658  0.75770487  0.06656866]\n",
      "Loss in iteration 3328: 0.4536538226209214\n",
      "Theta: [-1.23949008  0.75783956  0.06656513]\n",
      "Loss in iteration 3329: 0.45363966794260385\n",
      "Theta: [-1.23970352  0.75797422  0.0665616 ]\n",
      "Loss in iteration 3330: 0.45362552029886993\n",
      "Theta: [-1.23991691  0.75810885  0.06655807]\n",
      "Loss in iteration 3331: 0.45361137968523246\n",
      "Theta: [-1.24013024  0.75824345  0.06655453]\n",
      "Loss in iteration 3332: 0.45359724609720786\n",
      "Theta: [-1.24034352  0.75837802  0.066551  ]\n",
      "Loss in iteration 3333: 0.45358311953031605\n",
      "Theta: [-1.24055674  0.75851256  0.06654747]\n",
      "Loss in iteration 3334: 0.4535689999800805\n",
      "Theta: [-1.24076991  0.75864707  0.06654394]\n",
      "Loss in iteration 3335: 0.45355488744202804\n",
      "Theta: [-1.24098302  0.75878155  0.06654041]\n",
      "Loss in iteration 3336: 0.45354078191168895\n",
      "Theta: [-1.24119608  0.758916    0.06653688]\n",
      "Loss in iteration 3337: 0.45352668338459756\n",
      "Theta: [-1.24140908  0.75905042  0.06653335]\n",
      "Loss in iteration 3338: 0.4535125918562911\n",
      "Theta: [-1.24162203  0.75918481  0.06652983]\n",
      "Loss in iteration 3339: 0.45349850732231056\n",
      "Theta: [-1.24183492  0.75931918  0.0665263 ]\n",
      "Loss in iteration 3340: 0.4534844297782003\n",
      "Theta: [-1.24204776  0.75945351  0.06652277]\n",
      "Loss in iteration 3341: 0.45347035921950846\n",
      "Theta: [-1.24226054  0.75958781  0.06651924]\n",
      "Loss in iteration 3342: 0.45345629564178636\n",
      "Theta: [-1.24247326  0.75972208  0.06651571]\n",
      "Loss in iteration 3343: 0.45344223904058917\n",
      "Theta: [-1.24268594  0.75985632  0.06651218]\n",
      "Loss in iteration 3344: 0.45342818941147506\n",
      "Theta: [-1.24289855  0.75999053  0.06650866]\n",
      "Loss in iteration 3345: 0.45341414675000613\n",
      "Theta: [-1.24311112  0.76012471  0.06650513]\n",
      "Loss in iteration 3346: 0.45340011105174777\n",
      "Theta: [-1.24332362  0.76025887  0.0665016 ]\n",
      "Loss in iteration 3347: 0.4533860823122688\n",
      "Theta: [-1.24353607  0.76039299  0.06649807]\n",
      "Loss in iteration 3348: 0.45337206052714146\n",
      "Theta: [-1.24374847  0.76052708  0.06649455]\n",
      "Loss in iteration 3349: 0.4533580456919419\n",
      "Theta: [-1.24396081  0.76066114  0.06649102]\n",
      "Loss in iteration 3350: 0.4533440378022492\n",
      "Theta: [-1.2441731   0.76079518  0.06648749]\n",
      "Loss in iteration 3351: 0.45333003685364615\n",
      "Theta: [-1.24438534  0.76092918  0.06648397]\n",
      "Loss in iteration 3352: 0.453316042841719\n",
      "Theta: [-1.24459751  0.76106315  0.06648044]\n",
      "Loss in iteration 3353: 0.4533020557620576\n",
      "Theta: [-1.24480964  0.7611971   0.06647692]\n",
      "Loss in iteration 3354: 0.4532880756102548\n",
      "Theta: [-1.24502171  0.76133101  0.06647339]\n",
      "Loss in iteration 3355: 0.4532741023819076\n",
      "Theta: [-1.24523372  0.76146489  0.06646987]\n",
      "Loss in iteration 3356: 0.4532601360726155\n",
      "Theta: [-1.24544568  0.76159875  0.06646634]\n",
      "Loss in iteration 3357: 0.45324617667798245\n",
      "Theta: [-1.24565758  0.76173257  0.06646282]\n",
      "Loss in iteration 3358: 0.4532322241936152\n",
      "Theta: [-1.24586943  0.76186637  0.06645929]\n",
      "Loss in iteration 3359: 0.45321827861512426\n",
      "Theta: [-1.24608123  0.76200014  0.06645577]\n",
      "Loss in iteration 3360: 0.4532043399381232\n",
      "Theta: [-1.24629297  0.76213387  0.06645224]\n",
      "Loss in iteration 3361: 0.4531904081582296\n",
      "Theta: [-1.24650465  0.76226758  0.06644872]\n",
      "Loss in iteration 3362: 0.45317648327106386\n",
      "Theta: [-1.24671629  0.76240126  0.0664452 ]\n",
      "Loss in iteration 3363: 0.45316256527225035\n",
      "Theta: [-1.24692786  0.7625349   0.06644167]\n",
      "Loss in iteration 3364: 0.45314865415741645\n",
      "Theta: [-1.24713938  0.76266852  0.06643815]\n",
      "Loss in iteration 3365: 0.4531347499221932\n",
      "Theta: [-1.24735085  0.76280211  0.06643463]\n",
      "Loss in iteration 3366: 0.45312085256221485\n",
      "Theta: [-1.24756227  0.76293567  0.06643111]\n",
      "Loss in iteration 3367: 0.4531069620731192\n",
      "Theta: [-1.24777362  0.7630692   0.06642758]\n",
      "Loss in iteration 3368: 0.4530930784505476\n",
      "Theta: [-1.24798493  0.76320269  0.06642406]\n",
      "Loss in iteration 3369: 0.45307920169014465\n",
      "Theta: [-1.24819618  0.76333616  0.06642054]\n",
      "Loss in iteration 3370: 0.45306533178755826\n",
      "Theta: [-1.24840737  0.7634696   0.06641702]\n",
      "Loss in iteration 3371: 0.4530514687384399\n",
      "Theta: [-1.24861852  0.76360302  0.0664135 ]\n",
      "Loss in iteration 3372: 0.45303761253844443\n",
      "Theta: [-1.2488296   0.7637364   0.06640998]\n",
      "Loss in iteration 3373: 0.4530237631832299\n",
      "Theta: [-1.24904063  0.76386975  0.06640646]\n",
      "Loss in iteration 3374: 0.4530099206684583\n",
      "Theta: [-1.24925161  0.76400307  0.06640294]\n",
      "Loss in iteration 3375: 0.4529960849897944\n",
      "Theta: [-1.24946254  0.76413636  0.06639942]\n",
      "Loss in iteration 3376: 0.45298225614290627\n",
      "Theta: [-1.24967341  0.76426963  0.0663959 ]\n",
      "Loss in iteration 3377: 0.45296843412346627\n",
      "Theta: [-1.24988422  0.76440286  0.06639238]\n",
      "Loss in iteration 3378: 0.4529546189271493\n",
      "Theta: [-1.25009498  0.76453606  0.06638886]\n",
      "Loss in iteration 3379: 0.4529408105496337\n",
      "Theta: [-1.25030569  0.76466924  0.06638534]\n",
      "Loss in iteration 3380: 0.4529270089866015\n",
      "Theta: [-1.25051634  0.76480239  0.06638182]\n",
      "Loss in iteration 3381: 0.4529132142337383\n",
      "Theta: [-1.25072694  0.7649355   0.0663783 ]\n",
      "Loss in iteration 3382: 0.45289942628673224\n",
      "Theta: [-1.25093749  0.76506859  0.06637478]\n",
      "Loss in iteration 3383: 0.4528856451412757\n",
      "Theta: [-1.25114798  0.76520165  0.06637126]\n",
      "Loss in iteration 3384: 0.4528718707930639\n",
      "Theta: [-1.25135841  0.76533467  0.06636775]\n",
      "Loss in iteration 3385: 0.4528581032377956\n",
      "Theta: [-1.25156879  0.76546767  0.06636423]\n",
      "Loss in iteration 3386: 0.45284434247117294\n",
      "Theta: [-1.25177912  0.76560064  0.06636071]\n",
      "Loss in iteration 3387: 0.4528305884889013\n",
      "Theta: [-1.2519894   0.76573358  0.06635719]\n",
      "Loss in iteration 3388: 0.4528168412866895\n",
      "Theta: [-1.25219962  0.76586649  0.06635368]\n",
      "Loss in iteration 3389: 0.4528031008602496\n",
      "Theta: [-1.25240978  0.76599937  0.06635016]\n",
      "Loss in iteration 3390: 0.45278936720529706\n",
      "Theta: [-1.2526199   0.76613222  0.06634664]\n",
      "Loss in iteration 3391: 0.4527756403175511\n",
      "Theta: [-1.25282995  0.76626505  0.06634313]\n",
      "Loss in iteration 3392: 0.45276192019273337\n",
      "Theta: [-1.25303996  0.76639784  0.06633961]\n",
      "Loss in iteration 3393: 0.4527482068265696\n",
      "Theta: [-1.25324991  0.7665306   0.0663361 ]\n",
      "Loss in iteration 3394: 0.4527345002147885\n",
      "Theta: [-1.2534598   0.76666334  0.06633258]\n",
      "Loss in iteration 3395: 0.4527208003531225\n",
      "Theta: [-1.25366965  0.76679604  0.06632907]\n",
      "Loss in iteration 3396: 0.4527071072373069\n",
      "Theta: [-1.25387944  0.76692872  0.06632555]\n",
      "Loss in iteration 3397: 0.45269342086308034\n",
      "Theta: [-1.25408917  0.76706137  0.06632204]\n",
      "Loss in iteration 3398: 0.4526797412261852\n",
      "Theta: [-1.25429885  0.76719398  0.06631852]\n",
      "Loss in iteration 3399: 0.4526660683223669\n",
      "Theta: [-1.25450848  0.76732657  0.06631501]\n",
      "Loss in iteration 3400: 0.45265240214737396\n",
      "Theta: [-1.25471805  0.76745913  0.06631149]\n",
      "Loss in iteration 3401: 0.4526387426969588\n",
      "Theta: [-1.25492757  0.76759166  0.06630798]\n",
      "Loss in iteration 3402: 0.45262508996687667\n",
      "Theta: [-1.25513704  0.76772416  0.06630446]\n",
      "Loss in iteration 3403: 0.45261144395288594\n",
      "Theta: [-1.25534645  0.76785663  0.06630095]\n",
      "Loss in iteration 3404: 0.45259780465074895\n",
      "Theta: [-1.25555581  0.76798908  0.06629744]\n",
      "Loss in iteration 3405: 0.45258417205623097\n",
      "Theta: [-1.25576511  0.76812149  0.06629393]\n",
      "Loss in iteration 3406: 0.4525705461651002\n",
      "Theta: [-1.25597437  0.76825387  0.06629041]\n",
      "Loss in iteration 3407: 0.4525569269731288\n",
      "Theta: [-1.25618356  0.76838623  0.0662869 ]\n",
      "Loss in iteration 3408: 0.452543314476092\n",
      "Theta: [-1.25639271  0.76851855  0.06628339]\n",
      "Loss in iteration 3409: 0.45252970866976794\n",
      "Theta: [-1.2566018   0.76865085  0.06627988]\n",
      "Loss in iteration 3410: 0.4525161095499386\n",
      "Theta: [-1.25681084  0.76878312  0.06627637]\n",
      "Loss in iteration 3411: 0.45250251711238887\n",
      "Theta: [-1.25701982  0.76891536  0.06627285]\n",
      "Loss in iteration 3412: 0.45248893135290724\n",
      "Theta: [-1.25722875  0.76904757  0.06626934]\n",
      "Loss in iteration 3413: 0.4524753522672848\n",
      "Theta: [-1.25743763  0.76917975  0.06626583]\n",
      "Loss in iteration 3414: 0.45246177985131664\n",
      "Theta: [-1.25764645  0.7693119   0.06626232]\n",
      "Loss in iteration 3415: 0.452448214100801\n",
      "Theta: [-1.25785522  0.76944402  0.06625881]\n",
      "Loss in iteration 3416: 0.4524346550115389\n",
      "Theta: [-1.25806394  0.76957611  0.0662553 ]\n",
      "Loss in iteration 3417: 0.45242110257933527\n",
      "Theta: [-1.2582726   0.76970818  0.06625179]\n",
      "Loss in iteration 3418: 0.4524075567999978\n",
      "Theta: [-1.25848121  0.76984021  0.06624828]\n",
      "Loss in iteration 3419: 0.4523940176693377\n",
      "Theta: [-1.25868976  0.76997222  0.06624477]\n",
      "Loss in iteration 3420: 0.4523804851831693\n",
      "Theta: [-1.25889827  0.7701042   0.06624126]\n",
      "Loss in iteration 3421: 0.4523669593373102\n",
      "Theta: [-1.25910672  0.77023614  0.06623775]\n",
      "Loss in iteration 3422: 0.45235344012758155\n",
      "Theta: [-1.25931511  0.77036806  0.06623424]\n",
      "Loss in iteration 3423: 0.4523399275498069\n",
      "Theta: [-1.25952345  0.77049995  0.06623074]\n",
      "Loss in iteration 3424: 0.4523264215998142\n",
      "Theta: [-1.25973174  0.77063181  0.06622723]\n",
      "Loss in iteration 3425: 0.4523129222734339\n",
      "Theta: [-1.25993998  0.77076365  0.06622372]\n",
      "Loss in iteration 3426: 0.45229942956649966\n",
      "Theta: [-1.26014816  0.77089545  0.06622021]\n",
      "Loss in iteration 3427: 0.45228594347484874\n",
      "Theta: [-1.26035629  0.77102722  0.0662167 ]\n",
      "Loss in iteration 3428: 0.4522724639943212\n",
      "Theta: [-1.26056437  0.77115897  0.0662132 ]\n",
      "Loss in iteration 3429: 0.4522589911207609\n",
      "Theta: [-1.26077239  0.77129069  0.06620969]\n",
      "Loss in iteration 3430: 0.4522455248500144\n",
      "Theta: [-1.26098036  0.77142237  0.06620618]\n",
      "Loss in iteration 3431: 0.4522320651779317\n",
      "Theta: [-1.26118828  0.77155403  0.06620268]\n",
      "Loss in iteration 3432: 0.45221861210036596\n",
      "Theta: [-1.26139615  0.77168566  0.06619917]\n",
      "Loss in iteration 3433: 0.45220516561317375\n",
      "Theta: [-1.26160396  0.77181726  0.06619566]\n",
      "Loss in iteration 3434: 0.4521917257122143\n",
      "Theta: [-1.26181172  0.77194884  0.06619216]\n",
      "Loss in iteration 3435: 0.4521782923933509\n",
      "Theta: [-1.26201942  0.77208038  0.06618865]\n",
      "Loss in iteration 3436: 0.45216486565244923\n",
      "Theta: [-1.26222707  0.77221189  0.06618515]\n",
      "Loss in iteration 3437: 0.4521514454853788\n",
      "Theta: [-1.26243467  0.77234338  0.06618164]\n",
      "Loss in iteration 3438: 0.4521380318880117\n",
      "Theta: [-1.26264222  0.77247484  0.06617814]\n",
      "Loss in iteration 3439: 0.45212462485622396\n",
      "Theta: [-1.26284971  0.77260626  0.06617463]\n",
      "Loss in iteration 3440: 0.4521112243858942\n",
      "Theta: [-1.26305715  0.77273766  0.06617113]\n",
      "Loss in iteration 3441: 0.4520978304729043\n",
      "Theta: [-1.26326454  0.77286903  0.06616762]\n",
      "Loss in iteration 3442: 0.45208444311313967\n",
      "Theta: [-1.26347187  0.77300037  0.06616412]\n",
      "Loss in iteration 3443: 0.45207106230248856\n",
      "Theta: [-1.26367915  0.77313169  0.06616062]\n",
      "Loss in iteration 3444: 0.4520576880368427\n",
      "Theta: [-1.26388638  0.77326297  0.06615711]\n",
      "Loss in iteration 3445: 0.4520443203120968\n",
      "Theta: [-1.26409356  0.77339423  0.06615361]\n",
      "Loss in iteration 3446: 0.4520309591241486\n",
      "Theta: [-1.26430068  0.77352545  0.06615011]\n",
      "Loss in iteration 3447: 0.45201760446889944\n",
      "Theta: [-1.26450775  0.77365665  0.0661466 ]\n",
      "Loss in iteration 3448: 0.4520042563422534\n",
      "Theta: [-1.26471477  0.77378782  0.0661431 ]\n",
      "Loss in iteration 3449: 0.4519909147401182\n",
      "Theta: [-1.26492174  0.77391896  0.0661396 ]\n",
      "Loss in iteration 3450: 0.45197757965840407\n",
      "Theta: [-1.26512865  0.77405007  0.0661361 ]\n",
      "Loss in iteration 3451: 0.45196425109302507\n",
      "Theta: [-1.26533551  0.77418116  0.0661326 ]\n",
      "Loss in iteration 3452: 0.4519509290398982\n",
      "Theta: [-1.26554231  0.77431221  0.0661291 ]\n",
      "Loss in iteration 3453: 0.4519376134949431\n",
      "Theta: [-1.26574907  0.77444324  0.06612559]\n",
      "Loss in iteration 3454: 0.45192430445408327\n",
      "Theta: [-1.26595577  0.77457423  0.06612209]\n",
      "Loss in iteration 3455: 0.45191100191324524\n",
      "Theta: [-1.26616242  0.7747052   0.06611859]\n",
      "Loss in iteration 3456: 0.45189770586835826\n",
      "Theta: [-1.26636901  0.77483614  0.06611509]\n",
      "Loss in iteration 3457: 0.4518844163153554\n",
      "Theta: [-1.26657556  0.77496705  0.06611159]\n",
      "Loss in iteration 3458: 0.45187113325017203\n",
      "Theta: [-1.26678205  0.77509794  0.06610809]\n",
      "Loss in iteration 3459: 0.4518578566687473\n",
      "Theta: [-1.26698849  0.77522879  0.06610459]\n",
      "Loss in iteration 3460: 0.4518445865670235\n",
      "Theta: [-1.26719487  0.77535961  0.06610109]\n",
      "Loss in iteration 3461: 0.4518313229409457\n",
      "Theta: [-1.26740121  0.77549041  0.06609759]\n",
      "Loss in iteration 3462: 0.45181806578646205\n",
      "Theta: [-1.26760749  0.77562118  0.06609409]\n",
      "Loss in iteration 3463: 0.4518048150995244\n",
      "Theta: [-1.26781372  0.77575192  0.06609059]\n",
      "Loss in iteration 3464: 0.4517915708760871\n",
      "Theta: [-1.26801989  0.77588263  0.0660871 ]\n",
      "Loss in iteration 3465: 0.4517783331121082\n",
      "Theta: [-1.26822602  0.77601331  0.0660836 ]\n",
      "Loss in iteration 3466: 0.4517651018035481\n",
      "Theta: [-1.26843209  0.77614397  0.0660801 ]\n",
      "Loss in iteration 3467: 0.4517518769463711\n",
      "Theta: [-1.26863811  0.77627459  0.0660766 ]\n",
      "Loss in iteration 3468: 0.4517386585365441\n",
      "Theta: [-1.26884408  0.77640519  0.0660731 ]\n",
      "Loss in iteration 3469: 0.4517254465700376\n",
      "Theta: [-1.26904999  0.77653576  0.06606961]\n",
      "Loss in iteration 3470: 0.4517122410428247\n",
      "Theta: [-1.26925585  0.7766663   0.06606611]\n",
      "Loss in iteration 3471: 0.45169904195088173\n",
      "Theta: [-1.26946166  0.77679681  0.06606261]\n",
      "Loss in iteration 3472: 0.45168584929018835\n",
      "Theta: [-1.26966742  0.77692729  0.06605912]\n",
      "Loss in iteration 3473: 0.45167266305672704\n",
      "Theta: [-1.26987312  0.77705775  0.06605562]\n",
      "Loss in iteration 3474: 0.45165948324648364\n",
      "Theta: [-1.27007878  0.77718817  0.06605212]\n",
      "Loss in iteration 3475: 0.4516463098554469\n",
      "Theta: [-1.27028438  0.77731857  0.06604863]\n",
      "Loss in iteration 3476: 0.4516331428796086\n",
      "Theta: [-1.27048993  0.77744894  0.06604513]\n",
      "Loss in iteration 3477: 0.4516199823149639\n",
      "Theta: [-1.27069542  0.77757928  0.06604164]\n",
      "Loss in iteration 3478: 0.45160682815751085\n",
      "Theta: [-1.27090087  0.77770959  0.06603814]\n",
      "Loss in iteration 3479: 0.4515936804032505\n",
      "Theta: [-1.27110626  0.77783988  0.06603465]\n",
      "Loss in iteration 3480: 0.45158053904818707\n",
      "Theta: [-1.2713116   0.77797013  0.06603115]\n",
      "Loss in iteration 3481: 0.4515674040883279\n",
      "Theta: [-1.27151689  0.77810036  0.06602766]\n",
      "Loss in iteration 3482: 0.45155427551968347\n",
      "Theta: [-1.27172212  0.77823056  0.06602416]\n",
      "Loss in iteration 3483: 0.451541153338267\n",
      "Theta: [-1.27192731  0.77836073  0.06602067]\n",
      "Loss in iteration 3484: 0.45152803754009524\n",
      "Theta: [-1.27213244  0.77849087  0.06601717]\n",
      "Loss in iteration 3485: 0.4515149281211878\n",
      "Theta: [-1.27233752  0.77862099  0.06601368]\n",
      "Loss in iteration 3486: 0.45150182507756725\n",
      "Theta: [-1.27254255  0.77875107  0.06601019]\n",
      "Loss in iteration 3487: 0.4514887284052591\n",
      "Theta: [-1.27274752  0.77888113  0.06600669]\n",
      "Loss in iteration 3488: 0.4514756381002922\n",
      "Theta: [-1.27295245  0.77901116  0.0660032 ]\n",
      "Loss in iteration 3489: 0.4514625541586987\n",
      "Theta: [-1.27315732  0.77914116  0.06599971]\n",
      "Loss in iteration 3490: 0.45144947657651313\n",
      "Theta: [-1.27336214  0.77927113  0.06599622]\n",
      "Loss in iteration 3491: 0.45143640534977353\n",
      "Theta: [-1.27356691  0.77940108  0.06599272]\n",
      "Loss in iteration 3492: 0.4514233404745209\n",
      "Theta: [-1.27377162  0.77953099  0.06598923]\n",
      "Loss in iteration 3493: 0.45141028194679905\n",
      "Theta: [-1.27397629  0.77966088  0.06598574]\n",
      "Loss in iteration 3494: 0.4513972297626554\n",
      "Theta: [-1.2741809   0.77979074  0.06598225]\n",
      "Loss in iteration 3495: 0.4513841839181397\n",
      "Theta: [-1.27438546  0.77992057  0.06597876]\n",
      "Loss in iteration 3496: 0.45137114440930504\n",
      "Theta: [-1.27458997  0.78005037  0.06597527]\n",
      "Loss in iteration 3497: 0.451358111232208\n",
      "Theta: [-1.27479443  0.78018015  0.06597178]\n",
      "Loss in iteration 3498: 0.4513450843829075\n",
      "Theta: [-1.27499883  0.78030989  0.06596829]\n",
      "Loss in iteration 3499: 0.45133206385746566\n",
      "Theta: [-1.27520319  0.78043961  0.0659648 ]\n",
      "Loss in iteration 3500: 0.45131904965194786\n",
      "Theta: [-1.27540749  0.7805693   0.06596131]\n",
      "Loss in iteration 3501: 0.45130604176242245\n",
      "Theta: [-1.27561174  0.78069896  0.06595782]\n",
      "Loss in iteration 3502: 0.45129304018496036\n",
      "Theta: [-1.27581594  0.7808286   0.06595433]\n",
      "Loss in iteration 3503: 0.4512800449156363\n",
      "Theta: [-1.27602009  0.7809582   0.06595084]\n",
      "Loss in iteration 3504: 0.4512670559505274\n",
      "Theta: [-1.27622418  0.78108778  0.06594735]\n",
      "Loss in iteration 3505: 0.45125407328571393\n",
      "Theta: [-1.27642822  0.78121733  0.06594386]\n",
      "Loss in iteration 3506: 0.45124109691727926\n",
      "Theta: [-1.27663222  0.78134685  0.06594037]\n",
      "Loss in iteration 3507: 0.4512281268413097\n",
      "Theta: [-1.27683616  0.78147634  0.06593688]\n",
      "Loss in iteration 3508: 0.45121516305389475\n",
      "Theta: [-1.27704005  0.78160581  0.06593339]\n",
      "Loss in iteration 3509: 0.45120220555112667\n",
      "Theta: [-1.27724388  0.78173524  0.06592991]\n",
      "Loss in iteration 3510: 0.4511892543291006\n",
      "Theta: [-1.27744767  0.78186465  0.06592642]\n",
      "Loss in iteration 3511: 0.45117630938391495\n",
      "Theta: [-1.27765141  0.78199403  0.06592293]\n",
      "Loss in iteration 3512: 0.4511633707116713\n",
      "Theta: [-1.27785509  0.78212339  0.06591944]\n",
      "Loss in iteration 3513: 0.4511504383084736\n",
      "Theta: [-1.27805872  0.78225271  0.06591596]\n",
      "Loss in iteration 3514: 0.45113751217042947\n",
      "Theta: [-1.2782623   0.78238201  0.06591247]\n",
      "Loss in iteration 3515: 0.45112459229364904\n",
      "Theta: [-1.27846583  0.78251128  0.06590899]\n",
      "Loss in iteration 3516: 0.4511116786742455\n",
      "Theta: [-1.27866931  0.78264052  0.0659055 ]\n",
      "Loss in iteration 3517: 0.451098771308335\n",
      "Theta: [-1.27887273  0.78276973  0.06590201]\n",
      "Loss in iteration 3518: 0.4510858701920371\n",
      "Theta: [-1.27907611  0.78289891  0.06589853]\n",
      "Loss in iteration 3519: 0.4510729753214736\n",
      "Theta: [-1.27927943  0.78302807  0.06589504]\n",
      "Loss in iteration 3520: 0.45106008669277\n",
      "Theta: [-1.2794827   0.7831572   0.06589156]\n",
      "Loss in iteration 3521: 0.45104720430205425\n",
      "Theta: [-1.27968592  0.7832863   0.06588807]\n",
      "Loss in iteration 3522: 0.4510343281454574\n",
      "Theta: [-1.27988909  0.78341537  0.06588459]\n",
      "Loss in iteration 3523: 0.4510214582191135\n",
      "Theta: [-1.28009221  0.78354441  0.0658811 ]\n",
      "Loss in iteration 3524: 0.45100859451915976\n",
      "Theta: [-1.28029528  0.78367343  0.06587762]\n",
      "Loss in iteration 3525: 0.45099573704173596\n",
      "Theta: [-1.2804983   0.78380242  0.06587413]\n",
      "Loss in iteration 3526: 0.450982885782985\n",
      "Theta: [-1.28070126  0.78393138  0.06587065]\n",
      "Loss in iteration 3527: 0.45097004073905284\n",
      "Theta: [-1.28090417  0.78406031  0.06586717]\n",
      "Loss in iteration 3528: 0.4509572019060882\n",
      "Theta: [-1.28110704  0.78418922  0.06586368]\n",
      "Loss in iteration 3529: 0.450944369280243\n",
      "Theta: [-1.28130985  0.78431809  0.0658602 ]\n",
      "Loss in iteration 3530: 0.4509315428576718\n",
      "Theta: [-1.28151261  0.78444694  0.06585672]\n",
      "Loss in iteration 3531: 0.4509187226345323\n",
      "Theta: [-1.28171532  0.78457576  0.06585324]\n",
      "Loss in iteration 3532: 0.45090590860698526\n",
      "Theta: [-1.28191797  0.78470456  0.06584975]\n",
      "Loss in iteration 3533: 0.45089310077119404\n",
      "Theta: [-1.28212058  0.78483332  0.06584627]\n",
      "Loss in iteration 3534: 0.450880299123325\n",
      "Theta: [-1.28232314  0.78496206  0.06584279]\n",
      "Loss in iteration 3535: 0.45086750365954775\n",
      "Theta: [-1.28252564  0.78509077  0.06583931]\n",
      "Loss in iteration 3536: 0.4508547143760345\n",
      "Theta: [-1.2827281   0.78521945  0.06583583]\n",
      "Loss in iteration 3537: 0.4508419312689603\n",
      "Theta: [-1.2829305   0.78534811  0.06583234]\n",
      "Loss in iteration 3538: 0.45082915433450355\n",
      "Theta: [-1.28313285  0.78547673  0.06582886]\n",
      "Loss in iteration 3539: 0.45081638356884546\n",
      "Theta: [-1.28333515  0.78560533  0.06582538]\n",
      "Loss in iteration 3540: 0.4508036189681697\n",
      "Theta: [-1.2835374  0.7857339  0.0658219]\n",
      "Loss in iteration 3541: 0.45079086052866324\n",
      "Theta: [-1.2837396   0.78586244  0.06581842]\n",
      "Loss in iteration 3542: 0.450778108246516\n",
      "Theta: [-1.28394175  0.78599096  0.06581494]\n",
      "Loss in iteration 3543: 0.45076536211792084\n",
      "Theta: [-1.28414385  0.78611945  0.06581146]\n",
      "Loss in iteration 3544: 0.45075262213907324\n",
      "Theta: [-1.28434589  0.78624791  0.06580798]\n",
      "Loss in iteration 3545: 0.4507398883061715\n",
      "Theta: [-1.28454789  0.78637634  0.0658045 ]\n",
      "Loss in iteration 3546: 0.45072716061541757\n",
      "Theta: [-1.28474984  0.78650474  0.06580102]\n",
      "Loss in iteration 3547: 0.45071443906301545\n",
      "Theta: [-1.28495173  0.78663312  0.06579755]\n",
      "Loss in iteration 3548: 0.45070172364517264\n",
      "Theta: [-1.28515357  0.78676147  0.06579407]\n",
      "Loss in iteration 3549: 0.4506890143580988\n",
      "Theta: [-1.28535537  0.78688979  0.06579059]\n",
      "Loss in iteration 3550: 0.4506763111980075\n",
      "Theta: [-1.28555711  0.78701808  0.06578711]\n",
      "Loss in iteration 3551: 0.4506636141611143\n",
      "Theta: [-1.2857588   0.78714635  0.06578363]\n",
      "Loss in iteration 3552: 0.4506509232436381\n",
      "Theta: [-1.28596044  0.78727458  0.06578016]\n",
      "Loss in iteration 3553: 0.4506382384418006\n",
      "Theta: [-1.28616203  0.78740279  0.06577668]\n",
      "Loss in iteration 3554: 0.4506255597518264\n",
      "Theta: [-1.28636357  0.78753098  0.0657732 ]\n",
      "Loss in iteration 3555: 0.45061288716994286\n",
      "Theta: [-1.28656506  0.78765913  0.06576972]\n",
      "Loss in iteration 3556: 0.4506002206923803\n",
      "Theta: [-1.2867665   0.78778726  0.06576625]\n",
      "Loss in iteration 3557: 0.4505875603153718\n",
      "Theta: [-1.28696788  0.78791536  0.06576277]\n",
      "Loss in iteration 3558: 0.45057490603515354\n",
      "Theta: [-1.28716922  0.78804343  0.0657593 ]\n",
      "Loss in iteration 3559: 0.45056225784796455\n",
      "Theta: [-1.28737051  0.78817147  0.06575582]\n",
      "Loss in iteration 3560: 0.4505496157500465\n",
      "Theta: [-1.28757174  0.78829949  0.06575234]\n",
      "Loss in iteration 3561: 0.45053697973764395\n",
      "Theta: [-1.28777293  0.78842748  0.06574887]\n",
      "Loss in iteration 3562: 0.4505243498070044\n",
      "Theta: [-1.28797406  0.78855544  0.06574539]\n",
      "Loss in iteration 3563: 0.45051172595437855\n",
      "Theta: [-1.28817515  0.78868338  0.06574192]\n",
      "Loss in iteration 3564: 0.4504991081760192\n",
      "Theta: [-1.28837618  0.78881128  0.06573844]\n",
      "Loss in iteration 3565: 0.4504864964681828\n",
      "Theta: [-1.28857717  0.78893916  0.06573497]\n",
      "Loss in iteration 3566: 0.45047389082712785\n",
      "Theta: [-1.2887781   0.78906701  0.06573149]\n",
      "Loss in iteration 3567: 0.4504612912491164\n",
      "Theta: [-1.28897898  0.78919484  0.06572802]\n",
      "Loss in iteration 3568: 0.45044869773041296\n",
      "Theta: [-1.28917981  0.78932263  0.06572455]\n",
      "Loss in iteration 3569: 0.45043611026728514\n",
      "Theta: [-1.2893806   0.7894504   0.06572107]\n",
      "Loss in iteration 3570: 0.4504235288560032\n",
      "Theta: [-1.28958133  0.78957814  0.0657176 ]\n",
      "Loss in iteration 3571: 0.45041095349284\n",
      "Theta: [-1.28978201  0.78970586  0.06571413]\n",
      "Loss in iteration 3572: 0.4503983841740717\n",
      "Theta: [-1.28998264  0.78983354  0.06571065]\n",
      "Loss in iteration 3573: 0.4503858208959771\n",
      "Theta: [-1.29018322  0.7899612   0.06570718]\n",
      "Loss in iteration 3574: 0.4503732636548379\n",
      "Theta: [-1.29038375  0.79008883  0.06570371]\n",
      "Loss in iteration 3575: 0.4503607124469384\n",
      "Theta: [-1.29058423  0.79021644  0.06570024]\n",
      "Loss in iteration 3576: 0.45034816726856586\n",
      "Theta: [-1.29078466  0.79034401  0.06569676]\n",
      "Loss in iteration 3577: 0.4503356281160106\n",
      "Theta: [-1.29098504  0.79047156  0.06569329]\n",
      "Loss in iteration 3578: 0.45032309498556544\n",
      "Theta: [-1.29118537  0.79059909  0.06568982]\n",
      "Loss in iteration 3579: 0.4503105678735258\n",
      "Theta: [-1.29138565  0.79072658  0.06568635]\n",
      "Loss in iteration 3580: 0.4502980467761906\n",
      "Theta: [-1.29158588  0.79085405  0.06568288]\n",
      "Loss in iteration 3581: 0.45028553168986124\n",
      "Theta: [-1.29178606  0.79098149  0.06567941]\n",
      "Loss in iteration 3582: 0.4502730226108415\n",
      "Theta: [-1.29198619  0.7911089   0.06567594]\n",
      "Loss in iteration 3583: 0.4502605195354386\n",
      "Theta: [-1.29218627  0.79123628  0.06567247]\n",
      "Loss in iteration 3584: 0.45024802245996265\n",
      "Theta: [-1.2923863   0.79136364  0.065669  ]\n",
      "Loss in iteration 3585: 0.4502355313807254\n",
      "Theta: [-1.29258628  0.79149097  0.06566553]\n",
      "Loss in iteration 3586: 0.4502230462940428\n",
      "Theta: [-1.29278621  0.79161827  0.06566206]\n",
      "Loss in iteration 3587: 0.45021056719623304\n",
      "Theta: [-1.29298609  0.79174555  0.06565859]\n",
      "Loss in iteration 3588: 0.4501980940836169\n",
      "Theta: [-1.29318592  0.7918728   0.06565512]\n",
      "Loss in iteration 3589: 0.45018562695251807\n",
      "Theta: [-1.29338569  0.79200002  0.06565165]\n",
      "Loss in iteration 3590: 0.4501731657992633\n",
      "Theta: [-1.29358542  0.79212721  0.06564818]\n",
      "Loss in iteration 3591: 0.4501607106201819\n",
      "Theta: [-1.2937851   0.79225438  0.06564471]\n",
      "Loss in iteration 3592: 0.4501482614116059\n",
      "Theta: [-1.29398473  0.79238151  0.06564125]\n",
      "Loss in iteration 3593: 0.45013581816987014\n",
      "Theta: [-1.29418431  0.79250863  0.06563778]\n",
      "Loss in iteration 3594: 0.45012338089131243\n",
      "Theta: [-1.29438384  0.79263571  0.06563431]\n",
      "Loss in iteration 3595: 0.45011094957227304\n",
      "Theta: [-1.29458332  0.79276277  0.06563084]\n",
      "Loss in iteration 3596: 0.4500985242090954\n",
      "Theta: [-1.29478275  0.7928898   0.06562738]\n",
      "Loss in iteration 3597: 0.45008610479812533\n",
      "Theta: [-1.29498213  0.7930168   0.06562391]\n",
      "Loss in iteration 3598: 0.4500736913357118\n",
      "Theta: [-1.29518146  0.79314377  0.06562044]\n",
      "Loss in iteration 3599: 0.45006128381820604\n",
      "Theta: [-1.29538074  0.79327072  0.06561698]\n",
      "Loss in iteration 3600: 0.4500488822419627\n",
      "Theta: [-1.29557997  0.79339764  0.06561351]\n",
      "Loss in iteration 3601: 0.4500364866033384\n",
      "Theta: [-1.29577915  0.79352454  0.06561004]\n",
      "Loss in iteration 3602: 0.4500240968986934\n",
      "Theta: [-1.29597829  0.7936514   0.06560658]\n",
      "Loss in iteration 3603: 0.45001171312439003\n",
      "Theta: [-1.29617737  0.79377824  0.06560311]\n",
      "Loss in iteration 3604: 0.4499993352767936\n",
      "Theta: [-1.2963764   0.79390505  0.06559965]\n",
      "Loss in iteration 3605: 0.4499869633522722\n",
      "Theta: [-1.29657538  0.79403184  0.06559618]\n",
      "Loss in iteration 3606: 0.44997459734719664\n",
      "Theta: [-1.29677431  0.79415859  0.06559272]\n",
      "Loss in iteration 3607: 0.4499622372579406\n",
      "Theta: [-1.2969732   0.79428533  0.06558925]\n",
      "Loss in iteration 3608: 0.4499498830808804\n",
      "Theta: [-1.29717203  0.79441203  0.06558579]\n",
      "Loss in iteration 3609: 0.44993753481239496\n",
      "Theta: [-1.29737081  0.7945387   0.06558232]\n",
      "Loss in iteration 3610: 0.44992519244886614\n",
      "Theta: [-1.29756955  0.79466535  0.06557886]\n",
      "Loss in iteration 3611: 0.44991285598667835\n",
      "Theta: [-1.29776823  0.79479198  0.0655754 ]\n",
      "Loss in iteration 3612: 0.4499005254222191\n",
      "Theta: [-1.29796687  0.79491857  0.06557193]\n",
      "Loss in iteration 3613: 0.4498882007518784\n",
      "Theta: [-1.29816545  0.79504514  0.06556847]\n",
      "Loss in iteration 3614: 0.44987588197204853\n",
      "Theta: [-1.29836399  0.79517168  0.06556501]\n",
      "Loss in iteration 3615: 0.44986356907912545\n",
      "Theta: [-1.29856248  0.79529819  0.06556154]\n",
      "Loss in iteration 3616: 0.44985126206950704\n",
      "Theta: [-1.29876091  0.79542468  0.06555808]\n",
      "Loss in iteration 3617: 0.4498389609395943\n",
      "Theta: [-1.2989593   0.79555114  0.06555462]\n",
      "Loss in iteration 3618: 0.44982666568579077\n",
      "Theta: [-1.29915764  0.79567757  0.06555116]\n",
      "Loss in iteration 3619: 0.449814376304503\n",
      "Theta: [-1.29935593  0.79580398  0.0655477 ]\n",
      "Loss in iteration 3620: 0.4498020927921399\n",
      "Theta: [-1.29955417  0.79593035  0.06554423]\n",
      "Loss in iteration 3621: 0.4497898151451131\n",
      "Theta: [-1.29975236  0.79605671  0.06554077]\n",
      "Loss in iteration 3622: 0.44977754335983733\n",
      "Theta: [-1.2999505   0.79618303  0.06553731]\n",
      "Loss in iteration 3623: 0.4497652774327295\n",
      "Theta: [-1.30014859  0.79630933  0.06553385]\n",
      "Loss in iteration 3624: 0.4497530173602097\n",
      "Theta: [-1.30034663  0.7964356   0.06553039]\n",
      "Loss in iteration 3625: 0.4497407631387006\n",
      "Theta: [-1.30054463  0.79656184  0.06552693]\n",
      "Loss in iteration 3626: 0.44972851476462705\n",
      "Theta: [-1.30074257  0.79668806  0.06552347]\n",
      "Loss in iteration 3627: 0.4497162722344175\n",
      "Theta: [-1.30094047  0.79681425  0.06552001]\n",
      "Loss in iteration 3628: 0.44970403554450245\n",
      "Theta: [-1.30113831  0.79694041  0.06551655]\n",
      "Loss in iteration 3629: 0.4496918046913153\n",
      "Theta: [-1.30133611  0.79706654  0.06551309]\n",
      "Loss in iteration 3630: 0.449679579671292\n",
      "Theta: [-1.30153385  0.79719265  0.06550963]\n",
      "Loss in iteration 3631: 0.4496673604808714\n",
      "Theta: [-1.30173155  0.79731873  0.06550617]\n",
      "Loss in iteration 3632: 0.44965514711649507\n",
      "Theta: [-1.3019292   0.79744479  0.06550272]\n",
      "Loss in iteration 3633: 0.4496429395746069\n",
      "Theta: [-1.3021268   0.79757082  0.06549926]\n",
      "Loss in iteration 3634: 0.44963073785165375\n",
      "Theta: [-1.30232435  0.79769682  0.0654958 ]\n",
      "Loss in iteration 3635: 0.4496185419440852\n",
      "Theta: [-1.30252185  0.79782279  0.06549234]\n",
      "Loss in iteration 3636: 0.44960635184835335\n",
      "Theta: [-1.3027193   0.79794874  0.06548888]\n",
      "Loss in iteration 3637: 0.449594167560913\n",
      "Theta: [-1.30291671  0.79807466  0.06548543]\n",
      "Loss in iteration 3638: 0.4495819890782218\n",
      "Theta: [-1.30311406  0.79820055  0.06548197]\n",
      "Loss in iteration 3639: 0.44956981639673965\n",
      "Theta: [-1.30331136  0.79832642  0.06547851]\n",
      "Loss in iteration 3640: 0.44955764951292965\n",
      "Theta: [-1.30350862  0.79845226  0.06547505]\n",
      "Loss in iteration 3641: 0.4495454884232571\n",
      "Theta: [-1.30370583  0.79857807  0.0654716 ]\n",
      "Loss in iteration 3642: 0.44953333312419025\n",
      "Theta: [-1.30390299  0.79870386  0.06546814]\n",
      "Loss in iteration 3643: 0.4495211836122\n",
      "Theta: [-1.3041001   0.79882962  0.06546469]\n",
      "Loss in iteration 3644: 0.4495090398837599\n",
      "Theta: [-1.30429716  0.79895535  0.06546123]\n",
      "Loss in iteration 3645: 0.4494969019353457\n",
      "Theta: [-1.30449417  0.79908105  0.06545777]\n",
      "Loss in iteration 3646: 0.44948476976343654\n",
      "Theta: [-1.30469113  0.79920673  0.06545432]\n",
      "Loss in iteration 3647: 0.44947264336451376\n",
      "Theta: [-1.30488804  0.79933239  0.06545086]\n",
      "Loss in iteration 3648: 0.44946052273506154\n",
      "Theta: [-1.30508491  0.79945801  0.06544741]\n",
      "Loss in iteration 3649: 0.44944840787156637\n",
      "Theta: [-1.30528172  0.79958361  0.06544395]\n",
      "Loss in iteration 3650: 0.4494362987705179\n",
      "Theta: [-1.30547849  0.79970918  0.0654405 ]\n",
      "Loss in iteration 3651: 0.44942419542840795\n",
      "Theta: [-1.30567521  0.79983473  0.06543705]\n",
      "Loss in iteration 3652: 0.4494120978417312\n",
      "Theta: [-1.30587188  0.79996024  0.06543359]\n",
      "Loss in iteration 3653: 0.44940000600698504\n",
      "Theta: [-1.3060685   0.80008574  0.06543014]\n",
      "Loss in iteration 3654: 0.44938791992066945\n",
      "Theta: [-1.30626507  0.8002112   0.06542668]\n",
      "Loss in iteration 3655: 0.4493758395792866\n",
      "Theta: [-1.30646159  0.80033664  0.06542323]\n",
      "Loss in iteration 3656: 0.4493637649793422\n",
      "Theta: [-1.30665807  0.80046205  0.06541978]\n",
      "Loss in iteration 3657: 0.4493516961173436\n",
      "Theta: [-1.30685449  0.80058743  0.06541633]\n",
      "Loss in iteration 3658: 0.4493396329898015\n",
      "Theta: [-1.30705087  0.80071279  0.06541287]\n",
      "Loss in iteration 3659: 0.4493275755932289\n",
      "Theta: [-1.3072472   0.80083812  0.06540942]\n",
      "Loss in iteration 3660: 0.44931552392414154\n",
      "Theta: [-1.30744348  0.80096343  0.06540597]\n",
      "Loss in iteration 3661: 0.44930347797905745\n",
      "Theta: [-1.30763971  0.80108871  0.06540252]\n",
      "Loss in iteration 3662: 0.44929143775449804\n",
      "Theta: [-1.30783589  0.80121396  0.06539906]\n",
      "Loss in iteration 3663: 0.4492794032469864\n",
      "Theta: [-1.30803203  0.80133918  0.06539561]\n",
      "Loss in iteration 3664: 0.4492673744530486\n",
      "Theta: [-1.30822811  0.80146438  0.06539216]\n",
      "Loss in iteration 3665: 0.44925535136921363\n",
      "Theta: [-1.30842415  0.80158955  0.06538871]\n",
      "Loss in iteration 3666: 0.4492433339920129\n",
      "Theta: [-1.30862014  0.8017147   0.06538526]\n",
      "Loss in iteration 3667: 0.44923132231798013\n",
      "Theta: [-1.30881608  0.80183982  0.06538181]\n",
      "Loss in iteration 3668: 0.4492193163436521\n",
      "Theta: [-1.30901197  0.80196491  0.06537836]\n",
      "Loss in iteration 3669: 0.4492073160655677\n",
      "Theta: [-1.30920781  0.80208997  0.06537491]\n",
      "Loss in iteration 3670: 0.44919532148026875\n",
      "Theta: [-1.30940361  0.80221501  0.06537146]\n",
      "Loss in iteration 3671: 0.4491833325842998\n",
      "Theta: [-1.30959935  0.80234002  0.06536801]\n",
      "Loss in iteration 3672: 0.4491713493742075\n",
      "Theta: [-1.30979505  0.80246501  0.06536456]\n",
      "Loss in iteration 3673: 0.4491593718465415\n",
      "Theta: [-1.3099907   0.80258997  0.06536111]\n",
      "Loss in iteration 3674: 0.44914739999785397\n",
      "Theta: [-1.3101863   0.8027149   0.06535766]\n",
      "Loss in iteration 3675: 0.4491354338246994\n",
      "Theta: [-1.31038185  0.80283981  0.06535422]\n",
      "Loss in iteration 3676: 0.44912347332363534\n",
      "Theta: [-1.31057736  0.80296469  0.06535077]\n",
      "Loss in iteration 3677: 0.44911151849122133\n",
      "Theta: [-1.31077281  0.80308954  0.06534732]\n",
      "Loss in iteration 3678: 0.44909956932402006\n",
      "Theta: [-1.31096822  0.80321437  0.06534387]\n",
      "Loss in iteration 3679: 0.44908762581859646\n",
      "Theta: [-1.31116358  0.80333917  0.06534042]\n",
      "Loss in iteration 3680: 0.44907568797151803\n",
      "Theta: [-1.31135889  0.80346394  0.06533698]\n",
      "Loss in iteration 3681: 0.4490637557793551\n",
      "Theta: [-1.31155415  0.80358869  0.06533353]\n",
      "Loss in iteration 3682: 0.4490518292386802\n",
      "Theta: [-1.31174937  0.80371341  0.06533008]\n",
      "Loss in iteration 3683: 0.44903990834606866\n",
      "Theta: [-1.31194453  0.8038381   0.06532664]\n",
      "Loss in iteration 3684: 0.4490279930980985\n",
      "Theta: [-1.31213965  0.80396277  0.06532319]\n",
      "Loss in iteration 3685: 0.4490160834913498\n",
      "Theta: [-1.31233472  0.80408741  0.06531974]\n",
      "Loss in iteration 3686: 0.449004179522406\n",
      "Theta: [-1.31252974  0.80421202  0.0653163 ]\n",
      "Loss in iteration 3687: 0.44899228118785234\n",
      "Theta: [-1.31272472  0.80433661  0.06531285]\n",
      "Loss in iteration 3688: 0.44898038848427674\n",
      "Theta: [-1.31291964  0.80446117  0.06530941]\n",
      "Loss in iteration 3689: 0.44896850140827027\n",
      "Theta: [-1.31311452  0.80458571  0.06530596]\n",
      "Loss in iteration 3690: 0.44895661995642583\n",
      "Theta: [-1.31330935  0.80471022  0.06530252]\n",
      "Loss in iteration 3691: 0.44894474412533925\n",
      "Theta: [-1.31350413  0.8048347   0.06529907]\n",
      "Loss in iteration 3692: 0.44893287391160874\n",
      "Theta: [-1.31369886  0.80495916  0.06529563]\n",
      "Loss in iteration 3693: 0.4489210093118352\n",
      "Theta: [-1.31389355  0.80508359  0.06529218]\n",
      "Loss in iteration 3694: 0.4489091503226221\n",
      "Theta: [-1.31408819  0.80520799  0.06528874]\n",
      "Loss in iteration 3695: 0.44889729694057523\n",
      "Theta: [-1.31428277  0.80533237  0.06528529]\n",
      "Loss in iteration 3696: 0.44888544916230283\n",
      "Theta: [-1.31447732  0.80545672  0.06528185]\n",
      "Loss in iteration 3697: 0.4488736069844165\n",
      "Theta: [-1.31467181  0.80558104  0.06527841]\n",
      "Loss in iteration 3698: 0.44886177040352904\n",
      "Theta: [-1.31486625  0.80570534  0.06527496]\n",
      "Loss in iteration 3699: 0.44884993941625695\n",
      "Theta: [-1.31506065  0.80582962  0.06527152]\n",
      "Loss in iteration 3700: 0.44883811401921875\n",
      "Theta: [-1.315255    0.80595386  0.06526808]\n",
      "Loss in iteration 3701: 0.44882629420903525\n",
      "Theta: [-1.3154493   0.80607808  0.06526464]\n",
      "Loss in iteration 3702: 0.44881447998233037\n",
      "Theta: [-1.31564356  0.80620227  0.06526119]\n",
      "Loss in iteration 3703: 0.4488026713357304\n",
      "Theta: [-1.31583776  0.80632644  0.06525775]\n",
      "Loss in iteration 3704: 0.44879086826586345\n",
      "Theta: [-1.31603192  0.80645058  0.06525431]\n",
      "Loss in iteration 3705: 0.44877907076936124\n",
      "Theta: [-1.31622603  0.8065747   0.06525087]\n",
      "Loss in iteration 3706: 0.4487672788428573\n",
      "Theta: [-1.31642009  0.80669878  0.06524743]\n",
      "Loss in iteration 3707: 0.4487554924829877\n",
      "Theta: [-1.31661411  0.80682285  0.06524399]\n",
      "Loss in iteration 3708: 0.44874371168639127\n",
      "Theta: [-1.31680807  0.80694688  0.06524055]\n",
      "Loss in iteration 3709: 0.44873193644970927\n",
      "Theta: [-1.31700199  0.80707089  0.06523711]\n",
      "Loss in iteration 3710: 0.4487201667695856\n",
      "Theta: [-1.31719587  0.80719487  0.06523367]\n",
      "Loss in iteration 3711: 0.44870840264266626\n",
      "Theta: [-1.31738969  0.80731883  0.06523023]\n",
      "Loss in iteration 3712: 0.44869664406559984\n",
      "Theta: [-1.31758346  0.80744276  0.06522679]\n",
      "Loss in iteration 3713: 0.448684891035038\n",
      "Theta: [-1.31777719  0.80756667  0.06522335]\n",
      "Loss in iteration 3714: 0.4486731435476341\n",
      "Theta: [-1.31797087  0.80769055  0.06521991]\n",
      "Loss in iteration 3715: 0.44866140160004453\n",
      "Theta: [-1.31816451  0.8078144   0.06521647]\n",
      "Loss in iteration 3716: 0.44864966518892807\n",
      "Theta: [-1.31835809  0.80793822  0.06521303]\n",
      "Loss in iteration 3717: 0.44863793431094584\n",
      "Theta: [-1.31855163  0.80806202  0.06520959]\n",
      "Loss in iteration 3718: 0.4486262089627617\n",
      "Theta: [-1.31874512  0.8081858   0.06520615]\n",
      "Loss in iteration 3719: 0.4486144891410416\n",
      "Theta: [-1.31893856  0.80830955  0.06520271]\n",
      "Loss in iteration 3720: 0.44860277484245437\n",
      "Theta: [-1.31913196  0.80843327  0.06519928]\n",
      "Loss in iteration 3721: 0.4485910660636712\n",
      "Theta: [-1.31932531  0.80855696  0.06519584]\n",
      "Loss in iteration 3722: 0.4485793628013657\n",
      "Theta: [-1.31951861  0.80868063  0.0651924 ]\n",
      "Loss in iteration 3723: 0.448567665052214\n",
      "Theta: [-1.31971186  0.80880428  0.06518896]\n",
      "Loss in iteration 3724: 0.44855597281289455\n",
      "Theta: [-1.31990506  0.80892789  0.06518553]\n",
      "Loss in iteration 3725: 0.4485442860800884\n",
      "Theta: [-1.32009822  0.80905148  0.06518209]\n",
      "Loss in iteration 3726: 0.44853260485047936\n",
      "Theta: [-1.32029133  0.80917505  0.06517865]\n",
      "Loss in iteration 3727: 0.4485209291207532\n",
      "Theta: [-1.32048439  0.80929859  0.06517522]\n",
      "Loss in iteration 3728: 0.44850925888759846\n",
      "Theta: [-1.32067741  0.8094221   0.06517178]\n",
      "Loss in iteration 3729: 0.44849759414770607\n",
      "Theta: [-1.32087038  0.80954559  0.06516834]\n",
      "Loss in iteration 3730: 0.44848593489776933\n",
      "Theta: [-1.3210633   0.80966905  0.06516491]\n",
      "Loss in iteration 3731: 0.4484742811344842\n",
      "Theta: [-1.32125617  0.80979248  0.06516147]\n",
      "Loss in iteration 3732: 0.44846263285454896\n",
      "Theta: [-1.321449    0.80991589  0.06515804]\n",
      "Loss in iteration 3733: 0.4484509900546645\n",
      "Theta: [-1.32164178  0.81003928  0.0651546 ]\n",
      "Loss in iteration 3734: 0.4484393527315338\n",
      "Theta: [-1.32183451  0.81016263  0.06515117]\n",
      "Loss in iteration 3735: 0.4484277208818627\n",
      "Theta: [-1.32202719  0.81028596  0.06514773]\n",
      "Loss in iteration 3736: 0.4484160945023592\n",
      "Theta: [-1.32221983  0.81040927  0.0651443 ]\n",
      "Loss in iteration 3737: 0.4484044735897341\n",
      "Theta: [-1.32241242  0.81053255  0.06514087]\n",
      "Loss in iteration 3738: 0.44839285814070023\n",
      "Theta: [-1.32260496  0.8106558   0.06513743]\n",
      "Loss in iteration 3739: 0.4483812481519731\n",
      "Theta: [-1.32279746  0.81077903  0.065134  ]\n",
      "Loss in iteration 3740: 0.4483696436202705\n",
      "Theta: [-1.3229899   0.81090223  0.06513057]\n",
      "Loss in iteration 3741: 0.44835804454231293\n",
      "Theta: [-1.3231823   0.8110254   0.06512713]\n",
      "Loss in iteration 3742: 0.44834645091482295\n",
      "Theta: [-1.32337466  0.81114855  0.0651237 ]\n",
      "Loss in iteration 3743: 0.44833486273452605\n",
      "Theta: [-1.32356697  0.81127168  0.06512027]\n",
      "Loss in iteration 3744: 0.4483232799981498\n",
      "Theta: [-1.32375922  0.81139477  0.06511684]\n",
      "Loss in iteration 3745: 0.44831170270242393\n",
      "Theta: [-1.32395144  0.81151785  0.0651134 ]\n",
      "Loss in iteration 3746: 0.44830013084408143\n",
      "Theta: [-1.3241436   0.81164089  0.06510997]\n",
      "Loss in iteration 3747: 0.44828856441985687\n",
      "Theta: [-1.32433572  0.81176391  0.06510654]\n",
      "Loss in iteration 3748: 0.44827700342648774\n",
      "Theta: [-1.32452779  0.81188691  0.06510311]\n",
      "Loss in iteration 3749: 0.44826544786071376\n",
      "Theta: [-1.32471982  0.81200987  0.06509968]\n",
      "Loss in iteration 3750: 0.44825389771927704\n",
      "Theta: [-1.32491179  0.81213282  0.06509625]\n",
      "Loss in iteration 3751: 0.44824235299892246\n",
      "Theta: [-1.32510372  0.81225573  0.06509282]\n",
      "Loss in iteration 3752: 0.4482308136963967\n",
      "Theta: [-1.32529561  0.81237862  0.06508939]\n",
      "Loss in iteration 3753: 0.4482192798084494\n",
      "Theta: [-1.32548744  0.81250149  0.06508596]\n",
      "Loss in iteration 3754: 0.4482077513318323\n",
      "Theta: [-1.32567923  0.81262433  0.06508253]\n",
      "Loss in iteration 3755: 0.4481962282632997\n",
      "Theta: [-1.32587097  0.81274714  0.0650791 ]\n",
      "Loss in iteration 3756: 0.4481847105996084\n",
      "Theta: [-1.32606267  0.81286993  0.06507567]\n",
      "Loss in iteration 3757: 0.4481731983375171\n",
      "Theta: [-1.32625432  0.81299269  0.06507224]\n",
      "Loss in iteration 3758: 0.4481616914737874\n",
      "Theta: [-1.32644592  0.81311542  0.06506881]\n",
      "Loss in iteration 3759: 0.4481501900051834\n",
      "Theta: [-1.32663747  0.81323813  0.06506538]\n",
      "Loss in iteration 3760: 0.4481386939284711\n",
      "Theta: [-1.32682898  0.81336082  0.06506195]\n",
      "Loss in iteration 3761: 0.4481272032404193\n",
      "Theta: [-1.32702044  0.81348348  0.06505852]\n",
      "Loss in iteration 3762: 0.44811571793779903\n",
      "Theta: [-1.32721186  0.81360611  0.06505509]\n",
      "Loss in iteration 3763: 0.44810423801738364\n",
      "Theta: [-1.32740322  0.81372871  0.06505167]\n",
      "Loss in iteration 3764: 0.448092763475949\n",
      "Theta: [-1.32759454  0.8138513   0.06504824]\n",
      "Loss in iteration 3765: 0.4480812943102733\n",
      "Theta: [-1.32778582  0.81397385  0.06504481]\n",
      "Loss in iteration 3766: 0.44806983051713734\n",
      "Theta: [-1.32797705  0.81409638  0.06504138]\n",
      "Loss in iteration 3767: 0.44805837209332383\n",
      "Theta: [-1.32816823  0.81421888  0.06503796]\n",
      "Loss in iteration 3768: 0.4480469190356182\n",
      "Theta: [-1.32835936  0.81434136  0.06503453]\n",
      "Loss in iteration 3769: 0.44803547134080846\n",
      "Theta: [-1.32855045  0.81446382  0.0650311 ]\n",
      "Loss in iteration 3770: 0.4480240290056845\n",
      "Theta: [-1.32874149  0.81458624  0.06502768]\n",
      "Loss in iteration 3771: 0.4480125920270388\n",
      "Theta: [-1.32893248  0.81470864  0.06502425]\n",
      "Loss in iteration 3772: 0.4480011604016662\n",
      "Theta: [-1.32912343  0.81483102  0.06502083]\n",
      "Loss in iteration 3773: 0.4479897341263642\n",
      "Theta: [-1.32931433  0.81495337  0.0650174 ]\n",
      "Loss in iteration 3774: 0.44797831319793213\n",
      "Theta: [-1.32950518  0.81507569  0.06501398]\n",
      "Loss in iteration 3775: 0.44796689761317215\n",
      "Theta: [-1.32969599  0.81519799  0.06501055]\n",
      "Loss in iteration 3776: 0.44795548736888846\n",
      "Theta: [-1.32988675  0.81532026  0.06500713]\n",
      "Loss in iteration 3777: 0.44794408246188794\n",
      "Theta: [-1.33007747  0.81544251  0.0650037 ]\n",
      "Loss in iteration 3778: 0.44793268288897964\n",
      "Theta: [-1.33026813  0.81556473  0.06500028]\n",
      "Loss in iteration 3779: 0.44792128864697467\n",
      "Theta: [-1.33045876  0.81568693  0.06499685]\n",
      "Loss in iteration 3780: 0.44790989973268713\n",
      "Theta: [-1.33064933  0.8158091   0.06499343]\n",
      "Loss in iteration 3781: 0.447898516142933\n",
      "Theta: [-1.33083986  0.81593124  0.06499001]\n",
      "Loss in iteration 3782: 0.4478871378745312\n",
      "Theta: [-1.33103034  0.81605336  0.06498658]\n",
      "Loss in iteration 3783: 0.44787576492430176\n",
      "Theta: [-1.33122078  0.81617546  0.06498316]\n",
      "Loss in iteration 3784: 0.44786439728906857\n",
      "Theta: [-1.33141116  0.81629753  0.06497974]\n",
      "Loss in iteration 3785: 0.44785303496565687\n",
      "Theta: [-1.33160151  0.81641957  0.06497631]\n",
      "Loss in iteration 3786: 0.44784167795089447\n",
      "Theta: [-1.3317918   0.81654159  0.06497289]\n",
      "Loss in iteration 3787: 0.4478303262416118\n",
      "Theta: [-1.33198205  0.81666358  0.06496947]\n",
      "Loss in iteration 3788: 0.4478189798346412\n",
      "Theta: [-1.33217226  0.81678554  0.06496605]\n",
      "Loss in iteration 3789: 0.44780763872681767\n",
      "Theta: [-1.33236241  0.81690748  0.06496263]\n",
      "Loss in iteration 3790: 0.4477963029149785\n",
      "Theta: [-1.33255253  0.8170294   0.0649592 ]\n",
      "Loss in iteration 3791: 0.4477849723959632\n",
      "Theta: [-1.33274259  0.81715129  0.06495578]\n",
      "Loss in iteration 3792: 0.4477736471666137\n",
      "Theta: [-1.33293261  0.81727315  0.06495236]\n",
      "Loss in iteration 3793: 0.4477623272237741\n",
      "Theta: [-1.33312258  0.81739499  0.06494894]\n",
      "Loss in iteration 3794: 0.4477510125642911\n",
      "Theta: [-1.33331251  0.8175168   0.06494552]\n",
      "Loss in iteration 3795: 0.4477397031850135\n",
      "Theta: [-1.33350239  0.81763859  0.0649421 ]\n",
      "Loss in iteration 3796: 0.4477283990827926\n",
      "Theta: [-1.33369222  0.81776035  0.06493868]\n",
      "Loss in iteration 3797: 0.44771710025448164\n",
      "Theta: [-1.33388201  0.81788209  0.06493526]\n",
      "Loss in iteration 3798: 0.4477058066969369\n",
      "Theta: [-1.33407175  0.8180038   0.06493184]\n",
      "Loss in iteration 3799: 0.44769451840701613\n",
      "Theta: [-1.33426144  0.81812549  0.06492842]\n",
      "Loss in iteration 3800: 0.44768323538158\n",
      "Theta: [-1.33445109  0.81824715  0.064925  ]\n",
      "Loss in iteration 3801: 0.44767195761749135\n",
      "Theta: [-1.33464069  0.81836878  0.06492158]\n",
      "Loss in iteration 3802: 0.4476606851116152\n",
      "Theta: [-1.33483025  0.81849039  0.06491817]\n",
      "Loss in iteration 3803: 0.4476494178608191\n",
      "Theta: [-1.33501976  0.81861198  0.06491475]\n",
      "Loss in iteration 3804: 0.4476381558619725\n",
      "Theta: [-1.33520922  0.81873353  0.06491133]\n",
      "Loss in iteration 3805: 0.44762689911194753\n",
      "Theta: [-1.33539864  0.81885507  0.06490791]\n",
      "Loss in iteration 3806: 0.4476156476076186\n",
      "Theta: [-1.33558801  0.81897658  0.06490449]\n",
      "Loss in iteration 3807: 0.4476044013458623\n",
      "Theta: [-1.33577734  0.81909806  0.06490108]\n",
      "Loss in iteration 3808: 0.4475931603235576\n",
      "Theta: [-1.33596662  0.81921952  0.06489766]\n",
      "Loss in iteration 3809: 0.44758192453758566\n",
      "Theta: [-1.33615585  0.81934095  0.06489424]\n",
      "Loss in iteration 3810: 0.4475706939848301\n",
      "Theta: [-1.33634504  0.81946235  0.06489082]\n",
      "Loss in iteration 3811: 0.4475594686621765\n",
      "Theta: [-1.33653418  0.81958373  0.06488741]\n",
      "Loss in iteration 3812: 0.4475482485665131\n",
      "Theta: [-1.33672328  0.81970509  0.06488399]\n",
      "Loss in iteration 3813: 0.4475370336947305\n",
      "Theta: [-1.33691233  0.81982642  0.06488058]\n",
      "Loss in iteration 3814: 0.44752582404372104\n",
      "Theta: [-1.33710134  0.81994773  0.06487716]\n",
      "Loss in iteration 3815: 0.44751461961037975\n",
      "Theta: [-1.33729029  0.82006901  0.06487374]\n",
      "Loss in iteration 3816: 0.44750342039160407\n",
      "Theta: [-1.33747921  0.82019026  0.06487033]\n",
      "Loss in iteration 3817: 0.44749222638429337\n",
      "Theta: [-1.33766807  0.82031149  0.06486691]\n",
      "Loss in iteration 3818: 0.4474810375853496\n",
      "Theta: [-1.33785689  0.82043269  0.0648635 ]\n",
      "Loss in iteration 3819: 0.4474698539916766\n",
      "Theta: [-1.33804567  0.82055387  0.06486008]\n",
      "Loss in iteration 3820: 0.4474586756001811\n",
      "Theta: [-1.3382344   0.82067503  0.06485667]\n",
      "Loss in iteration 3821: 0.44744750240777154\n",
      "Theta: [-1.33842308  0.82079616  0.06485326]\n",
      "Loss in iteration 3822: 0.44743633441135855\n",
      "Theta: [-1.33861172  0.82091726  0.06484984]\n",
      "Loss in iteration 3823: 0.44742517160785594\n",
      "Theta: [-1.33880031  0.82103834  0.06484643]\n",
      "Loss in iteration 3824: 0.44741401399417846\n",
      "Theta: [-1.33898886  0.82115939  0.06484301]\n",
      "Loss in iteration 3825: 0.44740286156724424\n",
      "Theta: [-1.33917736  0.82128042  0.0648396 ]\n",
      "Loss in iteration 3826: 0.4473917143239732\n",
      "Theta: [-1.33936581  0.82140142  0.06483619]\n",
      "Loss in iteration 3827: 0.44738057226128747\n",
      "Theta: [-1.33955422  0.8215224   0.06483278]\n",
      "Loss in iteration 3828: 0.4473694353761117\n",
      "Theta: [-1.33974259  0.82164335  0.06482936]\n",
      "Loss in iteration 3829: 0.4473583036653725\n",
      "Theta: [-1.33993091  0.82176427  0.06482595]\n",
      "Loss in iteration 3830: 0.447347177125999\n",
      "Theta: [-1.34011918  0.82188517  0.06482254]\n",
      "Loss in iteration 3831: 0.4473360557549222\n",
      "Theta: [-1.3403074   0.82200605  0.06481913]\n",
      "Loss in iteration 3832: 0.4473249395490759\n",
      "Theta: [-1.34049559  0.8221269   0.06481572]\n",
      "Loss in iteration 3833: 0.44731382850539575\n",
      "Theta: [-1.34068372  0.82224773  0.0648123 ]\n",
      "Loss in iteration 3834: 0.4473027226208198\n",
      "Theta: [-1.34087181  0.82236853  0.06480889]\n",
      "Loss in iteration 3835: 0.4472916218922883\n",
      "Theta: [-1.34105985  0.8224893   0.06480548]\n",
      "Loss in iteration 3836: 0.44728052631674364\n",
      "Theta: [-1.34124785  0.82261006  0.06480207]\n",
      "Loss in iteration 3837: 0.4472694358911307\n",
      "Theta: [-1.34143581  0.82273078  0.06479866]\n",
      "Loss in iteration 3838: 0.44725835061239644\n",
      "Theta: [-1.34162371  0.82285148  0.06479525]\n",
      "Loss in iteration 3839: 0.4472472704774901\n",
      "Theta: [-1.34181158  0.82297216  0.06479184]\n",
      "Loss in iteration 3840: 0.44723619548336285\n",
      "Theta: [-1.34199939  0.82309281  0.06478843]\n",
      "Loss in iteration 3841: 0.44722512562696876\n",
      "Theta: [-1.34218717  0.82321343  0.06478502]\n",
      "Loss in iteration 3842: 0.4472140609052637\n",
      "Theta: [-1.34237489  0.82333403  0.06478161]\n",
      "Loss in iteration 3843: 0.4472030013152056\n",
      "Theta: [-1.34256257  0.82345461  0.0647782 ]\n",
      "Loss in iteration 3844: 0.4471919468537551\n",
      "Theta: [-1.34275021  0.82357516  0.06477479]\n",
      "Loss in iteration 3845: 0.4471808975178746\n",
      "Theta: [-1.3429378   0.82369568  0.06477139]\n",
      "Loss in iteration 3846: 0.44716985330452885\n",
      "Theta: [-1.34312534  0.82381618  0.06476798]\n",
      "Loss in iteration 3847: 0.44715881421068526\n",
      "Theta: [-1.34331284  0.82393666  0.06476457]\n",
      "Loss in iteration 3848: 0.4471477802333129\n",
      "Theta: [-1.34350029  0.82405711  0.06476116]\n",
      "Loss in iteration 3849: 0.44713675136938313\n",
      "Theta: [-1.3436877   0.82417753  0.06475775]\n",
      "Loss in iteration 3850: 0.44712572761587\n",
      "Theta: [-1.34387507  0.82429793  0.06475435]\n",
      "Loss in iteration 3851: 0.4471147089697489\n",
      "Theta: [-1.34406238  0.8244183   0.06475094]\n",
      "Loss in iteration 3852: 0.44710369542799866\n",
      "Theta: [-1.34424966  0.82453865  0.06474753]\n",
      "Loss in iteration 3853: 0.4470926869875991\n",
      "Theta: [-1.34443688  0.82465898  0.06474413]\n",
      "Loss in iteration 3854: 0.44708168364553286\n",
      "Theta: [-1.34462407  0.82477928  0.06474072]\n",
      "Loss in iteration 3855: 0.4470706853987849\n",
      "Theta: [-1.3448112   0.82489955  0.06473731]\n",
      "Loss in iteration 3856: 0.44705969224434206\n",
      "Theta: [-1.34499829  0.8250198   0.06473391]\n",
      "Loss in iteration 3857: 0.4470487041791937\n",
      "Theta: [-1.34518534  0.82514003  0.0647305 ]\n",
      "Loss in iteration 3858: 0.4470377212003308\n",
      "Theta: [-1.34537234  0.82526023  0.0647271 ]\n",
      "Loss in iteration 3859: 0.4470267433047471\n",
      "Theta: [-1.3455593   0.8253804   0.06472369]\n",
      "Loss in iteration 3860: 0.44701577048943864\n",
      "Theta: [-1.34574621  0.82550055  0.06472029]\n",
      "Loss in iteration 3861: 0.44700480275140303\n",
      "Theta: [-1.34593308  0.82562068  0.06471688]\n",
      "Loss in iteration 3862: 0.44699384008764054\n",
      "Theta: [-1.3461199   0.82574078  0.06471348]\n",
      "Loss in iteration 3863: 0.4469828824951537\n",
      "Theta: [-1.34630667  0.82586085  0.06471007]\n",
      "Loss in iteration 3864: 0.4469719299709468\n",
      "Theta: [-1.3464934   0.8259809   0.06470667]\n",
      "Loss in iteration 3865: 0.4469609825120267\n",
      "Theta: [-1.34668009  0.82610093  0.06470327]\n",
      "Loss in iteration 3866: 0.4469500401154023\n",
      "Theta: [-1.34686673  0.82622093  0.06469986]\n",
      "Loss in iteration 3867: 0.44693910277808463\n",
      "Theta: [-1.34705333  0.82634091  0.06469646]\n",
      "Loss in iteration 3868: 0.4469281704970872\n",
      "Theta: [-1.34723988  0.82646086  0.06469306]\n",
      "Loss in iteration 3869: 0.4469172432694251\n",
      "Theta: [-1.34742638  0.82658078  0.06468965]\n",
      "Loss in iteration 3870: 0.44690632109211637\n",
      "Theta: [-1.34761284  0.82670068  0.06468625]\n",
      "Loss in iteration 3871: 0.4468954039621806\n",
      "Theta: [-1.34779926  0.82682056  0.06468285]\n",
      "Loss in iteration 3872: 0.44688449187663953\n",
      "Theta: [-1.34798563  0.82694041  0.06467945]\n",
      "Loss in iteration 3873: 0.44687358483251804\n",
      "Theta: [-1.34817195  0.82706024  0.06467604]\n",
      "Loss in iteration 3874: 0.4468626828268419\n",
      "Theta: [-1.34835824  0.82718004  0.06467264]\n",
      "Loss in iteration 3875: 0.44685178585663976\n",
      "Theta: [-1.34854447  0.82729982  0.06466924]\n",
      "Loss in iteration 3876: 0.44684089391894216\n",
      "Theta: [-1.34873066  0.82741957  0.06466584]\n",
      "Loss in iteration 3877: 0.44683000701078224\n",
      "Theta: [-1.34891681  0.8275393   0.06466244]\n",
      "Loss in iteration 3878: 0.4468191251291948\n",
      "Theta: [-1.34910291  0.827659    0.06465904]\n",
      "Loss in iteration 3879: 0.44680824827121696\n",
      "Theta: [-1.34928897  0.82777868  0.06465564]\n",
      "Loss in iteration 3880: 0.44679737643388834\n",
      "Theta: [-1.34947498  0.82789833  0.06465224]\n",
      "Loss in iteration 3881: 0.4467865096142499\n",
      "Theta: [-1.34966095  0.82801796  0.06464884]\n",
      "Loss in iteration 3882: 0.44677564780934576\n",
      "Theta: [-1.34984687  0.82813756  0.06464544]\n",
      "Loss in iteration 3883: 0.4467647910162215\n",
      "Theta: [-1.35003275  0.82825714  0.06464204]\n",
      "Loss in iteration 3884: 0.44675393923192525\n",
      "Theta: [-1.35021858  0.8283767   0.06463864]\n",
      "Loss in iteration 3885: 0.4467430924535067\n",
      "Theta: [-1.35040437  0.82849623  0.06463524]\n",
      "Loss in iteration 3886: 0.44673225067801836\n",
      "Theta: [-1.35059011  0.82861573  0.06463184]\n",
      "Loss in iteration 3887: 0.44672141390251485\n",
      "Theta: [-1.35077581  0.82873521  0.06462844]\n",
      "Loss in iteration 3888: 0.44671058212405224\n",
      "Theta: [-1.35096146  0.82885467  0.06462504]\n",
      "Loss in iteration 3889: 0.4466997553396896\n",
      "Theta: [-1.35114707  0.8289741   0.06462164]\n",
      "Loss in iteration 3890: 0.4466889335464874\n",
      "Theta: [-1.35133264  0.8290935   0.06461825]\n",
      "Loss in iteration 3891: 0.4466781167415089\n",
      "Theta: [-1.35151816  0.82921288  0.06461485]\n",
      "Loss in iteration 3892: 0.446667304921819\n",
      "Theta: [-1.35170364  0.82933224  0.06461145]\n",
      "Loss in iteration 3893: 0.4466564980844852\n",
      "Theta: [-1.35188907  0.82945157  0.06460805]\n",
      "Loss in iteration 3894: 0.44664569622657646\n",
      "Theta: [-1.35207445  0.82957088  0.06460466]\n",
      "Loss in iteration 3895: 0.44663489934516465\n",
      "Theta: [-1.35225979  0.82969016  0.06460126]\n",
      "Loss in iteration 3896: 0.4466241074373231\n",
      "Theta: [-1.35244509  0.82980942  0.06459786]\n",
      "Loss in iteration 3897: 0.44661332050012775\n",
      "Theta: [-1.35263035  0.82992866  0.06459447]\n",
      "Loss in iteration 3898: 0.44660253853065646\n",
      "Theta: [-1.35281555  0.83004786  0.06459107]\n",
      "Loss in iteration 3899: 0.4465917615259892\n",
      "Theta: [-1.35300072  0.83016705  0.06458768]\n",
      "Loss in iteration 3900: 0.446580989483208\n",
      "Theta: [-1.35318584  0.83028621  0.06458428]\n",
      "Loss in iteration 3901: 0.4465702223993975\n",
      "Theta: [-1.35337091  0.83040534  0.06458089]\n",
      "Loss in iteration 3902: 0.4465594602716436\n",
      "Theta: [-1.35355594  0.83052445  0.06457749]\n",
      "Loss in iteration 3903: 0.446548703097035\n",
      "Theta: [-1.35374093  0.83064354  0.0645741 ]\n",
      "Loss in iteration 3904: 0.4465379508726621\n",
      "Theta: [-1.35392587  0.8307626   0.0645707 ]\n",
      "Loss in iteration 3905: 0.4465272035956181\n",
      "Theta: [-1.35411077  0.83088164  0.06456731]\n",
      "Loss in iteration 3906: 0.4465164612629974\n",
      "Theta: [-1.35429562  0.83100065  0.06456391]\n",
      "Loss in iteration 3907: 0.446505723871897\n",
      "Theta: [-1.35448043  0.83111964  0.06456052]\n",
      "Loss in iteration 3908: 0.4464949914194162\n",
      "Theta: [-1.35466519  0.8312386   0.06455713]\n",
      "Loss in iteration 3909: 0.4464842639026558\n",
      "Theta: [-1.35484991  0.83135754  0.06455373]\n",
      "Loss in iteration 3910: 0.4464735413187192\n",
      "Theta: [-1.35503459  0.83147645  0.06455034]\n",
      "Loss in iteration 3911: 0.44646282366471185\n",
      "Theta: [-1.35521922  0.83159534  0.06454695]\n",
      "Loss in iteration 3912: 0.44645211093774106\n",
      "Theta: [-1.35540381  0.83171421  0.06454355]\n",
      "Loss in iteration 3913: 0.44644140313491654\n",
      "Theta: [-1.35558835  0.83183305  0.06454016]\n",
      "Loss in iteration 3914: 0.4464307002533497\n",
      "Theta: [-1.35577285  0.83195187  0.06453677]\n",
      "Loss in iteration 3915: 0.4464200022901547\n",
      "Theta: [-1.3559573   0.83207066  0.06453338]\n",
      "Loss in iteration 3916: 0.44640930924244704\n",
      "Theta: [-1.35614171  0.83218942  0.06452998]\n",
      "Loss in iteration 3917: 0.44639862110734485\n",
      "Theta: [-1.35632608  0.83230817  0.06452659]\n",
      "Loss in iteration 3918: 0.44638793788196796\n",
      "Theta: [-1.3565104   0.83242689  0.0645232 ]\n",
      "Loss in iteration 3919: 0.44637725956343866\n",
      "Theta: [-1.35669468  0.83254558  0.06451981]\n",
      "Loss in iteration 3920: 0.446366586148881\n",
      "Theta: [-1.35687891  0.83266425  0.06451642]\n",
      "Loss in iteration 3921: 0.4463559176354214\n",
      "Theta: [-1.3570631   0.83278289  0.06451303]\n",
      "Loss in iteration 3922: 0.4463452540201883\n",
      "Theta: [-1.35724725  0.83290151  0.06450964]\n",
      "Loss in iteration 3923: 0.44633459530031205\n",
      "Theta: [-1.35743135  0.83302011  0.06450625]\n",
      "Loss in iteration 3924: 0.4463239414729249\n",
      "Theta: [-1.35761541  0.83313868  0.06450286]\n",
      "Loss in iteration 3925: 0.44631329253516205\n",
      "Theta: [-1.35779942  0.83325723  0.06449947]\n",
      "Loss in iteration 3926: 0.4463026484841597\n",
      "Theta: [-1.35798339  0.83337575  0.06449608]\n",
      "Loss in iteration 3927: 0.44629200931705687\n",
      "Theta: [-1.35816731  0.83349425  0.06449269]\n",
      "Loss in iteration 3928: 0.4462813750309942\n",
      "Theta: [-1.35835119  0.83361272  0.0644893 ]\n",
      "Loss in iteration 3929: 0.44627074562311464\n",
      "Theta: [-1.35853503  0.83373117  0.06448591]\n",
      "Loss in iteration 3930: 0.44626012109056323\n",
      "Theta: [-1.35871882  0.8338496   0.06448252]\n",
      "Loss in iteration 3931: 0.4462495014304871\n",
      "Theta: [-1.35890257  0.833968    0.06447914]\n",
      "Loss in iteration 3932: 0.4462388866400351\n",
      "Theta: [-1.35908628  0.83408638  0.06447575]\n",
      "Loss in iteration 3933: 0.44622827671635845\n",
      "Theta: [-1.35926994  0.83420473  0.06447236]\n",
      "Loss in iteration 3934: 0.4462176716566105\n",
      "Theta: [-1.35945355  0.83432306  0.06446897]\n",
      "Loss in iteration 3935: 0.4462070714579465\n",
      "Theta: [-1.35963713  0.83444136  0.06446559]\n",
      "Loss in iteration 3936: 0.44619647611752383\n",
      "Theta: [-1.35982066  0.83455964  0.0644622 ]\n",
      "Loss in iteration 3937: 0.4461858856325017\n",
      "Theta: [-1.36000414  0.8346779   0.06445881]\n",
      "Loss in iteration 3938: 0.44617530000004185\n",
      "Theta: [-1.36018758  0.83479613  0.06445543]\n",
      "Loss in iteration 3939: 0.4461647192173075\n",
      "Theta: [-1.36037098  0.83491433  0.06445204]\n",
      "Loss in iteration 3940: 0.44615414328146435\n",
      "Theta: [-1.36055434  0.83503251  0.06444865]\n",
      "Loss in iteration 3941: 0.44614357218968\n",
      "Theta: [-1.36073765  0.83515067  0.06444527]\n",
      "Loss in iteration 3942: 0.4461330059391241\n",
      "Theta: [-1.36092091  0.83526881  0.06444188]\n",
      "Loss in iteration 3943: 0.44612244452696825\n",
      "Theta: [-1.36110413  0.83538692  0.0644385 ]\n",
      "Loss in iteration 3944: 0.4461118879503866\n",
      "Theta: [-1.36128731  0.835505    0.06443511]\n",
      "Loss in iteration 3945: 0.4461013362065544\n",
      "Theta: [-1.36147045  0.83562306  0.06443173]\n",
      "Loss in iteration 3946: 0.4460907892926496\n",
      "Theta: [-1.36165354  0.8357411   0.06442834]\n",
      "Loss in iteration 3947: 0.4460802472058522\n",
      "Theta: [-1.36183659  0.83585911  0.06442496]\n",
      "Loss in iteration 3948: 0.4460697099433441\n",
      "Theta: [-1.36201959  0.8359771   0.06442157]\n",
      "Loss in iteration 3949: 0.4460591775023093\n",
      "Theta: [-1.36220255  0.83609506  0.06441819]\n",
      "Loss in iteration 3950: 0.44604864987993353\n",
      "Theta: [-1.36238547  0.836213    0.06441481]\n",
      "Loss in iteration 3951: 0.44603812707340496\n",
      "Theta: [-1.36256834  0.83633092  0.06441142]\n",
      "Loss in iteration 3952: 0.4460276090799135\n",
      "Theta: [-1.36275117  0.83644881  0.06440804]\n",
      "Loss in iteration 3953: 0.4460170958966514\n",
      "Theta: [-1.36293396  0.83656668  0.06440466]\n",
      "Loss in iteration 3954: 0.44600658752081257\n",
      "Theta: [-1.3631167   0.83668452  0.06440127]\n",
      "Loss in iteration 3955: 0.44599608394959345\n",
      "Theta: [-1.3632994   0.83680234  0.06439789]\n",
      "Loss in iteration 3956: 0.44598558518019166\n",
      "Theta: [-1.36348205  0.83692013  0.06439451]\n",
      "Loss in iteration 3957: 0.44597509120980755\n",
      "Theta: [-1.36366466  0.8370379   0.06439113]\n",
      "Loss in iteration 3958: 0.4459646020356434\n",
      "Theta: [-1.36384723  0.83715565  0.06438774]\n",
      "Loss in iteration 3959: 0.4459541176549034\n",
      "Theta: [-1.36402976  0.83727337  0.06438436]\n",
      "Loss in iteration 3960: 0.44594363806479365\n",
      "Theta: [-1.36421224  0.83739107  0.06438098]\n",
      "Loss in iteration 3961: 0.4459331632625225\n",
      "Theta: [-1.36439467  0.83750875  0.0643776 ]\n",
      "Loss in iteration 3962: 0.44592269324530015\n",
      "Theta: [-1.36457707  0.8376264   0.06437422]\n",
      "Loss in iteration 3963: 0.4459122280103386\n",
      "Theta: [-1.36475942  0.83774402  0.06437084]\n",
      "Loss in iteration 3964: 0.4459017675548524\n",
      "Theta: [-1.36494172  0.83786162  0.06436746]\n",
      "Loss in iteration 3965: 0.44589131187605774\n",
      "Theta: [-1.36512399  0.8379792   0.06436408]\n",
      "Loss in iteration 3966: 0.4458808609711729\n",
      "Theta: [-1.36530621  0.83809675  0.0643607 ]\n",
      "Loss in iteration 3967: 0.44587041483741807\n",
      "Theta: [-1.36548838  0.83821428  0.06435732]\n",
      "Loss in iteration 3968: 0.44585997347201556\n",
      "Theta: [-1.36567052  0.83833179  0.06435394]\n",
      "Loss in iteration 3969: 0.44584953687218964\n",
      "Theta: [-1.36585261  0.83844927  0.06435056]\n",
      "Loss in iteration 3970: 0.4458391050351667\n",
      "Theta: [-1.36603465  0.83856673  0.06434718]\n",
      "Loss in iteration 3971: 0.44582867795817477\n",
      "Theta: [-1.36621666  0.83868416  0.0643438 ]\n",
      "Loss in iteration 3972: 0.4458182556384442\n",
      "Theta: [-1.36639862  0.83880157  0.06434042]\n",
      "Loss in iteration 3973: 0.44580783807320734\n",
      "Theta: [-1.36658053  0.83891896  0.06433705]\n",
      "Loss in iteration 3974: 0.44579742525969857\n",
      "Theta: [-1.36676241  0.83903632  0.06433367]\n",
      "Loss in iteration 3975: 0.4457870171951537\n",
      "Theta: [-1.36694424  0.83915366  0.06433029]\n",
      "Loss in iteration 3976: 0.44577661387681133\n",
      "Theta: [-1.36712602  0.83927097  0.06432691]\n",
      "Loss in iteration 3977: 0.44576621530191163\n",
      "Theta: [-1.36730777  0.83938826  0.06432353]\n",
      "Loss in iteration 3978: 0.4457558214676966\n",
      "Theta: [-1.36748947  0.83950552  0.06432016]\n",
      "Loss in iteration 3979: 0.44574543237141057\n",
      "Theta: [-1.36767113  0.83962276  0.06431678]\n",
      "Loss in iteration 3980: 0.4457350480102998\n",
      "Theta: [-1.36785274  0.83973998  0.0643134 ]\n",
      "Loss in iteration 3981: 0.4457246683816122\n",
      "Theta: [-1.36803431  0.83985717  0.06431003]\n",
      "Loss in iteration 3982: 0.44571429348259806\n",
      "Theta: [-1.36821584  0.83997434  0.06430665]\n",
      "Loss in iteration 3983: 0.44570392331050945\n",
      "Theta: [-1.36839732  0.84009149  0.06430328]\n",
      "Loss in iteration 3984: 0.4456935578626004\n",
      "Theta: [-1.36857876  0.84020861  0.0642999 ]\n",
      "Loss in iteration 3985: 0.44568319713612703\n",
      "Theta: [-1.36876016  0.84032571  0.06429653]\n",
      "Loss in iteration 3986: 0.4456728411283473\n",
      "Theta: [-1.36894152  0.84044278  0.06429315]\n",
      "Loss in iteration 3987: 0.4456624898365212\n",
      "Theta: [-1.36912283  0.84055983  0.06428977]\n",
      "Loss in iteration 3988: 0.4456521432579108\n",
      "Theta: [-1.3693041   0.84067686  0.0642864 ]\n",
      "Loss in iteration 3989: 0.4456418013897798\n",
      "Theta: [-1.36948533  0.84079386  0.06428303]\n",
      "Loss in iteration 3990: 0.44563146422939426\n",
      "Theta: [-1.36966651  0.84091084  0.06427965]\n",
      "Loss in iteration 3991: 0.44562113177402213\n",
      "Theta: [-1.36984765  0.84102779  0.06427628]\n",
      "Loss in iteration 3992: 0.44561080402093317\n",
      "Theta: [-1.37002874  0.84114472  0.0642729 ]\n",
      "Loss in iteration 3993: 0.44560048096739885\n",
      "Theta: [-1.3702098   0.84126163  0.06426953]\n",
      "Loss in iteration 3994: 0.4455901626106933\n",
      "Theta: [-1.37039081  0.84137851  0.06426616]\n",
      "Loss in iteration 3995: 0.4455798489480919\n",
      "Theta: [-1.37057178  0.84149537  0.06426278]\n",
      "Loss in iteration 3996: 0.44556953997687254\n",
      "Theta: [-1.3707527   0.84161221  0.06425941]\n",
      "Loss in iteration 3997: 0.4455592356943147\n",
      "Theta: [-1.37093359  0.84172902  0.06425604]\n",
      "Loss in iteration 3998: 0.44554893609770013\n",
      "Theta: [-1.37111442  0.8418458   0.06425267]\n",
      "Loss in iteration 3999: 0.4455386411843119\n",
      "Theta: [-1.37129522  0.84196257  0.06424929]\n",
      "Loss in iteration 4000: 0.44552835095143584\n",
      "Theta: [-1.37147597  0.84207931  0.06424592]\n",
      "Loss in iteration 4001: 0.4455180653963592\n",
      "Theta: [-1.37165668  0.84219602  0.06424255]\n",
      "Loss in iteration 4002: 0.44550778451637135\n",
      "Theta: [-1.37183735  0.84231271  0.06423918]\n",
      "Loss in iteration 4003: 0.4454975083087634\n",
      "Theta: [-1.37201798  0.84242938  0.06423581]\n",
      "Loss in iteration 4004: 0.445487236770829\n",
      "Theta: [-1.37219856  0.84254603  0.06423244]\n",
      "Loss in iteration 4005: 0.44547696989986285\n",
      "Theta: [-1.3723791   0.84266265  0.06422907]\n",
      "Loss in iteration 4006: 0.44546670769316227\n",
      "Theta: [-1.3725596   0.84277924  0.0642257 ]\n",
      "Loss in iteration 4007: 0.44545645014802643\n",
      "Theta: [-1.37274005  0.84289582  0.06422233]\n",
      "Loss in iteration 4008: 0.44544619726175605\n",
      "Theta: [-1.37292046  0.84301237  0.06421896]\n",
      "Loss in iteration 4009: 0.445435949031654\n",
      "Theta: [-1.37310083  0.84312889  0.06421559]\n",
      "Loss in iteration 4010: 0.44542570545502536\n",
      "Theta: [-1.37328115  0.84324539  0.06421222]\n",
      "Loss in iteration 4011: 0.4454154665291769\n",
      "Theta: [-1.37346144  0.84336187  0.06420885]\n",
      "Loss in iteration 4012: 0.4454052322514171\n",
      "Theta: [-1.37364168  0.84347833  0.06420548]\n",
      "Loss in iteration 4013: 0.44539500261905673\n",
      "Theta: [-1.37382187  0.84359476  0.06420211]\n",
      "Loss in iteration 4014: 0.4453847776294083\n",
      "Theta: [-1.37400203  0.84371116  0.06419874]\n",
      "Loss in iteration 4015: 0.44537455727978625\n",
      "Theta: [-1.37418214  0.84382755  0.06419537]\n",
      "Loss in iteration 4016: 0.4453643415675071\n",
      "Theta: [-1.37436221  0.84394391  0.06419201]\n",
      "Loss in iteration 4017: 0.4453541304898891\n",
      "Theta: [-1.37454224  0.84406024  0.06418864]\n",
      "Loss in iteration 4018: 0.4453439240442522\n",
      "Theta: [-1.37472222  0.84417655  0.06418527]\n",
      "Loss in iteration 4019: 0.44533372222791906\n",
      "Theta: [-1.37490216  0.84429284  0.0641819 ]\n",
      "Loss in iteration 4020: 0.4453235250382134\n",
      "Theta: [-1.37508206  0.84440911  0.06417854]\n",
      "Loss in iteration 4021: 0.4453133324724614\n",
      "Theta: [-1.37526192  0.84452535  0.06417517]\n",
      "Loss in iteration 4022: 0.44530314452799075\n",
      "Theta: [-1.37544173  0.84464157  0.0641718 ]\n",
      "Loss in iteration 4023: 0.44529296120213124\n",
      "Theta: [-1.37562151  0.84475776  0.06416844]\n",
      "Loss in iteration 4024: 0.4452827824922148\n",
      "Theta: [-1.37580123  0.84487393  0.06416507]\n",
      "Loss in iteration 4025: 0.4452726083955751\n",
      "Theta: [-1.37598092  0.84499008  0.0641617 ]\n",
      "Loss in iteration 4026: 0.44526243890954725\n",
      "Theta: [-1.37616056  0.8451062   0.06415834]\n",
      "Loss in iteration 4027: 0.445252274031469\n",
      "Theta: [-1.37634017  0.8452223   0.06415497]\n",
      "Loss in iteration 4028: 0.4452421137586797\n",
      "Theta: [-1.37651973  0.84533838  0.06415161]\n",
      "Loss in iteration 4029: 0.4452319580885203\n",
      "Theta: [-1.37669924  0.84545443  0.06414824]\n",
      "Loss in iteration 4030: 0.4452218070183342\n",
      "Theta: [-1.37687872  0.84557046  0.06414488]\n",
      "Loss in iteration 4031: 0.44521166054546657\n",
      "Theta: [-1.37705815  0.84568646  0.06414151]\n",
      "Loss in iteration 4032: 0.4452015186672639\n",
      "Theta: [-1.37723754  0.84580244  0.06413815]\n",
      "Loss in iteration 4033: 0.4451913813810752\n",
      "Theta: [-1.37741689  0.8459184   0.06413479]\n",
      "Loss in iteration 4034: 0.44518124868425113\n",
      "Theta: [-1.37759619  0.84603434  0.06413142]\n",
      "Loss in iteration 4035: 0.44517112057414443\n",
      "Theta: [-1.37777545  0.84615025  0.06412806]\n",
      "Loss in iteration 4036: 0.44516099704810946\n",
      "Theta: [-1.37795467  0.84626613  0.06412469]\n",
      "Loss in iteration 4037: 0.44515087810350273\n",
      "Theta: [-1.37813385  0.846382    0.06412133]\n",
      "Loss in iteration 4038: 0.4451407637376824\n",
      "Theta: [-1.37831299  0.84649784  0.06411797]\n",
      "Loss in iteration 4039: 0.44513065394800855\n",
      "Theta: [-1.37849208  0.84661365  0.06411461]\n",
      "Loss in iteration 4040: 0.4451205487318434\n",
      "Theta: [-1.37867113  0.84672945  0.06411124]\n",
      "Loss in iteration 4041: 0.4451104480865507\n",
      "Theta: [-1.37885014  0.84684522  0.06410788]\n",
      "Loss in iteration 4042: 0.4451003520094965\n",
      "Theta: [-1.37902911  0.84696096  0.06410452]\n",
      "Loss in iteration 4043: 0.4450902604980481\n",
      "Theta: [-1.37920803  0.84707669  0.06410116]\n",
      "Loss in iteration 4044: 0.44508017354957524\n",
      "Theta: [-1.37938691  0.84719238  0.0640978 ]\n",
      "Loss in iteration 4045: 0.44507009116144935\n",
      "Theta: [-1.37956575  0.84730806  0.06409444]\n",
      "Loss in iteration 4046: 0.44506001333104367\n",
      "Theta: [-1.37974455  0.84742371  0.06409108]\n",
      "Loss in iteration 4047: 0.44504994005573345\n",
      "Theta: [-1.37992331  0.84753934  0.06408771]\n",
      "Loss in iteration 4048: 0.4450398713328957\n",
      "Theta: [-1.38010202  0.84765495  0.06408435]\n",
      "Loss in iteration 4049: 0.4450298071599093\n",
      "Theta: [-1.38028069  0.84777053  0.06408099]\n",
      "Loss in iteration 4050: 0.44501974753415496\n",
      "Theta: [-1.38045932  0.84788609  0.06407763]\n",
      "Loss in iteration 4051: 0.4450096924530155\n",
      "Theta: [-1.38063791  0.84800162  0.06407427]\n",
      "Loss in iteration 4052: 0.4449996419138753\n",
      "Theta: [-1.38081645  0.84811713  0.06407091]\n",
      "Loss in iteration 4053: 0.4449895959141207\n",
      "Theta: [-1.38099495  0.84823262  0.06406756]\n",
      "Loss in iteration 4054: 0.44497955445113996\n",
      "Theta: [-1.38117342  0.84834809  0.0640642 ]\n",
      "Loss in iteration 4055: 0.4449695175223232\n",
      "Theta: [-1.38135183  0.84846353  0.06406084]\n",
      "Loss in iteration 4056: 0.44495948512506234\n",
      "Theta: [-1.38153021  0.84857895  0.06405748]\n",
      "Loss in iteration 4057: 0.4449494572567513\n",
      "Theta: [-1.38170855  0.84869434  0.06405412]\n",
      "Loss in iteration 4058: 0.4449394339147854\n",
      "Theta: [-1.38188684  0.84880971  0.06405076]\n",
      "Loss in iteration 4059: 0.4449294150965625\n",
      "Theta: [-1.38206509  0.84892506  0.06404741]\n",
      "Loss in iteration 4060: 0.4449194007994819\n",
      "Theta: [-1.3822433   0.84904038  0.06404405]\n",
      "Loss in iteration 4061: 0.4449093910209447\n",
      "Theta: [-1.38242147  0.84915569  0.06404069]\n",
      "Loss in iteration 4062: 0.4448993857583538\n",
      "Theta: [-1.38259959  0.84927096  0.06403733]\n",
      "Loss in iteration 4063: 0.44488938500911446\n",
      "Theta: [-1.38277767  0.84938622  0.06403398]\n",
      "Loss in iteration 4064: 0.44487938877063327\n",
      "Theta: [-1.38295571  0.84950145  0.06403062]\n",
      "Loss in iteration 4065: 0.44486939704031864\n",
      "Theta: [-1.38313371  0.84961666  0.06402726]\n",
      "Loss in iteration 4066: 0.44485940981558136\n",
      "Theta: [-1.38331167  0.84973184  0.06402391]\n",
      "Loss in iteration 4067: 0.44484942709383346\n",
      "Theta: [-1.38348959  0.849847    0.06402055]\n",
      "Loss in iteration 4068: 0.4448394488724891\n",
      "Theta: [-1.38366746  0.84996214  0.0640172 ]\n",
      "Loss in iteration 4069: 0.4448294751489644\n",
      "Theta: [-1.38384529  0.85007725  0.06401384]\n",
      "Loss in iteration 4070: 0.4448195059206769\n",
      "Theta: [-1.38402308  0.85019235  0.06401049]\n",
      "Loss in iteration 4071: 0.4448095411850463\n",
      "Theta: [-1.38420083  0.85030741  0.06400713]\n",
      "Loss in iteration 4072: 0.44479958093949407\n",
      "Theta: [-1.38437854  0.85042246  0.06400378]\n",
      "Loss in iteration 4073: 0.44478962518144344\n",
      "Theta: [-1.3845562   0.85053748  0.06400042]\n",
      "Loss in iteration 4074: 0.4447796739083196\n",
      "Theta: [-1.38473383  0.85065248  0.06399707]\n",
      "Loss in iteration 4075: 0.4447697271175497\n",
      "Theta: [-1.38491141  0.85076745  0.06399371]\n",
      "Loss in iteration 4076: 0.44475978480656203\n",
      "Theta: [-1.38508895  0.8508824   0.06399036]\n",
      "Loss in iteration 4077: 0.4447498469727875\n",
      "Theta: [-1.38526644  0.85099733  0.06398701]\n",
      "Loss in iteration 4078: 0.4447399136136585\n",
      "Theta: [-1.3854439   0.85111224  0.06398365]\n",
      "Loss in iteration 4079: 0.4447299847266092\n",
      "Theta: [-1.38562132  0.85122712  0.0639803 ]\n",
      "Loss in iteration 4080: 0.4447200603090758\n",
      "Theta: [-1.38579869  0.85134198  0.06397695]\n",
      "Loss in iteration 4081: 0.444710140358496\n",
      "Theta: [-1.38597602  0.85145681  0.06397359]\n",
      "Loss in iteration 4082: 0.4447002248723095\n",
      "Theta: [-1.38615331  0.85157163  0.06397024]\n",
      "Loss in iteration 4083: 0.4446903138479578\n",
      "Theta: [-1.38633056  0.85168642  0.06396689]\n",
      "Loss in iteration 4084: 0.44468040728288455\n",
      "Theta: [-1.38650776  0.85180118  0.06396354]\n",
      "Loss in iteration 4085: 0.44467050517453466\n",
      "Theta: [-1.38668493  0.85191592  0.06396019]\n",
      "Loss in iteration 4086: 0.444660607520355\n",
      "Theta: [-1.38686205  0.85203064  0.06395684]\n",
      "Loss in iteration 4087: 0.4446507143177943\n",
      "Theta: [-1.38703913  0.85214534  0.06395348]\n",
      "Loss in iteration 4088: 0.4446408255643031\n",
      "Theta: [-1.38721617  0.85226001  0.06395013]\n",
      "Loss in iteration 4089: 0.4446309412573343\n",
      "Theta: [-1.38739317  0.85237466  0.06394678]\n",
      "Loss in iteration 4090: 0.44462106139434143\n",
      "Theta: [-1.38757013  0.85248929  0.06394343]\n",
      "Loss in iteration 4091: 0.44461118597278065\n",
      "Theta: [-1.38774704  0.85260389  0.06394008]\n",
      "Loss in iteration 4092: 0.4446013149901099\n",
      "Theta: [-1.38792392  0.85271847  0.06393673]\n",
      "Loss in iteration 4093: 0.44459144844378884\n",
      "Theta: [-1.38810075  0.85283303  0.06393338]\n",
      "Loss in iteration 4094: 0.44458158633127853\n",
      "Theta: [-1.38827754  0.85294757  0.06393003]\n",
      "Loss in iteration 4095: 0.4445717286500423\n",
      "Theta: [-1.38845429  0.85306208  0.06392668]\n",
      "Loss in iteration 4096: 0.4445618753975452\n",
      "Theta: [-1.388631    0.85317657  0.06392334]\n",
      "Loss in iteration 4097: 0.4445520265712539\n",
      "Theta: [-1.38880767  0.85329103  0.06391999]\n",
      "Loss in iteration 4098: 0.44454218216863706\n",
      "Theta: [-1.38898429  0.85340547  0.06391664]\n",
      "Loss in iteration 4099: 0.44453234218716486\n",
      "Theta: [-1.38916088  0.85351989  0.06391329]\n",
      "Loss in iteration 4100: 0.44452250662430964\n",
      "Theta: [-1.38933742  0.85363429  0.06390994]\n",
      "Loss in iteration 4101: 0.4445126754775453\n",
      "Theta: [-1.38951392  0.85374866  0.0639066 ]\n",
      "Loss in iteration 4102: 0.4445028487443475\n",
      "Theta: [-1.38969038  0.85386301  0.06390325]\n",
      "Loss in iteration 4103: 0.44449302642219385\n",
      "Theta: [-1.3898668   0.85397734  0.0638999 ]\n",
      "Loss in iteration 4104: 0.44448320850856343\n",
      "Theta: [-1.39004318  0.85409164  0.06389655]\n",
      "Loss in iteration 4105: 0.4444733950009375\n",
      "Theta: [-1.39021951  0.85420592  0.06389321]\n",
      "Loss in iteration 4106: 0.44446358589679913\n",
      "Theta: [-1.39039581  0.85432018  0.06388986]\n",
      "Loss in iteration 4107: 0.4444537811936323\n",
      "Theta: [-1.39057206  0.85443442  0.06388651]\n",
      "Loss in iteration 4108: 0.4444439808889239\n",
      "Theta: [-1.39074827  0.85454863  0.06388317]\n",
      "Loss in iteration 4109: 0.4444341849801621\n",
      "Theta: [-1.39092445  0.85466282  0.06387982]\n",
      "Loss in iteration 4110: 0.44442439346483675\n",
      "Theta: [-1.39110058  0.85477698  0.06387648]\n",
      "Loss in iteration 4111: 0.4444146063404397\n",
      "Theta: [-1.39127666  0.85489112  0.06387313]\n",
      "Loss in iteration 4112: 0.44440482360446426\n",
      "Theta: [-1.39145271  0.85500524  0.06386979]\n",
      "Loss in iteration 4113: 0.444395045254406\n",
      "Theta: [-1.39162872  0.85511934  0.06386644]\n",
      "Loss in iteration 4114: 0.44438527128776173\n",
      "Theta: [-1.39180468  0.85523341  0.0638631 ]\n",
      "Loss in iteration 4115: 0.44437550170203016\n",
      "Theta: [-1.39198061  0.85534746  0.06385975]\n",
      "Loss in iteration 4116: 0.4443657364947122\n",
      "Theta: [-1.39215649  0.85546149  0.06385641]\n",
      "Loss in iteration 4117: 0.44435597566331014\n",
      "Theta: [-1.39233233  0.8555755   0.06385306]\n",
      "Loss in iteration 4118: 0.44434621920532785\n",
      "Theta: [-1.39250813  0.85568948  0.06384972]\n",
      "Loss in iteration 4119: 0.44433646711827135\n",
      "Theta: [-1.39268389  0.85580344  0.06384638]\n",
      "Loss in iteration 4120: 0.4443267193996482\n",
      "Theta: [-1.39285961  0.85591737  0.06384303]\n",
      "Loss in iteration 4121: 0.44431697604696785\n",
      "Theta: [-1.39303529  0.85603129  0.06383969]\n",
      "Loss in iteration 4122: 0.4443072370577415\n",
      "Theta: [-1.39321093  0.85614518  0.06383635]\n",
      "Loss in iteration 4123: 0.4442975024294819\n",
      "Theta: [-1.39338652  0.85625905  0.06383301]\n",
      "Loss in iteration 4124: 0.444287772159704\n",
      "Theta: [-1.39356208  0.85637289  0.06382966]\n",
      "Loss in iteration 4125: 0.4442780462459238\n",
      "Theta: [-1.39373759  0.85648671  0.06382632]\n",
      "Loss in iteration 4126: 0.44426832468565985\n",
      "Theta: [-1.39391306  0.85660051  0.06382298]\n",
      "Loss in iteration 4127: 0.4442586074764317\n",
      "Theta: [-1.39408849  0.85671429  0.06381964]\n",
      "Loss in iteration 4128: 0.4442488946157612\n",
      "Theta: [-1.39426388  0.85682804  0.0638163 ]\n",
      "Loss in iteration 4129: 0.44423918610117175\n",
      "Theta: [-1.39443923  0.85694177  0.06381296]\n",
      "Loss in iteration 4130: 0.4442294819301885\n",
      "Theta: [-1.39461454  0.85705548  0.06380962]\n",
      "Loss in iteration 4131: 0.44421978210033847\n",
      "Theta: [-1.39478981  0.85716916  0.06380628]\n",
      "Loss in iteration 4132: 0.44421008660915\n",
      "Theta: [-1.39496504  0.85728282  0.06380294]\n",
      "Loss in iteration 4133: 0.4442003954541536\n",
      "Theta: [-1.39514022  0.85739646  0.0637996 ]\n",
      "Loss in iteration 4134: 0.4441907086328814\n",
      "Theta: [-1.39531537  0.85751008  0.06379626]\n",
      "Loss in iteration 4135: 0.4441810261428673\n",
      "Theta: [-1.39549047  0.85762367  0.06379292]\n",
      "Loss in iteration 4136: 0.4441713479816468\n",
      "Theta: [-1.39566554  0.85773724  0.06378958]\n",
      "Loss in iteration 4137: 0.4441616741467573\n",
      "Theta: [-1.39584056  0.85785079  0.06378624]\n",
      "Loss in iteration 4138: 0.44415200463573784\n",
      "Theta: [-1.39601554  0.85796431  0.0637829 ]\n",
      "Loss in iteration 4139: 0.44414233944612924\n",
      "Theta: [-1.39619048  0.85807781  0.06377956]\n",
      "Loss in iteration 4140: 0.44413267857547395\n",
      "Theta: [-1.39636538  0.85819129  0.06377622]\n",
      "Loss in iteration 4141: 0.4441230220213162\n",
      "Theta: [-1.39654024  0.85830475  0.06377288]\n",
      "Loss in iteration 4142: 0.444113369781202\n",
      "Theta: [-1.39671506  0.85841818  0.06376955]\n",
      "Loss in iteration 4143: 0.44410372185267916\n",
      "Theta: [-1.39688984  0.85853159  0.06376621]\n",
      "Loss in iteration 4144: 0.444094078233297\n",
      "Theta: [-1.39706458  0.85864498  0.06376287]\n",
      "Loss in iteration 4145: 0.4440844389206069\n",
      "Theta: [-1.39723927  0.85875835  0.06375953]\n",
      "Loss in iteration 4146: 0.4440748039121613\n",
      "Theta: [-1.39741393  0.85887169  0.0637562 ]\n",
      "Loss in iteration 4147: 0.44406517320551503\n",
      "Theta: [-1.39758854  0.85898501  0.06375286]\n",
      "Loss in iteration 4148: 0.4440555467982245\n",
      "Theta: [-1.39776312  0.85909831  0.06374952]\n",
      "Loss in iteration 4149: 0.4440459246878477\n",
      "Theta: [-1.39793765  0.85921158  0.06374619]\n",
      "Loss in iteration 4150: 0.4440363068719443\n",
      "Theta: [-1.39811215  0.85932483  0.06374285]\n",
      "Loss in iteration 4151: 0.44402669334807576\n",
      "Theta: [-1.3982866   0.85943806  0.06373952]\n",
      "Loss in iteration 4152: 0.4440170841138053\n",
      "Theta: [-1.39846101  0.85955127  0.06373618]\n",
      "Loss in iteration 4153: 0.4440074791666979\n",
      "Theta: [-1.39863538  0.85966445  0.06373285]\n",
      "Loss in iteration 4154: 0.44399787850432015\n",
      "Theta: [-1.39880971  0.85977761  0.06372951]\n",
      "Loss in iteration 4155: 0.4439882821242401\n",
      "Theta: [-1.398984    0.85989075  0.06372618]\n",
      "Loss in iteration 4156: 0.4439786900240279\n",
      "Theta: [-1.39915825  0.86000387  0.06372284]\n",
      "Loss in iteration 4157: 0.4439691022012556\n",
      "Theta: [-1.39933246  0.86011696  0.06371951]\n",
      "Loss in iteration 4158: 0.4439595186534961\n",
      "Theta: [-1.39950663  0.86023003  0.06371617]\n",
      "Loss in iteration 4159: 0.44394993937832483\n",
      "Theta: [-1.39968076  0.86034308  0.06371284]\n",
      "Loss in iteration 4160: 0.4439403643733188\n",
      "Theta: [-1.39985485  0.8604561   0.06370951]\n",
      "Loss in iteration 4161: 0.44393079363605603\n",
      "Theta: [-1.4000289   0.8605691   0.06370617]\n",
      "Loss in iteration 4162: 0.44392122716411725\n",
      "Theta: [-1.4002029   0.86068208  0.06370284]\n",
      "Loss in iteration 4163: 0.44391166495508416\n",
      "Theta: [-1.40037687  0.86079504  0.06369951]\n",
      "Loss in iteration 4164: 0.44390210700654037\n",
      "Theta: [-1.4005508   0.86090798  0.06369617]\n",
      "Loss in iteration 4165: 0.44389255331607125\n",
      "Theta: [-1.40072468  0.86102089  0.06369284]\n",
      "Loss in iteration 4166: 0.44388300388126384\n",
      "Theta: [-1.40089853  0.86113378  0.06368951]\n",
      "Loss in iteration 4167: 0.4438734586997068\n",
      "Theta: [-1.40107233  0.86124664  0.06368618]\n",
      "Loss in iteration 4168: 0.44386391776899053\n",
      "Theta: [-1.4012461   0.86135949  0.06368285]\n",
      "Loss in iteration 4169: 0.4438543810867072\n",
      "Theta: [-1.40141982  0.86147231  0.06367951]\n",
      "Loss in iteration 4170: 0.4438448486504506\n",
      "Theta: [-1.4015935   0.86158511  0.06367618]\n",
      "Loss in iteration 4171: 0.4438353204578162\n",
      "Theta: [-1.40176715  0.86169788  0.06367285]\n",
      "Loss in iteration 4172: 0.4438257965064009\n",
      "Theta: [-1.40194075  0.86181064  0.06366952]\n",
      "Loss in iteration 4173: 0.4438162767938038\n",
      "Theta: [-1.40211431  0.86192337  0.06366619]\n",
      "Loss in iteration 4174: 0.44380676131762525\n",
      "Theta: [-1.40228784  0.86203608  0.06366286]\n",
      "Loss in iteration 4175: 0.44379725007546766\n",
      "Theta: [-1.40246132  0.86214876  0.06365953]\n",
      "Loss in iteration 4176: 0.44378774306493457\n",
      "Theta: [-1.40263476  0.86226143  0.0636562 ]\n",
      "Loss in iteration 4177: 0.44377824028363194\n",
      "Theta: [-1.40280816  0.86237407  0.06365287]\n",
      "Loss in iteration 4178: 0.4437687417291666\n",
      "Theta: [-1.40298152  0.86248669  0.06364954]\n",
      "Loss in iteration 4179: 0.44375924739914774\n",
      "Theta: [-1.40315484  0.86259928  0.06364621]\n",
      "Loss in iteration 4180: 0.4437497572911858\n",
      "Theta: [-1.40332812  0.86271186  0.06364289]\n",
      "Loss in iteration 4181: 0.443740271402893\n",
      "Theta: [-1.40350137  0.86282441  0.06363956]\n",
      "Loss in iteration 4182: 0.4437307897318834\n",
      "Theta: [-1.40367457  0.86293694  0.06363623]\n",
      "Loss in iteration 4183: 0.44372131227577244\n",
      "Theta: [-1.40384773  0.86304944  0.0636329 ]\n",
      "Loss in iteration 4184: 0.4437118390321775\n",
      "Theta: [-1.40402085  0.86316193  0.06362957]\n",
      "Loss in iteration 4185: 0.4437023699987177\n",
      "Theta: [-1.40419393  0.86327439  0.06362625]\n",
      "Loss in iteration 4186: 0.443692905173013\n",
      "Theta: [-1.40436697  0.86338683  0.06362292]\n",
      "Loss in iteration 4187: 0.4436834445526862\n",
      "Theta: [-1.40453997  0.86349924  0.06361959]\n",
      "Loss in iteration 4188: 0.4436739881353613\n",
      "Theta: [-1.40471293  0.86361164  0.06361627]\n",
      "Loss in iteration 4189: 0.44366453591866345\n",
      "Theta: [-1.40488585  0.86372401  0.06361294]\n",
      "Loss in iteration 4190: 0.44365508790022007\n",
      "Theta: [-1.40505873  0.86383636  0.06360961]\n",
      "Loss in iteration 4191: 0.4436456440776603\n",
      "Theta: [-1.40523157  0.86394868  0.06360629]\n",
      "Loss in iteration 4192: 0.4436362044486142\n",
      "Theta: [-1.40540437  0.86406099  0.06360296]\n",
      "Loss in iteration 4193: 0.4436267690107143\n",
      "Theta: [-1.40557713  0.86417327  0.06359963]\n",
      "Loss in iteration 4194: 0.44361733776159445\n",
      "Theta: [-1.40574985  0.86428553  0.06359631]\n",
      "Loss in iteration 4195: 0.44360791069889016\n",
      "Theta: [-1.40592253  0.86439777  0.06359298]\n",
      "Loss in iteration 4196: 0.4435984878202386\n",
      "Theta: [-1.40609517  0.86450998  0.06358966]\n",
      "Loss in iteration 4197: 0.44358906912327856\n",
      "Theta: [-1.40626777  0.86462217  0.06358634]\n",
      "Loss in iteration 4198: 0.4435796546056505\n",
      "Theta: [-1.40644033  0.86473434  0.06358301]\n",
      "Loss in iteration 4199: 0.44357024426499664\n",
      "Theta: [-1.40661285  0.86484649  0.06357969]\n",
      "Loss in iteration 4200: 0.4435608380989606\n",
      "Theta: [-1.40678533  0.86495862  0.06357636]\n",
      "Loss in iteration 4201: 0.4435514361051878\n",
      "Theta: [-1.40695777  0.86507072  0.06357304]\n",
      "Loss in iteration 4202: 0.4435420382813254\n",
      "Theta: [-1.40713017  0.8651828   0.06356972]\n",
      "Loss in iteration 4203: 0.4435326446250222\n",
      "Theta: [-1.40730253  0.86529486  0.06356639]\n",
      "Loss in iteration 4204: 0.44352325513392815\n",
      "Theta: [-1.40747485  0.86540689  0.06356307]\n",
      "Loss in iteration 4205: 0.44351386980569546\n",
      "Theta: [-1.40764713  0.86551891  0.06355975]\n",
      "Loss in iteration 4206: 0.4435044886379778\n",
      "Theta: [-1.40781937  0.8656309   0.06355642]\n",
      "Loss in iteration 4207: 0.44349511162843025\n",
      "Theta: [-1.40799157  0.86574287  0.0635531 ]\n",
      "Loss in iteration 4208: 0.4434857387747098\n",
      "Theta: [-1.40816373  0.86585481  0.06354978]\n",
      "Loss in iteration 4209: 0.4434763700744751\n",
      "Theta: [-1.40833585  0.86596674  0.06354646]\n",
      "Loss in iteration 4210: 0.443467005525386\n",
      "Theta: [-1.40850793  0.86607864  0.06354314]\n",
      "Loss in iteration 4211: 0.44345764512510455\n",
      "Theta: [-1.40867997  0.86619052  0.06353982]\n",
      "Loss in iteration 4212: 0.44344828887129395\n",
      "Theta: [-1.40885198  0.86630238  0.0635365 ]\n",
      "Loss in iteration 4213: 0.4434389367616195\n",
      "Theta: [-1.40902394  0.86641421  0.06353318]\n",
      "Loss in iteration 4214: 0.4434295887937475\n",
      "Theta: [-1.40919586  0.86652602  0.06352985]\n",
      "Loss in iteration 4215: 0.44342024496534643\n",
      "Theta: [-1.40936774  0.86663781  0.06352653]\n",
      "Loss in iteration 4216: 0.44341090527408644\n",
      "Theta: [-1.40953959  0.86674958  0.06352321]\n",
      "Loss in iteration 4217: 0.44340156971763883\n",
      "Theta: [-1.40971139  0.86686133  0.06351989]\n",
      "Loss in iteration 4218: 0.44339223829367663\n",
      "Theta: [-1.40988316  0.86697305  0.06351658]\n",
      "Loss in iteration 4219: 0.44338291099987487\n",
      "Theta: [-1.41005488  0.86708475  0.06351326]\n",
      "Loss in iteration 4220: 0.44337358783390973\n",
      "Theta: [-1.41022656  0.86719643  0.06350994]\n",
      "Loss in iteration 4221: 0.4433642687934596\n",
      "Theta: [-1.41039821  0.86730809  0.06350662]\n",
      "Loss in iteration 4222: 0.4433549538762037\n",
      "Theta: [-1.41056981  0.86741973  0.0635033 ]\n",
      "Loss in iteration 4223: 0.4433456430798235\n",
      "Theta: [-1.41074138  0.86753134  0.06349998]\n",
      "Loss in iteration 4224: 0.4433363364020018\n",
      "Theta: [-1.41091291  0.86764293  0.06349666]\n",
      "Loss in iteration 4225: 0.4433270338404231\n",
      "Theta: [-1.41108439  0.8677545   0.06349335]\n",
      "Loss in iteration 4226: 0.4433177353927736\n",
      "Theta: [-1.41125584  0.86786604  0.06349003]\n",
      "Loss in iteration 4227: 0.4433084410567407\n",
      "Theta: [-1.41142725  0.86797757  0.06348671]\n",
      "Loss in iteration 4228: 0.44329915083001403\n",
      "Theta: [-1.41159862  0.86808907  0.06348339]\n",
      "Loss in iteration 4229: 0.4432898647102843\n",
      "Theta: [-1.41176994  0.86820055  0.06348008]\n",
      "Loss in iteration 4230: 0.4432805826952441\n",
      "Theta: [-1.41194123  0.86831201  0.06347676]\n",
      "Loss in iteration 4231: 0.4432713047825876\n",
      "Theta: [-1.41211248  0.86842344  0.06347344]\n",
      "Loss in iteration 4232: 0.4432620309700103\n",
      "Theta: [-1.41228369  0.86853486  0.06347013]\n",
      "Loss in iteration 4233: 0.4432527612552098\n",
      "Theta: [-1.41245486  0.86864625  0.06346681]\n",
      "Loss in iteration 4234: 0.443243495635885\n",
      "Theta: [-1.41262599  0.86875762  0.0634635 ]\n",
      "Loss in iteration 4235: 0.4432342341097362\n",
      "Theta: [-1.41279709  0.86886896  0.06346018]\n",
      "Loss in iteration 4236: 0.4432249766744657\n",
      "Theta: [-1.41296814  0.86898029  0.06345687]\n",
      "Loss in iteration 4237: 0.4432157233277772\n",
      "Theta: [-1.41313915  0.86909159  0.06345355]\n",
      "Loss in iteration 4238: 0.4432064740673761\n",
      "Theta: [-1.41331012  0.86920287  0.06345024]\n",
      "Loss in iteration 4239: 0.4431972288909691\n",
      "Theta: [-1.41348106  0.86931413  0.06344692]\n",
      "Loss in iteration 4240: 0.4431879877962648\n",
      "Theta: [-1.41365195  0.86942537  0.06344361]\n",
      "Loss in iteration 4241: 0.44317875078097346\n",
      "Theta: [-1.41382281  0.86953658  0.06344029]\n",
      "Loss in iteration 4242: 0.4431695178428064\n",
      "Theta: [-1.41399362  0.86964777  0.06343698]\n",
      "Loss in iteration 4243: 0.4431602889794773\n",
      "Theta: [-1.4141644   0.86975894  0.06343367]\n",
      "Loss in iteration 4244: 0.44315106418870065\n",
      "Theta: [-1.41433514  0.86987009  0.06343035]\n",
      "Loss in iteration 4245: 0.44314184346819324\n",
      "Theta: [-1.41450584  0.86998122  0.06342704]\n",
      "Loss in iteration 4246: 0.44313262681567295\n",
      "Theta: [-1.41467649  0.87009232  0.06342373]\n",
      "Loss in iteration 4247: 0.4431234142288592\n",
      "Theta: [-1.41484711  0.8702034   0.06342042]\n",
      "Loss in iteration 4248: 0.4431142057054736\n",
      "Theta: [-1.41501769  0.87031446  0.0634171 ]\n",
      "Loss in iteration 4249: 0.4431050012432384\n",
      "Theta: [-1.41518824  0.8704255   0.06341379]\n",
      "Loss in iteration 4250: 0.4430958008398785\n",
      "Theta: [-1.41535874  0.87053652  0.06341048]\n",
      "Loss in iteration 4251: 0.4430866044931193\n",
      "Theta: [-1.4155292   0.87064751  0.06340717]\n",
      "Loss in iteration 4252: 0.44307741220068864\n",
      "Theta: [-1.41569962  0.87075848  0.06340386]\n",
      "Loss in iteration 4253: 0.44306822396031564\n",
      "Theta: [-1.41587001  0.87086943  0.06340055]\n",
      "Loss in iteration 4254: 0.4430590397697308\n",
      "Theta: [-1.41604035  0.87098036  0.06339724]\n",
      "Loss in iteration 4255: 0.4430498596266665\n",
      "Theta: [-1.41621066  0.87109127  0.06339393]\n",
      "Loss in iteration 4256: 0.4430406835288563\n",
      "Theta: [-1.41638093  0.87120215  0.06339062]\n",
      "Loss in iteration 4257: 0.4430315114740359\n",
      "Theta: [-1.41655115  0.87131301  0.06338731]\n",
      "Loss in iteration 4258: 0.44302234345994185\n",
      "Theta: [-1.41672134  0.87142385  0.063384  ]\n",
      "Loss in iteration 4259: 0.44301317948431307\n",
      "Theta: [-1.41689149  0.87153467  0.06338069]\n",
      "Loss in iteration 4260: 0.4430040195448893\n",
      "Theta: [-1.4170616   0.87164547  0.06337738]\n",
      "Loss in iteration 4261: 0.4429948636394123\n",
      "Theta: [-1.41723167  0.87175624  0.06337407]\n",
      "Loss in iteration 4262: 0.4429857117656254\n",
      "Theta: [-1.41740171  0.87186699  0.06337076]\n",
      "Loss in iteration 4263: 0.44297656392127327\n",
      "Theta: [-1.4175717   0.87197772  0.06336745]\n",
      "Loss in iteration 4264: 0.4429674201041023\n",
      "Theta: [-1.41774165  0.87208843  0.06336414]\n",
      "Loss in iteration 4265: 0.44295828031186013\n",
      "Theta: [-1.41791157  0.87219912  0.06336083]\n",
      "Loss in iteration 4266: 0.4429491445422965\n",
      "Theta: [-1.41808144  0.87230978  0.06335753]\n",
      "Loss in iteration 4267: 0.44294001279316225\n",
      "Theta: [-1.41825128  0.87242043  0.06335422]\n",
      "Loss in iteration 4268: 0.44293088506221\n",
      "Theta: [-1.41842108  0.87253105  0.06335091]\n",
      "Loss in iteration 4269: 0.44292176134719385\n",
      "Theta: [-1.41859084  0.87264165  0.0633476 ]\n",
      "Loss in iteration 4270: 0.4429126416458696\n",
      "Theta: [-1.41876056  0.87275222  0.0633443 ]\n",
      "Loss in iteration 4271: 0.442903525955994\n",
      "Theta: [-1.41893024  0.87286278  0.06334099]\n",
      "Loss in iteration 4272: 0.4428944142753266\n",
      "Theta: [-1.41909988  0.87297331  0.06333769]\n",
      "Loss in iteration 4273: 0.44288530660162706\n",
      "Theta: [-1.41926949  0.87308382  0.06333438]\n",
      "Loss in iteration 4274: 0.44287620293265756\n",
      "Theta: [-1.41943905  0.87319431  0.06333107]\n",
      "Loss in iteration 4275: 0.4428671032661813\n",
      "Theta: [-1.41960858  0.87330478  0.06332777]\n",
      "Loss in iteration 4276: 0.44285800759996347\n",
      "Theta: [-1.41977806  0.87341523  0.06332446]\n",
      "Loss in iteration 4277: 0.44284891593177034\n",
      "Theta: [-1.41994751  0.87352565  0.06332116]\n",
      "Loss in iteration 4278: 0.4428398282593704\n",
      "Theta: [-1.42011692  0.87363605  0.06331785]\n",
      "Loss in iteration 4279: 0.44283074458053256\n",
      "Theta: [-1.42028629  0.87374643  0.06331455]\n",
      "Loss in iteration 4280: 0.44282166489302843\n",
      "Theta: [-1.42045562  0.87385679  0.06331124]\n",
      "Loss in iteration 4281: 0.4428125891946307\n",
      "Theta: [-1.42062491  0.87396713  0.06330794]\n",
      "Loss in iteration 4282: 0.4428035174831134\n",
      "Theta: [-1.42079417  0.87407744  0.06330464]\n",
      "Loss in iteration 4283: 0.44279444975625254\n",
      "Theta: [-1.42096338  0.87418773  0.06330133]\n",
      "Loss in iteration 4284: 0.442785386011825\n",
      "Theta: [-1.42113256  0.87429801  0.06329803]\n",
      "Loss in iteration 4285: 0.44277632624760976\n",
      "Theta: [-1.4213017   0.87440826  0.06329473]\n",
      "Loss in iteration 4286: 0.44276727046138725\n",
      "Theta: [-1.4214708   0.87451848  0.06329142]\n",
      "Loss in iteration 4287: 0.4427582186509394\n",
      "Theta: [-1.42163986  0.87462869  0.06328812]\n",
      "Loss in iteration 4288: 0.4427491708140493\n",
      "Theta: [-1.42180888  0.87473887  0.06328482]\n",
      "Loss in iteration 4289: 0.4427401269485024\n",
      "Theta: [-1.42197786  0.87484904  0.06328152]\n",
      "Loss in iteration 4290: 0.44273108705208464\n",
      "Theta: [-1.42214681  0.87495918  0.06327821]\n",
      "Loss in iteration 4291: 0.44272205112258467\n",
      "Theta: [-1.42231571  0.8750693   0.06327491]\n",
      "Loss in iteration 4292: 0.44271301915779127\n",
      "Theta: [-1.42248458  0.87517939  0.06327161]\n",
      "Loss in iteration 4293: 0.44270399115549586\n",
      "Theta: [-1.42265341  0.87528947  0.06326831]\n",
      "Loss in iteration 4294: 0.44269496711349116\n",
      "Theta: [-1.42282219  0.87539952  0.06326501]\n",
      "Loss in iteration 4295: 0.44268594702957104\n",
      "Theta: [-1.42299095  0.87550955  0.06326171]\n",
      "Loss in iteration 4296: 0.44267693090153104\n",
      "Theta: [-1.42315966  0.87561957  0.06325841]\n",
      "Loss in iteration 4297: 0.4426679187271684\n",
      "Theta: [-1.42332833  0.87572955  0.06325511]\n",
      "Loss in iteration 4298: 0.44265891050428174\n",
      "Theta: [-1.42349697  0.87583952  0.06325181]\n",
      "Loss in iteration 4299: 0.4426499062306714\n",
      "Theta: [-1.42366556  0.87594947  0.06324851]\n",
      "Loss in iteration 4300: 0.44264090590413874\n",
      "Theta: [-1.42383412  0.87605939  0.06324521]\n",
      "Loss in iteration 4301: 0.44263190952248743\n",
      "Theta: [-1.42400264  0.87616929  0.06324191]\n",
      "Loss in iteration 4302: 0.4426229170835216\n",
      "Theta: [-1.42417112  0.87627917  0.06323861]\n",
      "Loss in iteration 4303: 0.4426139285850478\n",
      "Theta: [-1.42433956  0.87638903  0.06323531]\n",
      "Loss in iteration 4304: 0.4426049440248738\n",
      "Theta: [-1.42450797  0.87649887  0.06323201]\n",
      "Loss in iteration 4305: 0.4425959634008087\n",
      "Theta: [-1.42467633  0.87660868  0.06322871]\n",
      "Loss in iteration 4306: 0.4425869867106633\n",
      "Theta: [-1.42484466  0.87671848  0.06322542]\n",
      "Loss in iteration 4307: 0.4425780139522499\n",
      "Theta: [-1.42501295  0.87682825  0.06322212]\n",
      "Loss in iteration 4308: 0.4425690451233823\n",
      "Theta: [-1.4251812   0.876938    0.06321882]\n",
      "Loss in iteration 4309: 0.44256008022187565\n",
      "Theta: [-1.42534941  0.87704773  0.06321552]\n",
      "Loss in iteration 4310: 0.44255111924554663\n",
      "Theta: [-1.42551759  0.87715744  0.06321223]\n",
      "Loss in iteration 4311: 0.44254216219221365\n",
      "Theta: [-1.42568572  0.87726712  0.06320893]\n",
      "Loss in iteration 4312: 0.44253320905969656\n",
      "Theta: [-1.42585382  0.87737678  0.06320563]\n",
      "Loss in iteration 4313: 0.4425242598458166\n",
      "Theta: [-1.42602188  0.87748643  0.06320234]\n",
      "Loss in iteration 4314: 0.4425153145483964\n",
      "Theta: [-1.42618989  0.87759605  0.06319904]\n",
      "Loss in iteration 4315: 0.4425063731652603\n",
      "Theta: [-1.42635788  0.87770565  0.06319575]\n",
      "Loss in iteration 4316: 0.442497435694234\n",
      "Theta: [-1.42652582  0.87781522  0.06319245]\n",
      "Loss in iteration 4317: 0.442488502133145\n",
      "Theta: [-1.42669372  0.87792478  0.06318915]\n",
      "Loss in iteration 4318: 0.4424795724798218\n",
      "Theta: [-1.42686159  0.87803431  0.06318586]\n",
      "Loss in iteration 4319: 0.44247064673209463\n",
      "Theta: [-1.42702942  0.87814383  0.06318256]\n",
      "Loss in iteration 4320: 0.44246172488779545\n",
      "Theta: [-1.42719721  0.87825332  0.06317927]\n",
      "Loss in iteration 4321: 0.44245280694475725\n",
      "Theta: [-1.42736496  0.87836279  0.06317598]\n",
      "Loss in iteration 4322: 0.4424438929008147\n",
      "Theta: [-1.42753267  0.87847224  0.06317268]\n",
      "Loss in iteration 4323: 0.4424349827538044\n",
      "Theta: [-1.42770035  0.87858166  0.06316939]\n",
      "Loss in iteration 4324: 0.4424260765015637\n",
      "Theta: [-1.42786799  0.87869107  0.06316609]\n",
      "Loss in iteration 4325: 0.4424171741419318\n",
      "Theta: [-1.42803559  0.87880045  0.0631628 ]\n",
      "Loss in iteration 4326: 0.44240827567274926\n",
      "Theta: [-1.42820315  0.87890981  0.06315951]\n",
      "Loss in iteration 4327: 0.4423993810918585\n",
      "Theta: [-1.42837067  0.87901916  0.06315622]\n",
      "Loss in iteration 4328: 0.4423904903971029\n",
      "Theta: [-1.42853815  0.87912847  0.06315292]\n",
      "Loss in iteration 4329: 0.4423816035863276\n",
      "Theta: [-1.4287056   0.87923777  0.06314963]\n",
      "Loss in iteration 4330: 0.4423727206573793\n",
      "Theta: [-1.42887301  0.87934705  0.06314634]\n",
      "Loss in iteration 4331: 0.4423638416081059\n",
      "Theta: [-1.42904038  0.8794563   0.06314305]\n",
      "Loss in iteration 4332: 0.4423549664363571\n",
      "Theta: [-1.42920771  0.87956554  0.06313975]\n",
      "Loss in iteration 4333: 0.44234609513998374\n",
      "Theta: [-1.429375    0.87967475  0.06313646]\n",
      "Loss in iteration 4334: 0.44233722771683814\n",
      "Theta: [-1.42954226  0.87978394  0.06313317]\n",
      "Loss in iteration 4335: 0.4423283641647746\n",
      "Theta: [-1.42970947  0.87989311  0.06312988]\n",
      "Loss in iteration 4336: 0.4423195044816486\n",
      "Theta: [-1.42987665  0.88000226  0.06312659]\n",
      "Loss in iteration 4337: 0.4423106486653166\n",
      "Theta: [-1.4300438   0.88011138  0.0631233 ]\n",
      "Loss in iteration 4338: 0.44230179671363723\n",
      "Theta: [-1.4302109   0.88022049  0.06312001]\n",
      "Loss in iteration 4339: 0.4422929486244702\n",
      "Theta: [-1.43037796  0.88032957  0.06311672]\n",
      "Loss in iteration 4340: 0.4422841043956771\n",
      "Theta: [-1.43054499  0.88043863  0.06311343]\n",
      "Loss in iteration 4341: 0.44227526402512046\n",
      "Theta: [-1.43071198  0.88054767  0.06311014]\n",
      "Loss in iteration 4342: 0.4422664275106644\n",
      "Theta: [-1.43087893  0.88065669  0.06310685]\n",
      "Loss in iteration 4343: 0.4422575948501747\n",
      "Theta: [-1.43104585  0.88076569  0.06310356]\n",
      "Loss in iteration 4344: 0.44224876604151875\n",
      "Theta: [-1.43121272  0.88087466  0.06310027]\n",
      "Loss in iteration 4345: 0.4422399410825648\n",
      "Theta: [-1.43137956  0.88098362  0.06309699]\n",
      "Loss in iteration 4346: 0.4422311199711831\n",
      "Theta: [-1.43154636  0.88109255  0.0630937 ]\n",
      "Loss in iteration 4347: 0.44222230270524515\n",
      "Theta: [-1.43171312  0.88120146  0.06309041]\n",
      "Loss in iteration 4348: 0.44221348928262394\n",
      "Theta: [-1.43187984  0.88131035  0.06308712]\n",
      "Loss in iteration 4349: 0.44220467970119404\n",
      "Theta: [-1.43204653  0.88141922  0.06308384]\n",
      "Loss in iteration 4350: 0.44219587395883103\n",
      "Theta: [-1.43221318  0.88152807  0.06308055]\n",
      "Loss in iteration 4351: 0.4421870720534127\n",
      "Theta: [-1.43237979  0.8816369   0.06307726]\n",
      "Loss in iteration 4352: 0.44217827398281734\n",
      "Theta: [-1.43254636  0.8817457   0.06307397]\n",
      "Loss in iteration 4353: 0.44216947974492554\n",
      "Theta: [-1.43271289  0.88185449  0.06307069]\n",
      "Loss in iteration 4354: 0.442160689337619\n",
      "Theta: [-1.43287939  0.88196325  0.0630674 ]\n",
      "Loss in iteration 4355: 0.44215190275878063\n",
      "Theta: [-1.43304585  0.88207199  0.06306412]\n",
      "Loss in iteration 4356: 0.4421431200062954\n",
      "Theta: [-1.43321227  0.88218071  0.06306083]\n",
      "Loss in iteration 4357: 0.44213434107804905\n",
      "Theta: [-1.43337865  0.88228941  0.06305754]\n",
      "Loss in iteration 4358: 0.4421255659719292\n",
      "Theta: [-1.433545    0.88239809  0.06305426]\n",
      "Loss in iteration 4359: 0.44211679468582493\n",
      "Theta: [-1.4337113   0.88250674  0.06305097]\n",
      "Loss in iteration 4360: 0.44210802721762626\n",
      "Theta: [-1.43387757  0.88261538  0.06304769]\n",
      "Loss in iteration 4361: 0.4420992635652253\n",
      "Theta: [-1.43404381  0.88272399  0.06304441]\n",
      "Loss in iteration 4362: 0.4420905037265151\n",
      "Theta: [-1.43421     0.88283258  0.06304112]\n",
      "Loss in iteration 4363: 0.44208174769939057\n",
      "Theta: [-1.43437616  0.88294115  0.06303784]\n",
      "Loss in iteration 4364: 0.4420729954817477\n",
      "Theta: [-1.43454228  0.8830497   0.06303455]\n",
      "Loss in iteration 4365: 0.44206424707148423\n",
      "Theta: [-1.43470836  0.88315823  0.06303127]\n",
      "Loss in iteration 4366: 0.442055502466499\n",
      "Theta: [-1.4348744   0.88326674  0.06302799]\n",
      "Loss in iteration 4367: 0.4420467616646925\n",
      "Theta: [-1.43504041  0.88337522  0.0630247 ]\n",
      "Loss in iteration 4368: 0.4420380246639666\n",
      "Theta: [-1.43520637  0.88348369  0.06302142]\n",
      "Loss in iteration 4369: 0.44202929146222486\n",
      "Theta: [-1.4353723   0.88359213  0.06301814]\n",
      "Loss in iteration 4370: 0.44202056205737167\n",
      "Theta: [-1.4355382   0.88370055  0.06301486]\n",
      "Loss in iteration 4371: 0.44201183644731323\n",
      "Theta: [-1.43570405  0.88380895  0.06301157]\n",
      "Loss in iteration 4372: 0.4420031146299575\n",
      "Theta: [-1.43586987  0.88391733  0.06300829]\n",
      "Loss in iteration 4373: 0.4419943966032129\n",
      "Theta: [-1.43603565  0.88402569  0.06300501]\n",
      "Loss in iteration 4374: 0.4419856823649906\n",
      "Theta: [-1.43620139  0.88413403  0.06300173]\n",
      "Loss in iteration 4375: 0.44197697191320195\n",
      "Theta: [-1.4363671   0.88424234  0.06299845]\n",
      "Loss in iteration 4376: 0.44196826524576044\n",
      "Theta: [-1.43653277  0.88435064  0.06299517]\n",
      "Loss in iteration 4377: 0.44195956236058087\n",
      "Theta: [-1.4366984   0.88445891  0.06299189]\n",
      "Loss in iteration 4378: 0.44195086325557936\n",
      "Theta: [-1.43686399  0.88456717  0.06298861]\n",
      "Loss in iteration 4379: 0.44194216792867347\n",
      "Theta: [-1.43702954  0.8846754   0.06298533]\n",
      "Loss in iteration 4380: 0.44193347637778196\n",
      "Theta: [-1.43719506  0.88478361  0.06298205]\n",
      "Loss in iteration 4381: 0.4419247886008255\n",
      "Theta: [-1.43736054  0.8848918   0.06297877]\n",
      "Loss in iteration 4382: 0.44191610459572594\n",
      "Theta: [-1.43752598  0.88499996  0.06297549]\n",
      "Loss in iteration 4383: 0.44190742436040653\n",
      "Theta: [-1.43769139  0.88510811  0.06297221]\n",
      "Loss in iteration 4384: 0.4418987478927916\n",
      "Theta: [-1.43785676  0.88521624  0.06296893]\n",
      "Loss in iteration 4385: 0.44189007519080775\n",
      "Theta: [-1.43802209  0.88532434  0.06296565]\n",
      "Loss in iteration 4386: 0.441881406252382\n",
      "Theta: [-1.43818738  0.88543242  0.06296237]\n",
      "Loss in iteration 4387: 0.4418727410754435\n",
      "Theta: [-1.43835263  0.88554049  0.0629591 ]\n",
      "Loss in iteration 4388: 0.4418640796579224\n",
      "Theta: [-1.43851785  0.88564853  0.06295582]\n",
      "Loss in iteration 4389: 0.4418554219977506\n",
      "Theta: [-1.43868303  0.88575655  0.06295254]\n",
      "Loss in iteration 4390: 0.44184676809286105\n",
      "Theta: [-1.43884818  0.88586455  0.06294926]\n",
      "Loss in iteration 4391: 0.44183811794118844\n",
      "Theta: [-1.43901328  0.88597252  0.06294599]\n",
      "Loss in iteration 4392: 0.44182947154066854\n",
      "Theta: [-1.43917835  0.88608048  0.06294271]\n",
      "Loss in iteration 4393: 0.4418208288892388\n",
      "Theta: [-1.43934338  0.88618842  0.06293943]\n",
      "Loss in iteration 4394: 0.44181218998483796\n",
      "Theta: [-1.43950838  0.88629633  0.06293616]\n",
      "Loss in iteration 4395: 0.4418035548254062\n",
      "Theta: [-1.43967333  0.88640422  0.06293288]\n",
      "Loss in iteration 4396: 0.44179492340888493\n",
      "Theta: [-1.43983825  0.8865121   0.06292961]\n",
      "Loss in iteration 4397: 0.44178629573321726\n",
      "Theta: [-1.44000313  0.88661995  0.06292633]\n",
      "Loss in iteration 4398: 0.4417776717963474\n",
      "Theta: [-1.44016798  0.88672778  0.06292305]\n",
      "Loss in iteration 4399: 0.4417690515962213\n",
      "Theta: [-1.44033279  0.88683559  0.06291978]\n",
      "Loss in iteration 4400: 0.4417604351307859\n",
      "Theta: [-1.44049756  0.88694337  0.0629165 ]\n",
      "Loss in iteration 4401: 0.44175182239798977\n",
      "Theta: [-1.44066229  0.88705114  0.06291323]\n",
      "Loss in iteration 4402: 0.44174321339578293\n",
      "Theta: [-1.44082699  0.88715889  0.06290996]\n",
      "Loss in iteration 4403: 0.4417346081221165\n",
      "Theta: [-1.44099165  0.88726661  0.06290668]\n",
      "Loss in iteration 4404: 0.4417260065749435\n",
      "Theta: [-1.44115627  0.88737432  0.06290341]\n",
      "Loss in iteration 4405: 0.4417174087522179\n",
      "Theta: [-1.44132085  0.887482    0.06290013]\n",
      "Loss in iteration 4406: 0.44170881465189527\n",
      "Theta: [-1.4414854   0.88758966  0.06289686]\n",
      "Loss in iteration 4407: 0.4417002242719322\n",
      "Theta: [-1.44164991  0.8876973   0.06289359]\n",
      "Loss in iteration 4408: 0.44169163761028735\n",
      "Theta: [-1.44181438  0.88780492  0.06289032]\n",
      "Loss in iteration 4409: 0.4416830546649201\n",
      "Theta: [-1.44197882  0.88791252  0.06288704]\n",
      "Loss in iteration 4410: 0.4416744754337916\n",
      "Theta: [-1.44214322  0.8880201   0.06288377]\n",
      "Loss in iteration 4411: 0.4416658999148643\n",
      "Theta: [-1.44230758  0.88812766  0.0628805 ]\n",
      "Loss in iteration 4412: 0.44165732810610214\n",
      "Theta: [-1.4424719   0.88823519  0.06287723]\n",
      "Loss in iteration 4413: 0.4416487600054701\n",
      "Theta: [-1.44263619  0.88834271  0.06287396]\n",
      "Loss in iteration 4414: 0.441640195610935\n",
      "Theta: [-1.44280044  0.8884502   0.06287068]\n",
      "Loss in iteration 4415: 0.4416316349204646\n",
      "Theta: [-1.44296465  0.88855768  0.06286741]\n",
      "Loss in iteration 4416: 0.44162307793202804\n",
      "Theta: [-1.44312883  0.88866513  0.06286414]\n",
      "Loss in iteration 4417: 0.44161452464359646\n",
      "Theta: [-1.44329297  0.88877256  0.06286087]\n",
      "Loss in iteration 4418: 0.44160597505314186\n",
      "Theta: [-1.44345707  0.88887997  0.0628576 ]\n",
      "Loss in iteration 4419: 0.4415974291586375\n",
      "Theta: [-1.44362114  0.88898736  0.06285433]\n",
      "Loss in iteration 4420: 0.44158888695805837\n",
      "Theta: [-1.44378517  0.88909473  0.06285106]\n",
      "Loss in iteration 4421: 0.4415803484493806\n",
      "Theta: [-1.44394916  0.88920208  0.06284779]\n",
      "Loss in iteration 4422: 0.441571813630582\n",
      "Theta: [-1.44411311  0.8893094   0.06284452]\n",
      "Loss in iteration 4423: 0.4415632824996411\n",
      "Theta: [-1.44427703  0.88941671  0.06284125]\n",
      "Loss in iteration 4424: 0.4415547550545388\n",
      "Theta: [-1.44444091  0.889524    0.06283798]\n",
      "Loss in iteration 4425: 0.4415462312932561\n",
      "Theta: [-1.44460475  0.88963126  0.06283472]\n",
      "Loss in iteration 4426: 0.44153771121377666\n",
      "Theta: [-1.44476856  0.8897385   0.06283145]\n",
      "Loss in iteration 4427: 0.44152919481408454\n",
      "Theta: [-1.44493233  0.88984573  0.06282818]\n",
      "Loss in iteration 4428: 0.441520682092166\n",
      "Theta: [-1.44509606  0.88995293  0.06282491]\n",
      "Loss in iteration 4429: 0.44151217304600754\n",
      "Theta: [-1.44525976  0.89006011  0.06282164]\n",
      "Loss in iteration 4430: 0.4415036676735982\n",
      "Theta: [-1.44542342  0.89016727  0.06281838]\n",
      "Loss in iteration 4431: 0.44149516597292765\n",
      "Theta: [-1.44558704  0.89027441  0.06281511]\n",
      "Loss in iteration 4432: 0.44148666794198704\n",
      "Theta: [-1.44575063  0.89038153  0.06281184]\n",
      "Loss in iteration 4433: 0.4414781735787694\n",
      "Theta: [-1.44591418  0.89048862  0.06280858]\n",
      "Loss in iteration 4434: 0.44146968288126814\n",
      "Theta: [-1.44607769  0.8905957   0.06280531]\n",
      "Loss in iteration 4435: 0.441461195847479\n",
      "Theta: [-1.44624116  0.89070276  0.06280204]\n",
      "Loss in iteration 4436: 0.4414527124753985\n",
      "Theta: [-1.4464046   0.89080979  0.06279878]\n",
      "Loss in iteration 4437: 0.44144423276302464\n",
      "Theta: [-1.446568    0.89091681  0.06279551]\n",
      "Loss in iteration 4438: 0.44143575670835683\n",
      "Theta: [-1.44673137  0.8910238   0.06279225]\n",
      "Loss in iteration 4439: 0.4414272843093958\n",
      "Theta: [-1.4468947   0.89113077  0.06278898]\n",
      "Loss in iteration 4440: 0.4414188155641437\n",
      "Theta: [-1.44705799  0.89123772  0.06278572]\n",
      "Loss in iteration 4441: 0.441410350470604\n",
      "Theta: [-1.44722124  0.89134465  0.06278245]\n",
      "Loss in iteration 4442: 0.44140188902678146\n",
      "Theta: [-1.44738446  0.89145156  0.06277919]\n",
      "Loss in iteration 4443: 0.4413934312306821\n",
      "Theta: [-1.44754764  0.89155845  0.06277592]\n",
      "Loss in iteration 4444: 0.4413849770803136\n",
      "Theta: [-1.44771079  0.89166532  0.06277266]\n",
      "Loss in iteration 4445: 0.44137652657368454\n",
      "Theta: [-1.4478739   0.89177217  0.0627694 ]\n",
      "Loss in iteration 4446: 0.4413680797088055\n",
      "Theta: [-1.44803697  0.891879    0.06276613]\n",
      "Loss in iteration 4447: 0.4413596364836877\n",
      "Theta: [-1.4482      0.8919858   0.06276287]\n",
      "Loss in iteration 4448: 0.441351196896344\n",
      "Theta: [-1.448363    0.89209259  0.06275961]\n",
      "Loss in iteration 4449: 0.4413427609447889\n",
      "Theta: [-1.44852596  0.89219935  0.06275634]\n",
      "Loss in iteration 4450: 0.4413343286270377\n",
      "Theta: [-1.44868889  0.8923061   0.06275308]\n",
      "Loss in iteration 4451: 0.4413258999411073\n",
      "Theta: [-1.44885177  0.89241282  0.06274982]\n",
      "Loss in iteration 4452: 0.4413174748850161\n",
      "Theta: [-1.44901463  0.89251953  0.06274656]\n",
      "Loss in iteration 4453: 0.4413090534567836\n",
      "Theta: [-1.44917744  0.89262621  0.0627433 ]\n",
      "Loss in iteration 4454: 0.4413006356544306\n",
      "Theta: [-1.44934022  0.89273287  0.06274004]\n",
      "Loss in iteration 4455: 0.4412922214759794\n",
      "Theta: [-1.44950296  0.89283951  0.06273677]\n",
      "Loss in iteration 4456: 0.44128381091945373\n",
      "Theta: [-1.44966567  0.89294613  0.06273351]\n",
      "Loss in iteration 4457: 0.4412754039828784\n",
      "Theta: [-1.44982834  0.89305273  0.06273025]\n",
      "Loss in iteration 4458: 0.44126700066427943\n",
      "Theta: [-1.44999097  0.89315931  0.06272699]\n",
      "Loss in iteration 4459: 0.4412586009616848\n",
      "Theta: [-1.45015357  0.89326587  0.06272373]\n",
      "Loss in iteration 4460: 0.4412502048731232\n",
      "Theta: [-1.45031613  0.8933724   0.06272047]\n",
      "Loss in iteration 4461: 0.4412418123966249\n",
      "Theta: [-1.45047865  0.89347892  0.06271721]\n",
      "Loss in iteration 4462: 0.4412334235302216\n",
      "Theta: [-1.45064114  0.89358542  0.06271395]\n",
      "Loss in iteration 4463: 0.44122503827194587\n",
      "Theta: [-1.45080359  0.89369189  0.06271069]\n",
      "Loss in iteration 4464: 0.4412166566198322\n",
      "Theta: [-1.450966    0.89379835  0.06270744]\n",
      "Loss in iteration 4465: 0.4412082785719162\n",
      "Theta: [-1.45112838  0.89390478  0.06270418]\n",
      "Loss in iteration 4466: 0.44119990412623444\n",
      "Theta: [-1.45129072  0.89401119  0.06270092]\n",
      "Loss in iteration 4467: 0.44119153328082544\n",
      "Theta: [-1.45145302  0.89411759  0.06269766]\n",
      "Loss in iteration 4468: 0.4411831660337285\n",
      "Theta: [-1.45161529  0.89422396  0.0626944 ]\n",
      "Loss in iteration 4469: 0.4411748023829844\n",
      "Theta: [-1.45177752  0.89433031  0.06269115]\n",
      "Loss in iteration 4470: 0.4411664423266354\n",
      "Theta: [-1.45193972  0.89443664  0.06268789]\n",
      "Loss in iteration 4471: 0.4411580858627252\n",
      "Theta: [-1.45210188  0.89454295  0.06268463]\n",
      "Loss in iteration 4472: 0.4411497329892984\n",
      "Theta: [-1.452264    0.89464924  0.06268137]\n",
      "Loss in iteration 4473: 0.4411413837044009\n",
      "Theta: [-1.45242609  0.89475551  0.06267812]\n",
      "Loss in iteration 4474: 0.4411330380060804\n",
      "Theta: [-1.45258814  0.89486176  0.06267486]\n",
      "Loss in iteration 4475: 0.4411246958923856\n",
      "Theta: [-1.45275015  0.89496799  0.0626716 ]\n",
      "Loss in iteration 4476: 0.4411163573613665\n",
      "Theta: [-1.45291213  0.8950742   0.06266835]\n",
      "Loss in iteration 4477: 0.44110802241107455\n",
      "Theta: [-1.45307407  0.89518038  0.06266509]\n",
      "Loss in iteration 4478: 0.44109969103956226\n",
      "Theta: [-1.45323598  0.89528655  0.06266184]\n",
      "Loss in iteration 4479: 0.44109136324488385\n",
      "Theta: [-1.45339784  0.89539269  0.06265858]\n",
      "Loss in iteration 4480: 0.44108303902509427\n",
      "Theta: [-1.45355968  0.89549882  0.06265533]\n",
      "Loss in iteration 4481: 0.44107471837825046\n",
      "Theta: [-1.45372147  0.89560493  0.06265207]\n",
      "Loss in iteration 4482: 0.4410664013024103\n",
      "Theta: [-1.45388323  0.89571101  0.06264882]\n",
      "Loss in iteration 4483: 0.4410580877956329\n",
      "Theta: [-1.45404496  0.89581707  0.06264556]\n",
      "Loss in iteration 4484: 0.4410497778559788\n",
      "Theta: [-1.45420665  0.89592312  0.06264231]\n",
      "Loss in iteration 4485: 0.4410414714815098\n",
      "Theta: [-1.4543683   0.89602914  0.06263906]\n",
      "Loss in iteration 4486: 0.441033168670289\n",
      "Theta: [-1.45452991  0.89613514  0.0626358 ]\n",
      "Loss in iteration 4487: 0.44102486942038105\n",
      "Theta: [-1.45469149  0.89624112  0.06263255]\n",
      "Loss in iteration 4488: 0.4410165737298516\n",
      "Theta: [-1.45485304  0.89634708  0.0626293 ]\n",
      "Loss in iteration 4489: 0.44100828159676747\n",
      "Theta: [-1.45501454  0.89645303  0.06262605]\n",
      "Loss in iteration 4490: 0.4409999930191973\n",
      "Theta: [-1.45517601  0.89655895  0.06262279]\n",
      "Loss in iteration 4491: 0.4409917079952105\n",
      "Theta: [-1.45533745  0.89666485  0.06261954]\n",
      "Loss in iteration 4492: 0.44098342652287803\n",
      "Theta: [-1.45549885  0.89677072  0.06261629]\n",
      "Loss in iteration 4493: 0.44097514860027226\n",
      "Theta: [-1.45566021  0.89687658  0.06261304]\n",
      "Loss in iteration 4494: 0.4409668742254666\n",
      "Theta: [-1.45582154  0.89698242  0.06260979]\n",
      "Loss in iteration 4495: 0.44095860339653575\n",
      "Theta: [-1.45598283  0.89708824  0.06260654]\n",
      "Loss in iteration 4496: 0.44095033611155615\n",
      "Theta: [-1.45614408  0.89719404  0.06260328]\n",
      "Loss in iteration 4497: 0.44094207236860483\n",
      "Theta: [-1.4563053   0.89729981  0.06260003]\n",
      "Loss in iteration 4498: 0.4409338121657606\n",
      "Theta: [-1.45646648  0.89740557  0.06259678]\n",
      "Loss in iteration 4499: 0.44092555550110357\n",
      "Theta: [-1.45662763  0.89751131  0.06259353]\n",
      "Loss in iteration 4500: 0.44091730237271487\n",
      "Theta: [-1.45678874  0.89761702  0.06259028]\n",
      "Loss in iteration 4501: 0.440909052778677\n",
      "Theta: [-1.45694982  0.89772272  0.06258703]\n",
      "Loss in iteration 4502: 0.44090080671707405\n",
      "Theta: [-1.45711086  0.89782839  0.06258378]\n",
      "Loss in iteration 4503: 0.44089256418599093\n",
      "Theta: [-1.45727186  0.89793405  0.06258054]\n",
      "Loss in iteration 4504: 0.44088432518351395\n",
      "Theta: [-1.45743283  0.89803968  0.06257729]\n",
      "Loss in iteration 4505: 0.44087608970773107\n",
      "Theta: [-1.45759376  0.8981453   0.06257404]\n",
      "Loss in iteration 4506: 0.440867857756731\n",
      "Theta: [-1.45775465  0.89825089  0.06257079]\n",
      "Loss in iteration 4507: 0.44085962932860434\n",
      "Theta: [-1.45791551  0.89835646  0.06256754]\n",
      "Loss in iteration 4508: 0.4408514044214424\n",
      "Theta: [-1.45807633  0.89846201  0.06256429]\n",
      "Loss in iteration 4509: 0.440843183033338\n",
      "Theta: [-1.45823712  0.89856755  0.06256105]\n",
      "Loss in iteration 4510: 0.4408349651623852\n",
      "Theta: [-1.45839787  0.89867306  0.0625578 ]\n",
      "Loss in iteration 4511: 0.4408267508066795\n",
      "Theta: [-1.45855859  0.89877855  0.06255455]\n",
      "Loss in iteration 4512: 0.4408185399643173\n",
      "Theta: [-1.45871927  0.89888402  0.06255131]\n",
      "Loss in iteration 4513: 0.4408103326333969\n",
      "Theta: [-1.45887991  0.89898947  0.06254806]\n",
      "Loss in iteration 4514: 0.4408021288120172\n",
      "Theta: [-1.45904052  0.8990949   0.06254481]\n",
      "Loss in iteration 4515: 0.4407939284982787\n",
      "Theta: [-1.45920109  0.89920031  0.06254157]\n",
      "Loss in iteration 4516: 0.4407857316902833\n",
      "Theta: [-1.45936163  0.8993057   0.06253832]\n",
      "Loss in iteration 4517: 0.440777538386134\n",
      "Theta: [-1.45952213  0.89941107  0.06253508]\n",
      "Loss in iteration 4518: 0.44076934858393485\n",
      "Theta: [-1.4596826   0.89951642  0.06253183]\n",
      "Loss in iteration 4519: 0.44076116228179174\n",
      "Theta: [-1.45984303  0.89962175  0.06252858]\n",
      "Loss in iteration 4520: 0.440752979477811\n",
      "Theta: [-1.46000342  0.89972706  0.06252534]\n",
      "Loss in iteration 4521: 0.44074480017010126\n",
      "Theta: [-1.46016378  0.89983235  0.0625221 ]\n",
      "Loss in iteration 4522: 0.4407366243567715\n",
      "Theta: [-1.4603241   0.89993761  0.06251885]\n",
      "Loss in iteration 4523: 0.44072845203593247\n",
      "Theta: [-1.46048439  0.90004286  0.06251561]\n",
      "Loss in iteration 4524: 0.44072028320569606\n",
      "Theta: [-1.46064464  0.90014809  0.06251236]\n",
      "Loss in iteration 4525: 0.4407121178641754\n",
      "Theta: [-1.46080485  0.9002533   0.06250912]\n",
      "Loss in iteration 4526: 0.4407039560094849\n",
      "Theta: [-1.46096503  0.90035848  0.06250588]\n",
      "Loss in iteration 4527: 0.44069579763974026\n",
      "Theta: [-1.46112518  0.90046365  0.06250263]\n",
      "Loss in iteration 4528: 0.44068764275305844\n",
      "Theta: [-1.46128528  0.9005688   0.06249939]\n",
      "Loss in iteration 4529: 0.4406794913475575\n",
      "Theta: [-1.46144536  0.90067392  0.06249615]\n",
      "Loss in iteration 4530: 0.44067134342135683\n",
      "Theta: [-1.46160539  0.90077903  0.06249291]\n",
      "Loss in iteration 4531: 0.4406631989725773\n",
      "Theta: [-1.46176539  0.90088411  0.06248966]\n",
      "Loss in iteration 4532: 0.440655057999341\n",
      "Theta: [-1.46192536  0.90098918  0.06248642]\n",
      "Loss in iteration 4533: 0.4406469204997708\n",
      "Theta: [-1.46208529  0.90109423  0.06248318]\n",
      "Loss in iteration 4534: 0.44063878647199123\n",
      "Theta: [-1.46224518  0.90119925  0.06247994]\n",
      "Loss in iteration 4535: 0.4406306559141283\n",
      "Theta: [-1.46240504  0.90130426  0.0624767 ]\n",
      "Loss in iteration 4536: 0.44062252882430863\n",
      "Theta: [-1.46256487  0.90140924  0.06247346]\n",
      "Loss in iteration 4537: 0.44061440520066064\n",
      "Theta: [-1.46272466  0.9015142   0.06247022]\n",
      "Loss in iteration 4538: 0.4406062850413137\n",
      "Theta: [-1.46288441  0.90161915  0.06246698]\n",
      "Loss in iteration 4539: 0.4405981683443986\n",
      "Theta: [-1.46304412  0.90172407  0.06246374]\n",
      "Loss in iteration 4540: 0.4405900551080474\n",
      "Theta: [-1.46320381  0.90182898  0.0624605 ]\n",
      "Loss in iteration 4541: 0.4405819453303931\n",
      "Theta: [-1.46336345  0.90193386  0.06245726]\n",
      "Loss in iteration 4542: 0.4405738390095702\n",
      "Theta: [-1.46352306  0.90203872  0.06245402]\n",
      "Loss in iteration 4543: 0.4405657361437145\n",
      "Theta: [-1.46368264  0.90214357  0.06245078]\n",
      "Loss in iteration 4544: 0.4405576367309631\n",
      "Theta: [-1.46384218  0.90224839  0.06244754]\n",
      "Loss in iteration 4545: 0.44054954076945385\n",
      "Theta: [-1.46400168  0.90235319  0.0624443 ]\n",
      "Loss in iteration 4546: 0.44054144825732644\n",
      "Theta: [-1.46416115  0.90245798  0.06244106]\n",
      "Loss in iteration 4547: 0.4405333591927216\n",
      "Theta: [-1.46432058  0.90256274  0.06243783]\n",
      "Loss in iteration 4548: 0.4405252735737808\n",
      "Theta: [-1.46447998  0.90266748  0.06243459]\n",
      "Loss in iteration 4549: 0.4405171913986477\n",
      "Theta: [-1.46463934  0.9027722   0.06243135]\n",
      "Loss in iteration 4550: 0.44050911266546644\n",
      "Theta: [-1.46479867  0.90287691  0.06242811]\n",
      "Loss in iteration 4551: 0.4405010373723826\n",
      "Theta: [-1.46495796  0.90298159  0.06242488]\n",
      "Loss in iteration 4552: 0.4404929655175433\n",
      "Theta: [-1.46511722  0.90308625  0.06242164]\n",
      "Loss in iteration 4553: 0.44048489709909655\n",
      "Theta: [-1.46527644  0.90319089  0.0624184 ]\n",
      "Loss in iteration 4554: 0.44047683211519145\n",
      "Theta: [-1.46543562  0.90329551  0.06241517]\n",
      "Loss in iteration 4555: 0.44046877056397876\n",
      "Theta: [-1.46559478  0.90340012  0.06241193]\n",
      "Loss in iteration 4556: 0.44046071244361046\n",
      "Theta: [-1.46575389  0.9035047   0.0624087 ]\n",
      "Loss in iteration 4557: 0.4404526577522392\n",
      "Theta: [-1.46591297  0.90360926  0.06240546]\n",
      "Loss in iteration 4558: 0.4404446064880194\n",
      "Theta: [-1.46607201  0.9037138   0.06240222]\n",
      "Loss in iteration 4559: 0.4404365586491068\n",
      "Theta: [-1.46623102  0.90381832  0.06239899]\n",
      "Loss in iteration 4560: 0.4404285142336577\n",
      "Theta: [-1.46639     0.90392282  0.06239576]\n",
      "Loss in iteration 4561: 0.44042047323983036\n",
      "Theta: [-1.46654894  0.9040273   0.06239252]\n",
      "Loss in iteration 4562: 0.44041243566578364\n",
      "Theta: [-1.46670784  0.90413177  0.06238929]\n",
      "Loss in iteration 4563: 0.4404044015096783\n",
      "Theta: [-1.46686671  0.90423621  0.06238605]\n",
      "Loss in iteration 4564: 0.44039637076967586\n",
      "Theta: [-1.46702554  0.90434063  0.06238282]\n",
      "Loss in iteration 4565: 0.44038834344393896\n",
      "Theta: [-1.46718434  0.90444503  0.06237959]\n",
      "Loss in iteration 4566: 0.4403803195306319\n",
      "Theta: [-1.4673431   0.90454941  0.06237635]\n",
      "Loss in iteration 4567: 0.44037229902791986\n",
      "Theta: [-1.46750183  0.90465377  0.06237312]\n",
      "Loss in iteration 4568: 0.44036428193396937\n",
      "Theta: [-1.46766052  0.90475811  0.06236989]\n",
      "Loss in iteration 4569: 0.4403562682469483\n",
      "Theta: [-1.46781918  0.90486243  0.06236665]\n",
      "Loss in iteration 4570: 0.44034825796502525\n",
      "Theta: [-1.4679778   0.90496673  0.06236342]\n",
      "Loss in iteration 4571: 0.44034025108637076\n",
      "Theta: [-1.46813639  0.90507102  0.06236019]\n",
      "Loss in iteration 4572: 0.44033224760915585\n",
      "Theta: [-1.46829494  0.90517528  0.06235696]\n",
      "Loss in iteration 4573: 0.4403242475315535\n",
      "Theta: [-1.46845346  0.90527952  0.06235373]\n",
      "Loss in iteration 4574: 0.44031625085173737\n",
      "Theta: [-1.46861194  0.90538374  0.0623505 ]\n",
      "Loss in iteration 4575: 0.4403082575678824\n",
      "Theta: [-1.46877038  0.90548794  0.06234727]\n",
      "Loss in iteration 4576: 0.4403002676781647\n",
      "Theta: [-1.4689288   0.90559212  0.06234403]\n",
      "Loss in iteration 4577: 0.440292281180762\n",
      "Theta: [-1.46908717  0.90569628  0.0623408 ]\n",
      "Loss in iteration 4578: 0.44028429807385294\n",
      "Theta: [-1.46924551  0.90580042  0.06233757]\n",
      "Loss in iteration 4579: 0.4402763183556174\n",
      "Theta: [-1.46940382  0.90590454  0.06233434]\n",
      "Loss in iteration 4580: 0.4402683420242362\n",
      "Theta: [-1.46956209  0.90600865  0.06233111]\n",
      "Loss in iteration 4581: 0.44026036907789184\n",
      "Theta: [-1.46972033  0.90611273  0.06232789]\n",
      "Loss in iteration 4582: 0.44025239951476786\n",
      "Theta: [-1.46987853  0.90621679  0.06232466]\n",
      "Loss in iteration 4583: 0.44024443333304863\n",
      "Theta: [-1.47003669  0.90632083  0.06232143]\n",
      "Loss in iteration 4584: 0.4402364705309206\n",
      "Theta: [-1.47019483  0.90642485  0.0623182 ]\n",
      "Loss in iteration 4585: 0.44022851110657046\n",
      "Theta: [-1.47035292  0.90652885  0.06231497]\n",
      "Loss in iteration 4586: 0.44022055505818664\n",
      "Theta: [-1.47051098  0.90663284  0.06231174]\n",
      "Loss in iteration 4587: 0.4402126023839587\n",
      "Theta: [-1.47066901  0.9067368   0.06230851]\n",
      "Loss in iteration 4588: 0.4402046530820771\n",
      "Theta: [-1.470827    0.90684074  0.06230529]\n",
      "Loss in iteration 4589: 0.44019670715073417\n",
      "Theta: [-1.47098496  0.90694466  0.06230206]\n",
      "Loss in iteration 4590: 0.4401887645881228\n",
      "Theta: [-1.47114288  0.90704856  0.06229883]\n",
      "Loss in iteration 4591: 0.4401808253924373\n",
      "Theta: [-1.47130077  0.90715245  0.06229561]\n",
      "Loss in iteration 4592: 0.4401728895618732\n",
      "Theta: [-1.47145862  0.90725631  0.06229238]\n",
      "Loss in iteration 4593: 0.44016495709462716\n",
      "Theta: [-1.47161644  0.90736015  0.06228915]\n",
      "Loss in iteration 4594: 0.4401570279888973\n",
      "Theta: [-1.47177422  0.90746397  0.06228593]\n",
      "Loss in iteration 4595: 0.44014910224288245\n",
      "Theta: [-1.47193196  0.90756778  0.0622827 ]\n",
      "Loss in iteration 4596: 0.440141179854783\n",
      "Theta: [-1.47208968  0.90767156  0.06227947]\n",
      "Loss in iteration 4597: 0.4401332608228003\n",
      "Theta: [-1.47224735  0.90777532  0.06227625]\n",
      "Loss in iteration 4598: 0.44012534514513746\n",
      "Theta: [-1.472405    0.90787906  0.06227302]\n",
      "Loss in iteration 4599: 0.44011743281999793\n",
      "Theta: [-1.47256261  0.90798279  0.0622698 ]\n",
      "Loss in iteration 4600: 0.4401095238455868\n",
      "Theta: [-1.47272018  0.90808649  0.06226658]\n",
      "Loss in iteration 4601: 0.4401016182201104\n",
      "Theta: [-1.47287772  0.90819018  0.06226335]\n",
      "Loss in iteration 4602: 0.4400937159417763\n",
      "Theta: [-1.47303522  0.90829384  0.06226013]\n",
      "Loss in iteration 4603: 0.44008581700879285\n",
      "Theta: [-1.47319269  0.90839748  0.0622569 ]\n",
      "Loss in iteration 4604: 0.4400779214193701\n",
      "Theta: [-1.47335012  0.90850111  0.06225368]\n",
      "Loss in iteration 4605: 0.44007002917171884\n",
      "Theta: [-1.47350752  0.90860471  0.06225046]\n",
      "Loss in iteration 4606: 0.4400621402640514\n",
      "Theta: [-1.47366489  0.9087083   0.06224723]\n",
      "Loss in iteration 4607: 0.440054254694581\n",
      "Theta: [-1.47382222  0.90881186  0.06224401]\n",
      "Loss in iteration 4608: 0.4400463724615223\n",
      "Theta: [-1.47397951  0.90891541  0.06224079]\n",
      "Loss in iteration 4609: 0.4400384935630909\n",
      "Theta: [-1.47413677  0.90901893  0.06223757]\n",
      "Loss in iteration 4610: 0.4400306179975039\n",
      "Theta: [-1.474294    0.90912244  0.06223434]\n",
      "Loss in iteration 4611: 0.44002274576297923\n",
      "Theta: [-1.47445119  0.90922592  0.06223112]\n",
      "Loss in iteration 4612: 0.44001487685773616\n",
      "Theta: [-1.47460835  0.90932939  0.0622279 ]\n",
      "Loss in iteration 4613: 0.44000701127999514\n",
      "Theta: [-1.47476547  0.90943284  0.06222468]\n",
      "Loss in iteration 4614: 0.43999914902797793\n",
      "Theta: [-1.47492256  0.90953626  0.06222146]\n",
      "Loss in iteration 4615: 0.439991290099907\n",
      "Theta: [-1.47507961  0.90963967  0.06221824]\n",
      "Loss in iteration 4616: 0.43998343449400656\n",
      "Theta: [-1.47523663  0.90974306  0.06221502]\n",
      "Loss in iteration 4617: 0.4399755822085018\n",
      "Theta: [-1.47539361  0.90984642  0.0622118 ]\n",
      "Loss in iteration 4618: 0.43996773324161864\n",
      "Theta: [-1.47555056  0.90994977  0.06220858]\n",
      "Loss in iteration 4619: 0.43995988759158516\n",
      "Theta: [-1.47570748  0.9100531   0.06220536]\n",
      "Loss in iteration 4620: 0.4399520452566296\n",
      "Theta: [-1.47586436  0.91015641  0.06220214]\n",
      "Loss in iteration 4621: 0.43994420623498187\n",
      "Theta: [-1.4760212   0.91025969  0.06219892]\n",
      "Loss in iteration 4622: 0.43993637052487294\n",
      "Theta: [-1.47617801  0.91036296  0.0621957 ]\n",
      "Loss in iteration 4623: 0.4399285381245351\n",
      "Theta: [-1.47633479  0.91046621  0.06219248]\n",
      "Loss in iteration 4624: 0.43992070903220154\n",
      "Theta: [-1.47649153  0.91056944  0.06218926]\n",
      "Loss in iteration 4625: 0.4399128832461068\n",
      "Theta: [-1.47664824  0.91067265  0.06218604]\n",
      "Loss in iteration 4626: 0.4399050607644866\n",
      "Theta: [-1.47680491  0.91077584  0.06218283]\n",
      "Loss in iteration 4627: 0.43989724158557775\n",
      "Theta: [-1.47696155  0.91087901  0.06217961]\n",
      "Loss in iteration 4628: 0.43988942570761813\n",
      "Theta: [-1.47711815  0.91098216  0.06217639]\n",
      "Loss in iteration 4629: 0.4398816131288472\n",
      "Theta: [-1.47727472  0.91108529  0.06217317]\n",
      "Loss in iteration 4630: 0.4398738038475048\n",
      "Theta: [-1.47743126  0.9111884   0.06216996]\n",
      "Loss in iteration 4631: 0.4398659978618328\n",
      "Theta: [-1.47758776  0.9112915   0.06216674]\n",
      "Loss in iteration 4632: 0.4398581951700736\n",
      "Theta: [-1.47774422  0.91139457  0.06216352]\n",
      "Loss in iteration 4633: 0.43985039577047125\n",
      "Theta: [-1.47790066  0.91149762  0.06216031]\n",
      "Loss in iteration 4634: 0.43984259966127054\n",
      "Theta: [-1.47805705  0.91160065  0.06215709]\n",
      "Loss in iteration 4635: 0.4398348068407176\n",
      "Theta: [-1.47821342  0.91170367  0.06215388]\n",
      "Loss in iteration 4636: 0.4398270173070597\n",
      "Theta: [-1.47836974  0.91180666  0.06215066]\n",
      "Loss in iteration 4637: 0.4398192310585452\n",
      "Theta: [-1.47852604  0.91190963  0.06214745]\n",
      "Loss in iteration 4638: 0.43981144809342376\n",
      "Theta: [-1.4786823   0.91201259  0.06214423]\n",
      "Loss in iteration 4639: 0.4398036684099461\n",
      "Theta: [-1.47883852  0.91211552  0.06214102]\n",
      "Loss in iteration 4640: 0.43979589200636404\n",
      "Theta: [-1.47899472  0.91221844  0.0621378 ]\n",
      "Loss in iteration 4641: 0.4397881188809308\n",
      "Theta: [-1.47915087  0.91232133  0.06213459]\n",
      "Loss in iteration 4642: 0.43978034903190033\n",
      "Theta: [-1.479307    0.91242421  0.06213137]\n",
      "Loss in iteration 4643: 0.43977258245752815\n",
      "Theta: [-1.47946308  0.91252706  0.06212816]\n",
      "Loss in iteration 4644: 0.4397648191560708\n",
      "Theta: [-1.47961914  0.9126299   0.06212495]\n",
      "Loss in iteration 4645: 0.4397570591257856\n",
      "Theta: [-1.47977516  0.91273272  0.06212173]\n",
      "Loss in iteration 4646: 0.43974930236493165\n",
      "Theta: [-1.47993114  0.91283551  0.06211852]\n",
      "Loss in iteration 4647: 0.43974154887176875\n",
      "Theta: [-1.48008709  0.91293829  0.06211531]\n",
      "Loss in iteration 4648: 0.4397337986445581\n",
      "Theta: [-1.48024301  0.91304105  0.0621121 ]\n",
      "Loss in iteration 4649: 0.4397260516815614\n",
      "Theta: [-1.48039889  0.91314379  0.06210888]\n",
      "Loss in iteration 4650: 0.43971830798104294\n",
      "Theta: [-1.48055474  0.91324651  0.06210567]\n",
      "Loss in iteration 4651: 0.4397105675412663\n",
      "Theta: [-1.48071056  0.91334921  0.06210246]\n",
      "Loss in iteration 4652: 0.4397028303604978\n",
      "Theta: [-1.48086634  0.91345189  0.06209925]\n",
      "Loss in iteration 4653: 0.4396950964370039\n",
      "Theta: [-1.48102208  0.91355455  0.06209604]\n",
      "Loss in iteration 4654: 0.43968736576905265\n",
      "Theta: [-1.48117779  0.91365719  0.06209283]\n",
      "Loss in iteration 4655: 0.4396796383549129\n",
      "Theta: [-1.48133347  0.91375981  0.06208962]\n",
      "Loss in iteration 4656: 0.4396719141928553\n",
      "Theta: [-1.48148912  0.91386241  0.06208641]\n",
      "Loss in iteration 4657: 0.4396641932811506\n",
      "Theta: [-1.48164473  0.913965    0.0620832 ]\n",
      "Loss in iteration 4658: 0.4396564756180718\n",
      "Theta: [-1.4818003   0.91406756  0.06207999]\n",
      "Loss in iteration 4659: 0.43964876120189234\n",
      "Theta: [-1.48195584  0.9141701   0.06207678]\n",
      "Loss in iteration 4660: 0.439641050030887\n",
      "Theta: [-1.48211135  0.91427263  0.06207357]\n",
      "Loss in iteration 4661: 0.43963334210333144\n",
      "Theta: [-1.48226682  0.91437513  0.06207036]\n",
      "Loss in iteration 4662: 0.4396256374175029\n",
      "Theta: [-1.48242226  0.91447762  0.06206715]\n",
      "Loss in iteration 4663: 0.43961793597167953\n",
      "Theta: [-1.48257767  0.91458008  0.06206394]\n",
      "Loss in iteration 4664: 0.4396102377641406\n",
      "Theta: [-1.48273304  0.91468253  0.06206073]\n",
      "Loss in iteration 4665: 0.4396025427931665\n",
      "Theta: [-1.48288837  0.91478495  0.06205753]\n",
      "Loss in iteration 4666: 0.4395948510570387\n",
      "Theta: [-1.48304368  0.91488736  0.06205432]\n",
      "Loss in iteration 4667: 0.43958716255404007\n",
      "Theta: [-1.48319894  0.91498975  0.06205111]\n",
      "Loss in iteration 4668: 0.4395794772824542\n",
      "Theta: [-1.48335418  0.91509212  0.0620479 ]\n",
      "Loss in iteration 4669: 0.43957179524056605\n",
      "Theta: [-1.48350938  0.91519447  0.0620447 ]\n",
      "Loss in iteration 4670: 0.4395641164266619\n",
      "Theta: [-1.48366455  0.9152968   0.06204149]\n",
      "Loss in iteration 4671: 0.43955644083902856\n",
      "Theta: [-1.48381968  0.91539911  0.06203828]\n",
      "Loss in iteration 4672: 0.4395487684759546\n",
      "Theta: [-1.48397478  0.9155014   0.06203508]\n",
      "Loss in iteration 4673: 0.4395410993357293\n",
      "Theta: [-1.48412984  0.91560367  0.06203187]\n",
      "Loss in iteration 4674: 0.4395334334166433\n",
      "Theta: [-1.48428487  0.91570592  0.06202867]\n",
      "Loss in iteration 4675: 0.4395257707169882\n",
      "Theta: [-1.48443987  0.91580815  0.06202546]\n",
      "Loss in iteration 4676: 0.4395181112350569\n",
      "Theta: [-1.48459483  0.91591036  0.06202226]\n",
      "Loss in iteration 4677: 0.43951045496914326\n",
      "Theta: [-1.48474976  0.91601256  0.06201905]\n",
      "Loss in iteration 4678: 0.43950280191754215\n",
      "Theta: [-1.48490466  0.91611473  0.06201585]\n",
      "Loss in iteration 4679: 0.4394951520785499\n",
      "Theta: [-1.48505952  0.91621689  0.06201264]\n",
      "Loss in iteration 4680: 0.43948750545046367\n",
      "Theta: [-1.48521435  0.91631902  0.06200944]\n",
      "Loss in iteration 4681: 0.43947986203158196\n",
      "Theta: [-1.48536914  0.91642114  0.06200623]\n",
      "Loss in iteration 4682: 0.4394722218202042\n",
      "Theta: [-1.4855239   0.91652323  0.06200303]\n",
      "Loss in iteration 4683: 0.439464584814631\n",
      "Theta: [-1.48567863  0.91662531  0.06199983]\n",
      "Loss in iteration 4684: 0.4394569510131641\n",
      "Theta: [-1.48583332  0.91672737  0.06199662]\n",
      "Loss in iteration 4685: 0.4394493204141061\n",
      "Theta: [-1.48598798  0.91682941  0.06199342]\n",
      "Loss in iteration 4686: 0.4394416930157614\n",
      "Theta: [-1.4861426   0.91693143  0.06199022]\n",
      "Loss in iteration 4687: 0.4394340688164346\n",
      "Theta: [-1.48629719  0.91703343  0.06198702]\n",
      "Loss in iteration 4688: 0.43942644781443235\n",
      "Theta: [-1.48645175  0.91713541  0.06198381]\n",
      "Loss in iteration 4689: 0.4394188300080614\n",
      "Theta: [-1.48660627  0.91723737  0.06198061]\n",
      "Loss in iteration 4690: 0.4394112153956305\n",
      "Theta: [-1.48676076  0.91733931  0.06197741]\n",
      "Loss in iteration 4691: 0.439403603975449\n",
      "Theta: [-1.48691522  0.91744123  0.06197421]\n",
      "Loss in iteration 4692: 0.43939599574582755\n",
      "Theta: [-1.48706964  0.91754314  0.06197101]\n",
      "Loss in iteration 4693: 0.43938839070507785\n",
      "Theta: [-1.48722403  0.91764502  0.06196781]\n",
      "Loss in iteration 4694: 0.43938078885151266\n",
      "Theta: [-1.48737838  0.91774688  0.06196461]\n",
      "Loss in iteration 4695: 0.4393731901834461\n",
      "Theta: [-1.4875327   0.91784873  0.06196141]\n",
      "Loss in iteration 4696: 0.4393655946991928\n",
      "Theta: [-1.48768699  0.91795055  0.06195821]\n",
      "Loss in iteration 4697: 0.4393580023970693\n",
      "Theta: [-1.48784124  0.91805236  0.06195501]\n",
      "Loss in iteration 4698: 0.4393504132753926\n",
      "Theta: [-1.48799546  0.91815415  0.06195181]\n",
      "Loss in iteration 4699: 0.439342827332481\n",
      "Theta: [-1.48814965  0.91825592  0.06194861]\n",
      "Loss in iteration 4700: 0.43933524456665396\n",
      "Theta: [-1.4883038   0.91835767  0.06194541]\n",
      "Loss in iteration 4701: 0.43932766497623205\n",
      "Theta: [-1.48845792  0.9184594   0.06194221]\n",
      "Loss in iteration 4702: 0.4393200885595368\n",
      "Theta: [-1.488612    0.91856111  0.06193901]\n",
      "Loss in iteration 4703: 0.439312515314891\n",
      "Theta: [-1.48876606  0.9186628   0.06193581]\n",
      "Loss in iteration 4704: 0.43930494524061836\n",
      "Theta: [-1.48892007  0.91876447  0.06193262]\n",
      "Loss in iteration 4705: 0.4392973783350441\n",
      "Theta: [-1.48907406  0.91886612  0.06192942]\n",
      "Loss in iteration 4706: 0.4392898145964938\n",
      "Theta: [-1.48922801  0.91896775  0.06192622]\n",
      "Loss in iteration 4707: 0.43928225402329496\n",
      "Theta: [-1.48938193  0.91906937  0.06192302]\n",
      "Loss in iteration 4708: 0.43927469661377544\n",
      "Theta: [-1.48953581  0.91917096  0.06191983]\n",
      "Loss in iteration 4709: 0.43926714236626446\n",
      "Theta: [-1.48968966  0.91927254  0.06191663]\n",
      "Loss in iteration 4710: 0.43925959127909303\n",
      "Theta: [-1.48984348  0.9193741   0.06191343]\n",
      "Loss in iteration 4711: 0.43925204335059176\n",
      "Theta: [-1.48999726  0.91947563  0.06191024]\n",
      "Loss in iteration 4712: 0.4392444985790938\n",
      "Theta: [-1.49015101  0.91957715  0.06190704]\n",
      "Loss in iteration 4713: 0.4392369569629326\n",
      "Theta: [-1.49030472  0.91967865  0.06190385]\n",
      "Loss in iteration 4714: 0.4392294185004427\n",
      "Theta: [-1.49045841  0.91978013  0.06190065]\n",
      "Loss in iteration 4715: 0.43922188318996036\n",
      "Theta: [-1.49061206  0.91988159  0.06189746]\n",
      "Loss in iteration 4716: 0.43921435102982204\n",
      "Theta: [-1.49076567  0.91998303  0.06189426]\n",
      "Loss in iteration 4717: 0.43920682201836597\n",
      "Theta: [-1.49091925  0.92008445  0.06189107]\n",
      "Loss in iteration 4718: 0.43919929615393116\n",
      "Theta: [-1.4910728   0.92018586  0.06188787]\n",
      "Loss in iteration 4719: 0.43919177343485777\n",
      "Theta: [-1.49122632  0.92028724  0.06188468]\n",
      "Loss in iteration 4720: 0.439184253859487\n",
      "Theta: [-1.4913798   0.9203886   0.06188148]\n",
      "Loss in iteration 4721: 0.4391767374261613\n",
      "Theta: [-1.49153325  0.92048995  0.06187829]\n",
      "Loss in iteration 4722: 0.43916922413322385\n",
      "Theta: [-1.49168666  0.92059128  0.0618751 ]\n",
      "Loss in iteration 4723: 0.43916171397901943\n",
      "Theta: [-1.49184004  0.92069258  0.0618719 ]\n",
      "Loss in iteration 4724: 0.4391542069618934\n",
      "Theta: [-1.49199339  0.92079387  0.06186871]\n",
      "Loss in iteration 4725: 0.4391467030801923\n",
      "Theta: [-1.49214671  0.92089514  0.06186552]\n",
      "Loss in iteration 4726: 0.439139202332264\n",
      "Theta: [-1.49229999  0.92099639  0.06186233]\n",
      "Loss in iteration 4727: 0.4391317047164574\n",
      "Theta: [-1.49245324  0.92109762  0.06185913]\n",
      "Loss in iteration 4728: 0.43912421023112214\n",
      "Theta: [-1.49260645  0.92119883  0.06185594]\n",
      "Loss in iteration 4729: 0.4391167188746094\n",
      "Theta: [-1.49275963  0.92130002  0.06185275]\n",
      "Loss in iteration 4730: 0.43910923064527096\n",
      "Theta: [-1.49291278  0.9214012   0.06184956]\n",
      "Loss in iteration 4731: 0.43910174554145986\n",
      "Theta: [-1.49306589  0.92150235  0.06184637]\n",
      "Loss in iteration 4732: 0.43909426356153064\n",
      "Theta: [-1.49321898  0.92160349  0.06184318]\n",
      "Loss in iteration 4733: 0.4390867847038384\n",
      "Theta: [-1.49337202  0.9217046   0.06183999]\n",
      "Loss in iteration 4734: 0.4390793089667391\n",
      "Theta: [-1.49352504  0.9218057   0.0618368 ]\n",
      "Loss in iteration 4735: 0.4390718363485906\n",
      "Theta: [-1.49367802  0.92190678  0.06183361]\n",
      "Loss in iteration 4736: 0.4390643668477511\n",
      "Theta: [-1.49383097  0.92200784  0.06183042]\n",
      "Loss in iteration 4737: 0.43905690046258017\n",
      "Theta: [-1.49398388  0.92210888  0.06182723]\n",
      "Loss in iteration 4738: 0.43904943719143824\n",
      "Theta: [-1.49413677  0.9222099   0.06182404]\n",
      "Loss in iteration 4739: 0.43904197703268727\n",
      "Theta: [-1.49428962  0.9223109   0.06182085]\n",
      "Loss in iteration 4740: 0.4390345199846896\n",
      "Theta: [-1.49444243  0.92241188  0.06181766]\n",
      "Loss in iteration 4741: 0.43902706604580943\n",
      "Theta: [-1.49459521  0.92251285  0.06181447]\n",
      "Loss in iteration 4742: 0.4390196152144113\n",
      "Theta: [-1.49474796  0.92261379  0.06181129]\n",
      "Loss in iteration 4743: 0.4390121674888611\n",
      "Theta: [-1.49490068  0.92271471  0.0618081 ]\n",
      "Loss in iteration 4744: 0.4390047228675262\n",
      "Theta: [-1.49505336  0.92281562  0.06180491]\n",
      "Loss in iteration 4745: 0.4389972813487742\n",
      "Theta: [-1.49520601  0.92291651  0.06180172]\n",
      "Loss in iteration 4746: 0.43898984293097437\n",
      "Theta: [-1.49535863  0.92301738  0.06179854]\n",
      "Loss in iteration 4747: 0.4389824076124967\n",
      "Theta: [-1.49551121  0.92311823  0.06179535]\n",
      "Loss in iteration 4748: 0.4389749753917127\n",
      "Theta: [-1.49566376  0.92321906  0.06179216]\n",
      "Loss in iteration 4749: 0.4389675462669944\n",
      "Theta: [-1.49581628  0.92331987  0.06178898]\n",
      "Loss in iteration 4750: 0.4389601202367153\n",
      "Theta: [-1.49596876  0.92342066  0.06178579]\n",
      "Loss in iteration 4751: 0.43895269729924963\n",
      "Theta: [-1.49612121  0.92352143  0.0617826 ]\n",
      "Loss in iteration 4752: 0.4389452774529729\n",
      "Theta: [-1.49627363  0.92362219  0.06177942]\n",
      "Loss in iteration 4753: 0.43893786069626173\n",
      "Theta: [-1.49642602  0.92372292  0.06177623]\n",
      "Loss in iteration 4754: 0.43893044702749334\n",
      "Theta: [-1.49657837  0.92382364  0.06177305]\n",
      "Loss in iteration 4755: 0.4389230364450467\n",
      "Theta: [-1.49673069  0.92392434  0.06176986]\n",
      "Loss in iteration 4756: 0.4389156289473014\n",
      "Theta: [-1.49688297  0.92402502  0.06176668]\n",
      "Loss in iteration 4757: 0.43890822453263817\n",
      "Theta: [-1.49703522  0.92412567  0.06176349]\n",
      "Loss in iteration 4758: 0.43890082319943846\n",
      "Theta: [-1.49718744  0.92422632  0.06176031]\n",
      "Loss in iteration 4759: 0.4388934249460854\n",
      "Theta: [-1.49733963  0.92432694  0.06175713]\n",
      "Loss in iteration 4760: 0.4388860297709627\n",
      "Theta: [-1.49749178  0.92442754  0.06175394]\n",
      "Loss in iteration 4761: 0.43887863767245533\n",
      "Theta: [-1.4976439   0.92452812  0.06175076]\n",
      "Loss in iteration 4762: 0.4388712486489494\n",
      "Theta: [-1.49779599  0.92462869  0.06174758]\n",
      "Loss in iteration 4763: 0.4388638626988317\n",
      "Theta: [-1.49794805  0.92472923  0.06174439]\n",
      "Loss in iteration 4764: 0.43885647982049014\n",
      "Theta: [-1.49810007  0.92482976  0.06174121]\n",
      "Loss in iteration 4765: 0.43884910001231425\n",
      "Theta: [-1.49825206  0.92493027  0.06173803]\n",
      "Loss in iteration 4766: 0.438841723272694\n",
      "Theta: [-1.49840401  0.92503076  0.06173485]\n",
      "Loss in iteration 4767: 0.43883434960002043\n",
      "Theta: [-1.49855594  0.92513123  0.06173167]\n",
      "Loss in iteration 4768: 0.4388269789926858\n",
      "Theta: [-1.49870783  0.92523168  0.06172849]\n",
      "Loss in iteration 4769: 0.43881961144908366\n",
      "Theta: [-1.49885968  0.92533211  0.0617253 ]\n",
      "Loss in iteration 4770: 0.43881224696760796\n",
      "Theta: [-1.49901151  0.92543253  0.06172212]\n",
      "Loss in iteration 4771: 0.4388048855466543\n",
      "Theta: [-1.4991633   0.92553292  0.06171894]\n",
      "Loss in iteration 4772: 0.43879752718461895\n",
      "Theta: [-1.49931506  0.9256333   0.06171576]\n",
      "Loss in iteration 4773: 0.4387901718798993\n",
      "Theta: [-1.49946678  0.92573365  0.06171258]\n",
      "Loss in iteration 4774: 0.438782819630894\n",
      "Theta: [-1.49961848  0.92583399  0.0617094 ]\n",
      "Loss in iteration 4775: 0.43877547043600246\n",
      "Theta: [-1.49977014  0.92593431  0.06170622]\n",
      "Loss in iteration 4776: 0.43876812429362516\n",
      "Theta: [-1.49992176  0.92603461  0.06170304]\n",
      "Loss in iteration 4777: 0.4387607812021638\n",
      "Theta: [-1.50007336  0.92613489  0.06169986]\n",
      "Loss in iteration 4778: 0.43875344116002096\n",
      "Theta: [-1.50022492  0.92623515  0.06169669]\n",
      "Loss in iteration 4779: 0.43874610416560017\n",
      "Theta: [-1.50037645  0.9263354   0.06169351]\n",
      "Loss in iteration 4780: 0.43873877021730623\n",
      "Theta: [-1.50052795  0.92643562  0.06169033]\n",
      "Loss in iteration 4781: 0.43873143931354497\n",
      "Theta: [-1.50067941  0.92653583  0.06168715]\n",
      "Loss in iteration 4782: 0.43872411145272294\n",
      "Theta: [-1.50083084  0.92663602  0.06168397]\n",
      "Loss in iteration 4783: 0.438716786633248\n",
      "Theta: [-1.50098224  0.92673618  0.0616808 ]\n",
      "Loss in iteration 4784: 0.4387094648535289\n",
      "Theta: [-1.5011336   0.92683633  0.06167762]\n",
      "Loss in iteration 4785: 0.4387021461119756\n",
      "Theta: [-1.50128493  0.92693646  0.06167444]\n",
      "Loss in iteration 4786: 0.4386948304069989\n",
      "Theta: [-1.50143623  0.92703658  0.06167126]\n",
      "Loss in iteration 4787: 0.4386875177370106\n",
      "Theta: [-1.5015875   0.92713667  0.06166809]\n",
      "Loss in iteration 4788: 0.43868020810042374\n",
      "Theta: [-1.50173874  0.92723674  0.06166491]\n",
      "Loss in iteration 4789: 0.4386729014956522\n",
      "Theta: [-1.50188994  0.9273368   0.06166174]\n",
      "Loss in iteration 4790: 0.4386655979211111\n",
      "Theta: [-1.50204111  0.92743684  0.06165856]\n",
      "Loss in iteration 4791: 0.4386582973752163\n",
      "Theta: [-1.50219224  0.92753685  0.06165538]\n",
      "Loss in iteration 4792: 0.4386509998563847\n",
      "Theta: [-1.50234335  0.92763685  0.06165221]\n",
      "Loss in iteration 4793: 0.4386437053630347\n",
      "Theta: [-1.50249442  0.92773683  0.06164903]\n",
      "Loss in iteration 4794: 0.43863641389358515\n",
      "Theta: [-1.50264546  0.92783679  0.06164586]\n",
      "Loss in iteration 4795: 0.4386291254464561\n",
      "Theta: [-1.50279646  0.92793674  0.06164269]\n",
      "Loss in iteration 4796: 0.43862184002006865\n",
      "Theta: [-1.50294743  0.92803666  0.06163951]\n",
      "Loss in iteration 4797: 0.438614557612845\n",
      "Theta: [-1.50309838  0.92813657  0.06163634]\n",
      "Loss in iteration 4798: 0.43860727822320844\n",
      "Theta: [-1.50324928  0.92823645  0.06163316]\n",
      "Loss in iteration 4799: 0.438600001849583\n",
      "Theta: [-1.50340016  0.92833632  0.06162999]\n",
      "Loss in iteration 4800: 0.43859272849039355\n",
      "Theta: [-1.503551    0.92843617  0.06162682]\n",
      "Loss in iteration 4801: 0.4385854581440668\n",
      "Theta: [-1.50370181  0.928536    0.06162365]\n",
      "Loss in iteration 4802: 0.4385781908090298\n",
      "Theta: [-1.50385259  0.92863581  0.06162047]\n",
      "Loss in iteration 4803: 0.4385709264837107\n",
      "Theta: [-1.50400333  0.92873561  0.0616173 ]\n",
      "Loss in iteration 4804: 0.4385636651665387\n",
      "Theta: [-1.50415405  0.92883538  0.06161413]\n",
      "Loss in iteration 4805: 0.4385564068559444\n",
      "Theta: [-1.50430473  0.92893514  0.06161096]\n",
      "Loss in iteration 4806: 0.4385491515503586\n",
      "Theta: [-1.50445538  0.92903487  0.06160778]\n",
      "Loss in iteration 4807: 0.4385418992482139\n",
      "Theta: [-1.50460599  0.92913459  0.06160461]\n",
      "Loss in iteration 4808: 0.43853464994794344\n",
      "Theta: [-1.50475657  0.92923429  0.06160144]\n",
      "Loss in iteration 4809: 0.43852740364798154\n",
      "Theta: [-1.50490712  0.92933397  0.06159827]\n",
      "Loss in iteration 4810: 0.43852016034676367\n",
      "Theta: [-1.50505764  0.92943363  0.0615951 ]\n",
      "Loss in iteration 4811: 0.43851292004272613\n",
      "Theta: [-1.50520813  0.92953328  0.06159193]\n",
      "Loss in iteration 4812: 0.4385056827343061\n",
      "Theta: [-1.50535858  0.9296329   0.06158876]\n",
      "Loss in iteration 4813: 0.43849844841994207\n",
      "Theta: [-1.505509    0.92973251  0.06158559]\n",
      "Loss in iteration 4814: 0.43849121709807304\n",
      "Theta: [-1.50565939  0.9298321   0.06158242]\n",
      "Loss in iteration 4815: 0.4384839887671398\n",
      "Theta: [-1.50580974  0.92993167  0.06157925]\n",
      "Loss in iteration 4816: 0.43847676342558345\n",
      "Theta: [-1.50596007  0.93003122  0.06157608]\n",
      "Loss in iteration 4817: 0.4384695410718465\n",
      "Theta: [-1.50611036  0.93013075  0.06157292]\n",
      "Loss in iteration 4818: 0.4384623217043723\n",
      "Theta: [-1.50626062  0.93023026  0.06156975]\n",
      "Loss in iteration 4819: 0.4384551053216052\n",
      "Theta: [-1.50641084  0.93032975  0.06156658]\n",
      "Loss in iteration 4820: 0.4384478919219906\n",
      "Theta: [-1.50656104  0.93042923  0.06156341]\n",
      "Loss in iteration 4821: 0.4384406815039747\n",
      "Theta: [-1.5067112   0.93052869  0.06156024]\n",
      "Loss in iteration 4822: 0.4384334740660051\n",
      "Theta: [-1.50686133  0.93062813  0.06155708]\n",
      "Loss in iteration 4823: 0.4384262696065299\n",
      "Theta: [-1.50701143  0.93072755  0.06155391]\n",
      "Loss in iteration 4824: 0.4384190681239989\n",
      "Theta: [-1.50716149  0.93082695  0.06155074]\n",
      "Loss in iteration 4825: 0.43841186961686196\n",
      "Theta: [-1.50731152  0.93092633  0.06154758]\n",
      "Loss in iteration 4826: 0.43840467408357087\n",
      "Theta: [-1.50746152  0.93102569  0.06154441]\n",
      "Loss in iteration 4827: 0.4383974815225776\n",
      "Theta: [-1.50761149  0.93112504  0.06154124]\n",
      "Loss in iteration 4828: 0.438390291932336\n",
      "Theta: [-1.50776143  0.93122437  0.06153808]\n",
      "Loss in iteration 4829: 0.4383831053112999\n",
      "Theta: [-1.50791133  0.93132367  0.06153491]\n",
      "Loss in iteration 4830: 0.43837592165792494\n",
      "Theta: [-1.5080612   0.93142296  0.06153175]\n",
      "Loss in iteration 4831: 0.43836874097066747\n",
      "Theta: [-1.50821104  0.93152223  0.06152858]\n",
      "Loss in iteration 4832: 0.43836156324798475\n",
      "Theta: [-1.50836085  0.93162149  0.06152542]\n",
      "Loss in iteration 4833: 0.43835438848833513\n",
      "Theta: [-1.50851062  0.93172072  0.06152225]\n",
      "Loss in iteration 4834: 0.43834721669017795\n",
      "Theta: [-1.50866036  0.93181994  0.06151909]\n",
      "Loss in iteration 4835: 0.43834004785197345\n",
      "Theta: [-1.50881007  0.93191913  0.06151592]\n",
      "Loss in iteration 4836: 0.4383328819721829\n",
      "Theta: [-1.50895975  0.93201831  0.06151276]\n",
      "Loss in iteration 4837: 0.43832571904926865\n",
      "Theta: [-1.50910939  0.93211747  0.0615096 ]\n",
      "Loss in iteration 4838: 0.4383185590816941\n",
      "Theta: [-1.50925901  0.93221661  0.06150643]\n",
      "Loss in iteration 4839: 0.4383114020679233\n",
      "Theta: [-1.50940859  0.93231574  0.06150327]\n",
      "Loss in iteration 4840: 0.4383042480064215\n",
      "Theta: [-1.50955814  0.93241484  0.06150011]\n",
      "Loss in iteration 4841: 0.4382970968956552\n",
      "Theta: [-1.50970766  0.93251393  0.06149695]\n",
      "Loss in iteration 4842: 0.4382899487340913\n",
      "Theta: [-1.50985714  0.93261299  0.06149378]\n",
      "Loss in iteration 4843: 0.4382828035201981\n",
      "Theta: [-1.51000659  0.93271204  0.06149062]\n",
      "Loss in iteration 4844: 0.43827566125244494\n",
      "Theta: [-1.51015601  0.93281107  0.06148746]\n",
      "Loss in iteration 4845: 0.4382685219293019\n",
      "Theta: [-1.5103054   0.93291008  0.0614843 ]\n",
      "Loss in iteration 4846: 0.43826138554924\n",
      "Theta: [-1.51045476  0.93300908  0.06148114]\n",
      "Loss in iteration 4847: 0.43825425211073143\n",
      "Theta: [-1.51060408  0.93310805  0.06147798]\n",
      "Loss in iteration 4848: 0.43824712161224944\n",
      "Theta: [-1.51075338  0.93320701  0.06147482]\n",
      "Loss in iteration 4849: 0.438239994052268\n",
      "Theta: [-1.51090264  0.93330595  0.06147166]\n",
      "Loss in iteration 4850: 0.4382328694292623\n",
      "Theta: [-1.51105186  0.93340486  0.0614685 ]\n",
      "Loss in iteration 4851: 0.43822574774170825\n",
      "Theta: [-1.51120106  0.93350377  0.06146534]\n",
      "Loss in iteration 4852: 0.438218628988083\n",
      "Theta: [-1.51135023  0.93360265  0.06146218]\n",
      "Loss in iteration 4853: 0.43821151316686424\n",
      "Theta: [-1.51149936  0.93370151  0.06145902]\n",
      "Loss in iteration 4854: 0.4382044002765315\n",
      "Theta: [-1.51164846  0.93380036  0.06145586]\n",
      "Loss in iteration 4855: 0.43819729031556437\n",
      "Theta: [-1.51179753  0.93389918  0.0614527 ]\n",
      "Loss in iteration 4856: 0.4381901832824438\n",
      "Theta: [-1.51194656  0.93399799  0.06144954]\n",
      "Loss in iteration 4857: 0.4381830791756517\n",
      "Theta: [-1.51209557  0.93409678  0.06144638]\n",
      "Loss in iteration 4858: 0.4381759779936711\n",
      "Theta: [-1.51224454  0.93419555  0.06144323]\n",
      "Loss in iteration 4859: 0.43816887973498575\n",
      "Theta: [-1.51239348  0.93429431  0.06144007]\n",
      "Loss in iteration 4860: 0.4381617843980803\n",
      "Theta: [-1.51254239  0.93439304  0.06143691]\n",
      "Loss in iteration 4861: 0.43815469198144086\n",
      "Theta: [-1.51269126  0.93449176  0.06143375]\n",
      "Loss in iteration 4862: 0.438147602483554\n",
      "Theta: [-1.51284011  0.93459046  0.0614306 ]\n",
      "Loss in iteration 4863: 0.43814051590290753\n",
      "Theta: [-1.51298892  0.93468914  0.06142744]\n",
      "Loss in iteration 4864: 0.4381334322379899\n",
      "Theta: [-1.5131377   0.9347878   0.06142428]\n",
      "Loss in iteration 4865: 0.43812635148729123\n",
      "Theta: [-1.51328645  0.93488644  0.06142113]\n",
      "Loss in iteration 4866: 0.4381192736493019\n",
      "Theta: [-1.51343517  0.93498507  0.06141797]\n",
      "Loss in iteration 4867: 0.43811219872251345\n",
      "Theta: [-1.51358386  0.93508367  0.06141482]\n",
      "Loss in iteration 4868: 0.43810512670541846\n",
      "Theta: [-1.51373251  0.93518226  0.06141166]\n",
      "Loss in iteration 4869: 0.4380980575965106\n",
      "Theta: [-1.51388113  0.93528083  0.06140851]\n",
      "Loss in iteration 4870: 0.4380909913942844\n",
      "Theta: [-1.51402972  0.93537938  0.06140535]\n",
      "Loss in iteration 4871: 0.43808392809723523\n",
      "Theta: [-1.51417828  0.93547791  0.0614022 ]\n",
      "Loss in iteration 4872: 0.43807686770385934\n",
      "Theta: [-1.5143268   0.93557643  0.06139904]\n",
      "Loss in iteration 4873: 0.4380698102126543\n",
      "Theta: [-1.5144753   0.93567492  0.06139589]\n",
      "Loss in iteration 4874: 0.4380627556221184\n",
      "Theta: [-1.51462376  0.9357734   0.06139273]\n",
      "Loss in iteration 4875: 0.4380557039307512\n",
      "Theta: [-1.51477219  0.93587186  0.06138958]\n",
      "Loss in iteration 4876: 0.4380486551370526\n",
      "Theta: [-1.51492059  0.9359703   0.06138643]\n",
      "Loss in iteration 4877: 0.438041609239524\n",
      "Theta: [-1.51506896  0.93606872  0.06138328]\n",
      "Loss in iteration 4878: 0.43803456623666753\n",
      "Theta: [-1.51521729  0.93616713  0.06138012]\n",
      "Loss in iteration 4879: 0.4380275261269863\n",
      "Theta: [-1.5153656   0.93626551  0.06137697]\n",
      "Loss in iteration 4880: 0.43802048890898454\n",
      "Theta: [-1.51551387  0.93636388  0.06137382]\n",
      "Loss in iteration 4881: 0.4380134545811672\n",
      "Theta: [-1.51566211  0.93646223  0.06137067]\n",
      "Loss in iteration 4882: 0.4380064231420404\n",
      "Theta: [-1.51581032  0.93656056  0.06136751]\n",
      "Loss in iteration 4883: 0.43799939459011084\n",
      "Theta: [-1.5159585   0.93665887  0.06136436]\n",
      "Loss in iteration 4884: 0.43799236892388677\n",
      "Theta: [-1.51610664  0.93675717  0.06136121]\n",
      "Loss in iteration 4885: 0.43798534614187695\n",
      "Theta: [-1.51625476  0.93685544  0.06135806]\n",
      "Loss in iteration 4886: 0.4379783262425909\n",
      "Theta: [-1.51640284  0.9369537   0.06135491]\n",
      "Loss in iteration 4887: 0.43797130922454\n",
      "Theta: [-1.51655089  0.93705194  0.06135176]\n",
      "Loss in iteration 4888: 0.4379642950862354\n",
      "Theta: [-1.51669891  0.93715016  0.06134861]\n",
      "Loss in iteration 4889: 0.4379572838261902\n",
      "Theta: [-1.51684689  0.93724836  0.06134546]\n",
      "Loss in iteration 4890: 0.43795027544291765\n",
      "Theta: [-1.51699485  0.93734655  0.06134231]\n",
      "Loss in iteration 4891: 0.43794326993493266\n",
      "Theta: [-1.51714277  0.93744472  0.06133916]\n",
      "Loss in iteration 4892: 0.4379362673007503\n",
      "Theta: [-1.51729066  0.93754286  0.06133601]\n",
      "Loss in iteration 4893: 0.4379292675388877\n",
      "Theta: [-1.51743853  0.93764099  0.06133286]\n",
      "Loss in iteration 4894: 0.4379222706478618\n",
      "Theta: [-1.51758635  0.93773911  0.06132972]\n",
      "Loss in iteration 4895: 0.437915276626191\n",
      "Theta: [-1.51773415  0.9378372   0.06132657]\n",
      "Loss in iteration 4896: 0.43790828547239485\n",
      "Theta: [-1.51788192  0.93793527  0.06132342]\n",
      "Loss in iteration 4897: 0.4379012971849933\n",
      "Theta: [-1.51802965  0.93803333  0.06132027]\n",
      "Loss in iteration 4898: 0.4378943117625077\n",
      "Theta: [-1.51817736  0.93813137  0.06131712]\n",
      "Loss in iteration 4899: 0.43788732920346035\n",
      "Theta: [-1.51832503  0.93822939  0.06131398]\n",
      "Loss in iteration 4900: 0.43788034950637394\n",
      "Theta: [-1.51847267  0.93832739  0.06131083]\n",
      "Loss in iteration 4901: 0.43787337266977283\n",
      "Theta: [-1.51862027  0.93842538  0.06130768]\n",
      "Loss in iteration 4902: 0.4378663986921819\n",
      "Theta: [-1.51876785  0.93852334  0.06130454]\n",
      "Loss in iteration 4903: 0.4378594275721271\n",
      "Theta: [-1.5189154   0.93862129  0.06130139]\n",
      "Loss in iteration 4904: 0.43785245930813493\n",
      "Theta: [-1.51906291  0.93871922  0.06129824]\n",
      "Loss in iteration 4905: 0.4378454938987336\n",
      "Theta: [-1.51921039  0.93881713  0.0612951 ]\n",
      "Loss in iteration 4906: 0.43783853134245165\n",
      "Theta: [-1.51935784  0.93891502  0.06129195]\n",
      "Loss in iteration 4907: 0.4378315716378188\n",
      "Theta: [-1.51950526  0.9390129   0.06128881]\n",
      "Loss in iteration 4908: 0.4378246147833656\n",
      "Theta: [-1.51965265  0.93911076  0.06128566]\n",
      "Loss in iteration 4909: 0.4378176607776234\n",
      "Theta: [-1.51980001  0.93920859  0.06128252]\n",
      "Loss in iteration 4910: 0.437810709619125\n",
      "Theta: [-1.51994733  0.93930641  0.06127938]\n",
      "Loss in iteration 4911: 0.4378037613064036\n",
      "Theta: [-1.52009463  0.93940422  0.06127623]\n",
      "Loss in iteration 4912: 0.43779681583799357\n",
      "Theta: [-1.52024189  0.939502    0.06127309]\n",
      "Loss in iteration 4913: 0.43778987321243024\n",
      "Theta: [-1.52038912  0.93959977  0.06126994]\n",
      "Loss in iteration 4914: 0.43778293342824975\n",
      "Theta: [-1.52053632  0.93969751  0.0612668 ]\n",
      "Loss in iteration 4915: 0.43777599648398907\n",
      "Theta: [-1.52068349  0.93979524  0.06126366]\n",
      "Loss in iteration 4916: 0.43776906237818664\n",
      "Theta: [-1.52083062  0.93989296  0.06126052]\n",
      "Loss in iteration 4917: 0.4377621311093811\n",
      "Theta: [-1.52097773  0.93999065  0.06125737]\n",
      "Loss in iteration 4918: 0.4377552026761125\n",
      "Theta: [-1.5211248   0.94008832  0.06125423]\n",
      "Loss in iteration 4919: 0.4377482770769218\n",
      "Theta: [-1.52127185  0.94018598  0.06125109]\n",
      "Loss in iteration 4920: 0.43774135431035055\n",
      "Theta: [-1.52141886  0.94028362  0.06124795]\n",
      "Loss in iteration 4921: 0.43773443437494153\n",
      "Theta: [-1.52156584  0.94038124  0.06124481]\n",
      "Loss in iteration 4922: 0.43772751726923853\n",
      "Theta: [-1.52171279  0.94047884  0.06124166]\n",
      "Loss in iteration 4923: 0.437720602991786\n",
      "Theta: [-1.52185971  0.94057643  0.06123852]\n",
      "Loss in iteration 4924: 0.43771369154112927\n",
      "Theta: [-1.52200659  0.940674    0.06123538]\n",
      "Loss in iteration 4925: 0.437706782915815\n",
      "Theta: [-1.52215345  0.94077154  0.06123224]\n",
      "Loss in iteration 4926: 0.43769987711439046\n",
      "Theta: [-1.52230027  0.94086907  0.0612291 ]\n",
      "Loss in iteration 4927: 0.4376929741354036\n",
      "Theta: [-1.52244706  0.94096659  0.06122596]\n",
      "Loss in iteration 4928: 0.4376860739774041\n",
      "Theta: [-1.52259382  0.94106408  0.06122282]\n",
      "Loss in iteration 4929: 0.4376791766389416\n",
      "Theta: [-1.52274055  0.94116156  0.06121968]\n",
      "Loss in iteration 4930: 0.4376722821185676\n",
      "Theta: [-1.52288725  0.94125902  0.06121655]\n",
      "Loss in iteration 4931: 0.4376653904148336\n",
      "Theta: [-1.52303392  0.94135646  0.06121341]\n",
      "Loss in iteration 4932: 0.4376585015262926\n",
      "Theta: [-1.52318056  0.94145388  0.06121027]\n",
      "Loss in iteration 4933: 0.43765161545149844\n",
      "Theta: [-1.52332716  0.94155128  0.06120713]\n",
      "Loss in iteration 4934: 0.4376447321890058\n",
      "Theta: [-1.52347374  0.94164867  0.06120399]\n",
      "Loss in iteration 4935: 0.43763785173737013\n",
      "Theta: [-1.52362028  0.94174604  0.06120085]\n",
      "Loss in iteration 4936: 0.4376309740951483\n",
      "Theta: [-1.52376679  0.94184339  0.06119772]\n",
      "Loss in iteration 4937: 0.43762409926089746\n",
      "Theta: [-1.52391327  0.94194072  0.06119458]\n",
      "Loss in iteration 4938: 0.4376172272331761\n",
      "Theta: [-1.52405972  0.94203803  0.06119144]\n",
      "Loss in iteration 4939: 0.43761035801054343\n",
      "Theta: [-1.52420614  0.94213533  0.06118831]\n",
      "Loss in iteration 4940: 0.43760349159155965\n",
      "Theta: [-1.52435253  0.9422326   0.06118517]\n",
      "Loss in iteration 4941: 0.4375966279747858\n",
      "Theta: [-1.52449888  0.94232986  0.06118203]\n",
      "Loss in iteration 4942: 0.4375897671587843\n",
      "Theta: [-1.52464521  0.94242711  0.0611789 ]\n",
      "Loss in iteration 4943: 0.43758290914211734\n",
      "Theta: [-1.5247915   0.94252433  0.06117576]\n",
      "Loss in iteration 4944: 0.4375760539233495\n",
      "Theta: [-1.52493777  0.94262154  0.06117263]\n",
      "Loss in iteration 4945: 0.437569201501045\n",
      "Theta: [-1.525084    0.94271872  0.06116949]\n",
      "Loss in iteration 4946: 0.4375623518737698\n",
      "Theta: [-1.5252302   0.94281589  0.06116636]\n",
      "Loss in iteration 4947: 0.4375555050400904\n",
      "Theta: [-1.52537637  0.94291304  0.06116322]\n",
      "Loss in iteration 4948: 0.43754866099857426\n",
      "Theta: [-1.52552251  0.94301018  0.06116009]\n",
      "Loss in iteration 4949: 0.4375418197477896\n",
      "Theta: [-1.52566861  0.94310729  0.06115696]\n",
      "Loss in iteration 4950: 0.4375349812863061\n",
      "Theta: [-1.52581469  0.94320439  0.06115382]\n",
      "Loss in iteration 4951: 0.43752814561269365\n",
      "Theta: [-1.52596074  0.94330147  0.06115069]\n",
      "Loss in iteration 4952: 0.4375213127255233\n",
      "Theta: [-1.52610675  0.94339853  0.06114755]\n",
      "Loss in iteration 4953: 0.4375144826233673\n",
      "Theta: [-1.52625274  0.94349558  0.06114442]\n",
      "Loss in iteration 4954: 0.4375076553047985\n",
      "Theta: [-1.52639869  0.9435926   0.06114129]\n",
      "Loss in iteration 4955: 0.43750083076839064\n",
      "Theta: [-1.52654461  0.94368961  0.06113816]\n",
      "Loss in iteration 4956: 0.43749400901271857\n",
      "Theta: [-1.5266905   0.9437866   0.06113502]\n",
      "Loss in iteration 4957: 0.4374871900363576\n",
      "Theta: [-1.52683636  0.94388357  0.06113189]\n",
      "Loss in iteration 4958: 0.43748037383788474\n",
      "Theta: [-1.52698219  0.94398053  0.06112876]\n",
      "Loss in iteration 4959: 0.4374735604158769\n",
      "Theta: [-1.52712799  0.94407747  0.06112563]\n",
      "Loss in iteration 4960: 0.43746674976891287\n",
      "Theta: [-1.52727375  0.94417438  0.0611225 ]\n",
      "Loss in iteration 4961: 0.4374599418955715\n",
      "Theta: [-1.52741949  0.94427128  0.06111937]\n",
      "Loss in iteration 4962: 0.43745313679443315\n",
      "Theta: [-1.5275652   0.94436817  0.06111624]\n",
      "Loss in iteration 4963: 0.43744633446407866\n",
      "Theta: [-1.52771087  0.94446503  0.06111311]\n",
      "Loss in iteration 4964: 0.43743953490309023\n",
      "Theta: [-1.52785651  0.94456188  0.06110998]\n",
      "Loss in iteration 4965: 0.4374327381100504\n",
      "Theta: [-1.52800213  0.94465871  0.06110685]\n",
      "Loss in iteration 4966: 0.437425944083543\n",
      "Theta: [-1.52814771  0.94475552  0.06110372]\n",
      "Loss in iteration 4967: 0.43741915282215266\n",
      "Theta: [-1.52829326  0.94485231  0.06110059]\n",
      "Loss in iteration 4968: 0.43741236432446484\n",
      "Theta: [-1.52843878  0.94494909  0.06109746]\n",
      "Loss in iteration 4969: 0.4374055785890659\n",
      "Theta: [-1.52858427  0.94504584  0.06109433]\n",
      "Loss in iteration 4970: 0.43739879561454326\n",
      "Theta: [-1.52872973  0.94514258  0.0610912 ]\n",
      "Loss in iteration 4971: 0.43739201539948497\n",
      "Theta: [-1.52887515  0.94523931  0.06108807]\n",
      "Loss in iteration 4972: 0.4373852379424801\n",
      "Theta: [-1.52902055  0.94533601  0.06108495]\n",
      "Loss in iteration 4973: 0.4373784632421188\n",
      "Theta: [-1.52916592  0.9454327   0.06108182]\n",
      "Loss in iteration 4974: 0.43737169129699177\n",
      "Theta: [-1.52931125  0.94552936  0.06107869]\n",
      "Loss in iteration 4975: 0.4373649221056906\n",
      "Theta: [-1.52945656  0.94562601  0.06107556]\n",
      "Loss in iteration 4976: 0.43735815566680825\n",
      "Theta: [-1.52960183  0.94572265  0.06107244]\n",
      "Loss in iteration 4977: 0.43735139197893813\n",
      "Theta: [-1.52974707  0.94581926  0.06106931]\n",
      "Loss in iteration 4978: 0.43734463104067467\n",
      "Theta: [-1.52989229  0.94591586  0.06106619]\n",
      "Loss in iteration 4979: 0.4373378728506132\n",
      "Theta: [-1.53003747  0.94601244  0.06106306]\n",
      "Loss in iteration 4980: 0.4373311174073497\n",
      "Theta: [-1.53018262  0.946109    0.06105993]\n",
      "Loss in iteration 4981: 0.4373243647094815\n",
      "Theta: [-1.53032774  0.94620554  0.06105681]\n",
      "Loss in iteration 4982: 0.4373176147556064\n",
      "Theta: [-1.53047283  0.94630207  0.06105368]\n",
      "Loss in iteration 4983: 0.43731086754432325\n",
      "Theta: [-1.53061789  0.94639857  0.06105056]\n",
      "Loss in iteration 4984: 0.43730412307423194\n",
      "Theta: [-1.53076291  0.94649506  0.06104743]\n",
      "Loss in iteration 4985: 0.4372973813439328\n",
      "Theta: [-1.53090791  0.94659154  0.06104431]\n",
      "Loss in iteration 4986: 0.43729064235202764\n",
      "Theta: [-1.53105288  0.94668799  0.06104118]\n",
      "Loss in iteration 4987: 0.4372839060971186\n",
      "Theta: [-1.53119781  0.94678443  0.06103806]\n",
      "Loss in iteration 4988: 0.43727717257780907\n",
      "Theta: [-1.53134272  0.94688085  0.06103494]\n",
      "Loss in iteration 4989: 0.4372704417927031\n",
      "Theta: [-1.53148759  0.94697725  0.06103181]\n",
      "Loss in iteration 4990: 0.43726371374040596\n",
      "Theta: [-1.53163244  0.94707363  0.06102869]\n",
      "Loss in iteration 4991: 0.4372569884195231\n",
      "Theta: [-1.53177725  0.94717     0.06102557]\n",
      "Loss in iteration 4992: 0.43725026582866156\n",
      "Theta: [-1.53192204  0.94726634  0.06102245]\n",
      "Loss in iteration 4993: 0.4372435459664291\n",
      "Theta: [-1.53206679  0.94736267  0.06101932]\n",
      "Loss in iteration 4994: 0.43723682883143405\n",
      "Theta: [-1.53221151  0.94745899  0.0610162 ]\n",
      "Loss in iteration 4995: 0.4372301144222859\n",
      "Theta: [-1.5323562   0.94755528  0.06101308]\n",
      "Loss in iteration 4996: 0.43722340273759497\n",
      "Theta: [-1.53250086  0.94765156  0.06100996]\n",
      "Loss in iteration 4997: 0.43721669377597244\n",
      "Theta: [-1.53264549  0.94774782  0.06100684]\n",
      "Loss in iteration 4998: 0.43720998753603013\n",
      "Theta: [-1.53279009  0.94784406  0.06100372]\n",
      "Loss in iteration 4999: 0.4372032840163812\n",
      "Theta: [-1.53293466  0.94794028  0.06100059]\n",
      "Loss in iteration 5000: 0.43719658321563926\n",
      "Theta: [-1.5330792   0.94803649  0.06099747]\n",
      "Loss in iteration 5001: 0.43718988513241913\n",
      "Theta: [-1.53322371  0.94813268  0.06099435]\n",
      "Loss in iteration 5002: 0.4371831897653363\n",
      "Theta: [-1.53336818  0.94822885  0.06099123]\n",
      "Loss in iteration 5003: 0.43717649711300693\n",
      "Theta: [-1.53351263  0.948325    0.06098811]\n",
      "Loss in iteration 5004: 0.43716980717404863\n",
      "Theta: [-1.53365705  0.94842113  0.060985  ]\n",
      "Loss in iteration 5005: 0.43716311994707935\n",
      "Theta: [-1.53380143  0.94851725  0.06098188]\n",
      "Loss in iteration 5006: 0.43715643543071836\n",
      "Theta: [-1.53394579  0.94861335  0.06097876]\n",
      "Loss in iteration 5007: 0.437149753623585\n",
      "Theta: [-1.53409011  0.94870943  0.06097564]\n",
      "Loss in iteration 5008: 0.4371430745243005\n",
      "Theta: [-1.53423441  0.9488055   0.06097252]\n",
      "Loss in iteration 5009: 0.4371363981314863\n",
      "Theta: [-1.53437867  0.94890154  0.0609694 ]\n",
      "Loss in iteration 5010: 0.4371297244437649\n",
      "Theta: [-1.53452291  0.94899757  0.06096628]\n",
      "Loss in iteration 5011: 0.43712305345975966\n",
      "Theta: [-1.53466711  0.94909358  0.06096317]\n",
      "Loss in iteration 5012: 0.43711638517809476\n",
      "Theta: [-1.53481128  0.94918958  0.06096005]\n",
      "Loss in iteration 5013: 0.4371097195973953\n",
      "Theta: [-1.53495542  0.94928555  0.06095693]\n",
      "Loss in iteration 5014: 0.4371030567162872\n",
      "Theta: [-1.53509954  0.94938151  0.06095382]\n",
      "Loss in iteration 5015: 0.4370963965333972\n",
      "Theta: [-1.53524362  0.94947745  0.0609507 ]\n",
      "Loss in iteration 5016: 0.4370897390473531\n",
      "Theta: [-1.53538767  0.94957337  0.06094758]\n",
      "Loss in iteration 5017: 0.43708308425678344\n",
      "Theta: [-1.53553169  0.94966928  0.06094447]\n",
      "Loss in iteration 5018: 0.4370764321603177\n",
      "Theta: [-1.53567568  0.94976517  0.06094135]\n",
      "Loss in iteration 5019: 0.4370697827565857\n",
      "Theta: [-1.53581964  0.94986104  0.06093824]\n",
      "Loss in iteration 5020: 0.437063136044219\n",
      "Theta: [-1.53596357  0.94995689  0.06093512]\n",
      "Loss in iteration 5021: 0.43705649202184943\n",
      "Theta: [-1.53610747  0.95005272  0.06093201]\n",
      "Loss in iteration 5022: 0.43704985068810975\n",
      "Theta: [-1.53625134  0.95014854  0.06092889]\n",
      "Loss in iteration 5023: 0.43704321204163377\n",
      "Theta: [-1.53639518  0.95024434  0.06092578]\n",
      "Loss in iteration 5024: 0.43703657608105595\n",
      "Theta: [-1.53653899  0.95034012  0.06092266]\n",
      "Loss in iteration 5025: 0.4370299428050117\n",
      "Theta: [-1.53668277  0.95043589  0.06091955]\n",
      "Loss in iteration 5026: 0.43702331221213725\n",
      "Theta: [-1.53682652  0.95053163  0.06091644]\n",
      "Loss in iteration 5027: 0.43701668430106994\n",
      "Theta: [-1.53697023  0.95062736  0.06091332]\n",
      "Loss in iteration 5028: 0.43701005907044754\n",
      "Theta: [-1.53711392  0.95072308  0.06091021]\n",
      "Loss in iteration 5029: 0.4370034365189089\n",
      "Theta: [-1.53725758  0.95081877  0.0609071 ]\n",
      "Loss in iteration 5030: 0.43699681664509366\n",
      "Theta: [-1.53740121  0.95091445  0.06090399]\n",
      "Loss in iteration 5031: 0.4369901994476425\n",
      "Theta: [-1.5375448   0.9510101   0.06090087]\n",
      "Loss in iteration 5032: 0.43698358492519673\n",
      "Theta: [-1.53768837  0.95110575  0.06089776]\n",
      "Loss in iteration 5033: 0.43697697307639866\n",
      "Theta: [-1.53783191  0.95120137  0.06089465]\n",
      "Loss in iteration 5034: 0.43697036389989125\n",
      "Theta: [-1.53797541  0.95129698  0.06089154]\n",
      "Loss in iteration 5035: 0.43696375739431853\n",
      "Theta: [-1.53811889  0.95139256  0.06088843]\n",
      "Loss in iteration 5036: 0.4369571535583251\n",
      "Theta: [-1.53826233  0.95148814  0.06088532]\n",
      "Loss in iteration 5037: 0.43695055239055697\n",
      "Theta: [-1.53840575  0.95158369  0.06088221]\n",
      "Loss in iteration 5038: 0.4369439538896603\n",
      "Theta: [-1.53854914  0.95167922  0.0608791 ]\n",
      "Loss in iteration 5039: 0.4369373580542827\n",
      "Theta: [-1.53869249  0.95177474  0.06087599]\n",
      "Loss in iteration 5040: 0.43693076488307203\n",
      "Theta: [-1.53883582  0.95187024  0.06087288]\n",
      "Loss in iteration 5041: 0.4369241743746777\n",
      "Theta: [-1.53897911  0.95196573  0.06086977]\n",
      "Loss in iteration 5042: 0.4369175865277493\n",
      "Theta: [-1.53912238  0.95206119  0.06086666]\n",
      "Loss in iteration 5043: 0.4369110013409378\n",
      "Theta: [-1.53926561  0.95215664  0.06086355]\n",
      "Loss in iteration 5044: 0.43690441881289455\n",
      "Theta: [-1.53940882  0.95225207  0.06086044]\n",
      "Loss in iteration 5045: 0.43689783894227185\n",
      "Theta: [-1.53955199  0.95234749  0.06085733]\n",
      "Loss in iteration 5046: 0.4368912617277234\n",
      "Theta: [-1.53969514  0.95244288  0.06085422]\n",
      "Loss in iteration 5047: 0.4368846871679029\n",
      "Theta: [-1.53983825  0.95253826  0.06085111]\n",
      "Loss in iteration 5048: 0.43687811526146547\n",
      "Theta: [-1.53998134  0.95263362  0.06084801]\n",
      "Loss in iteration 5049: 0.43687154600706696\n",
      "Theta: [-1.54012439  0.95272896  0.0608449 ]\n",
      "Loss in iteration 5050: 0.4368649794033637\n",
      "Theta: [-1.54026742  0.95282429  0.06084179]\n",
      "Loss in iteration 5051: 0.43685841544901366\n",
      "Theta: [-1.54041041  0.9529196   0.06083869]\n",
      "Loss in iteration 5052: 0.43685185414267474\n",
      "Theta: [-1.54055337  0.95301489  0.06083558]\n",
      "Loss in iteration 5053: 0.43684529548300616\n",
      "Theta: [-1.54069631  0.95311016  0.06083247]\n",
      "Loss in iteration 5054: 0.43683873946866797\n",
      "Theta: [-1.54083921  0.95320542  0.06082937]\n",
      "Loss in iteration 5055: 0.43683218609832086\n",
      "Theta: [-1.54098209  0.95330066  0.06082626]\n",
      "Loss in iteration 5056: 0.4368256353706269\n",
      "Theta: [-1.54112493  0.95339588  0.06082316]\n",
      "Loss in iteration 5057: 0.43681908728424795\n",
      "Theta: [-1.54126775  0.95349108  0.06082005]\n",
      "Loss in iteration 5058: 0.43681254183784796\n",
      "Theta: [-1.54141053  0.95358627  0.06081695]\n",
      "Loss in iteration 5059: 0.4368059990300906\n",
      "Theta: [-1.54155329  0.95368144  0.06081384]\n",
      "Loss in iteration 5060: 0.4367994588596412\n",
      "Theta: [-1.54169601  0.95377659  0.06081074]\n",
      "Loss in iteration 5061: 0.4367929213251655\n",
      "Theta: [-1.54183871  0.95387172  0.06080763]\n",
      "Loss in iteration 5062: 0.43678638642533024\n",
      "Theta: [-1.54198137  0.95396684  0.06080453]\n",
      "Loss in iteration 5063: 0.4367798541588029\n",
      "Theta: [-1.54212401  0.95406194  0.06080142]\n",
      "Loss in iteration 5064: 0.43677332452425155\n",
      "Theta: [-1.54226661  0.95415702  0.06079832]\n",
      "Loss in iteration 5065: 0.43676679752034575\n",
      "Theta: [-1.54240919  0.95425208  0.06079522]\n",
      "Loss in iteration 5066: 0.4367602731457553\n",
      "Theta: [-1.54255173  0.95434713  0.06079212]\n",
      "Loss in iteration 5067: 0.43675375139915107\n",
      "Theta: [-1.54269425  0.95444216  0.06078901]\n",
      "Loss in iteration 5068: 0.43674723227920464\n",
      "Theta: [-1.54283673  0.95453717  0.06078591]\n",
      "Loss in iteration 5069: 0.4367407157845888\n",
      "Theta: [-1.54297919  0.95463217  0.06078281]\n",
      "Loss in iteration 5070: 0.4367342019139763\n",
      "Theta: [-1.54312161  0.95472714  0.06077971]\n",
      "Loss in iteration 5071: 0.43672769066604195\n",
      "Theta: [-1.54326401  0.9548221   0.06077661]\n",
      "Loss in iteration 5072: 0.4367211820394604\n",
      "Theta: [-1.54340637  0.95491705  0.0607735 ]\n",
      "Loss in iteration 5073: 0.43671467603290737\n",
      "Theta: [-1.54354871  0.95501197  0.0607704 ]\n",
      "Loss in iteration 5074: 0.43670817264505957\n",
      "Theta: [-1.54369102  0.95510688  0.0607673 ]\n",
      "Loss in iteration 5075: 0.4367016718745946\n",
      "Theta: [-1.54383329  0.95520177  0.0607642 ]\n",
      "Loss in iteration 5076: 0.43669517372019034\n",
      "Theta: [-1.54397554  0.95529664  0.0607611 ]\n",
      "Loss in iteration 5077: 0.4366886781805265\n",
      "Theta: [-1.54411776  0.9553915   0.060758  ]\n",
      "Loss in iteration 5078: 0.43668218525428254\n",
      "Theta: [-1.54425994  0.95548634  0.0607549 ]\n",
      "Loss in iteration 5079: 0.4366756949401392\n",
      "Theta: [-1.5444021   0.95558116  0.0607518 ]\n",
      "Loss in iteration 5080: 0.4366692072367783\n",
      "Theta: [-1.54454423  0.95567596  0.0607487 ]\n",
      "Loss in iteration 5081: 0.43666272214288215\n",
      "Theta: [-1.54468633  0.95577075  0.06074561]\n",
      "Loss in iteration 5082: 0.43665623965713396\n",
      "Theta: [-1.5448284   0.95586552  0.06074251]\n",
      "Loss in iteration 5083: 0.4366497597782177\n",
      "Theta: [-1.54497043  0.95596027  0.06073941]\n",
      "Loss in iteration 5084: 0.4366432825048184\n",
      "Theta: [-1.54511244  0.956055    0.06073631]\n",
      "Loss in iteration 5085: 0.43663680783562137\n",
      "Theta: [-1.54525442  0.95614972  0.06073321]\n",
      "Loss in iteration 5086: 0.4366303357693133\n",
      "Theta: [-1.54539637  0.95624442  0.06073012]\n",
      "Loss in iteration 5087: 0.4366238663045819\n",
      "Theta: [-1.54553829  0.9563391   0.06072702]\n",
      "Loss in iteration 5088: 0.43661739944011474\n",
      "Theta: [-1.54568018  0.95643377  0.06072392]\n",
      "Loss in iteration 5089: 0.4366109351746011\n",
      "Theta: [-1.54582204  0.95652841  0.06072082]\n",
      "Loss in iteration 5090: 0.4366044735067304\n",
      "Theta: [-1.54596387  0.95662305  0.06071773]\n",
      "Loss in iteration 5091: 0.43659801443519364\n",
      "Theta: [-1.54610567  0.95671766  0.06071463]\n",
      "Loss in iteration 5092: 0.43659155795868204\n",
      "Theta: [-1.54624744  0.95681225  0.06071154]\n",
      "Loss in iteration 5093: 0.4365851040758877\n",
      "Theta: [-1.54638918  0.95690683  0.06070844]\n",
      "Loss in iteration 5094: 0.43657865278550373\n",
      "Theta: [-1.5465309   0.95700139  0.06070535]\n",
      "Loss in iteration 5095: 0.43657220408622394\n",
      "Theta: [-1.54667258  0.95709594  0.06070225]\n",
      "Loss in iteration 5096: 0.43656575797674324\n",
      "Theta: [-1.54681423  0.95719047  0.06069916]\n",
      "Loss in iteration 5097: 0.43655931445575663\n",
      "Theta: [-1.54695585  0.95728497  0.06069606]\n",
      "Loss in iteration 5098: 0.4365528735219607\n",
      "Theta: [-1.54709745  0.95737947  0.06069297]\n",
      "Loss in iteration 5099: 0.43654643517405234\n",
      "Theta: [-1.54723901  0.95747394  0.06068987]\n",
      "Loss in iteration 5100: 0.4365399994107297\n",
      "Theta: [-1.54738055  0.9575684   0.06068678]\n",
      "Loss in iteration 5101: 0.4365335662306913\n",
      "Theta: [-1.54752205  0.95766284  0.06068369]\n",
      "Loss in iteration 5102: 0.4365271356326367\n",
      "Theta: [-1.54766353  0.95775726  0.06068059]\n",
      "Loss in iteration 5103: 0.43652070761526623\n",
      "Theta: [-1.54780497  0.95785167  0.0606775 ]\n",
      "Loss in iteration 5104: 0.43651428217728094\n",
      "Theta: [-1.54794639  0.95794606  0.06067441]\n",
      "Loss in iteration 5105: 0.4365078593173829\n",
      "Theta: [-1.54808778  0.95804043  0.06067131]\n",
      "Loss in iteration 5106: 0.4365014390342749\n",
      "Theta: [-1.54822913  0.95813478  0.06066822]\n",
      "Loss in iteration 5107: 0.4364950213266603\n",
      "Theta: [-1.54837046  0.95822912  0.06066513]\n",
      "Loss in iteration 5108: 0.43648860619324337\n",
      "Theta: [-1.54851176  0.95832344  0.06066204]\n",
      "Loss in iteration 5109: 0.4364821936327297\n",
      "Theta: [-1.54865303  0.95841774  0.06065895]\n",
      "Loss in iteration 5110: 0.4364757836438249\n",
      "Theta: [-1.54879427  0.95851203  0.06065586]\n",
      "Loss in iteration 5111: 0.43646937622523574\n",
      "Theta: [-1.54893548  0.9586063   0.06065277]\n",
      "Loss in iteration 5112: 0.43646297137567\n",
      "Theta: [-1.54907666  0.95870055  0.06064968]\n",
      "Loss in iteration 5113: 0.4364565690938359\n",
      "Theta: [-1.54921781  0.95879478  0.06064659]\n",
      "Loss in iteration 5114: 0.43645016937844267\n",
      "Theta: [-1.54935893  0.958889    0.0606435 ]\n",
      "Loss in iteration 5115: 0.43644377222820024\n",
      "Theta: [-1.54950002  0.9589832   0.06064041]\n",
      "Loss in iteration 5116: 0.43643737764181956\n",
      "Theta: [-1.54964108  0.95907738  0.06063732]\n",
      "Loss in iteration 5117: 0.43643098561801197\n",
      "Theta: [-1.54978212  0.95917155  0.06063423]\n",
      "Loss in iteration 5118: 0.43642459615548995\n",
      "Theta: [-1.54992312  0.9592657   0.06063114]\n",
      "Loss in iteration 5119: 0.4364182092529667\n",
      "Theta: [-1.55006409  0.95935983  0.06062805]\n",
      "Loss in iteration 5120: 0.4364118249091562\n",
      "Theta: [-1.55020504  0.95945394  0.06062496]\n",
      "Loss in iteration 5121: 0.4364054431227732\n",
      "Theta: [-1.55034595  0.95954804  0.06062187]\n",
      "Loss in iteration 5122: 0.43639906389253325\n",
      "Theta: [-1.55048684  0.95964212  0.06061879]\n",
      "Loss in iteration 5123: 0.43639268721715285\n",
      "Theta: [-1.5506277   0.95973618  0.0606157 ]\n",
      "Loss in iteration 5124: 0.43638631309534887\n",
      "Theta: [-1.55076853  0.95983023  0.06061261]\n",
      "Loss in iteration 5125: 0.4363799415258396\n",
      "Theta: [-1.55090932  0.95992425  0.06060952]\n",
      "Loss in iteration 5126: 0.43637357250734377\n",
      "Theta: [-1.55105009  0.96001826  0.06060644]\n",
      "Loss in iteration 5127: 0.43636720603858054\n",
      "Theta: [-1.55119083  0.96011226  0.06060335]\n",
      "Loss in iteration 5128: 0.4363608421182706\n",
      "Theta: [-1.55133154  0.96020624  0.06060026]\n",
      "Loss in iteration 5129: 0.4363544807451351\n",
      "Theta: [-1.55147222  0.96030019  0.06059718]\n",
      "Loss in iteration 5130: 0.4363481219178958\n",
      "Theta: [-1.55161287  0.96039414  0.06059409]\n",
      "Loss in iteration 5131: 0.4363417656352755\n",
      "Theta: [-1.5517535   0.96048806  0.06059101]\n",
      "Loss in iteration 5132: 0.4363354118959976\n",
      "Theta: [-1.55189409  0.96058197  0.06058792]\n",
      "Loss in iteration 5133: 0.4363290606987866\n",
      "Theta: [-1.55203465  0.96067586  0.06058484]\n",
      "Loss in iteration 5134: 0.43632271204236744\n",
      "Theta: [-1.55217519  0.96076974  0.06058175]\n",
      "Loss in iteration 5135: 0.4363163659254662\n",
      "Theta: [-1.55231569  0.96086359  0.06057867]\n",
      "Loss in iteration 5136: 0.4363100223468093\n",
      "Theta: [-1.55245617  0.96095743  0.06057558]\n",
      "Loss in iteration 5137: 0.4363036813051243\n",
      "Theta: [-1.55259662  0.96105126  0.0605725 ]\n",
      "Loss in iteration 5138: 0.43629734279913945\n",
      "Theta: [-1.55273703  0.96114506  0.06056942]\n",
      "Loss in iteration 5139: 0.43629100682758376\n",
      "Theta: [-1.55287742  0.96123885  0.06056633]\n",
      "Loss in iteration 5140: 0.4362846733891872\n",
      "Theta: [-1.55301778  0.96133262  0.06056325]\n",
      "Loss in iteration 5141: 0.4362783424826801\n",
      "Theta: [-1.55315811  0.96142638  0.06056017]\n",
      "Loss in iteration 5142: 0.43627201410679406\n",
      "Theta: [-1.55329841  0.96152012  0.06055709]\n",
      "Loss in iteration 5143: 0.43626568826026113\n",
      "Theta: [-1.55343868  0.96161384  0.060554  ]\n",
      "Loss in iteration 5144: 0.4362593649418144\n",
      "Theta: [-1.55357893  0.96170754  0.06055092]\n",
      "Loss in iteration 5145: 0.43625304415018745\n",
      "Theta: [-1.55371914  0.96180123  0.06054784]\n",
      "Loss in iteration 5146: 0.4362467258841151\n",
      "Theta: [-1.55385932  0.9618949   0.06054476]\n",
      "Loss in iteration 5147: 0.43624041014233234\n",
      "Theta: [-1.55399948  0.96198855  0.06054168]\n",
      "Loss in iteration 5148: 0.43623409692357534\n",
      "Theta: [-1.5541396   0.96208218  0.0605386 ]\n",
      "Loss in iteration 5149: 0.4362277862265811\n",
      "Theta: [-1.5542797   0.9621758   0.06053552]\n",
      "Loss in iteration 5150: 0.4362214780500872\n",
      "Theta: [-1.55441977  0.9622694   0.06053244]\n",
      "Loss in iteration 5151: 0.43621517239283214\n",
      "Theta: [-1.55455981  0.96236299  0.06052936]\n",
      "Loss in iteration 5152: 0.436208869253555\n",
      "Theta: [-1.55469982  0.96245655  0.06052628]\n",
      "Loss in iteration 5153: 0.4362025686309956\n",
      "Theta: [-1.5548398  0.9625501  0.0605232]\n",
      "Loss in iteration 5154: 0.43619627052389526\n",
      "Theta: [-1.55497975  0.96264364  0.06052012]\n",
      "Loss in iteration 5155: 0.43618997493099515\n",
      "Theta: [-1.55511967  0.96273715  0.06051704]\n",
      "Loss in iteration 5156: 0.43618368185103756\n",
      "Theta: [-1.55525956  0.96283065  0.06051396]\n",
      "Loss in iteration 5157: 0.4361773912827658\n",
      "Theta: [-1.55539943  0.96292414  0.06051088]\n",
      "Loss in iteration 5158: 0.43617110322492364\n",
      "Theta: [-1.55553926  0.9630176   0.0605078 ]\n",
      "Loss in iteration 5159: 0.43616481767625565\n",
      "Theta: [-1.55567907  0.96311105  0.06050473]\n",
      "Loss in iteration 5160: 0.4361585346355073\n",
      "Theta: [-1.55581884  0.96320448  0.06050165]\n",
      "Loss in iteration 5161: 0.43615225410142505\n",
      "Theta: [-1.55595859  0.9632979   0.06049857]\n",
      "Loss in iteration 5162: 0.4361459760727555\n",
      "Theta: [-1.55609831  0.96339129  0.06049549]\n",
      "Loss in iteration 5163: 0.43613970054824674\n",
      "Theta: [-1.556238    0.96348467  0.06049242]\n",
      "Loss in iteration 5164: 0.436133427526647\n",
      "Theta: [-1.55637766  0.96357804  0.06048934]\n",
      "Loss in iteration 5165: 0.43612715700670557\n",
      "Theta: [-1.55651729  0.96367138  0.06048627]\n",
      "Loss in iteration 5166: 0.4361208889871728\n",
      "Theta: [-1.5566569   0.96376471  0.06048319]\n",
      "Loss in iteration 5167: 0.43611462346679936\n",
      "Theta: [-1.55679647  0.96385803  0.06048011]\n",
      "Loss in iteration 5168: 0.4361083604443369\n",
      "Theta: [-1.55693602  0.96395132  0.06047704]\n",
      "Loss in iteration 5169: 0.43610209991853777\n",
      "Theta: [-1.55707553  0.9640446   0.06047396]\n",
      "Loss in iteration 5170: 0.4360958418881551\n",
      "Theta: [-1.55721502  0.96413786  0.06047089]\n",
      "Loss in iteration 5171: 0.436089586351943\n",
      "Theta: [-1.55735448  0.96423111  0.06046781]\n",
      "Loss in iteration 5172: 0.43608333330865584\n",
      "Theta: [-1.55749391  0.96432434  0.06046474]\n",
      "Loss in iteration 5173: 0.43607708275704915\n",
      "Theta: [-1.55763331  0.96441755  0.06046167]\n",
      "Loss in iteration 5174: 0.43607083469587943\n",
      "Theta: [-1.55777268  0.96451074  0.06045859]\n",
      "Loss in iteration 5175: 0.4360645891239034\n",
      "Theta: [-1.55791202  0.96460392  0.06045552]\n",
      "Loss in iteration 5176: 0.4360583460398788\n",
      "Theta: [-1.55805134  0.96469708  0.06045245]\n",
      "Loss in iteration 5177: 0.43605210544256423\n",
      "Theta: [-1.55819062  0.96479022  0.06044937]\n",
      "Loss in iteration 5178: 0.43604586733071904\n",
      "Theta: [-1.55832988  0.96488335  0.0604463 ]\n",
      "Loss in iteration 5179: 0.43603963170310306\n",
      "Theta: [-1.55846911  0.96497646  0.06044323]\n",
      "Loss in iteration 5180: 0.43603339855847745\n",
      "Theta: [-1.5586083   0.96506955  0.06044015]\n",
      "Loss in iteration 5181: 0.4360271678956035\n",
      "Theta: [-1.55874747  0.96516263  0.06043708]\n",
      "Loss in iteration 5182: 0.4360209397132436\n",
      "Theta: [-1.55888661  0.96525569  0.06043401]\n",
      "Loss in iteration 5183: 0.43601471401016084\n",
      "Theta: [-1.55902573  0.96534873  0.06043094]\n",
      "Loss in iteration 5184: 0.4360084907851192\n",
      "Theta: [-1.55916481  0.96544176  0.06042787]\n",
      "Loss in iteration 5185: 0.43600227003688324\n",
      "Theta: [-1.55930386  0.96553476  0.0604248 ]\n",
      "Loss in iteration 5186: 0.43599605176421824\n",
      "Theta: [-1.55944289  0.96562776  0.06042173]\n",
      "Loss in iteration 5187: 0.4359898359658904\n",
      "Theta: [-1.55958189  0.96572073  0.06041866]\n",
      "Loss in iteration 5188: 0.4359836226406667\n",
      "Theta: [-1.55972085  0.96581369  0.06041559]\n",
      "Loss in iteration 5189: 0.43597741178731475\n",
      "Theta: [-1.55985979  0.96590663  0.06041252]\n",
      "Loss in iteration 5190: 0.4359712034046029\n",
      "Theta: [-1.5599987   0.96599955  0.06040945]\n",
      "Loss in iteration 5191: 0.4359649974913004\n",
      "Theta: [-1.56013759  0.96609246  0.06040638]\n",
      "Loss in iteration 5192: 0.43595879404617727\n",
      "Theta: [-1.56027644  0.96618535  0.06040331]\n",
      "Loss in iteration 5193: 0.43595259306800394\n",
      "Theta: [-1.56041526  0.96627823  0.06040024]\n",
      "Loss in iteration 5194: 0.4359463945555521\n",
      "Theta: [-1.56055406  0.96637108  0.06039717]\n",
      "Loss in iteration 5195: 0.43594019850759375\n",
      "Theta: [-1.56069283  0.96646392  0.06039411]\n",
      "Loss in iteration 5196: 0.435934004922902\n",
      "Theta: [-1.56083156  0.96655675  0.06039104]\n",
      "Loss in iteration 5197: 0.4359278138002505\n",
      "Theta: [-1.56097027  0.96664955  0.06038797]\n",
      "Loss in iteration 5198: 0.4359216251384136\n",
      "Theta: [-1.56110895  0.96674234  0.0603849 ]\n",
      "Loss in iteration 5199: 0.4359154389361668\n",
      "Theta: [-1.56124761  0.96683512  0.06038184]\n",
      "Loss in iteration 5200: 0.43590925519228585\n",
      "Theta: [-1.56138623  0.96692787  0.06037877]\n",
      "Loss in iteration 5201: 0.4359030739055475\n",
      "Theta: [-1.56152482  0.96702061  0.0603757 ]\n",
      "Loss in iteration 5202: 0.4358968950747292\n",
      "Theta: [-1.56166339  0.96711334  0.06037264]\n",
      "Loss in iteration 5203: 0.43589071869860924\n",
      "Theta: [-1.56180193  0.96720604  0.06036957]\n",
      "Loss in iteration 5204: 0.4358845447759666\n",
      "Theta: [-1.56194044  0.96729873  0.0603665 ]\n",
      "Loss in iteration 5205: 0.43587837330558094\n",
      "Theta: [-1.56207892  0.9673914   0.06036344]\n",
      "Loss in iteration 5206: 0.4358722042862327\n",
      "Theta: [-1.56221737  0.96748406  0.06036037]\n",
      "Loss in iteration 5207: 0.43586603771670307\n",
      "Theta: [-1.56235579  0.9675767   0.06035731]\n",
      "Loss in iteration 5208: 0.4358598735957741\n",
      "Theta: [-1.56249419  0.96766932  0.06035424]\n",
      "Loss in iteration 5209: 0.43585371192222866\n",
      "Theta: [-1.56263255  0.96776193  0.06035118]\n",
      "Loss in iteration 5210: 0.4358475526948498\n",
      "Theta: [-1.56277089  0.96785451  0.06034812]\n",
      "Loss in iteration 5211: 0.43584139591242227\n",
      "Theta: [-1.5629092   0.96794709  0.06034505]\n",
      "Loss in iteration 5212: 0.4358352415737305\n",
      "Theta: [-1.56304748  0.96803964  0.06034199]\n",
      "Loss in iteration 5213: 0.43582908967756057\n",
      "Theta: [-1.56318573  0.96813218  0.06033893]\n",
      "Loss in iteration 5214: 0.4358229402226986\n",
      "Theta: [-1.56332395  0.9682247   0.06033586]\n",
      "Loss in iteration 5215: 0.435816793207932\n",
      "Theta: [-1.56346215  0.96831721  0.0603328 ]\n",
      "Loss in iteration 5216: 0.43581064863204866\n",
      "Theta: [-1.56360032  0.96840969  0.06032974]\n",
      "Loss in iteration 5217: 0.4358045064938373\n",
      "Theta: [-1.56373845  0.96850217  0.06032668]\n",
      "Loss in iteration 5218: 0.43579836679208717\n",
      "Theta: [-1.56387656  0.96859462  0.06032361]\n",
      "Loss in iteration 5219: 0.43579222952558866\n",
      "Theta: [-1.56401464  0.96868706  0.06032055]\n",
      "Loss in iteration 5220: 0.4357860946931325\n",
      "Theta: [-1.5641527   0.96877948  0.06031749]\n",
      "Loss in iteration 5221: 0.43577996229351035\n",
      "Theta: [-1.56429072  0.96887188  0.06031443]\n",
      "Loss in iteration 5222: 0.43577383232551464\n",
      "Theta: [-1.56442871  0.96896427  0.06031137]\n",
      "Loss in iteration 5223: 0.43576770478793847\n",
      "Theta: [-1.56456668  0.96905664  0.06030831]\n",
      "Loss in iteration 5224: 0.4357615796795757\n",
      "Theta: [-1.56470462  0.969149    0.06030525]\n",
      "Loss in iteration 5225: 0.435755456999221\n",
      "Theta: [-1.56484253  0.96924134  0.06030219]\n",
      "Loss in iteration 5226: 0.43574933674566957\n",
      "Theta: [-1.56498041  0.96933366  0.06029913]\n",
      "Loss in iteration 5227: 0.43574321891771767\n",
      "Theta: [-1.56511826  0.96942596  0.06029607]\n",
      "Loss in iteration 5228: 0.43573710351416184\n",
      "Theta: [-1.56525609  0.96951825  0.06029301]\n",
      "Loss in iteration 5229: 0.43573099053380004\n",
      "Theta: [-1.56539388  0.96961052  0.06028995]\n",
      "Loss in iteration 5230: 0.4357248799754299\n",
      "Theta: [-1.56553165  0.96970278  0.06028689]\n",
      "Loss in iteration 5231: 0.4357187718378512\n",
      "Theta: [-1.56566939  0.96979501  0.06028384]\n",
      "Loss in iteration 5232: 0.43571266611986315\n",
      "Theta: [-1.5658071   0.96988723  0.06028078]\n",
      "Loss in iteration 5233: 0.4357065628202667\n",
      "Theta: [-1.56594479  0.96997944  0.06027772]\n",
      "Loss in iteration 5234: 0.43570046193786266\n",
      "Theta: [-1.56608244  0.97007163  0.06027466]\n",
      "Loss in iteration 5235: 0.43569436347145296\n",
      "Theta: [-1.56622007  0.9701638   0.0602716 ]\n",
      "Loss in iteration 5236: 0.43568826741984074\n",
      "Theta: [-1.56635766  0.97025595  0.06026855]\n",
      "Loss in iteration 5237: 0.435682173781829\n",
      "Theta: [-1.56649523  0.97034809  0.06026549]\n",
      "Loss in iteration 5238: 0.4356760825562222\n",
      "Theta: [-1.56663277  0.97044021  0.06026243]\n",
      "Loss in iteration 5239: 0.4356699937418249\n",
      "Theta: [-1.56677029  0.97053232  0.06025938]\n",
      "Loss in iteration 5240: 0.435663907337443\n",
      "Theta: [-1.56690777  0.97062441  0.06025632]\n",
      "Loss in iteration 5241: 0.43565782334188263\n",
      "Theta: [-1.56704523  0.97071648  0.06025327]\n",
      "Loss in iteration 5242: 0.43565174175395105\n",
      "Theta: [-1.56718265  0.97080853  0.06025021]\n",
      "Loss in iteration 5243: 0.43564566257245607\n",
      "Theta: [-1.56732005  0.97090057  0.06024716]\n",
      "Loss in iteration 5244: 0.435639585796206\n",
      "Theta: [-1.56745743  0.97099259  0.0602441 ]\n",
      "Loss in iteration 5245: 0.4356335114240104\n",
      "Theta: [-1.56759477  0.9710846   0.06024105]\n",
      "Loss in iteration 5246: 0.4356274394546791\n",
      "Theta: [-1.56773208  0.97117659  0.06023799]\n",
      "Loss in iteration 5247: 0.4356213698870227\n",
      "Theta: [-1.56786937  0.97126856  0.06023494]\n",
      "Loss in iteration 5248: 0.4356153027198528\n",
      "Theta: [-1.56800663  0.97136051  0.06023189]\n",
      "Loss in iteration 5249: 0.43560923795198164\n",
      "Theta: [-1.56814386  0.97145245  0.06022883]\n",
      "Loss in iteration 5250: 0.4356031755822219\n",
      "Theta: [-1.56828106  0.97154438  0.06022578]\n",
      "Loss in iteration 5251: 0.43559711560938735\n",
      "Theta: [-1.56841823  0.97163628  0.06022273]\n",
      "Loss in iteration 5252: 0.4355910580322922\n",
      "Theta: [-1.56855538  0.97172817  0.06021967]\n",
      "Loss in iteration 5253: 0.4355850028497518\n",
      "Theta: [-1.5686925   0.97182004  0.06021662]\n",
      "Loss in iteration 5254: 0.4355789500605817\n",
      "Theta: [-1.56882958  0.9719119   0.06021357]\n",
      "Loss in iteration 5255: 0.4355728996635985\n",
      "Theta: [-1.56896664  0.97200374  0.06021052]\n",
      "Loss in iteration 5256: 0.4355668516576193\n",
      "Theta: [-1.56910368  0.97209556  0.06020747]\n",
      "Loss in iteration 5257: 0.43556080604146225\n",
      "Theta: [-1.56924068  0.97218737  0.06020441]\n",
      "Loss in iteration 5258: 0.43555476281394584\n",
      "Theta: [-1.56937766  0.97227916  0.06020136]\n",
      "Loss in iteration 5259: 0.4355487219738896\n",
      "Theta: [-1.56951461  0.97237093  0.06019831]\n",
      "Loss in iteration 5260: 0.4355426835201136\n",
      "Theta: [-1.56965153  0.97246269  0.06019526]\n",
      "Loss in iteration 5261: 0.4355366474514388\n",
      "Theta: [-1.56978842  0.97255443  0.06019221]\n",
      "Loss in iteration 5262: 0.4355306137666865\n",
      "Theta: [-1.56992528  0.97264615  0.06018916]\n",
      "Loss in iteration 5263: 0.43552458246467923\n",
      "Theta: [-1.57006212  0.97273786  0.06018611]\n",
      "Loss in iteration 5264: 0.43551855354424\n",
      "Theta: [-1.57019893  0.97282955  0.06018306]\n",
      "Loss in iteration 5265: 0.4355125270041922\n",
      "Theta: [-1.57033571  0.97292123  0.06018001]\n",
      "Loss in iteration 5266: 0.43550650284336057\n",
      "Theta: [-1.57047246  0.97301288  0.06017697]\n",
      "Loss in iteration 5267: 0.43550048106057004\n",
      "Theta: [-1.57060918  0.97310452  0.06017392]\n",
      "Loss in iteration 5268: 0.43549446165464656\n",
      "Theta: [-1.57074588  0.97319615  0.06017087]\n",
      "Loss in iteration 5269: 0.435488444624417\n",
      "Theta: [-1.57088254  0.97328776  0.06016782]\n",
      "Loss in iteration 5270: 0.4354824299687083\n",
      "Theta: [-1.57101918  0.97337935  0.06016477]\n",
      "Loss in iteration 5271: 0.43547641768634837\n",
      "Theta: [-1.57115579  0.97347093  0.06016173]\n",
      "Loss in iteration 5272: 0.43547040777616614\n",
      "Theta: [-1.57129238  0.97356248  0.06015868]\n",
      "Loss in iteration 5273: 0.4354644002369909\n",
      "Theta: [-1.57142893  0.97365403  0.06015563]\n",
      "Loss in iteration 5274: 0.43545839506765316\n",
      "Theta: [-1.57156546  0.97374555  0.06015258]\n",
      "Loss in iteration 5275: 0.43545239226698335\n",
      "Theta: [-1.57170196  0.97383706  0.06014954]\n",
      "Loss in iteration 5276: 0.43544639183381334\n",
      "Theta: [-1.57183843  0.97392856  0.06014649]\n",
      "Loss in iteration 5277: 0.4354403937669752\n",
      "Theta: [-1.57197487  0.97402003  0.06014345]\n",
      "Loss in iteration 5278: 0.4354343980653018\n",
      "Theta: [-1.57211129  0.97411149  0.0601404 ]\n",
      "Loss in iteration 5279: 0.4354284047276274\n",
      "Theta: [-1.57224767  0.97420294  0.06013736]\n",
      "Loss in iteration 5280: 0.4354224137527858\n",
      "Theta: [-1.57238403  0.97429436  0.06013431]\n",
      "Loss in iteration 5281: 0.43541642513961243\n",
      "Theta: [-1.57252036  0.97438577  0.06013127]\n",
      "Loss in iteration 5282: 0.43541043888694303\n",
      "Theta: [-1.57265667  0.97447717  0.06012822]\n",
      "Loss in iteration 5283: 0.4354044549936142\n",
      "Theta: [-1.57279294  0.97456855  0.06012518]\n",
      "Loss in iteration 5284: 0.4353984734584631\n",
      "Theta: [-1.57292919  0.97465991  0.06012213]\n",
      "Loss in iteration 5285: 0.4353924942803279\n",
      "Theta: [-1.57306541  0.97475125  0.06011909]\n",
      "Loss in iteration 5286: 0.43538651745804685\n",
      "Theta: [-1.5732016   0.97484258  0.06011605]\n",
      "Loss in iteration 5287: 0.43538054299045953\n",
      "Theta: [-1.57333776  0.97493389  0.060113  ]\n",
      "Loss in iteration 5288: 0.4353745708764062\n",
      "Theta: [-1.5734739   0.97502519  0.06010996]\n",
      "Loss in iteration 5289: 0.4353686011147274\n",
      "Theta: [-1.57361001  0.97511647  0.06010692]\n",
      "Loss in iteration 5290: 0.4353626337042646\n",
      "Theta: [-1.57374609  0.97520773  0.06010388]\n",
      "Loss in iteration 5291: 0.43535666864386013\n",
      "Theta: [-1.57388214  0.97529898  0.06010083]\n",
      "Loss in iteration 5292: 0.43535070593235686\n",
      "Theta: [-1.57401817  0.97539021  0.06009779]\n",
      "Loss in iteration 5293: 0.43534474556859815\n",
      "Theta: [-1.57415416  0.97548142  0.06009475]\n",
      "Loss in iteration 5294: 0.4353387875514286\n",
      "Theta: [-1.57429013  0.97557262  0.06009171]\n",
      "Loss in iteration 5295: 0.4353328318796931\n",
      "Theta: [-1.57442607  0.9756638   0.06008867]\n",
      "Loss in iteration 5296: 0.43532687855223723\n",
      "Theta: [-1.57456198  0.97575497  0.06008563]\n",
      "Loss in iteration 5297: 0.4353209275679074\n",
      "Theta: [-1.57469787  0.97584611  0.06008259]\n",
      "Loss in iteration 5298: 0.4353149789255508\n",
      "Theta: [-1.57483373  0.97593725  0.06007955]\n",
      "Loss in iteration 5299: 0.4353090326240153\n",
      "Theta: [-1.57496956  0.97602836  0.06007651]\n",
      "Loss in iteration 5300: 0.43530308866214923\n",
      "Theta: [-1.57510536  0.97611946  0.06007347]\n",
      "Loss in iteration 5301: 0.43529714703880173\n",
      "Theta: [-1.57524113  0.97621055  0.06007043]\n",
      "Loss in iteration 5302: 0.43529120775282293\n",
      "Theta: [-1.57537688  0.97630161  0.06006739]\n",
      "Loss in iteration 5303: 0.43528527080306334\n",
      "Theta: [-1.5755126   0.97639266  0.06006435]\n",
      "Loss in iteration 5304: 0.435279336188374\n",
      "Theta: [-1.57564829  0.9764837   0.06006131]\n",
      "Loss in iteration 5305: 0.4352734039076072\n",
      "Theta: [-1.57578395  0.97657471  0.06005828]\n",
      "Loss in iteration 5306: 0.4352674739596156\n",
      "Theta: [-1.57591959  0.97666572  0.06005524]\n",
      "Loss in iteration 5307: 0.4352615463432524\n",
      "Theta: [-1.57605519  0.9767567   0.0600522 ]\n",
      "Loss in iteration 5308: 0.43525562105737187\n",
      "Theta: [-1.57619077  0.97684767  0.06004916]\n",
      "Loss in iteration 5309: 0.43524969810082864\n",
      "Theta: [-1.57632633  0.97693862  0.06004613]\n",
      "Loss in iteration 5310: 0.43524377747247817\n",
      "Theta: [-1.57646185  0.97702956  0.06004309]\n",
      "Loss in iteration 5311: 0.4352378591711767\n",
      "Theta: [-1.57659735  0.97712048  0.06004005]\n",
      "Loss in iteration 5312: 0.43523194319578096\n",
      "Theta: [-1.57673282  0.97721138  0.06003702]\n",
      "Loss in iteration 5313: 0.4352260295451486\n",
      "Theta: [-1.57686826  0.97730227  0.06003398]\n",
      "Loss in iteration 5314: 0.43522011821813783\n",
      "Theta: [-1.57700367  0.97739314  0.06003094]\n",
      "Loss in iteration 5315: 0.4352142092136076\n",
      "Theta: [-1.57713906  0.97748399  0.06002791]\n",
      "Loss in iteration 5316: 0.4352083025304173\n",
      "Theta: [-1.57727441  0.97757483  0.06002487]\n",
      "Loss in iteration 5317: 0.43520239816742756\n",
      "Theta: [-1.57740975  0.97766565  0.06002184]\n",
      "Loss in iteration 5318: 0.4351964961234993\n",
      "Theta: [-1.57754505  0.97775646  0.0600188 ]\n",
      "Loss in iteration 5319: 0.435190596397494\n",
      "Theta: [-1.57768032  0.97784725  0.06001577]\n",
      "Loss in iteration 5320: 0.4351846989882743\n",
      "Theta: [-1.57781557  0.97793802  0.06001274]\n",
      "Loss in iteration 5321: 0.4351788038947031\n",
      "Theta: [-1.57795079  0.97802878  0.0600097 ]\n",
      "Loss in iteration 5322: 0.43517291111564427\n",
      "Theta: [-1.57808598  0.97811952  0.06000667]\n",
      "Loss in iteration 5323: 0.43516702064996204\n",
      "Theta: [-1.57822115  0.97821024  0.06000364]\n",
      "Loss in iteration 5324: 0.4351611324965217\n",
      "Theta: [-1.57835629  0.97830095  0.0600006 ]\n",
      "Loss in iteration 5325: 0.43515524665418914\n",
      "Theta: [-1.5784914   0.97839164  0.05999757]\n",
      "Loss in iteration 5326: 0.4351493631218307\n",
      "Theta: [-1.57862648  0.97848232  0.05999454]\n",
      "Loss in iteration 5327: 0.4351434818983136\n",
      "Theta: [-1.57876153  0.97857298  0.05999151]\n",
      "Loss in iteration 5328: 0.43513760298250587\n",
      "Theta: [-1.57889656  0.97866362  0.05998847]\n",
      "Loss in iteration 5329: 0.43513172637327585\n",
      "Theta: [-1.57903156  0.97875425  0.05998544]\n",
      "Loss in iteration 5330: 0.43512585206949284\n",
      "Theta: [-1.57916653  0.97884486  0.05998241]\n",
      "Loss in iteration 5331: 0.43511998007002683\n",
      "Theta: [-1.57930148  0.97893545  0.05997938]\n",
      "Loss in iteration 5332: 0.4351141103737486\n",
      "Theta: [-1.57943639  0.97902603  0.05997635]\n",
      "Loss in iteration 5333: 0.435108242979529\n",
      "Theta: [-1.57957128  0.97911659  0.05997332]\n",
      "Loss in iteration 5334: 0.43510237788624034\n",
      "Theta: [-1.57970615  0.97920714  0.05997029]\n",
      "Loss in iteration 5335: 0.43509651509275504\n",
      "Theta: [-1.57984098  0.97929767  0.05996726]\n",
      "Loss in iteration 5336: 0.43509065459794677\n",
      "Theta: [-1.57997579  0.97938818  0.05996423]\n",
      "Loss in iteration 5337: 0.4350847964006894\n",
      "Theta: [-1.58011057  0.97947868  0.0599612 ]\n",
      "Loss in iteration 5338: 0.43507894049985735\n",
      "Theta: [-1.58024532  0.97956916  0.05995817]\n",
      "Loss in iteration 5339: 0.43507308689432633\n",
      "Theta: [-1.58038004  0.97965963  0.05995514]\n",
      "Loss in iteration 5340: 0.4350672355829724\n",
      "Theta: [-1.58051474  0.97975008  0.05995211]\n",
      "Loss in iteration 5341: 0.4350613865646721\n",
      "Theta: [-1.58064941  0.97984051  0.05994908]\n",
      "Loss in iteration 5342: 0.4350555398383029\n",
      "Theta: [-1.58078405  0.97993092  0.05994606]\n",
      "Loss in iteration 5343: 0.43504969540274296\n",
      "Theta: [-1.58091867  0.98002132  0.05994303]\n",
      "Loss in iteration 5344: 0.4350438532568711\n",
      "Theta: [-1.58105326  0.98011171  0.05994   ]\n",
      "Loss in iteration 5345: 0.43503801339956666\n",
      "Theta: [-1.58118782  0.98020208  0.05993697]\n",
      "Loss in iteration 5346: 0.4350321758297097\n",
      "Theta: [-1.58132235  0.98029243  0.05993395]\n",
      "Loss in iteration 5347: 0.43502634054618133\n",
      "Theta: [-1.58145685  0.98038276  0.05993092]\n",
      "Loss in iteration 5348: 0.4350205075478627\n",
      "Theta: [-1.58159133  0.98047308  0.05992789]\n",
      "Loss in iteration 5349: 0.43501467683363587\n",
      "Theta: [-1.58172578  0.98056339  0.05992487]\n",
      "Loss in iteration 5350: 0.43500884840238413\n",
      "Theta: [-1.58186021  0.98065367  0.05992184]\n",
      "Loss in iteration 5351: 0.4350030222529906\n",
      "Theta: [-1.5819946   0.98074394  0.05991882]\n",
      "Loss in iteration 5352: 0.43499719838433953\n",
      "Theta: [-1.58212897  0.9808342   0.05991579]\n",
      "Loss in iteration 5353: 0.43499137679531585\n",
      "Theta: [-1.58226331  0.98092444  0.05991277]\n",
      "Loss in iteration 5354: 0.43498555748480505\n",
      "Theta: [-1.58239762  0.98101466  0.05990974]\n",
      "Loss in iteration 5355: 0.43497974045169313\n",
      "Theta: [-1.58253191  0.98110487  0.05990672]\n",
      "Loss in iteration 5356: 0.43497392569486726\n",
      "Theta: [-1.58266617  0.98119506  0.05990369]\n",
      "Loss in iteration 5357: 0.4349681132132147\n",
      "Theta: [-1.5828004   0.98128523  0.05990067]\n",
      "Loss in iteration 5358: 0.4349623030056239\n",
      "Theta: [-1.58293461  0.98137539  0.05989765]\n",
      "Loss in iteration 5359: 0.4349564950709835\n",
      "Theta: [-1.58306878  0.98146553  0.05989462]\n",
      "Loss in iteration 5360: 0.43495068940818316\n",
      "Theta: [-1.58320293  0.98155566  0.0598916 ]\n",
      "Loss in iteration 5361: 0.43494488601611325\n",
      "Theta: [-1.58333706  0.98164577  0.05988858]\n",
      "Loss in iteration 5362: 0.4349390848936643\n",
      "Theta: [-1.58347115  0.98173586  0.05988555]\n",
      "Loss in iteration 5363: 0.434933286039728\n",
      "Theta: [-1.58360522  0.98182594  0.05988253]\n",
      "Loss in iteration 5364: 0.4349274894531967\n",
      "Theta: [-1.58373926  0.981916    0.05987951]\n",
      "Loss in iteration 5365: 0.4349216951329631\n",
      "Theta: [-1.58387327  0.98200605  0.05987649]\n",
      "Loss in iteration 5366: 0.4349159030779209\n",
      "Theta: [-1.58400726  0.98209608  0.05987347]\n",
      "Loss in iteration 5367: 0.4349101132869642\n",
      "Theta: [-1.58414122  0.98218609  0.05987044]\n",
      "Loss in iteration 5368: 0.43490432575898796\n",
      "Theta: [-1.58427515  0.98227609  0.05986742]\n",
      "Loss in iteration 5369: 0.4348985404928877\n",
      "Theta: [-1.58440906  0.98236607  0.0598644 ]\n",
      "Loss in iteration 5370: 0.43489275748755957\n",
      "Theta: [-1.58454293  0.98245603  0.05986138]\n",
      "Loss in iteration 5371: 0.4348869767419005\n",
      "Theta: [-1.58467679  0.98254598  0.05985836]\n",
      "Loss in iteration 5372: 0.4348811982548081\n",
      "Theta: [-1.58481061  0.98263591  0.05985534]\n",
      "Loss in iteration 5373: 0.4348754220251804\n",
      "Theta: [-1.5849444   0.98272583  0.05985232]\n",
      "Loss in iteration 5374: 0.4348696480519165\n",
      "Theta: [-1.58507817  0.98281573  0.0598493 ]\n",
      "Loss in iteration 5375: 0.4348638763339158\n",
      "Theta: [-1.58521192  0.98290562  0.05984629]\n",
      "Loss in iteration 5376: 0.43485810687007836\n",
      "Theta: [-1.58534563  0.98299549  0.05984327]\n",
      "Loss in iteration 5377: 0.4348523396593052\n",
      "Theta: [-1.58547932  0.98308534  0.05984025]\n",
      "Loss in iteration 5378: 0.43484657470049776\n",
      "Theta: [-1.58561298  0.98317518  0.05983723]\n",
      "Loss in iteration 5379: 0.4348408119925583\n",
      "Theta: [-1.58574661  0.983265    0.05983421]\n",
      "Loss in iteration 5380: 0.4348350515343896\n",
      "Theta: [-1.58588022  0.9833548   0.05983119]\n",
      "Loss in iteration 5381: 0.43482929332489495\n",
      "Theta: [-1.5860138   0.98344459  0.05982818]\n",
      "Loss in iteration 5382: 0.43482353736297896\n",
      "Theta: [-1.58614735  0.98353436  0.05982516]\n",
      "Loss in iteration 5383: 0.43481778364754603\n",
      "Theta: [-1.58628087  0.98362412  0.05982214]\n",
      "Loss in iteration 5384: 0.43481203217750186\n",
      "Theta: [-1.58641437  0.98371386  0.05981913]\n",
      "Loss in iteration 5385: 0.43480628295175244\n",
      "Theta: [-1.58654784  0.98380359  0.05981611]\n",
      "Loss in iteration 5386: 0.4348005359692045\n",
      "Theta: [-1.58668128  0.98389329  0.05981309]\n",
      "Loss in iteration 5387: 0.4347947912287657\n",
      "Theta: [-1.5868147   0.98398299  0.05981008]\n",
      "Loss in iteration 5388: 0.43478904872934393\n",
      "Theta: [-1.58694809  0.98407266  0.05980706]\n",
      "Loss in iteration 5389: 0.4347833084698482\n",
      "Theta: [-1.58708145  0.98416232  0.05980405]\n",
      "Loss in iteration 5390: 0.4347775704491875\n",
      "Theta: [-1.58721479  0.98425197  0.05980103]\n",
      "Loss in iteration 5391: 0.4347718346662722\n",
      "Theta: [-1.5873481   0.9843416   0.05979802]\n",
      "Loss in iteration 5392: 0.434766101120013\n",
      "Theta: [-1.58748138  0.98443121  0.059795  ]\n",
      "Loss in iteration 5393: 0.43476036980932137\n",
      "Theta: [-1.58761463  0.98452081  0.05979199]\n",
      "Loss in iteration 5394: 0.43475464073310893\n",
      "Theta: [-1.58774786  0.98461039  0.05978898]\n",
      "Loss in iteration 5395: 0.4347489138902887\n",
      "Theta: [-1.58788106  0.98469995  0.05978596]\n",
      "Loss in iteration 5396: 0.43474318927977396\n",
      "Theta: [-1.58801423  0.9847895   0.05978295]\n",
      "Loss in iteration 5397: 0.4347374669004784\n",
      "Theta: [-1.58814738  0.98487904  0.05977994]\n",
      "Loss in iteration 5398: 0.43473174675131715\n",
      "Theta: [-1.5882805   0.98496855  0.05977692]\n",
      "Loss in iteration 5399: 0.43472602883120515\n",
      "Theta: [-1.58841359  0.98505806  0.05977391]\n",
      "Loss in iteration 5400: 0.4347203131390585\n",
      "Theta: [-1.58854666  0.98514754  0.0597709 ]\n",
      "Loss in iteration 5401: 0.4347145996737936\n",
      "Theta: [-1.5886797   0.98523701  0.05976789]\n",
      "Loss in iteration 5402: 0.4347088884343278\n",
      "Theta: [-1.58881271  0.98532646  0.05976488]\n",
      "Loss in iteration 5403: 0.43470317941957903\n",
      "Theta: [-1.58894569  0.9854159   0.05976187]\n",
      "Loss in iteration 5404: 0.4346974726284657\n",
      "Theta: [-1.58907865  0.98550532  0.05975885]\n",
      "Loss in iteration 5405: 0.434691768059907\n",
      "Theta: [-1.58921158  0.98559473  0.05975584]\n",
      "Loss in iteration 5406: 0.4346860657128229\n",
      "Theta: [-1.58934448  0.98568412  0.05975283]\n",
      "Loss in iteration 5407: 0.43468036558613377\n",
      "Theta: [-1.58947736  0.98577349  0.05974982]\n",
      "Loss in iteration 5408: 0.4346746676787606\n",
      "Theta: [-1.58961021  0.98586285  0.05974681]\n",
      "Loss in iteration 5409: 0.4346689719896254\n",
      "Theta: [-1.58974303  0.98595219  0.0597438 ]\n",
      "Loss in iteration 5410: 0.43466327851765046\n",
      "Theta: [-1.58987583  0.98604152  0.05974079]\n",
      "Loss in iteration 5411: 0.4346575872617589\n",
      "Theta: [-1.5900086   0.98613083  0.05973779]\n",
      "Loss in iteration 5412: 0.43465189822087424\n",
      "Theta: [-1.59014134  0.98622012  0.05973478]\n",
      "Loss in iteration 5413: 0.4346462113939211\n",
      "Theta: [-1.59027406  0.9863094   0.05973177]\n",
      "Loss in iteration 5414: 0.4346405267798243\n",
      "Theta: [-1.59040675  0.98639866  0.05972876]\n",
      "Loss in iteration 5415: 0.43463484437750965\n",
      "Theta: [-1.59053941  0.98648791  0.05972575]\n",
      "Loss in iteration 5416: 0.4346291641859031\n",
      "Theta: [-1.59067205  0.98657714  0.05972274]\n",
      "Loss in iteration 5417: 0.43462348620393176\n",
      "Theta: [-1.59080465  0.98666636  0.05971974]\n",
      "Loss in iteration 5418: 0.43461781043052333\n",
      "Theta: [-1.59093724  0.98675556  0.05971673]\n",
      "Loss in iteration 5419: 0.43461213686460576\n",
      "Theta: [-1.59106979  0.98684474  0.05971372]\n",
      "Loss in iteration 5420: 0.43460646550510795\n",
      "Theta: [-1.59120232  0.98693391  0.05971072]\n",
      "Loss in iteration 5421: 0.4346007963509598\n",
      "Theta: [-1.59133482  0.98702306  0.05970771]\n",
      "Loss in iteration 5422: 0.4345951294010908\n",
      "Theta: [-1.59146729  0.9871122   0.0597047 ]\n",
      "Loss in iteration 5423: 0.434589464654432\n",
      "Theta: [-1.59159974  0.98720132  0.0597017 ]\n",
      "Loss in iteration 5424: 0.43458380210991493\n",
      "Theta: [-1.59173216  0.98729042  0.05969869]\n",
      "Loss in iteration 5425: 0.43457814176647164\n",
      "Theta: [-1.59186456  0.98737951  0.05969569]\n",
      "Loss in iteration 5426: 0.4345724836230343\n",
      "Theta: [-1.59199693  0.98746858  0.05969268]\n",
      "Loss in iteration 5427: 0.4345668276785368\n",
      "Theta: [-1.59212927  0.98755764  0.05968968]\n",
      "Loss in iteration 5428: 0.4345611739319131\n",
      "Theta: [-1.59226158  0.98764668  0.05968667]\n",
      "Loss in iteration 5429: 0.4345555223820976\n",
      "Theta: [-1.59239387  0.9877357   0.05968367]\n",
      "Loss in iteration 5430: 0.43454987302802534\n",
      "Theta: [-1.59252613  0.98782471  0.05968067]\n",
      "Loss in iteration 5431: 0.4345442258686326\n",
      "Theta: [-1.59265836  0.98791371  0.05967766]\n",
      "Loss in iteration 5432: 0.4345385809028557\n",
      "Theta: [-1.59279057  0.98800268  0.05967466]\n",
      "Loss in iteration 5433: 0.4345329381296316\n",
      "Theta: [-1.59292275  0.98809165  0.05967166]\n",
      "Loss in iteration 5434: 0.4345272975478986\n",
      "Theta: [-1.5930549   0.98818059  0.05966865]\n",
      "Loss in iteration 5435: 0.4345216591565944\n",
      "Theta: [-1.59318703  0.98826952  0.05966565]\n",
      "Loss in iteration 5436: 0.4345160229546585\n",
      "Theta: [-1.59331913  0.98835844  0.05966265]\n",
      "Loss in iteration 5437: 0.43451038894103067\n",
      "Theta: [-1.59345121  0.98844734  0.05965965]\n",
      "Loss in iteration 5438: 0.43450475711465086\n",
      "Theta: [-1.59358325  0.98853622  0.05965664]\n",
      "Loss in iteration 5439: 0.4344991274744603\n",
      "Theta: [-1.59371527  0.98862509  0.05965364]\n",
      "Loss in iteration 5440: 0.43449350001940035\n",
      "Theta: [-1.59384727  0.98871394  0.05965064]\n",
      "Loss in iteration 5441: 0.43448787474841344\n",
      "Theta: [-1.59397924  0.98880277  0.05964764]\n",
      "Loss in iteration 5442: 0.4344822516604423\n",
      "Theta: [-1.59411118  0.98889159  0.05964464]\n",
      "Loss in iteration 5443: 0.43447663075443027\n",
      "Theta: [-1.59424309  0.9889804   0.05964164]\n",
      "Loss in iteration 5444: 0.43447101202932165\n",
      "Theta: [-1.59437498  0.98906918  0.05963864]\n",
      "Loss in iteration 5445: 0.43446539548406116\n",
      "Theta: [-1.59450684  0.98915796  0.05963564]\n",
      "Loss in iteration 5446: 0.4344597811175939\n",
      "Theta: [-1.59463867  0.98924671  0.05963264]\n",
      "Loss in iteration 5447: 0.4344541689288661\n",
      "Theta: [-1.59477048  0.98933546  0.05962964]\n",
      "Loss in iteration 5448: 0.4344485589168245\n",
      "Theta: [-1.59490226  0.98942418  0.05962664]\n",
      "Loss in iteration 5449: 0.43444295108041603\n",
      "Theta: [-1.59503402  0.98951289  0.05962365]\n",
      "Loss in iteration 5450: 0.43443734541858875\n",
      "Theta: [-1.59516575  0.98960158  0.05962065]\n",
      "Loss in iteration 5451: 0.43443174193029116\n",
      "Theta: [-1.59529745  0.98969026  0.05961765]\n",
      "Loss in iteration 5452: 0.4344261406144722\n",
      "Theta: [-1.59542912  0.98977892  0.05961465]\n",
      "Loss in iteration 5453: 0.4344205414700819\n",
      "Theta: [-1.59556077  0.98986757  0.05961165]\n",
      "Loss in iteration 5454: 0.43441494449607043\n",
      "Theta: [-1.59569239  0.9899562   0.05960866]\n",
      "Loss in iteration 5455: 0.43440934969138895\n",
      "Theta: [-1.59582399  0.99004482  0.05960566]\n",
      "Loss in iteration 5456: 0.43440375705498896\n",
      "Theta: [-1.59595556  0.99013342  0.05960266]\n",
      "Loss in iteration 5457: 0.4343981665858228\n",
      "Theta: [-1.5960871   0.990222    0.05959967]\n",
      "Loss in iteration 5458: 0.43439257828284317\n",
      "Theta: [-1.59621862  0.99031057  0.05959667]\n",
      "Loss in iteration 5459: 0.4343869921450038\n",
      "Theta: [-1.59635011  0.99039912  0.05959367]\n",
      "Loss in iteration 5460: 0.4343814081712587\n",
      "Theta: [-1.59648157  0.99048766  0.05959068]\n",
      "Loss in iteration 5461: 0.4343758263605628\n",
      "Theta: [-1.59661301  0.99057618  0.05958768]\n",
      "Loss in iteration 5462: 0.4343702467118711\n",
      "Theta: [-1.59674442  0.99066469  0.05958469]\n",
      "Loss in iteration 5463: 0.43436466922413985\n",
      "Theta: [-1.5968758   0.99075318  0.05958169]\n",
      "Loss in iteration 5464: 0.4343590938963257\n",
      "Theta: [-1.59700716  0.99084165  0.0595787 ]\n",
      "Loss in iteration 5465: 0.43435352072738576\n",
      "Theta: [-1.59713849  0.99093011  0.05957571]\n",
      "Loss in iteration 5466: 0.43434794971627794\n",
      "Theta: [-1.59726979  0.99101855  0.05957271]\n",
      "Loss in iteration 5467: 0.43434238086196053\n",
      "Theta: [-1.59740107  0.99110698  0.05956972]\n",
      "Loss in iteration 5468: 0.434336814163393\n",
      "Theta: [-1.59753232  0.99119539  0.05956672]\n",
      "Loss in iteration 5469: 0.43433124961953473\n",
      "Theta: [-1.59766355  0.99128379  0.05956373]\n",
      "Loss in iteration 5470: 0.43432568722934617\n",
      "Theta: [-1.59779475  0.99137217  0.05956074]\n",
      "Loss in iteration 5471: 0.4343201269917884\n",
      "Theta: [-1.59792592  0.99146053  0.05955775]\n",
      "Loss in iteration 5472: 0.4343145689058228\n",
      "Theta: [-1.59805707  0.99154888  0.05955475]\n",
      "Loss in iteration 5473: 0.4343090129704117\n",
      "Theta: [-1.59818819  0.99163721  0.05955176]\n",
      "Loss in iteration 5474: 0.4343034591845176\n",
      "Theta: [-1.59831928  0.99172553  0.05954877]\n",
      "Loss in iteration 5475: 0.43429790754710423\n",
      "Theta: [-1.59845035  0.99181383  0.05954578]\n",
      "Loss in iteration 5476: 0.4342923580571356\n",
      "Theta: [-1.59858139  0.99190212  0.05954279]\n",
      "Loss in iteration 5477: 0.4342868107135763\n",
      "Theta: [-1.5987124   0.99199039  0.0595398 ]\n",
      "Loss in iteration 5478: 0.43428126551539153\n",
      "Theta: [-1.59884339  0.99207864  0.05953681]\n",
      "Loss in iteration 5479: 0.4342757224615472\n",
      "Theta: [-1.59897435  0.99216688  0.05953382]\n",
      "Loss in iteration 5480: 0.43427018155100994\n",
      "Theta: [-1.59910529  0.99225511  0.05953083]\n",
      "Loss in iteration 5481: 0.43426464278274673\n",
      "Theta: [-1.5992362   0.99234332  0.05952784]\n",
      "Loss in iteration 5482: 0.4342591061557252\n",
      "Theta: [-1.59936708  0.99243151  0.05952485]\n",
      "Loss in iteration 5483: 0.4342535716689139\n",
      "Theta: [-1.59949794  0.99251969  0.05952186]\n",
      "Loss in iteration 5484: 0.43424803932128164\n",
      "Theta: [-1.59962877  0.99260785  0.05951887]\n",
      "Loss in iteration 5485: 0.43424250911179807\n",
      "Theta: [-1.59975957  0.99269599  0.05951588]\n",
      "Loss in iteration 5486: 0.43423698103943337\n",
      "Theta: [-1.59989035  0.99278412  0.05951289]\n",
      "Loss in iteration 5487: 0.4342314551031582\n",
      "Theta: [-1.6000211   0.99287224  0.0595099 ]\n",
      "Loss in iteration 5488: 0.4342259313019439\n",
      "Theta: [-1.60015183  0.99296034  0.05950692]\n",
      "Loss in iteration 5489: 0.4342204096347626\n",
      "Theta: [-1.60028252  0.99304842  0.05950393]\n",
      "Loss in iteration 5490: 0.4342148901005871\n",
      "Theta: [-1.6004132   0.99313649  0.05950094]\n",
      "Loss in iteration 5491: 0.43420937269839044\n",
      "Theta: [-1.60054384  0.99322454  0.05949795]\n",
      "Loss in iteration 5492: 0.43420385742714623\n",
      "Theta: [-1.60067446  0.99331258  0.05949497]\n",
      "Loss in iteration 5493: 0.4341983442858293\n",
      "Theta: [-1.60080506  0.9934006   0.05949198]\n",
      "Loss in iteration 5494: 0.43419283327341446\n",
      "Theta: [-1.60093563  0.99348861  0.05948899]\n",
      "Loss in iteration 5495: 0.4341873243888774\n",
      "Theta: [-1.60106617  0.9935766   0.05948601]\n",
      "Loss in iteration 5496: 0.4341818176311944\n",
      "Theta: [-1.60119668  0.99366457  0.05948302]\n",
      "Loss in iteration 5497: 0.4341763129993425\n",
      "Theta: [-1.60132717  0.99375253  0.05948004]\n",
      "Loss in iteration 5498: 0.434170810492299\n",
      "Theta: [-1.60145764  0.99384047  0.05947705]\n",
      "Loss in iteration 5499: 0.43416531010904186\n",
      "Theta: [-1.60158807  0.9939284   0.05947407]\n",
      "Loss in iteration 5500: 0.43415981184855007\n",
      "Theta: [-1.60171848  0.99401631  0.05947108]\n",
      "Loss in iteration 5501: 0.43415431570980284\n",
      "Theta: [-1.60184887  0.99410421  0.0594681 ]\n",
      "Loss in iteration 5502: 0.4341488216917797\n",
      "Theta: [-1.60197923  0.99419209  0.05946512]\n",
      "Loss in iteration 5503: 0.43414332979346176\n",
      "Theta: [-1.60210956  0.99427996  0.05946213]\n",
      "Loss in iteration 5504: 0.4341378400138299\n",
      "Theta: [-1.60223987  0.99436781  0.05945915]\n",
      "Loss in iteration 5505: 0.4341323523518655\n",
      "Theta: [-1.60237015  0.99445565  0.05945617]\n",
      "Loss in iteration 5506: 0.4341268668065512\n",
      "Theta: [-1.6025004   0.99454346  0.05945318]\n",
      "Loss in iteration 5507: 0.43412138337686995\n",
      "Theta: [-1.60263063  0.99463127  0.0594502 ]\n",
      "Loss in iteration 5508: 0.4341159020618052\n",
      "Theta: [-1.60276083  0.99471906  0.05944722]\n",
      "Loss in iteration 5509: 0.434110422860341\n",
      "Theta: [-1.60289101  0.99480683  0.05944424]\n",
      "Loss in iteration 5510: 0.4341049457714622\n",
      "Theta: [-1.60302116  0.99489459  0.05944125]\n",
      "Loss in iteration 5511: 0.43409947079415395\n",
      "Theta: [-1.60315128  0.99498233  0.05943827]\n",
      "Loss in iteration 5512: 0.4340939979274022\n",
      "Theta: [-1.60328138  0.99507006  0.05943529]\n",
      "Loss in iteration 5513: 0.43408852717019386\n",
      "Theta: [-1.60341145  0.99515777  0.05943231]\n",
      "Loss in iteration 5514: 0.4340830585215155\n",
      "Theta: [-1.6035415   0.99524546  0.05942933]\n",
      "Loss in iteration 5515: 0.4340775919803551\n",
      "Theta: [-1.60367152  0.99533314  0.05942635]\n",
      "Loss in iteration 5516: 0.4340721275457011\n",
      "Theta: [-1.60380151  0.99542081  0.05942337]\n",
      "Loss in iteration 5517: 0.43406666521654214\n",
      "Theta: [-1.60393148  0.99550846  0.05942039]\n",
      "Loss in iteration 5518: 0.4340612049918681\n",
      "Theta: [-1.60406142  0.99559609  0.05941741]\n",
      "Loss in iteration 5519: 0.43405574687066867\n",
      "Theta: [-1.60419134  0.99568371  0.05941443]\n",
      "Loss in iteration 5520: 0.4340502908519349\n",
      "Theta: [-1.60432122  0.99577131  0.05941145]\n",
      "Loss in iteration 5521: 0.43404483693465806\n",
      "Theta: [-1.60445109  0.9958589   0.05940847]\n",
      "Loss in iteration 5522: 0.4340393851178298\n",
      "Theta: [-1.60458093  0.99594647  0.05940549]\n",
      "Loss in iteration 5523: 0.43403393540044294\n",
      "Theta: [-1.60471074  0.99603403  0.05940252]\n",
      "Loss in iteration 5524: 0.43402848778149034\n",
      "Theta: [-1.60484052  0.99612157  0.05939954]\n",
      "Loss in iteration 5525: 0.43402304225996585\n",
      "Theta: [-1.60497028  0.99620909  0.05939656]\n",
      "Loss in iteration 5526: 0.4340175988348638\n",
      "Theta: [-1.60510002  0.9962966   0.05939358]\n",
      "Loss in iteration 5527: 0.43401215750517885\n",
      "Theta: [-1.60522973  0.9963841   0.05939061]\n",
      "Loss in iteration 5528: 0.43400671826990667\n",
      "Theta: [-1.60535941  0.99647158  0.05938763]\n",
      "Loss in iteration 5529: 0.43400128112804315\n",
      "Theta: [-1.60548906  0.99655904  0.05938465]\n",
      "Loss in iteration 5530: 0.43399584607858516\n",
      "Theta: [-1.60561869  0.99664649  0.05938168]\n",
      "Loss in iteration 5531: 0.4339904131205299\n",
      "Theta: [-1.6057483   0.99673393  0.0593787 ]\n",
      "Loss in iteration 5532: 0.433984982252875\n",
      "Theta: [-1.60587788  0.99682134  0.05937573]\n",
      "Loss in iteration 5533: 0.43397955347461914\n",
      "Theta: [-1.60600743  0.99690875  0.05937275]\n",
      "Loss in iteration 5534: 0.43397412678476127\n",
      "Theta: [-1.60613695  0.99699613  0.05936978]\n",
      "Loss in iteration 5535: 0.4339687021823011\n",
      "Theta: [-1.60626646  0.9970835   0.0593668 ]\n",
      "Loss in iteration 5536: 0.43396327966623877\n",
      "Theta: [-1.60639593  0.99717086  0.05936383]\n",
      "Loss in iteration 5537: 0.43395785923557495\n",
      "Theta: [-1.60652538  0.9972582   0.05936085]\n",
      "Loss in iteration 5538: 0.43395244088931123\n",
      "Theta: [-1.6066548   0.99734553  0.05935788]\n",
      "Loss in iteration 5539: 0.4339470246264495\n",
      "Theta: [-1.6067842   0.99743284  0.0593549 ]\n",
      "Loss in iteration 5540: 0.43394161044599244\n",
      "Theta: [-1.60691357  0.99752013  0.05935193]\n",
      "Loss in iteration 5541: 0.4339361983469429\n",
      "Theta: [-1.60704292  0.99760741  0.05934896]\n",
      "Loss in iteration 5542: 0.43393078832830495\n",
      "Theta: [-1.60717224  0.99769467  0.05934599]\n",
      "Loss in iteration 5543: 0.43392538038908285\n",
      "Theta: [-1.60730153  0.99778192  0.05934301]\n",
      "Loss in iteration 5544: 0.43391997452828135\n",
      "Theta: [-1.6074308   0.99786916  0.05934004]\n",
      "Loss in iteration 5545: 0.4339145707449061\n",
      "Theta: [-1.60756004  0.99795637  0.05933707]\n",
      "Loss in iteration 5546: 0.4339091690379632\n",
      "Theta: [-1.60768926  0.99804358  0.0593341 ]\n",
      "Loss in iteration 5547: 0.43390376940645936\n",
      "Theta: [-1.60781845  0.99813076  0.05933113]\n",
      "Loss in iteration 5548: 0.4338983718494017\n",
      "Theta: [-1.60794761  0.99821794  0.05932815]\n",
      "Loss in iteration 5549: 0.4338929763657981\n",
      "Theta: [-1.60807675  0.99830509  0.05932518]\n",
      "Loss in iteration 5550: 0.43388758295465707\n",
      "Theta: [-1.60820586  0.99839223  0.05932221]\n",
      "Loss in iteration 5551: 0.4338821916149877\n",
      "Theta: [-1.60833495  0.99847936  0.05931924]\n",
      "Loss in iteration 5552: 0.43387680234579923\n",
      "Theta: [-1.60846401  0.99856647  0.05931627]\n",
      "Loss in iteration 5553: 0.4338714151461022\n",
      "Theta: [-1.60859305  0.99865357  0.0593133 ]\n",
      "Loss in iteration 5554: 0.4338660300149074\n",
      "Theta: [-1.60872206  0.99874065  0.05931033]\n",
      "Loss in iteration 5555: 0.43386064695122606\n",
      "Theta: [-1.60885105  0.99882771  0.05930736]\n",
      "Loss in iteration 5556: 0.4338552659540699\n",
      "Theta: [-1.60898     0.99891476  0.05930439]\n",
      "Loss in iteration 5557: 0.43384988702245175\n",
      "Theta: [-1.60910894  0.99900179  0.05930143]\n",
      "Loss in iteration 5558: 0.43384451015538444\n",
      "Theta: [-1.60923785  0.99908881  0.05929846]\n",
      "Loss in iteration 5559: 0.4338391353518821\n",
      "Theta: [-1.60936673  0.99917582  0.05929549]\n",
      "Loss in iteration 5560: 0.4338337626109584\n",
      "Theta: [-1.60949558  0.9992628   0.05929252]\n",
      "Loss in iteration 5561: 0.4338283919316286\n",
      "Theta: [-1.60962441  0.99934978  0.05928955]\n",
      "Loss in iteration 5562: 0.4338230233129079\n",
      "Theta: [-1.60975322  0.99943673  0.05928659]\n",
      "Loss in iteration 5563: 0.43381765675381245\n",
      "Theta: [-1.609882    0.99952368  0.05928362]\n",
      "Loss in iteration 5564: 0.43381229225335866\n",
      "Theta: [-1.61001075  0.9996106   0.05928065]\n",
      "Loss in iteration 5565: 0.4338069298105637\n",
      "Theta: [-1.61013948  0.99969751  0.05927769]\n",
      "Loss in iteration 5566: 0.4338015694244456\n",
      "Theta: [-1.61026818  0.99978441  0.05927472]\n",
      "Loss in iteration 5567: 0.43379621109402217\n",
      "Theta: [-1.61039686  0.99987129  0.05927175]\n",
      "Loss in iteration 5568: 0.43379085481831253\n",
      "Theta: [-1.61052551  0.99995816  0.05926879]\n",
      "Loss in iteration 5569: 0.4337855005963363\n",
      "Theta: [-1.61065413  1.00004501  0.05926582]\n",
      "Loss in iteration 5570: 0.4337801484271133\n",
      "Theta: [-1.61078273  1.00013184  0.05926286]\n",
      "Loss in iteration 5571: 0.43377479830966437\n",
      "Theta: [-1.61091131  1.00021866  0.05925989]\n",
      "Loss in iteration 5572: 0.4337694502430103\n",
      "Theta: [-1.61103986  1.00030547  0.05925693]\n",
      "Loss in iteration 5573: 0.43376410422617334\n",
      "Theta: [-1.61116838  1.00039226  0.05925397]\n",
      "Loss in iteration 5574: 0.4337587602581754\n",
      "Theta: [-1.61129688  1.00047903  0.059251  ]\n",
      "Loss in iteration 5575: 0.4337534183380397\n",
      "Theta: [-1.61142535  1.00056579  0.05924804]\n",
      "Loss in iteration 5576: 0.4337480784647896\n",
      "Theta: [-1.61155379  1.00065254  0.05924507]\n",
      "Loss in iteration 5577: 0.4337427406374492\n",
      "Theta: [-1.61168222  1.00073927  0.05924211]\n",
      "Loss in iteration 5578: 0.433737404855043\n",
      "Theta: [-1.61181061  1.00082598  0.05923915]\n",
      "Loss in iteration 5579: 0.4337320711165965\n",
      "Theta: [-1.61193898  1.00091268  0.05923619]\n",
      "Loss in iteration 5580: 0.4337267394211351\n",
      "Theta: [-1.61206732  1.00099936  0.05923322]\n",
      "Loss in iteration 5581: 0.4337214097676854\n",
      "Theta: [-1.61219564  1.00108603  0.05923026]\n",
      "Loss in iteration 5582: 0.4337160821552743\n",
      "Theta: [-1.61232394  1.00117268  0.0592273 ]\n",
      "Loss in iteration 5583: 0.43371075658292924\n",
      "Theta: [-1.6124522   1.00125932  0.05922434]\n",
      "Loss in iteration 5584: 0.43370543304967835\n",
      "Theta: [-1.61258045  1.00134594  0.05922138]\n",
      "Loss in iteration 5585: 0.4337001115545501\n",
      "Theta: [-1.61270866  1.00143255  0.05921842]\n",
      "Loss in iteration 5586: 0.43369479209657386\n",
      "Theta: [-1.61283685  1.00151914  0.05921546]\n",
      "Loss in iteration 5587: 0.4336894746747795\n",
      "Theta: [-1.61296502  1.00160572  0.0592125 ]\n",
      "Loss in iteration 5588: 0.4336841592881971\n",
      "Theta: [-1.61309316  1.00169228  0.05920954]\n",
      "Loss in iteration 5589: 0.43367884593585765\n",
      "Theta: [-1.61322127  1.00177882  0.05920658]\n",
      "Loss in iteration 5590: 0.4336735346167928\n",
      "Theta: [-1.61334936  1.00186535  0.05920362]\n",
      "Loss in iteration 5591: 0.4336682253300343\n",
      "Theta: [-1.61347743  1.00195187  0.05920066]\n",
      "Loss in iteration 5592: 0.43366291807461493\n",
      "Theta: [-1.61360546  1.00203837  0.0591977 ]\n",
      "Loss in iteration 5593: 0.43365761284956794\n",
      "Theta: [-1.61373348  1.00212486  0.05919474]\n",
      "Loss in iteration 5594: 0.4336523096539272\n",
      "Theta: [-1.61386146  1.00221133  0.05919178]\n",
      "Loss in iteration 5595: 0.43364700848672655\n",
      "Theta: [-1.61398943  1.00229778  0.05918882]\n",
      "Loss in iteration 5596: 0.4336417093470014\n",
      "Theta: [-1.61411736  1.00238422  0.05918586]\n",
      "Loss in iteration 5597: 0.43363641223378685\n",
      "Theta: [-1.61424527  1.00247065  0.05918291]\n",
      "Loss in iteration 5598: 0.433631117146119\n",
      "Theta: [-1.61437316  1.00255706  0.05917995]\n",
      "Loss in iteration 5599: 0.43362582408303463\n",
      "Theta: [-1.61450102  1.00264345  0.05917699]\n",
      "Loss in iteration 5600: 0.43362053304357046\n",
      "Theta: [-1.61462886  1.00272983  0.05917404]\n",
      "Loss in iteration 5601: 0.4336152440267645\n",
      "Theta: [-1.61475666  1.0028162   0.05917108]\n",
      "Loss in iteration 5602: 0.433609957031655\n",
      "Theta: [-1.61488445  1.00290255  0.05916812]\n",
      "Loss in iteration 5603: 0.43360467205728065\n",
      "Theta: [-1.61501221  1.00298888  0.05916517]\n",
      "Loss in iteration 5604: 0.4335993891026812\n",
      "Theta: [-1.61513994  1.0030752   0.05916221]\n",
      "Loss in iteration 5605: 0.4335941081668962\n",
      "Theta: [-1.61526765  1.0031615   0.05915926]\n",
      "Loss in iteration 5606: 0.4335888292489662\n",
      "Theta: [-1.61539533  1.00324779  0.0591563 ]\n",
      "Loss in iteration 5607: 0.4335835523479325\n",
      "Theta: [-1.61552299  1.00333407  0.05915335]\n",
      "Loss in iteration 5608: 0.43357827746283667\n",
      "Theta: [-1.61565062  1.00342032  0.05915039]\n",
      "Loss in iteration 5609: 0.4335730045927209\n",
      "Theta: [-1.61577823  1.00350657  0.05914744]\n",
      "Loss in iteration 5610: 0.4335677337366279\n",
      "Theta: [-1.61590581  1.0035928   0.05914448]\n",
      "Loss in iteration 5611: 0.43356246489360095\n",
      "Theta: [-1.61603337  1.00367901  0.05914153]\n",
      "Loss in iteration 5612: 0.4335571980626842\n",
      "Theta: [-1.6161609   1.00376521  0.05913858]\n",
      "Loss in iteration 5613: 0.4335519332429218\n",
      "Theta: [-1.6162884   1.00385139  0.05913562]\n",
      "Loss in iteration 5614: 0.43354667043335887\n",
      "Theta: [-1.61641588  1.00393756  0.05913267]\n",
      "Loss in iteration 5615: 0.4335414096330409\n",
      "Theta: [-1.61654334  1.00402371  0.05912972]\n",
      "Loss in iteration 5616: 0.43353615084101416\n",
      "Theta: [-1.61667077  1.00410985  0.05912677]\n",
      "Loss in iteration 5617: 0.43353089405632517\n",
      "Theta: [-1.61679817  1.00419597  0.05912381]\n",
      "Loss in iteration 5618: 0.4335256392780212\n",
      "Theta: [-1.61692555  1.00428208  0.05912086]\n",
      "Loss in iteration 5619: 0.4335203865051501\n",
      "Theta: [-1.61705291  1.00436817  0.05911791]\n",
      "Loss in iteration 5620: 0.43351513573676004\n",
      "Theta: [-1.61718024  1.00445425  0.05911496]\n",
      "Loss in iteration 5621: 0.43350988697190024\n",
      "Theta: [-1.61730754  1.00454031  0.05911201]\n",
      "Loss in iteration 5622: 0.43350464020961993\n",
      "Theta: [-1.61743482  1.00462636  0.05910906]\n",
      "Loss in iteration 5623: 0.43349939544896904\n",
      "Theta: [-1.61756207  1.00471239  0.05910611]\n",
      "Loss in iteration 5624: 0.4334941526889983\n",
      "Theta: [-1.6176893   1.00479841  0.05910316]\n",
      "Loss in iteration 5625: 0.433488911928759\n",
      "Theta: [-1.6178165   1.00488441  0.05910021]\n",
      "Loss in iteration 5626: 0.43348367316730235\n",
      "Theta: [-1.61794368  1.0049704   0.05909726]\n",
      "Loss in iteration 5627: 0.4334784364036809\n",
      "Theta: [-1.61807083  1.00505637  0.05909431]\n",
      "Loss in iteration 5628: 0.4334732016369473\n",
      "Theta: [-1.61819796  1.00514233  0.05909136]\n",
      "Loss in iteration 5629: 0.43346796886615524\n",
      "Theta: [-1.61832506  1.00522827  0.05908841]\n",
      "Loss in iteration 5630: 0.43346273809035807\n",
      "Theta: [-1.61845214  1.0053142   0.05908546]\n",
      "Loss in iteration 5631: 0.43345750930861043\n",
      "Theta: [-1.61857919  1.00540011  0.05908252]\n",
      "Loss in iteration 5632: 0.4334522825199676\n",
      "Theta: [-1.61870622  1.00548601  0.05907957]\n",
      "Loss in iteration 5633: 0.4334470577234847\n",
      "Theta: [-1.61883322  1.00557189  0.05907662]\n",
      "Loss in iteration 5634: 0.4334418349182181\n",
      "Theta: [-1.6189602   1.00565776  0.05907367]\n",
      "Loss in iteration 5635: 0.4334366141032243\n",
      "Theta: [-1.61908715  1.00574361  0.05907073]\n",
      "Loss in iteration 5636: 0.43343139527756064\n",
      "Theta: [-1.61921407  1.00582945  0.05906778]\n",
      "Loss in iteration 5637: 0.4334261784402848\n",
      "Theta: [-1.61934097  1.00591527  0.05906483]\n",
      "Loss in iteration 5638: 0.43342096359045507\n",
      "Theta: [-1.61946785  1.00600107  0.05906189]\n",
      "Loss in iteration 5639: 0.4334157507271303\n",
      "Theta: [-1.6195947   1.00608687  0.05905894]\n",
      "Loss in iteration 5640: 0.4334105398493697\n",
      "Theta: [-1.61972153  1.00617264  0.059056  ]\n",
      "Loss in iteration 5641: 0.4334053309562335\n",
      "Theta: [-1.61984833  1.00625841  0.05905305]\n",
      "Loss in iteration 5642: 0.4334001240467821\n",
      "Theta: [-1.6199751   1.00634415  0.05905011]\n",
      "Loss in iteration 5643: 0.4333949191200763\n",
      "Theta: [-1.62010185  1.00642989  0.05904716]\n",
      "Loss in iteration 5644: 0.43338971617517813\n",
      "Theta: [-1.62022858  1.0065156   0.05904422]\n",
      "Loss in iteration 5645: 0.4333845152111494\n",
      "Theta: [-1.62035528  1.0066013   0.05904127]\n",
      "Loss in iteration 5646: 0.433379316227053\n",
      "Theta: [-1.62048196  1.00668699  0.05903833]\n",
      "Loss in iteration 5647: 0.43337411922195174\n",
      "Theta: [-1.62060861  1.00677266  0.05903539]\n",
      "Loss in iteration 5648: 0.43336892419490985\n",
      "Theta: [-1.62073523  1.00685832  0.05903244]\n",
      "Loss in iteration 5649: 0.43336373114499144\n",
      "Theta: [-1.62086183  1.00694396  0.0590295 ]\n",
      "Loss in iteration 5650: 0.43335854007126146\n",
      "Theta: [-1.62098841  1.00702959  0.05902656]\n",
      "Loss in iteration 5651: 0.43335335097278505\n",
      "Theta: [-1.62111496  1.0071152   0.05902361]\n",
      "Loss in iteration 5652: 0.43334816384862856\n",
      "Theta: [-1.62124148  1.0072008   0.05902067]\n",
      "Loss in iteration 5653: 0.4333429786978581\n",
      "Theta: [-1.62136798  1.00728638  0.05901773]\n",
      "Loss in iteration 5654: 0.4333377955195409\n",
      "Theta: [-1.62149446  1.00737195  0.05901479]\n",
      "Loss in iteration 5655: 0.43333261431274467\n",
      "Theta: [-1.62162091  1.00745751  0.05901185]\n",
      "Loss in iteration 5656: 0.4333274350765373\n",
      "Theta: [-1.62174734  1.00754304  0.05900891]\n",
      "Loss in iteration 5657: 0.43332225780998757\n",
      "Theta: [-1.62187374  1.00762857  0.05900596]\n",
      "Loss in iteration 5658: 0.4333170825121645\n",
      "Theta: [-1.62200011  1.00771407  0.05900302]\n",
      "Loss in iteration 5659: 0.4333119091821382\n",
      "Theta: [-1.62212646  1.00779957  0.05900008]\n",
      "Loss in iteration 5660: 0.43330673781897866\n",
      "Theta: [-1.62225279  1.00788505  0.05899714]\n",
      "Loss in iteration 5661: 0.4333015684217568\n",
      "Theta: [-1.62237909  1.00797051  0.0589942 ]\n",
      "Loss in iteration 5662: 0.433296400989544\n",
      "Theta: [-1.62250536  1.00805596  0.05899126]\n",
      "Loss in iteration 5663: 0.433291235521412\n",
      "Theta: [-1.62263162  1.00814139  0.05898833]\n",
      "Loss in iteration 5664: 0.4332860720164336\n",
      "Theta: [-1.62275784  1.00822681  0.05898539]\n",
      "Loss in iteration 5665: 0.43328091047368145\n",
      "Theta: [-1.62288404  1.00831221  0.05898245]\n",
      "Loss in iteration 5666: 0.4332757508922293\n",
      "Theta: [-1.62301022  1.0083976   0.05897951]\n",
      "Loss in iteration 5667: 0.4332705932711509\n",
      "Theta: [-1.62313637  1.00848298  0.05897657]\n",
      "Loss in iteration 5668: 0.4332654376095214\n",
      "Theta: [-1.6232625   1.00856833  0.05897363]\n",
      "Loss in iteration 5669: 0.4332602839064153\n",
      "Theta: [-1.6233886   1.00865368  0.0589707 ]\n",
      "Loss in iteration 5670: 0.4332551321609089\n",
      "Theta: [-1.62351467  1.00873901  0.05896776]\n",
      "Loss in iteration 5671: 0.433249982372078\n",
      "Theta: [-1.62364073  1.00882432  0.05896482]\n",
      "Loss in iteration 5672: 0.43324483453899953\n",
      "Theta: [-1.62376675  1.00890962  0.05896189]\n",
      "Loss in iteration 5673: 0.43323968866075047\n",
      "Theta: [-1.62389276  1.00899491  0.05895895]\n",
      "Loss in iteration 5674: 0.43323454473640916\n",
      "Theta: [-1.62401873  1.00908018  0.05895601]\n",
      "Loss in iteration 5675: 0.43322940276505356\n",
      "Theta: [-1.62414469  1.00916543  0.05895308]\n",
      "Loss in iteration 5676: 0.43322426274576264\n",
      "Theta: [-1.62427061  1.00925067  0.05895014]\n",
      "Loss in iteration 5677: 0.4332191246776159\n",
      "Theta: [-1.62439652  1.0093359   0.05894721]\n",
      "Loss in iteration 5678: 0.43321398855969334\n",
      "Theta: [-1.62452239  1.00942111  0.05894427]\n",
      "Loss in iteration 5679: 0.43320885439107537\n",
      "Theta: [-1.62464825  1.0095063   0.05894134]\n",
      "Loss in iteration 5680: 0.43320372217084313\n",
      "Theta: [-1.62477408  1.00959148  0.0589384 ]\n",
      "Loss in iteration 5681: 0.4331985918980779\n",
      "Theta: [-1.62489988  1.00967665  0.05893547]\n",
      "Loss in iteration 5682: 0.43319346357186217\n",
      "Theta: [-1.62502566  1.0097618   0.05893254]\n",
      "Loss in iteration 5683: 0.43318833719127836\n",
      "Theta: [-1.62515141  1.00984694  0.0589296 ]\n",
      "Loss in iteration 5684: 0.43318321275540966\n",
      "Theta: [-1.62527714  1.00993206  0.05892667]\n",
      "Loss in iteration 5685: 0.43317809026333953\n",
      "Theta: [-1.62540285  1.01001716  0.05892374]\n",
      "Loss in iteration 5686: 0.43317296971415264\n",
      "Theta: [-1.62552853  1.01010226  0.0589208 ]\n",
      "Loss in iteration 5687: 0.43316785110693345\n",
      "Theta: [-1.62565418  1.01018733  0.05891787]\n",
      "Loss in iteration 5688: 0.43316273444076736\n",
      "Theta: [-1.62577981  1.01027239  0.05891494]\n",
      "Loss in iteration 5689: 0.4331576197147402\n",
      "Theta: [-1.62590542  1.01035744  0.05891201]\n",
      "Loss in iteration 5690: 0.4331525069279383\n",
      "Theta: [-1.626031    1.01044247  0.05890907]\n",
      "Loss in iteration 5691: 0.4331473960794483\n",
      "Theta: [-1.62615656  1.01052749  0.05890614]\n",
      "Loss in iteration 5692: 0.433142287168358\n",
      "Theta: [-1.62628209  1.0106125   0.05890321]\n",
      "Loss in iteration 5693: 0.4331371801937551\n",
      "Theta: [-1.62640759  1.01069748  0.05890028]\n",
      "Loss in iteration 5694: 0.43313207515472796\n",
      "Theta: [-1.62653308  1.01078246  0.05889735]\n",
      "Loss in iteration 5695: 0.43312697205036593\n",
      "Theta: [-1.62665853  1.01086742  0.05889442]\n",
      "Loss in iteration 5696: 0.4331218708797582\n",
      "Theta: [-1.62678397  1.01095236  0.05889149]\n",
      "Loss in iteration 5697: 0.43311677164199486\n",
      "Theta: [-1.62690938  1.01103729  0.05888856]\n",
      "Loss in iteration 5698: 0.4331116743361666\n",
      "Theta: [-1.62703476  1.0111222   0.05888563]\n",
      "Loss in iteration 5699: 0.43310657896136445\n",
      "Theta: [-1.62716012  1.0112071   0.0588827 ]\n",
      "Loss in iteration 5700: 0.43310148551668015\n",
      "Theta: [-1.62728545  1.01129199  0.05887977]\n",
      "Loss in iteration 5701: 0.4330963940012058\n",
      "Theta: [-1.62741076  1.01137686  0.05887685]\n",
      "Loss in iteration 5702: 0.43309130441403404\n",
      "Theta: [-1.62753605  1.01146171  0.05887392]\n",
      "Loss in iteration 5703: 0.4330862167542579\n",
      "Theta: [-1.62766131  1.01154655  0.05887099]\n",
      "Loss in iteration 5704: 0.43308113102097145\n",
      "Theta: [-1.62778654  1.01163138  0.05886806]\n",
      "Loss in iteration 5705: 0.43307604721326853\n",
      "Theta: [-1.62791175  1.01171619  0.05886513]\n",
      "Loss in iteration 5706: 0.4330709653302444\n",
      "Theta: [-1.62803694  1.01180099  0.05886221]\n",
      "Loss in iteration 5707: 0.433065885370994\n",
      "Theta: [-1.6281621   1.01188577  0.05885928]\n",
      "Loss in iteration 5708: 0.4330608073346134\n",
      "Theta: [-1.62828724  1.01197053  0.05885635]\n",
      "Loss in iteration 5709: 0.43305573122019864\n",
      "Theta: [-1.62841235  1.01205529  0.05885343]\n",
      "Loss in iteration 5710: 0.4330506570268469\n",
      "Theta: [-1.62853744  1.01214002  0.0588505 ]\n",
      "Loss in iteration 5711: 0.43304558475365523\n",
      "Theta: [-1.6286625   1.01222475  0.05884758]\n",
      "Loss in iteration 5712: 0.43304051439972197\n",
      "Theta: [-1.62878754  1.01230945  0.05884465]\n",
      "Loss in iteration 5713: 0.4330354459641452\n",
      "Theta: [-1.62891256  1.01239415  0.05884173]\n",
      "Loss in iteration 5714: 0.43303037944602407\n",
      "Theta: [-1.62903755  1.01247883  0.0588388 ]\n",
      "Loss in iteration 5715: 0.43302531484445794\n",
      "Theta: [-1.62916251  1.01256349  0.05883588]\n",
      "Loss in iteration 5716: 0.43302025215854684\n",
      "Theta: [-1.62928745  1.01264814  0.05883295]\n",
      "Loss in iteration 5717: 0.43301519138739136\n",
      "Theta: [-1.62941237  1.01273277  0.05883003]\n",
      "Loss in iteration 5718: 0.43301013253009246\n",
      "Theta: [-1.62953726  1.01281739  0.0588271 ]\n",
      "Loss in iteration 5719: 0.43300507558575174\n",
      "Theta: [-1.62966213  1.012902    0.05882418]\n",
      "Loss in iteration 5720: 0.43300002055347114\n",
      "Theta: [-1.62978697  1.01298659  0.05882126]\n",
      "Loss in iteration 5721: 0.43299496743235344\n",
      "Theta: [-1.62991179  1.01307116  0.05881833]\n",
      "Loss in iteration 5722: 0.43298991622150174\n",
      "Theta: [-1.63003659  1.01315572  0.05881541]\n",
      "Loss in iteration 5723: 0.4329848669200194\n",
      "Theta: [-1.63016135  1.01324027  0.05881249]\n",
      "Loss in iteration 5724: 0.4329798195270109\n",
      "Theta: [-1.6302861   1.0133248   0.05880957]\n",
      "Loss in iteration 5725: 0.43297477404158097\n",
      "Theta: [-1.63041082  1.01340932  0.05880665]\n",
      "Loss in iteration 5726: 0.4329697304628341\n",
      "Theta: [-1.63053552  1.01349382  0.05880372]\n",
      "Loss in iteration 5727: 0.432964688789877\n",
      "Theta: [-1.63066019  1.01357831  0.0588008 ]\n",
      "Loss in iteration 5728: 0.4329596490218151\n",
      "Theta: [-1.63078483  1.01366278  0.05879788]\n",
      "Loss in iteration 5729: 0.4329546111577553\n",
      "Theta: [-1.63090946  1.01374724  0.05879496]\n",
      "Loss in iteration 5730: 0.4329495751968052\n",
      "Theta: [-1.63103406  1.01383168  0.05879204]\n",
      "Loss in iteration 5731: 0.4329445411380721\n",
      "Theta: [-1.63115863  1.01391611  0.05878912]\n",
      "Loss in iteration 5732: 0.4329395089806646\n",
      "Theta: [-1.63128318  1.01400053  0.0587862 ]\n",
      "Loss in iteration 5733: 0.43293447872369123\n",
      "Theta: [-1.6314077   1.01408493  0.05878328]\n",
      "Loss in iteration 5734: 0.43292945036626157\n",
      "Theta: [-1.6315322   1.01416931  0.05878036]\n",
      "Loss in iteration 5735: 0.4329244239074852\n",
      "Theta: [-1.63165668  1.01425368  0.05877744]\n",
      "Loss in iteration 5736: 0.43291939934647256\n",
      "Theta: [-1.63178113  1.01433804  0.05877452]\n",
      "Loss in iteration 5737: 0.4329143766823345\n",
      "Theta: [-1.63190556  1.01442238  0.05877161]\n",
      "Loss in iteration 5738: 0.43290935591418234\n",
      "Theta: [-1.63202996  1.0145067   0.05876869]\n",
      "Loss in iteration 5739: 0.43290433704112785\n",
      "Theta: [-1.63215434  1.01459102  0.05876577]\n",
      "Loss in iteration 5740: 0.4328993200622837\n",
      "Theta: [-1.6322787   1.01467531  0.05876285]\n",
      "Loss in iteration 5741: 0.4328943049767625\n",
      "Theta: [-1.63240303  1.0147596   0.05875993]\n",
      "Loss in iteration 5742: 0.4328892917836777\n",
      "Theta: [-1.63252733  1.01484386  0.05875702]\n",
      "Loss in iteration 5743: 0.4328842804821433\n",
      "Theta: [-1.63265161  1.01492812  0.0587541 ]\n",
      "Loss in iteration 5744: 0.43287927107127383\n",
      "Theta: [-1.63277587  1.01501236  0.05875118]\n",
      "Loss in iteration 5745: 0.43287426355018377\n",
      "Theta: [-1.6329001   1.01509658  0.05874827]\n",
      "Loss in iteration 5746: 0.4328692579179893\n",
      "Theta: [-1.63302431  1.01518079  0.05874535]\n",
      "Loss in iteration 5747: 0.4328642541738056\n",
      "Theta: [-1.6331485   1.01526498  0.05874244]\n",
      "Loss in iteration 5748: 0.43285925231674954\n",
      "Theta: [-1.63327265  1.01534916  0.05873952]\n",
      "Loss in iteration 5749: 0.432854252345938\n",
      "Theta: [-1.63339679  1.01543333  0.05873661]\n",
      "Loss in iteration 5750: 0.4328492542604886\n",
      "Theta: [-1.6335209   1.01551748  0.05873369]\n",
      "Loss in iteration 5751: 0.43284425805951904\n",
      "Theta: [-1.63364499  1.01560162  0.05873078]\n",
      "Loss in iteration 5752: 0.4328392637421482\n",
      "Theta: [-1.63376905  1.01568574  0.05872786]\n",
      "Loss in iteration 5753: 0.43283427130749474\n",
      "Theta: [-1.63389309  1.01576985  0.05872495]\n",
      "Loss in iteration 5754: 0.4328292807546784\n",
      "Theta: [-1.6340171   1.01585394  0.05872204]\n",
      "Loss in iteration 5755: 0.432824292082819\n",
      "Theta: [-1.63414109  1.01593802  0.05871912]\n",
      "Loss in iteration 5756: 0.4328193052910371\n",
      "Theta: [-1.63426506  1.01602208  0.05871621]\n",
      "Loss in iteration 5757: 0.4328143203784539\n",
      "Theta: [-1.634389    1.01610613  0.0587133 ]\n",
      "Loss in iteration 5758: 0.43280933734419075\n",
      "Theta: [-1.63451292  1.01619017  0.05871038]\n",
      "Loss in iteration 5759: 0.43280435618736973\n",
      "Theta: [-1.63463681  1.01627419  0.05870747]\n",
      "Loss in iteration 5760: 0.4327993769071135\n",
      "Theta: [-1.63476068  1.01635819  0.05870456]\n",
      "Loss in iteration 5761: 0.43279439950254484\n",
      "Theta: [-1.63488452  1.01644218  0.05870165]\n",
      "Loss in iteration 5762: 0.43278942397278747\n",
      "Theta: [-1.63500834  1.01652616  0.05869874]\n",
      "Loss in iteration 5763: 0.4327844503169656\n",
      "Theta: [-1.63513214  1.01661012  0.05869583]\n",
      "Loss in iteration 5764: 0.43277947853420373\n",
      "Theta: [-1.63525591  1.01669407  0.05869291]\n",
      "Loss in iteration 5765: 0.4327745086236265\n",
      "Theta: [-1.63537966  1.016778    0.05869   ]\n",
      "Loss in iteration 5766: 0.43276954058436007\n",
      "Theta: [-1.63550338  1.01686192  0.05868709]\n",
      "Loss in iteration 5767: 0.43276457441553\n",
      "Theta: [-1.63562708  1.01694583  0.05868418]\n",
      "Loss in iteration 5768: 0.4327596101162633\n",
      "Theta: [-1.63575076  1.01702971  0.05868127]\n",
      "Loss in iteration 5769: 0.43275464768568683\n",
      "Theta: [-1.63587441  1.01711359  0.05867836]\n",
      "Loss in iteration 5770: 0.43274968712292805\n",
      "Theta: [-1.63599803  1.01719745  0.05867546]\n",
      "Loss in iteration 5771: 0.43274472842711525\n",
      "Theta: [-1.63612164  1.0172813   0.05867255]\n",
      "Loss in iteration 5772: 0.4327397715973769\n",
      "Theta: [-1.63624522  1.01736513  0.05866964]\n",
      "Loss in iteration 5773: 0.432734816632842\n",
      "Theta: [-1.63636877  1.01744894  0.05866673]\n",
      "Loss in iteration 5774: 0.43272986353264026\n",
      "Theta: [-1.6364923   1.01753275  0.05866382]\n",
      "Loss in iteration 5775: 0.43272491229590165\n",
      "Theta: [-1.63661581  1.01761653  0.05866091]\n",
      "Loss in iteration 5776: 0.43271996292175685\n",
      "Theta: [-1.63673929  1.01770031  0.05865801]\n",
      "Loss in iteration 5777: 0.4327150154093368\n",
      "Theta: [-1.63686275  1.01778407  0.0586551 ]\n",
      "Loss in iteration 5778: 0.43271006975777326\n",
      "Theta: [-1.63698618  1.01786781  0.05865219]\n",
      "Loss in iteration 5779: 0.43270512596619826\n",
      "Theta: [-1.63710959  1.01795154  0.05864929]\n",
      "Loss in iteration 5780: 0.432700184033744\n",
      "Theta: [-1.63723298  1.01803526  0.05864638]\n",
      "Loss in iteration 5781: 0.432695243959544\n",
      "Theta: [-1.63735634  1.01811896  0.05864347]\n",
      "Loss in iteration 5782: 0.43269030574273176\n",
      "Theta: [-1.63747968  1.01820264  0.05864057]\n",
      "Loss in iteration 5783: 0.43268536938244084\n",
      "Theta: [-1.63760299  1.01828632  0.05863766]\n",
      "Loss in iteration 5784: 0.43268043487780644\n",
      "Theta: [-1.63772628  1.01836997  0.05863476]\n",
      "Loss in iteration 5785: 0.43267550222796347\n",
      "Theta: [-1.63784955  1.01845362  0.05863185]\n",
      "Loss in iteration 5786: 0.4326705714320474\n",
      "Theta: [-1.63797279  1.01853725  0.05862895]\n",
      "Loss in iteration 5787: 0.43266564248919404\n",
      "Theta: [-1.638096    1.01862086  0.05862604]\n",
      "Loss in iteration 5788: 0.4326607153985402\n",
      "Theta: [-1.6382192   1.01870446  0.05862314]\n",
      "Loss in iteration 5789: 0.4326557901592228\n",
      "Theta: [-1.63834237  1.01878805  0.05862023]\n",
      "Loss in iteration 5790: 0.43265086677037934\n",
      "Theta: [-1.63846551  1.01887162  0.05861733]\n",
      "Loss in iteration 5791: 0.4326459452311482\n",
      "Theta: [-1.63858863  1.01895517  0.05861443]\n",
      "Loss in iteration 5792: 0.4326410255406673\n",
      "Theta: [-1.63871173  1.01903872  0.05861152]\n",
      "Loss in iteration 5793: 0.43263610769807603\n",
      "Theta: [-1.63883481  1.01912224  0.05860862]\n",
      "Loss in iteration 5794: 0.4326311917025139\n",
      "Theta: [-1.63895785  1.01920576  0.05860572]\n",
      "Loss in iteration 5795: 0.4326262775531207\n",
      "Theta: [-1.63908088  1.01928925  0.05860282]\n",
      "Loss in iteration 5796: 0.43262136524903705\n",
      "Theta: [-1.63920388  1.01937274  0.05859992]\n",
      "Loss in iteration 5797: 0.43261645478940414\n",
      "Theta: [-1.63932686  1.01945621  0.05859701]\n",
      "Loss in iteration 5798: 0.432611546173363\n",
      "Theta: [-1.63944981  1.01953966  0.05859411]\n",
      "Loss in iteration 5799: 0.43260663940005584\n",
      "Theta: [-1.63957274  1.01962311  0.05859121]\n",
      "Loss in iteration 5800: 0.4326017344686251\n",
      "Theta: [-1.63969565  1.01970653  0.05858831]\n",
      "Loss in iteration 5801: 0.43259683137821375\n",
      "Theta: [-1.63981853  1.01978995  0.05858541]\n",
      "Loss in iteration 5802: 0.43259193012796515\n",
      "Theta: [-1.63994139  1.01987334  0.05858251]\n",
      "Loss in iteration 5803: 0.43258703071702315\n",
      "Theta: [-1.64006422  1.01995673  0.05857961]\n",
      "Loss in iteration 5804: 0.43258213314453253\n",
      "Theta: [-1.64018703  1.0200401   0.05857671]\n",
      "Loss in iteration 5805: 0.4325772374096376\n",
      "Theta: [-1.64030982  1.02012345  0.05857381]\n",
      "Loss in iteration 5806: 0.4325723435114844\n",
      "Theta: [-1.64043258  1.02020679  0.05857091]\n",
      "Loss in iteration 5807: 0.4325674514492184\n",
      "Theta: [-1.64055532  1.02029012  0.05856801]\n",
      "Loss in iteration 5808: 0.432562561221986\n",
      "Theta: [-1.64067803  1.02037343  0.05856511]\n",
      "Loss in iteration 5809: 0.43255767282893415\n",
      "Theta: [-1.64080072  1.02045673  0.05856222]\n",
      "Loss in iteration 5810: 0.4325527862692102\n",
      "Theta: [-1.64092339  1.02054001  0.05855932]\n",
      "Loss in iteration 5811: 0.43254790154196215\n",
      "Theta: [-1.64104603  1.02062328  0.05855642]\n",
      "Loss in iteration 5812: 0.43254301864633793\n",
      "Theta: [-1.64116865  1.02070653  0.05855352]\n",
      "Loss in iteration 5813: 0.4325381375814865\n",
      "Theta: [-1.64129125  1.02078977  0.05855063]\n",
      "Loss in iteration 5814: 0.4325332583465574\n",
      "Theta: [-1.64141382  1.020873    0.05854773]\n",
      "Loss in iteration 5815: 0.43252838094070006\n",
      "Theta: [-1.64153637  1.02095621  0.05854483]\n",
      "Loss in iteration 5816: 0.432523505363065\n",
      "Theta: [-1.64165889  1.02103941  0.05854194]\n",
      "Loss in iteration 5817: 0.43251863161280285\n",
      "Theta: [-1.64178139  1.02112259  0.05853904]\n",
      "Loss in iteration 5818: 0.4325137596890648\n",
      "Theta: [-1.64190387  1.02120576  0.05853615]\n",
      "Loss in iteration 5819: 0.43250888959100264\n",
      "Theta: [-1.64202632  1.02128891  0.05853325]\n",
      "Loss in iteration 5820: 0.4325040213177687\n",
      "Theta: [-1.64214875  1.02137205  0.05853035]\n",
      "Loss in iteration 5821: 0.4324991548685155\n",
      "Theta: [-1.64227115  1.02145517  0.05852746]\n",
      "Loss in iteration 5822: 0.4324942902423963\n",
      "Theta: [-1.64239353  1.02153829  0.05852457]\n",
      "Loss in iteration 5823: 0.4324894274385646\n",
      "Theta: [-1.64251589  1.02162138  0.05852167]\n",
      "Loss in iteration 5824: 0.4324845664561747\n",
      "Theta: [-1.64263822  1.02170446  0.05851878]\n",
      "Loss in iteration 5825: 0.43247970729438134\n",
      "Theta: [-1.64276053  1.02178753  0.05851588]\n",
      "Loss in iteration 5826: 0.4324748499523393\n",
      "Theta: [-1.64288282  1.02187059  0.05851299]\n",
      "Loss in iteration 5827: 0.4324699944292043\n",
      "Theta: [-1.64300508  1.02195362  0.0585101 ]\n",
      "Loss in iteration 5828: 0.4324651407241326\n",
      "Theta: [-1.64312732  1.02203665  0.0585072 ]\n",
      "Loss in iteration 5829: 0.43246028883628057\n",
      "Theta: [-1.64324953  1.02211966  0.05850431]\n",
      "Loss in iteration 5830: 0.4324554387648052\n",
      "Theta: [-1.64337172  1.02220266  0.05850142]\n",
      "Loss in iteration 5831: 0.43245059050886425\n",
      "Theta: [-1.64349389  1.02228564  0.05849853]\n",
      "Loss in iteration 5832: 0.43244574406761527\n",
      "Theta: [-1.64361603  1.02236861  0.05849564]\n",
      "Loss in iteration 5833: 0.4324408994402171\n",
      "Theta: [-1.64373815  1.02245156  0.05849274]\n",
      "Loss in iteration 5834: 0.43243605662582874\n",
      "Theta: [-1.64386025  1.0225345   0.05848985]\n",
      "Loss in iteration 5835: 0.4324312156236093\n",
      "Theta: [-1.64398232  1.02261742  0.05848696]\n",
      "Loss in iteration 5836: 0.4324263764327189\n",
      "Theta: [-1.64410437  1.02270033  0.05848407]\n",
      "Loss in iteration 5837: 0.43242153905231795\n",
      "Theta: [-1.6442264   1.02278323  0.05848118]\n",
      "Loss in iteration 5838: 0.43241670348156724\n",
      "Theta: [-1.6443484   1.02286611  0.05847829]\n",
      "Loss in iteration 5839: 0.43241186971962814\n",
      "Theta: [-1.64447037  1.02294898  0.0584754 ]\n",
      "Loss in iteration 5840: 0.43240703776566264\n",
      "Theta: [-1.64459233  1.02303183  0.05847251]\n",
      "Loss in iteration 5841: 0.43240220761883263\n",
      "Theta: [-1.64471426  1.02311467  0.05846962]\n",
      "Loss in iteration 5842: 0.4323973792783013\n",
      "Theta: [-1.64483617  1.0231975   0.05846673]\n",
      "Loss in iteration 5843: 0.4323925527432316\n",
      "Theta: [-1.64495805  1.02328031  0.05846384]\n",
      "Loss in iteration 5844: 0.4323877280127876\n",
      "Theta: [-1.64507991  1.02336311  0.05846096]\n",
      "Loss in iteration 5845: 0.43238290508613325\n",
      "Theta: [-1.64520174  1.02344589  0.05845807]\n",
      "Loss in iteration 5846: 0.4323780839624333\n",
      "Theta: [-1.64532356  1.02352866  0.05845518]\n",
      "Loss in iteration 5847: 0.4323732646408529\n",
      "Theta: [-1.64544534  1.02361141  0.05845229]\n",
      "Loss in iteration 5848: 0.4323684471205578\n",
      "Theta: [-1.64556711  1.02369415  0.05844941]\n",
      "Loss in iteration 5849: 0.43236363140071404\n",
      "Theta: [-1.64568885  1.02377688  0.05844652]\n",
      "Loss in iteration 5850: 0.432358817480488\n",
      "Theta: [-1.64581057  1.02385959  0.05844363]\n",
      "Loss in iteration 5851: 0.43235400535904717\n",
      "Theta: [-1.64593226  1.02394228  0.05844075]\n",
      "Loss in iteration 5852: 0.4323491950355586\n",
      "Theta: [-1.64605393  1.02402497  0.05843786]\n",
      "Loss in iteration 5853: 0.4323443865091906\n",
      "Theta: [-1.64617558  1.02410764  0.05843497]\n",
      "Loss in iteration 5854: 0.4323395797791117\n",
      "Theta: [-1.6462972   1.02419029  0.05843209]\n",
      "Loss in iteration 5855: 0.4323347748444907\n",
      "Theta: [-1.6464188   1.02427293  0.0584292 ]\n",
      "Loss in iteration 5856: 0.432329971704497\n",
      "Theta: [-1.64654038  1.02435556  0.05842632]\n",
      "Loss in iteration 5857: 0.43232517035830065\n",
      "Theta: [-1.64666193  1.02443817  0.05842343]\n",
      "Loss in iteration 5858: 0.4323203708050719\n",
      "Theta: [-1.64678346  1.02452077  0.05842055]\n",
      "Loss in iteration 5859: 0.43231557304398166\n",
      "Theta: [-1.64690497  1.02460335  0.05841766]\n",
      "Loss in iteration 5860: 0.4323107770742011\n",
      "Theta: [-1.64702645  1.02468592  0.05841478]\n",
      "Loss in iteration 5861: 0.4323059828949021\n",
      "Theta: [-1.64714791  1.02476847  0.0584119 ]\n",
      "Loss in iteration 5862: 0.43230119050525717\n",
      "Theta: [-1.64726934  1.02485101  0.05840901]\n",
      "Loss in iteration 5863: 0.4322963999044387\n",
      "Theta: [-1.64739075  1.02493354  0.05840613]\n",
      "Loss in iteration 5864: 0.43229161109162006\n",
      "Theta: [-1.64751214  1.02501605  0.05840325]\n",
      "Loss in iteration 5865: 0.43228682406597474\n",
      "Theta: [-1.64763351  1.02509855  0.05840037]\n",
      "Loss in iteration 5866: 0.432282038826677\n",
      "Theta: [-1.64775485  1.02518103  0.05839748]\n",
      "Loss in iteration 5867: 0.43227725537290146\n",
      "Theta: [-1.64787617  1.0252635   0.0583946 ]\n",
      "Loss in iteration 5868: 0.43227247370382316\n",
      "Theta: [-1.64799746  1.02534596  0.05839172]\n",
      "Loss in iteration 5869: 0.4322676938186175\n",
      "Theta: [-1.64811873  1.0254284   0.05838884]\n",
      "Loss in iteration 5870: 0.43226291571646086\n",
      "Theta: [-1.64823998  1.02551083  0.05838596]\n",
      "Loss in iteration 5871: 0.43225813939652946\n",
      "Theta: [-1.6483612   1.02559324  0.05838308]\n",
      "Loss in iteration 5872: 0.43225336485800014\n",
      "Theta: [-1.6484824   1.02567564  0.0583802 ]\n",
      "Loss in iteration 5873: 0.43224859210005057\n",
      "Theta: [-1.64860358  1.02575803  0.05837732]\n",
      "Loss in iteration 5874: 0.43224382112185844\n",
      "Theta: [-1.64872473  1.0258404   0.05837444]\n",
      "Loss in iteration 5875: 0.4322390519226021\n",
      "Theta: [-1.64884586  1.02592275  0.05837156]\n",
      "Loss in iteration 5876: 0.43223428450146073\n",
      "Theta: [-1.64896697  1.0260051   0.05836868]\n",
      "Loss in iteration 5877: 0.43222951885761296\n",
      "Theta: [-1.64908805  1.02608742  0.0583658 ]\n",
      "Loss in iteration 5878: 0.4322247549902391\n",
      "Theta: [-1.64920911  1.02616974  0.05836292]\n",
      "Loss in iteration 5879: 0.43221999289851903\n",
      "Theta: [-1.64933015  1.02625204  0.05836004]\n",
      "Loss in iteration 5880: 0.4322152325816336\n",
      "Theta: [-1.64945116  1.02633433  0.05835716]\n",
      "Loss in iteration 5881: 0.43221047403876384\n",
      "Theta: [-1.64957215  1.0264166   0.05835428]\n",
      "Loss in iteration 5882: 0.43220571726909135\n",
      "Theta: [-1.64969312  1.02649885  0.05835141]\n",
      "Loss in iteration 5883: 0.4322009622717982\n",
      "Theta: [-1.64981406  1.0265811   0.05834853]\n",
      "Loss in iteration 5884: 0.43219620904606726\n",
      "Theta: [-1.64993498  1.02666333  0.05834565]\n",
      "Loss in iteration 5885: 0.43219145759108096\n",
      "Theta: [-1.65005588  1.02674554  0.05834278]\n",
      "Loss in iteration 5886: 0.4321867079060231\n",
      "Theta: [-1.65017675  1.02682775  0.0583399 ]\n",
      "Loss in iteration 5887: 0.4321819599900775\n",
      "Theta: [-1.6502976   1.02690993  0.05833702]\n",
      "Loss in iteration 5888: 0.4321772138424287\n",
      "Theta: [-1.65041842  1.02699211  0.05833415]\n",
      "Loss in iteration 5889: 0.4321724694622614\n",
      "Theta: [-1.65053923  1.02707426  0.05833127]\n",
      "Loss in iteration 5890: 0.4321677268487607\n",
      "Theta: [-1.65066001  1.02715641  0.0583284 ]\n",
      "Loss in iteration 5891: 0.4321629860011128\n",
      "Theta: [-1.65078076  1.02723854  0.05832552]\n",
      "Loss in iteration 5892: 0.43215824691850363\n",
      "Theta: [-1.65090149  1.02732066  0.05832265]\n",
      "Loss in iteration 5893: 0.4321535096001201\n",
      "Theta: [-1.6510222   1.02740276  0.05831977]\n",
      "Loss in iteration 5894: 0.43214877404514906\n",
      "Theta: [-1.65114289  1.02748485  0.0583169 ]\n",
      "Loss in iteration 5895: 0.43214404025277836\n",
      "Theta: [-1.65126355  1.02756692  0.05831402]\n",
      "Loss in iteration 5896: 0.43213930822219615\n",
      "Theta: [-1.65138419  1.02764898  0.05831115]\n",
      "Loss in iteration 5897: 0.4321345779525907\n",
      "Theta: [-1.65150481  1.02773103  0.05830828]\n",
      "Loss in iteration 5898: 0.432129849443151\n",
      "Theta: [-1.6516254   1.02781306  0.0583054 ]\n",
      "Loss in iteration 5899: 0.43212512269306685\n",
      "Theta: [-1.65174597  1.02789508  0.05830253]\n",
      "Loss in iteration 5900: 0.43212039770152777\n",
      "Theta: [-1.65186652  1.02797709  0.05829966]\n",
      "Loss in iteration 5901: 0.4321156744677244\n",
      "Theta: [-1.65198704  1.02805908  0.05829678]\n",
      "Loss in iteration 5902: 0.43211095299084723\n",
      "Theta: [-1.65210754  1.02814105  0.05829391]\n",
      "Loss in iteration 5903: 0.432106233270088\n",
      "Theta: [-1.65222802  1.02822301  0.05829104]\n",
      "Loss in iteration 5904: 0.43210151530463814\n",
      "Theta: [-1.65234847  1.02830496  0.05828817]\n",
      "Loss in iteration 5905: 0.4320967990936899\n",
      "Theta: [-1.6524689  1.0283869  0.0582853]\n",
      "Loss in iteration 5906: 0.432092084636436\n",
      "Theta: [-1.65258931  1.02846882  0.05828243]\n",
      "Loss in iteration 5907: 0.4320873719320694\n",
      "Theta: [-1.65270969  1.02855072  0.05827956]\n",
      "Loss in iteration 5908: 0.43208266097978393\n",
      "Theta: [-1.65283006  1.02863261  0.05827669]\n",
      "Loss in iteration 5909: 0.43207795177877323\n",
      "Theta: [-1.65295039  1.02871449  0.05827382]\n",
      "Loss in iteration 5910: 0.43207324432823213\n",
      "Theta: [-1.65307071  1.02879636  0.05827095]\n",
      "Loss in iteration 5911: 0.4320685386273553\n",
      "Theta: [-1.653191    1.02887821  0.05826808]\n",
      "Loss in iteration 5912: 0.4320638346753385\n",
      "Theta: [-1.65331127  1.02896004  0.05826521]\n",
      "Loss in iteration 5913: 0.43205913247137706\n",
      "Theta: [-1.65343151  1.02904186  0.05826234]\n",
      "Loss in iteration 5914: 0.4320544320146677\n",
      "Theta: [-1.65355173  1.02912367  0.05825947]\n",
      "Loss in iteration 5915: 0.4320497333044071\n",
      "Theta: [-1.65367193  1.02920547  0.0582566 ]\n",
      "Loss in iteration 5916: 0.43204503633979235\n",
      "Theta: [-1.65379211  1.02928725  0.05825373]\n",
      "Loss in iteration 5917: 0.432040341120021\n",
      "Theta: [-1.65391226  1.02936901  0.05825087]\n",
      "Loss in iteration 5918: 0.4320356476442915\n",
      "Theta: [-1.65403239  1.02945076  0.058248  ]\n",
      "Loss in iteration 5919: 0.4320309559118021\n",
      "Theta: [-1.65415249  1.0295325   0.05824513]\n",
      "Loss in iteration 5920: 0.43202626592175186\n",
      "Theta: [-1.65427258  1.02961423  0.05824226]\n",
      "Loss in iteration 5921: 0.4320215776733405\n",
      "Theta: [-1.65439264  1.02969594  0.0582394 ]\n",
      "Loss in iteration 5922: 0.4320168911657678\n",
      "Theta: [-1.65451267  1.02977763  0.05823653]\n",
      "Loss in iteration 5923: 0.4320122063982339\n",
      "Theta: [-1.65463269  1.02985931  0.05823367]\n",
      "Loss in iteration 5924: 0.43200752336994\n",
      "Theta: [-1.65475268  1.02994098  0.0582308 ]\n",
      "Loss in iteration 5925: 0.4320028420800871\n",
      "Theta: [-1.65487264  1.03002264  0.05822793]\n",
      "Loss in iteration 5926: 0.43199816252787715\n",
      "Theta: [-1.65499259  1.03010428  0.05822507]\n",
      "Loss in iteration 5927: 0.43199348471251214\n",
      "Theta: [-1.65511251  1.0301859   0.0582222 ]\n",
      "Loss in iteration 5928: 0.4319888086331947\n",
      "Theta: [-1.65523241  1.03026751  0.05821934]\n",
      "Loss in iteration 5929: 0.431984134289128\n",
      "Theta: [-1.65535228  1.03034911  0.05821647]\n",
      "Loss in iteration 5930: 0.43197946167951556\n",
      "Theta: [-1.65547213  1.0304307   0.05821361]\n",
      "Loss in iteration 5931: 0.4319747908035614\n",
      "Theta: [-1.65559196  1.03051227  0.05821075]\n",
      "Loss in iteration 5932: 0.4319701216604697\n",
      "Theta: [-1.65571177  1.03059382  0.05820788]\n",
      "Loss in iteration 5933: 0.43196545424944566\n",
      "Theta: [-1.65583155  1.03067537  0.05820502]\n",
      "Loss in iteration 5934: 0.43196078856969444\n",
      "Theta: [-1.65595131  1.0307569   0.05820216]\n",
      "Loss in iteration 5935: 0.43195612462042177\n",
      "Theta: [-1.65607105  1.03083841  0.05819929]\n",
      "Loss in iteration 5936: 0.4319514624008338\n",
      "Theta: [-1.65619076  1.03091991  0.05819643]\n",
      "Loss in iteration 5937: 0.4319468019101375\n",
      "Theta: [-1.65631045  1.0310014   0.05819357]\n",
      "Loss in iteration 5938: 0.43194214314753976\n",
      "Theta: [-1.65643012  1.03108287  0.05819071]\n",
      "Loss in iteration 5939: 0.43193748611224797\n",
      "Theta: [-1.65654977  1.03116433  0.05818785]\n",
      "Loss in iteration 5940: 0.43193283080347056\n",
      "Theta: [-1.65666939  1.03124577  0.05818498]\n",
      "Loss in iteration 5941: 0.4319281772204156\n",
      "Theta: [-1.65678899  1.03132721  0.05818212]\n",
      "Loss in iteration 5942: 0.4319235253622922\n",
      "Theta: [-1.65690856  1.03140862  0.05817926]\n",
      "Loss in iteration 5943: 0.4319188752283095\n",
      "Theta: [-1.65702811  1.03149003  0.0581764 ]\n",
      "Loss in iteration 5944: 0.43191422681767755\n",
      "Theta: [-1.65714764  1.03157142  0.05817354]\n",
      "Loss in iteration 5945: 0.43190958012960656\n",
      "Theta: [-1.65726715  1.03165279  0.05817068]\n",
      "Loss in iteration 5946: 0.43190493516330697\n",
      "Theta: [-1.65738664  1.03173415  0.05816782]\n",
      "Loss in iteration 5947: 0.43190029191799\n",
      "Theta: [-1.6575061   1.0318155   0.05816496]\n",
      "Loss in iteration 5948: 0.43189565039286726\n",
      "Theta: [-1.65762553  1.03189683  0.0581621 ]\n",
      "Loss in iteration 5949: 0.4318910105871508\n",
      "Theta: [-1.65774495  1.03197815  0.05815925]\n",
      "Loss in iteration 5950: 0.43188637250005285\n",
      "Theta: [-1.65786434  1.03205946  0.05815639]\n",
      "Loss in iteration 5951: 0.4318817361307867\n",
      "Theta: [-1.65798371  1.03214075  0.05815353]\n",
      "Loss in iteration 5952: 0.4318771014785653\n",
      "Theta: [-1.65810306  1.03222203  0.05815067]\n",
      "Loss in iteration 5953: 0.43187246854260264\n",
      "Theta: [-1.65822238  1.03230329  0.05814781]\n",
      "Loss in iteration 5954: 0.431867837322113\n",
      "Theta: [-1.65834168  1.03238454  0.05814496]\n",
      "Loss in iteration 5955: 0.43186320781631077\n",
      "Theta: [-1.65846096  1.03246578  0.0581421 ]\n",
      "Loss in iteration 5956: 0.4318585800244113\n",
      "Theta: [-1.65858021  1.032547    0.05813924]\n",
      "Loss in iteration 5957: 0.43185395394562986\n",
      "Theta: [-1.65869945  1.03262821  0.05813639]\n",
      "Loss in iteration 5958: 0.43184932957918276\n",
      "Theta: [-1.65881865  1.03270941  0.05813353]\n",
      "Loss in iteration 5959: 0.4318447069242864\n",
      "Theta: [-1.65893784  1.03279059  0.05813067]\n",
      "Loss in iteration 5960: 0.4318400859801575\n",
      "Theta: [-1.659057    1.03287176  0.05812782]\n",
      "Loss in iteration 5961: 0.4318354667460133\n",
      "Theta: [-1.65917614  1.03295291  0.05812496]\n",
      "Loss in iteration 5962: 0.4318308492210719\n",
      "Theta: [-1.65929526  1.03303405  0.05812211]\n",
      "Loss in iteration 5963: 0.4318262334045512\n",
      "Theta: [-1.65941436  1.03311518  0.05811925]\n",
      "Loss in iteration 5964: 0.4318216192956698\n",
      "Theta: [-1.65953343  1.03319629  0.0581164 ]\n",
      "Loss in iteration 5965: 0.4318170068936468\n",
      "Theta: [-1.65965248  1.03327739  0.05811354]\n",
      "Loss in iteration 5966: 0.43181239619770195\n",
      "Theta: [-1.6597715   1.03335847  0.05811069]\n",
      "Loss in iteration 5967: 0.431807787207055\n",
      "Theta: [-1.65989051  1.03343954  0.05810784]\n",
      "Loss in iteration 5968: 0.4318031799209261\n",
      "Theta: [-1.66000949  1.0335206   0.05810498]\n",
      "Loss in iteration 5969: 0.4317985743385366\n",
      "Theta: [-1.66012844  1.03360164  0.05810213]\n",
      "Loss in iteration 5970: 0.4317939704591074\n",
      "Theta: [-1.66024738  1.03368267  0.05809928]\n",
      "Loss in iteration 5971: 0.4317893682818601\n",
      "Theta: [-1.66036629  1.03376368  0.05809642]\n",
      "Loss in iteration 5972: 0.43178476780601704\n",
      "Theta: [-1.66048518  1.03384469  0.05809357]\n",
      "Loss in iteration 5973: 0.43178016903080085\n",
      "Theta: [-1.66060405  1.03392567  0.05809072]\n",
      "Loss in iteration 5974: 0.4317755719554344\n",
      "Theta: [-1.66072289  1.03400665  0.05808787]\n",
      "Loss in iteration 5975: 0.43177097657914115\n",
      "Theta: [-1.66084171  1.03408761  0.05808502]\n",
      "Loss in iteration 5976: 0.4317663829011451\n",
      "Theta: [-1.66096051  1.03416855  0.05808217]\n",
      "Loss in iteration 5977: 0.43176179092067024\n",
      "Theta: [-1.66107929  1.03424949  0.05807931]\n",
      "Loss in iteration 5978: 0.4317572006369418\n",
      "Theta: [-1.66119804  1.03433041  0.05807646]\n",
      "Loss in iteration 5979: 0.43175261204918447\n",
      "Theta: [-1.66131677  1.03441131  0.05807361]\n",
      "Loss in iteration 5980: 0.4317480251566243\n",
      "Theta: [-1.66143548  1.0344922   0.05807076]\n",
      "Loss in iteration 5981: 0.4317434399584868\n",
      "Theta: [-1.66155416  1.03457308  0.05806791]\n",
      "Loss in iteration 5982: 0.431738856453999\n",
      "Theta: [-1.66167282  1.03465394  0.05806506]\n",
      "Loss in iteration 5983: 0.43173427464238756\n",
      "Theta: [-1.66179146  1.03473479  0.05806222]\n",
      "Loss in iteration 5984: 0.43172969452287996\n",
      "Theta: [-1.66191008  1.03481563  0.05805937]\n",
      "Loss in iteration 5985: 0.43172511609470376\n",
      "Theta: [-1.66202867  1.03489645  0.05805652]\n",
      "Loss in iteration 5986: 0.4317205393570873\n",
      "Theta: [-1.66214724  1.03497726  0.05805367]\n",
      "Loss in iteration 5987: 0.4317159643092594\n",
      "Theta: [-1.66226579  1.03505805  0.05805082]\n",
      "Loss in iteration 5988: 0.4317113909504489\n",
      "Theta: [-1.66238432  1.03513883  0.05804797]\n",
      "Loss in iteration 5989: 0.43170681927988547\n",
      "Theta: [-1.66250282  1.0352196   0.05804513]\n",
      "Loss in iteration 5990: 0.4317022492967989\n",
      "Theta: [-1.6626213   1.03530035  0.05804228]\n",
      "Loss in iteration 5991: 0.4316976810004198\n",
      "Theta: [-1.66273976  1.03538109  0.05803943]\n",
      "Loss in iteration 5992: 0.4316931143899788\n",
      "Theta: [-1.66285819  1.03546182  0.05803659]\n",
      "Loss in iteration 5993: 0.4316885494647071\n",
      "Theta: [-1.66297661  1.03554253  0.05803374]\n",
      "Loss in iteration 5994: 0.43168398622383647\n",
      "Theta: [-1.663095    1.03562323  0.05803089]\n",
      "Loss in iteration 5995: 0.4316794246665989\n",
      "Theta: [-1.66321336  1.03570392  0.05802805]\n",
      "Loss in iteration 5996: 0.4316748647922272\n",
      "Theta: [-1.66333171  1.03578459  0.0580252 ]\n",
      "Loss in iteration 5997: 0.43167030659995403\n",
      "Theta: [-1.66345003  1.03586524  0.05802236]\n",
      "Loss in iteration 5998: 0.431665750089013\n",
      "Theta: [-1.66356833  1.03594589  0.05801951]\n",
      "Loss in iteration 5999: 0.4316611952586376\n",
      "Theta: [-1.66368661  1.03602652  0.05801667]\n",
      "Loss in iteration 6000: 0.4316566421080625\n",
      "Theta: [-1.66380486  1.03610713  0.05801382]\n",
      "Loss in iteration 6001: 0.43165209063652216\n",
      "Theta: [-1.66392309  1.03618774  0.05801098]\n",
      "Loss in iteration 6002: 0.43164754084325146\n",
      "Theta: [-1.6640413   1.03626832  0.05800813]\n",
      "Loss in iteration 6003: 0.4316429927274864\n",
      "Theta: [-1.66415949  1.0363489   0.05800529]\n",
      "Loss in iteration 6004: 0.43163844628846265\n",
      "Theta: [-1.66427765  1.03642946  0.05800245]\n",
      "Loss in iteration 6005: 0.43163390152541675\n",
      "Theta: [-1.66439579  1.03651001  0.0579996 ]\n",
      "Loss in iteration 6006: 0.4316293584375851\n",
      "Theta: [-1.66451391  1.03659054  0.05799676]\n",
      "Loss in iteration 6007: 0.4316248170242055\n",
      "Theta: [-1.66463201  1.03667106  0.05799392]\n",
      "Loss in iteration 6008: 0.43162027728451524\n",
      "Theta: [-1.66475008  1.03675157  0.05799108]\n",
      "Loss in iteration 6009: 0.4316157392177528\n",
      "Theta: [-1.66486813  1.03683206  0.05798824]\n",
      "Loss in iteration 6010: 0.4316112028231563\n",
      "Theta: [-1.66498616  1.03691254  0.05798539]\n",
      "Loss in iteration 6011: 0.4316066680999646\n",
      "Theta: [-1.66510416  1.03699301  0.05798255]\n",
      "Loss in iteration 6012: 0.43160213504741746\n",
      "Theta: [-1.66522215  1.03707346  0.05797971]\n",
      "Loss in iteration 6013: 0.4315976036647546\n",
      "Theta: [-1.66534011  1.0371539   0.05797687]\n",
      "Loss in iteration 6014: 0.43159307395121616\n",
      "Theta: [-1.66545805  1.03723432  0.05797403]\n",
      "Loss in iteration 6015: 0.43158854590604256\n",
      "Theta: [-1.66557596  1.03731473  0.05797119]\n",
      "Loss in iteration 6016: 0.43158401952847525\n",
      "Theta: [-1.66569386  1.03739513  0.05796835]\n",
      "Loss in iteration 6017: 0.4315794948177556\n",
      "Theta: [-1.66581173  1.03747551  0.05796551]\n",
      "Loss in iteration 6018: 0.4315749717731254\n",
      "Theta: [-1.66592957  1.03755588  0.05796267]\n",
      "Loss in iteration 6019: 0.431570450393827\n",
      "Theta: [-1.6660474   1.03763624  0.05795983]\n",
      "Loss in iteration 6020: 0.4315659306791033\n",
      "Theta: [-1.6661652   1.03771658  0.05795699]\n",
      "Loss in iteration 6021: 0.43156141262819747\n",
      "Theta: [-1.66628298  1.03779691  0.05795416]\n",
      "Loss in iteration 6022: 0.43155689624035287\n",
      "Theta: [-1.66640074  1.03787722  0.05795132]\n",
      "Loss in iteration 6023: 0.4315523815148139\n",
      "Theta: [-1.66651848  1.03795753  0.05794848]\n",
      "Loss in iteration 6024: 0.4315478684508248\n",
      "Theta: [-1.66663619  1.03803781  0.05794564]\n",
      "Loss in iteration 6025: 0.4315433570476306\n",
      "Theta: [-1.66675388  1.03811809  0.05794281]\n",
      "Loss in iteration 6026: 0.43153884730447645\n",
      "Theta: [-1.66687155  1.03819835  0.05793997]\n",
      "Loss in iteration 6027: 0.4315343392206077\n",
      "Theta: [-1.6669892   1.0382786   0.05793713]\n",
      "Loss in iteration 6028: 0.4315298327952713\n",
      "Theta: [-1.66710682  1.03835883  0.05793429]\n",
      "Loss in iteration 6029: 0.4315253280277132\n",
      "Theta: [-1.66722442  1.03843905  0.05793146]\n",
      "Loss in iteration 6030: 0.43152082491718063\n",
      "Theta: [-1.667342    1.03851926  0.05792862]\n",
      "Loss in iteration 6031: 0.43151632346292074\n",
      "Theta: [-1.66745956  1.03859945  0.05792579]\n",
      "Loss in iteration 6032: 0.4315118236641818\n",
      "Theta: [-1.66757709  1.03867963  0.05792295]\n",
      "Loss in iteration 6033: 0.43150732552021154\n",
      "Theta: [-1.6676946   1.03875979  0.05792012]\n",
      "Loss in iteration 6034: 0.4315028290302589\n",
      "Theta: [-1.66781209  1.03883994  0.05791728]\n",
      "Loss in iteration 6035: 0.4314983341935729\n",
      "Theta: [-1.66792956  1.03892008  0.05791445]\n",
      "Loss in iteration 6036: 0.431493841009403\n",
      "Theta: [-1.668047    1.03900021  0.05791161]\n",
      "Loss in iteration 6037: 0.4314893494769992\n",
      "Theta: [-1.66816443  1.03908032  0.05790878]\n",
      "Loss in iteration 6038: 0.4314848595956116\n",
      "Theta: [-1.66828183  1.03916042  0.05790595]\n",
      "Loss in iteration 6039: 0.43148037136449136\n",
      "Theta: [-1.6683992   1.0392405   0.05790311]\n",
      "Loss in iteration 6040: 0.43147588478288923\n",
      "Theta: [-1.66851656  1.03932057  0.05790028]\n",
      "Loss in iteration 6041: 0.43147139985005706\n",
      "Theta: [-1.66863389  1.03940063  0.05789745]\n",
      "Loss in iteration 6042: 0.43146691656524666\n",
      "Theta: [-1.6687512   1.03948067  0.05789461]\n",
      "Loss in iteration 6043: 0.43146243492771064\n",
      "Theta: [-1.66886849  1.0395607   0.05789178]\n",
      "Loss in iteration 6044: 0.4314579549367016\n",
      "Theta: [-1.66898576  1.03964071  0.05788895]\n",
      "Loss in iteration 6045: 0.43145347659147304\n",
      "Theta: [-1.669103    1.03972072  0.05788612]\n",
      "Loss in iteration 6046: 0.4314489998912782\n",
      "Theta: [-1.66922022  1.03980071  0.05788329]\n",
      "Loss in iteration 6047: 0.4314445248353717\n",
      "Theta: [-1.66933742  1.03988068  0.05788046]\n",
      "Loss in iteration 6048: 0.4314400514230078\n",
      "Theta: [-1.6694546   1.03996064  0.05787763]\n",
      "Loss in iteration 6049: 0.4314355796534413\n",
      "Theta: [-1.66957175  1.04004059  0.05787479]\n",
      "Loss in iteration 6050: 0.43143110952592756\n",
      "Theta: [-1.66968888  1.04012052  0.05787196]\n",
      "Loss in iteration 6051: 0.4314266410397224\n",
      "Theta: [-1.66980599  1.04020045  0.05786913]\n",
      "Loss in iteration 6052: 0.43142217419408196\n",
      "Theta: [-1.66992308  1.04028035  0.0578663 ]\n",
      "Loss in iteration 6053: 0.4314177089882628\n",
      "Theta: [-1.67004014  1.04036025  0.05786348]\n",
      "Loss in iteration 6054: 0.43141324542152193\n",
      "Theta: [-1.67015719  1.04044013  0.05786065]\n",
      "Loss in iteration 6055: 0.43140878349311657\n",
      "Theta: [-1.67027421  1.04051999  0.05785782]\n",
      "Loss in iteration 6056: 0.43140432320230465\n",
      "Theta: [-1.6703912   1.04059985  0.05785499]\n",
      "Loss in iteration 6057: 0.43139986454834434\n",
      "Theta: [-1.67050818  1.04067969  0.05785216]\n",
      "Loss in iteration 6058: 0.4313954075304946\n",
      "Theta: [-1.67062513  1.04075951  0.05784933]\n",
      "Loss in iteration 6059: 0.4313909521480139\n",
      "Theta: [-1.67074207  1.04083933  0.05784651]\n",
      "Loss in iteration 6060: 0.43138649840016213\n",
      "Theta: [-1.67085898  1.04091913  0.05784368]\n",
      "Loss in iteration 6061: 0.431382046286199\n",
      "Theta: [-1.67097586  1.04099891  0.05784085]\n",
      "Loss in iteration 6062: 0.43137759580538465\n",
      "Theta: [-1.67109273  1.04107868  0.05783802]\n",
      "Loss in iteration 6063: 0.43137314695698004\n",
      "Theta: [-1.67120957  1.04115844  0.0578352 ]\n",
      "Loss in iteration 6064: 0.43136869974024605\n",
      "Theta: [-1.67132639  1.04123819  0.05783237]\n",
      "Loss in iteration 6065: 0.4313642541544443\n",
      "Theta: [-1.67144319  1.04131792  0.05782955]\n",
      "Loss in iteration 6066: 0.4313598101988368\n",
      "Theta: [-1.67155997  1.04139764  0.05782672]\n",
      "Loss in iteration 6067: 0.43135536787268564\n",
      "Theta: [-1.67167672  1.04147734  0.05782389]\n",
      "Loss in iteration 6068: 0.43135092717525375\n",
      "Theta: [-1.67179345  1.04155703  0.05782107]\n",
      "Loss in iteration 6069: 0.43134648810580417\n",
      "Theta: [-1.67191016  1.04163671  0.05781824]\n",
      "Loss in iteration 6070: 0.43134205066360054\n",
      "Theta: [-1.67202685  1.04171637  0.05781542]\n",
      "Loss in iteration 6071: 0.4313376148479067\n",
      "Theta: [-1.67214351  1.04179602  0.0578126 ]\n",
      "Loss in iteration 6072: 0.4313331806579873\n",
      "Theta: [-1.67226016  1.04187566  0.05780977]\n",
      "Loss in iteration 6073: 0.43132874809310684\n",
      "Theta: [-1.67237678  1.04195529  0.05780695]\n",
      "Loss in iteration 6074: 0.4313243171525306\n",
      "Theta: [-1.67249338  1.0420349   0.05780412]\n",
      "Loss in iteration 6075: 0.4313198878355242\n",
      "Theta: [-1.67260995  1.04211449  0.0578013 ]\n",
      "Loss in iteration 6076: 0.4313154601413536\n",
      "Theta: [-1.67272651  1.04219408  0.05779848]\n",
      "Loss in iteration 6077: 0.4313110340692852\n",
      "Theta: [-1.67284304  1.04227365  0.05779566]\n",
      "Loss in iteration 6078: 0.431306609618586\n",
      "Theta: [-1.67295955  1.0423532   0.05779283]\n",
      "Loss in iteration 6079: 0.43130218678852295\n",
      "Theta: [-1.67307604  1.04243274  0.05779001]\n",
      "Loss in iteration 6080: 0.431297765578364\n",
      "Theta: [-1.67319251  1.04251227  0.05778719]\n",
      "Loss in iteration 6081: 0.43129334598737684\n",
      "Theta: [-1.67330895  1.04259179  0.05778437]\n",
      "Loss in iteration 6082: 0.4312889280148303\n",
      "Theta: [-1.67342537  1.04267129  0.05778155]\n",
      "Loss in iteration 6083: 0.43128451165999293\n",
      "Theta: [-1.67354177  1.04275078  0.05777873]\n",
      "Loss in iteration 6084: 0.43128009692213404\n",
      "Theta: [-1.67365815  1.04283026  0.05777591]\n",
      "Loss in iteration 6085: 0.4312756838005234\n",
      "Theta: [-1.67377451  1.04290972  0.05777308]\n",
      "Loss in iteration 6086: 0.431271272294431\n",
      "Theta: [-1.67389084  1.04298917  0.05777026]\n",
      "Loss in iteration 6087: 0.4312668624031273\n",
      "Theta: [-1.67400715  1.0430686   0.05776745]\n",
      "Loss in iteration 6088: 0.43126245412588327\n",
      "Theta: [-1.67412344  1.04314803  0.05776463]\n",
      "Loss in iteration 6089: 0.43125804746197005\n",
      "Theta: [-1.67423971  1.04322743  0.05776181]\n",
      "Loss in iteration 6090: 0.43125364241065933\n",
      "Theta: [-1.67435595  1.04330683  0.05775899]\n",
      "Loss in iteration 6091: 0.4312492389712234\n",
      "Theta: [-1.67447218  1.04338621  0.05775617]\n",
      "Loss in iteration 6092: 0.4312448371429346\n",
      "Theta: [-1.67458838  1.04346558  0.05775335]\n",
      "Loss in iteration 6093: 0.4312404369250658\n",
      "Theta: [-1.67470456  1.04354493  0.05775053]\n",
      "Loss in iteration 6094: 0.4312360383168904\n",
      "Theta: [-1.67482072  1.04362428  0.05774771]\n",
      "Loss in iteration 6095: 0.43123164131768194\n",
      "Theta: [-1.67493685  1.0437036   0.0577449 ]\n",
      "Loss in iteration 6096: 0.4312272459267146\n",
      "Theta: [-1.67505296  1.04378292  0.05774208]\n",
      "Loss in iteration 6097: 0.43122285214326306\n",
      "Theta: [-1.67516906  1.04386222  0.05773926]\n",
      "Loss in iteration 6098: 0.4312184599666019\n",
      "Theta: [-1.67528513  1.04394151  0.05773645]\n",
      "Loss in iteration 6099: 0.43121406939600676\n",
      "Theta: [-1.67540117  1.04402078  0.05773363]\n",
      "Loss in iteration 6100: 0.4312096804307529\n",
      "Theta: [-1.6755172   1.04410004  0.05773081]\n",
      "Loss in iteration 6101: 0.43120529307011685\n",
      "Theta: [-1.6756332   1.04417929  0.057728  ]\n",
      "Loss in iteration 6102: 0.4312009073133751\n",
      "Theta: [-1.67574918  1.04425852  0.05772518]\n",
      "Loss in iteration 6103: 0.4311965231598041\n",
      "Theta: [-1.67586514  1.04433775  0.05772237]\n",
      "Loss in iteration 6104: 0.43119214060868166\n",
      "Theta: [-1.67598108  1.04441695  0.05771955]\n",
      "Loss in iteration 6105: 0.4311877596592854\n",
      "Theta: [-1.676097    1.04449615  0.05771674]\n",
      "Loss in iteration 6106: 0.4311833803108933\n",
      "Theta: [-1.67621289  1.04457533  0.05771392]\n",
      "Loss in iteration 6107: 0.43117900256278374\n",
      "Theta: [-1.67632876  1.04465449  0.05771111]\n",
      "Loss in iteration 6108: 0.4311746264142359\n",
      "Theta: [-1.67644461  1.04473365  0.0577083 ]\n",
      "Loss in iteration 6109: 0.431170251864529\n",
      "Theta: [-1.67656044  1.04481279  0.05770548]\n",
      "Loss in iteration 6110: 0.4311658789129427\n",
      "Theta: [-1.67667625  1.04489192  0.05770267]\n",
      "Loss in iteration 6111: 0.431161507558757\n",
      "Theta: [-1.67679203  1.04497103  0.05769986]\n",
      "Loss in iteration 6112: 0.43115713780125264\n",
      "Theta: [-1.67690779  1.04505013  0.05769704]\n",
      "Loss in iteration 6113: 0.43115276963971033\n",
      "Theta: [-1.67702353  1.04512922  0.05769423]\n",
      "Loss in iteration 6114: 0.43114840307341146\n",
      "Theta: [-1.67713925  1.04520829  0.05769142]\n",
      "Loss in iteration 6115: 0.43114403810163765\n",
      "Theta: [-1.67725495  1.04528735  0.05768861]\n",
      "Loss in iteration 6116: 0.4311396747236711\n",
      "Theta: [-1.67737062  1.0453664   0.0576858 ]\n",
      "Loss in iteration 6117: 0.4311353129387941\n",
      "Theta: [-1.67748627  1.04544543  0.05768298]\n",
      "Loss in iteration 6118: 0.4311309527462896\n",
      "Theta: [-1.67760191  1.04552445  0.05768017]\n",
      "Loss in iteration 6119: 0.43112659414544113\n",
      "Theta: [-1.67771751  1.04560346  0.05767736]\n",
      "Loss in iteration 6120: 0.43112223713553194\n",
      "Theta: [-1.6778331   1.04568246  0.05767455]\n",
      "Loss in iteration 6121: 0.4311178817158465\n",
      "Theta: [-1.67794867  1.04576144  0.05767174]\n",
      "Loss in iteration 6122: 0.4311135278856689\n",
      "Theta: [-1.67806421  1.0458404   0.05766893]\n",
      "Loss in iteration 6123: 0.43110917564428425\n",
      "Theta: [-1.67817973  1.04591936  0.05766612]\n",
      "Loss in iteration 6124: 0.4311048249909778\n",
      "Theta: [-1.67829523  1.0459983   0.05766331]\n",
      "Loss in iteration 6125: 0.43110047592503514\n",
      "Theta: [-1.67841071  1.04607722  0.0576605 ]\n",
      "Loss in iteration 6126: 0.43109612844574224\n",
      "Theta: [-1.67852617  1.04615614  0.0576577 ]\n",
      "Loss in iteration 6127: 0.43109178255238545\n",
      "Theta: [-1.6786416   1.04623504  0.05765489]\n",
      "Loss in iteration 6128: 0.43108743824425205\n",
      "Theta: [-1.67875701  1.04631393  0.05765208]\n",
      "Loss in iteration 6129: 0.4310830955206288\n",
      "Theta: [-1.6788724   1.0463928   0.05764927]\n",
      "Loss in iteration 6130: 0.4310787543808034\n",
      "Theta: [-1.67898777  1.04647166  0.05764646]\n",
      "Loss in iteration 6131: 0.43107441482406395\n",
      "Theta: [-1.67910312  1.04655051  0.05764366]\n",
      "Loss in iteration 6132: 0.4310700768496988\n",
      "Theta: [-1.67921845  1.04662934  0.05764085]\n",
      "Loss in iteration 6133: 0.4310657404569968\n",
      "Theta: [-1.67933375  1.04670816  0.05763804]\n",
      "Loss in iteration 6134: 0.43106140564524714\n",
      "Theta: [-1.67944903  1.04678697  0.05763524]\n",
      "Loss in iteration 6135: 0.4310570724137394\n",
      "Theta: [-1.67956429  1.04686577  0.05763243]\n",
      "Loss in iteration 6136: 0.43105274076176364\n",
      "Theta: [-1.67967953  1.04694455  0.05762962]\n",
      "Loss in iteration 6137: 0.43104841068860983\n",
      "Theta: [-1.67979475  1.04702331  0.05762682]\n",
      "Loss in iteration 6138: 0.431044082193569\n",
      "Theta: [-1.67990994  1.04710207  0.05762401]\n",
      "Loss in iteration 6139: 0.4310397552759324\n",
      "Theta: [-1.68002511  1.04718081  0.05762121]\n",
      "Loss in iteration 6140: 0.4310354299349914\n",
      "Theta: [-1.68014027  1.04725954  0.0576184 ]\n",
      "Loss in iteration 6141: 0.4310311061700381\n",
      "Theta: [-1.6802554   1.04733825  0.0576156 ]\n",
      "Loss in iteration 6142: 0.43102678398036454\n",
      "Theta: [-1.6803705   1.04741695  0.05761279]\n",
      "Loss in iteration 6143: 0.4310224633652635\n",
      "Theta: [-1.68048559  1.04749564  0.05760999]\n",
      "Loss in iteration 6144: 0.43101814432402835\n",
      "Theta: [-1.68060065  1.04757432  0.05760719]\n",
      "Loss in iteration 6145: 0.43101382685595213\n",
      "Theta: [-1.6807157   1.04765298  0.05760438]\n",
      "Loss in iteration 6146: 0.4310095109603291\n",
      "Theta: [-1.68083072  1.04773163  0.05760158]\n",
      "Loss in iteration 6147: 0.43100519663645315\n",
      "Theta: [-1.68094572  1.04781026  0.05759878]\n",
      "Loss in iteration 6148: 0.43100088388361923\n",
      "Theta: [-1.6810607   1.04788888  0.05759598]\n",
      "Loss in iteration 6149: 0.4309965727011224\n",
      "Theta: [-1.68117565  1.04796749  0.05759317]\n",
      "Loss in iteration 6150: 0.43099226308825783\n",
      "Theta: [-1.68129059  1.04804609  0.05759037]\n",
      "Loss in iteration 6151: 0.43098795504432164\n",
      "Theta: [-1.6814055   1.04812467  0.05758757]\n",
      "Loss in iteration 6152: 0.4309836485686096\n",
      "Theta: [-1.68152039  1.04820324  0.05758477]\n",
      "Loss in iteration 6153: 0.4309793436604188\n",
      "Theta: [-1.68163526  1.0482818   0.05758197]\n",
      "Loss in iteration 6154: 0.43097504031904577\n",
      "Theta: [-1.68175011  1.04836034  0.05757917]\n",
      "Loss in iteration 6155: 0.43097073854378815\n",
      "Theta: [-1.68186493  1.04843887  0.05757637]\n",
      "Loss in iteration 6156: 0.43096643833394355\n",
      "Theta: [-1.68197974  1.04851738  0.05757357]\n",
      "Loss in iteration 6157: 0.43096213968881025\n",
      "Theta: [-1.68209452  1.04859589  0.05757077]\n",
      "Loss in iteration 6158: 0.4309578426076866\n",
      "Theta: [-1.68220928  1.04867438  0.05756797]\n",
      "Loss in iteration 6159: 0.43095354708987155\n",
      "Theta: [-1.68232402  1.04875285  0.05756517]\n",
      "Loss in iteration 6160: 0.4309492531346646\n",
      "Theta: [-1.68243874  1.04883132  0.05756237]\n",
      "Loss in iteration 6161: 0.43094496074136507\n",
      "Theta: [-1.68255344  1.04890977  0.05755957]\n",
      "Loss in iteration 6162: 0.43094066990927327\n",
      "Theta: [-1.68266811  1.0489882   0.05755677]\n",
      "Loss in iteration 6163: 0.4309363806376895\n",
      "Theta: [-1.68278276  1.04906663  0.05755397]\n",
      "Loss in iteration 6164: 0.4309320929259147\n",
      "Theta: [-1.6828974   1.04914504  0.05755117]\n",
      "Loss in iteration 6165: 0.43092780677325004\n",
      "Theta: [-1.68301201  1.04922344  0.05754838]\n",
      "Loss in iteration 6166: 0.4309235221789971\n",
      "Theta: [-1.68312659  1.04930182  0.05754558]\n",
      "Loss in iteration 6167: 0.43091923914245805\n",
      "Theta: [-1.68324116  1.04938019  0.05754278]\n",
      "Loss in iteration 6168: 0.43091495766293497\n",
      "Theta: [-1.68335571  1.04945855  0.05753999]\n",
      "Loss in iteration 6169: 0.4309106777397307\n",
      "Theta: [-1.68347023  1.04953689  0.05753719]\n",
      "Loss in iteration 6170: 0.4309063993721485\n",
      "Theta: [-1.68358473  1.04961522  0.05753439]\n",
      "Loss in iteration 6171: 0.43090212255949156\n",
      "Theta: [-1.68369921  1.04969354  0.0575316 ]\n",
      "Loss in iteration 6172: 0.4308978473010642\n",
      "Theta: [-1.68381367  1.04977185  0.0575288 ]\n",
      "Loss in iteration 6173: 0.4308935735961704\n",
      "Theta: [-1.68392811  1.04985014  0.05752601]\n",
      "Loss in iteration 6174: 0.43088930144411497\n",
      "Theta: [-1.68404253  1.04992842  0.05752321]\n",
      "Loss in iteration 6175: 0.4308850308442028\n",
      "Theta: [-1.68415692  1.05000668  0.05752042]\n",
      "Loss in iteration 6176: 0.4308807617957395\n",
      "Theta: [-1.68427129  1.05008494  0.05751762]\n",
      "Loss in iteration 6177: 0.43087649429803093\n",
      "Theta: [-1.68438565  1.05016318  0.05751483]\n",
      "Loss in iteration 6178: 0.4308722283503829\n",
      "Theta: [-1.68449998  1.0502414   0.05751203]\n",
      "Loss in iteration 6179: 0.4308679639521023\n",
      "Theta: [-1.68461428  1.05031962  0.05750924]\n",
      "Loss in iteration 6180: 0.43086370110249583\n",
      "Theta: [-1.68472857  1.05039782  0.05750645]\n",
      "Loss in iteration 6181: 0.43085943980087116\n",
      "Theta: [-1.68484284  1.050476    0.05750365]\n",
      "Loss in iteration 6182: 0.43085518004653567\n",
      "Theta: [-1.68495708  1.05055418  0.05750086]\n",
      "Loss in iteration 6183: 0.43085092183879775\n",
      "Theta: [-1.6850713   1.05063234  0.05749807]\n",
      "Loss in iteration 6184: 0.4308466651769656\n",
      "Theta: [-1.6851855   1.05071048  0.05749527]\n",
      "Loss in iteration 6185: 0.43084241006034807\n",
      "Theta: [-1.68529968  1.05078862  0.05749248]\n",
      "Loss in iteration 6186: 0.4308381564882547\n",
      "Theta: [-1.68541384  1.05086674  0.05748969]\n",
      "Loss in iteration 6187: 0.43083390445999475\n",
      "Theta: [-1.68552798  1.05094485  0.0574869 ]\n",
      "Loss in iteration 6188: 0.43082965397487816\n",
      "Theta: [-1.68564209  1.05102294  0.05748411]\n",
      "Loss in iteration 6189: 0.43082540503221556\n",
      "Theta: [-1.68575619  1.05110103  0.05748132]\n",
      "Loss in iteration 6190: 0.4308211576313176\n",
      "Theta: [-1.68587026  1.05117909  0.05747853]\n",
      "Loss in iteration 6191: 0.4308169117714954\n",
      "Theta: [-1.68598431  1.05125715  0.05747574]\n",
      "Loss in iteration 6192: 0.4308126674520603\n",
      "Theta: [-1.68609834  1.05133519  0.05747295]\n",
      "Loss in iteration 6193: 0.4308084246723244\n",
      "Theta: [-1.68621235  1.05141322  0.05747016]\n",
      "Loss in iteration 6194: 0.43080418343159976\n",
      "Theta: [-1.68632634  1.05149124  0.05746737]\n",
      "Loss in iteration 6195: 0.43079994372919905\n",
      "Theta: [-1.6864403   1.05156924  0.05746458]\n",
      "Loss in iteration 6196: 0.4307957055644354\n",
      "Theta: [-1.68655425  1.05164723  0.05746179]\n",
      "Loss in iteration 6197: 0.43079146893662196\n",
      "Theta: [-1.68666817  1.05172521  0.057459  ]\n",
      "Loss in iteration 6198: 0.4307872338450726\n",
      "Theta: [-1.68678207  1.05180317  0.05745621]\n",
      "Loss in iteration 6199: 0.43078300028910155\n",
      "Theta: [-1.68689595  1.05188112  0.05745342]\n",
      "Loss in iteration 6200: 0.4307787682680231\n",
      "Theta: [-1.68700981  1.05195906  0.05745064]\n",
      "Loss in iteration 6201: 0.4307745377811525\n",
      "Theta: [-1.68712364  1.05203699  0.05744785]\n",
      "Loss in iteration 6202: 0.4307703088278043\n",
      "Theta: [-1.68723746  1.0521149   0.05744506]\n",
      "Loss in iteration 6203: 0.4307660814072949\n",
      "Theta: [-1.68735125  1.0521928   0.05744228]\n",
      "Loss in iteration 6204: 0.4307618555189398\n",
      "Theta: [-1.68746503  1.05227068  0.05743949]\n",
      "Loss in iteration 6205: 0.43075763116205573\n",
      "Theta: [-1.68757878  1.05234855  0.0574367 ]\n",
      "Loss in iteration 6206: 0.43075340833595904\n",
      "Theta: [-1.68769251  1.05242641  0.05743392]\n",
      "Loss in iteration 6207: 0.430749187039967\n",
      "Theta: [-1.68780622  1.05250426  0.05743113]\n",
      "Loss in iteration 6208: 0.4307449672733973\n",
      "Theta: [-1.68791991  1.05258209  0.05742835]\n",
      "Loss in iteration 6209: 0.4307407490355677\n",
      "Theta: [-1.68803357  1.05265991  0.05742556]\n",
      "Loss in iteration 6210: 0.4307365323257964\n",
      "Theta: [-1.68814722  1.05273772  0.05742278]\n",
      "Loss in iteration 6211: 0.4307323171434021\n",
      "Theta: [-1.68826084  1.05281551  0.05741999]\n",
      "Loss in iteration 6212: 0.4307281034877037\n",
      "Theta: [-1.68837444  1.0528933   0.05741721]\n",
      "Loss in iteration 6213: 0.43072389135802047\n",
      "Theta: [-1.68848803  1.05297106  0.05741442]\n",
      "Loss in iteration 6214: 0.4307196807536724\n",
      "Theta: [-1.68860159  1.05304882  0.05741164]\n",
      "Loss in iteration 6215: 0.43071547167397933\n",
      "Theta: [-1.68871512  1.05312656  0.05740885]\n",
      "Loss in iteration 6216: 0.43071126411826194\n",
      "Theta: [-1.68882864  1.05320429  0.05740607]\n",
      "Loss in iteration 6217: 0.4307070580858409\n",
      "Theta: [-1.68894214  1.05328201  0.05740329]\n",
      "Loss in iteration 6218: 0.4307028535760375\n",
      "Theta: [-1.68905561  1.05335971  0.05740051]\n",
      "Loss in iteration 6219: 0.43069865058817347\n",
      "Theta: [-1.68916907  1.0534374   0.05739772]\n",
      "Loss in iteration 6220: 0.4306944491215706\n",
      "Theta: [-1.6892825   1.05351508  0.05739494]\n",
      "Loss in iteration 6221: 0.43069024917555127\n",
      "Theta: [-1.68939591  1.05359274  0.05739216]\n",
      "Loss in iteration 6222: 0.43068605074943817\n",
      "Theta: [-1.6895093   1.05367039  0.05738938]\n",
      "Loss in iteration 6223: 0.43068185384255453\n",
      "Theta: [-1.68962267  1.05374803  0.0573866 ]\n",
      "Loss in iteration 6224: 0.43067765845422346\n",
      "Theta: [-1.68973601  1.05382565  0.05738382]\n",
      "Loss in iteration 6225: 0.4306734645837689\n",
      "Theta: [-1.68984934  1.05390327  0.05738104]\n",
      "Loss in iteration 6226: 0.4306692722305151\n",
      "Theta: [-1.68996264  1.05398086  0.05737826]\n",
      "Loss in iteration 6227: 0.4306650813937868\n",
      "Theta: [-1.69007593  1.05405845  0.05737547]\n",
      "Loss in iteration 6228: 0.43066089207290836\n",
      "Theta: [-1.69018919  1.05413602  0.0573727 ]\n",
      "Loss in iteration 6229: 0.43065670426720565\n",
      "Theta: [-1.69030243  1.05421358  0.05736992]\n",
      "Loss in iteration 6230: 0.4306525179760039\n",
      "Theta: [-1.69041565  1.05429113  0.05736714]\n",
      "Loss in iteration 6231: 0.43064833319862933\n",
      "Theta: [-1.69052885  1.05436866  0.05736436]\n",
      "Loss in iteration 6232: 0.4306441499344084\n",
      "Theta: [-1.69064203  1.05444618  0.05736158]\n",
      "Loss in iteration 6233: 0.43063996818266764\n",
      "Theta: [-1.69075518  1.05452369  0.0573588 ]\n",
      "Loss in iteration 6234: 0.43063578794273455\n",
      "Theta: [-1.69086832  1.05460119  0.05735602]\n",
      "Loss in iteration 6235: 0.43063160921393595\n",
      "Theta: [-1.69098143  1.05467867  0.05735324]\n",
      "Loss in iteration 6236: 0.4306274319956003\n",
      "Theta: [-1.69109453  1.05475614  0.05735047]\n",
      "Loss in iteration 6237: 0.43062325628705556\n",
      "Theta: [-1.6912076   1.0548336   0.05734769]\n",
      "Loss in iteration 6238: 0.4306190820876305\n",
      "Theta: [-1.69132065  1.05491104  0.05734491]\n",
      "Loss in iteration 6239: 0.430614909396654\n",
      "Theta: [-1.69143368  1.05498847  0.05734214]\n",
      "Loss in iteration 6240: 0.4306107382134552\n",
      "Theta: [-1.69154669  1.05506589  0.05733936]\n",
      "Loss in iteration 6241: 0.43060656853736395\n",
      "Theta: [-1.69165967  1.05514329  0.05733658]\n",
      "Loss in iteration 6242: 0.43060240036771025\n",
      "Theta: [-1.69177264  1.05522068  0.05733381]\n",
      "Loss in iteration 6243: 0.43059823370382444\n",
      "Theta: [-1.69188559  1.05529806  0.05733103]\n",
      "Loss in iteration 6244: 0.4305940685450375\n",
      "Theta: [-1.69199851  1.05537543  0.05732826]\n",
      "Loss in iteration 6245: 0.43058990489068044\n",
      "Theta: [-1.69211141  1.05545278  0.05732548]\n",
      "Loss in iteration 6246: 0.4305857427400849\n",
      "Theta: [-1.69222429  1.05553012  0.05732271]\n",
      "Loss in iteration 6247: 0.4305815820925825\n",
      "Theta: [-1.69233715  1.05560744  0.05731993]\n",
      "Loss in iteration 6248: 0.43057742294750584\n",
      "Theta: [-1.69244999  1.05568476  0.05731716]\n",
      "Loss in iteration 6249: 0.43057326530418716\n",
      "Theta: [-1.69256281  1.05576206  0.05731438]\n",
      "Loss in iteration 6250: 0.43056910916195945\n",
      "Theta: [-1.69267561  1.05583935  0.05731161]\n",
      "Loss in iteration 6251: 0.4305649545201564\n",
      "Theta: [-1.69278838  1.05591662  0.05730884]\n",
      "Loss in iteration 6252: 0.4305608013781112\n",
      "Theta: [-1.69290114  1.05599388  0.05730606]\n",
      "Loss in iteration 6253: 0.43055664973515834\n",
      "Theta: [-1.69301387  1.05607113  0.05730329]\n",
      "Loss in iteration 6254: 0.43055249959063197\n",
      "Theta: [-1.69312659  1.05614837  0.05730052]\n",
      "Loss in iteration 6255: 0.4305483509438669\n",
      "Theta: [-1.69323928  1.05622559  0.05729775]\n",
      "Loss in iteration 6256: 0.4305442037941984\n",
      "Theta: [-1.69335195  1.0563028   0.05729498]\n",
      "Loss in iteration 6257: 0.4305400581409619\n",
      "Theta: [-1.6934646  1.05638    0.0572922]\n",
      "Loss in iteration 6258: 0.4305359139834933\n",
      "Theta: [-1.69357723  1.05645718  0.05728943]\n",
      "Loss in iteration 6259: 0.4305317713211286\n",
      "Theta: [-1.69368984  1.05653436  0.05728666]\n",
      "Loss in iteration 6260: 0.43052763015320467\n",
      "Theta: [-1.69380242  1.05661151  0.05728389]\n",
      "Loss in iteration 6261: 0.4305234904790583\n",
      "Theta: [-1.69391499  1.05668866  0.05728112]\n",
      "Loss in iteration 6262: 0.43051935229802674\n",
      "Theta: [-1.69402753  1.05676579  0.05727835]\n",
      "Loss in iteration 6263: 0.43051521560944783\n",
      "Theta: [-1.69414006  1.05684291  0.05727558]\n",
      "Loss in iteration 6264: 0.4305110804126597\n",
      "Theta: [-1.69425256  1.05692002  0.05727281]\n",
      "Loss in iteration 6265: 0.4305069467070002\n",
      "Theta: [-1.69436504  1.05699712  0.05727004]\n",
      "Loss in iteration 6266: 0.43050281449180866\n",
      "Theta: [-1.6944775   1.0570742   0.05726727]\n",
      "Loss in iteration 6267: 0.4304986837664239\n",
      "Theta: [-1.69458994  1.05715127  0.0572645 ]\n",
      "Loss in iteration 6268: 0.4304945545301855\n",
      "Theta: [-1.69470236  1.05722832  0.05726174]\n",
      "Loss in iteration 6269: 0.430490426782433\n",
      "Theta: [-1.69481476  1.05730536  0.05725897]\n",
      "Loss in iteration 6270: 0.430486300522507\n",
      "Theta: [-1.69492714  1.05738239  0.0572562 ]\n",
      "Loss in iteration 6271: 0.43048217574974773\n",
      "Theta: [-1.69503949  1.05745941  0.05725343]\n",
      "Loss in iteration 6272: 0.4304780524634962\n",
      "Theta: [-1.69515183  1.05753642  0.05725066]\n",
      "Loss in iteration 6273: 0.43047393066309375\n",
      "Theta: [-1.69526414  1.05761341  0.0572479 ]\n",
      "Loss in iteration 6274: 0.43046981034788173\n",
      "Theta: [-1.69537643  1.05769039  0.05724513]\n",
      "Loss in iteration 6275: 0.4304656915172023\n",
      "Theta: [-1.69548871  1.05776735  0.05724236]\n",
      "Loss in iteration 6276: 0.43046157417039793\n",
      "Theta: [-1.69560096  1.0578443   0.0572396 ]\n",
      "Loss in iteration 6277: 0.430457458306811\n",
      "Theta: [-1.69571319  1.05792124  0.05723683]\n",
      "Loss in iteration 6278: 0.43045334392578477\n",
      "Theta: [-1.6958254   1.05799817  0.05723407]\n",
      "Loss in iteration 6279: 0.43044923102666244\n",
      "Theta: [-1.69593759  1.05807509  0.0572313 ]\n",
      "Loss in iteration 6280: 0.43044511960878795\n",
      "Theta: [-1.69604975  1.05815199  0.05722854]\n",
      "Loss in iteration 6281: 0.43044100967150534\n",
      "Theta: [-1.6961619   1.05822888  0.05722577]\n",
      "Loss in iteration 6282: 0.4304369012141591\n",
      "Theta: [-1.69627402  1.05830575  0.05722301]\n",
      "Loss in iteration 6283: 0.43043279423609415\n",
      "Theta: [-1.69638613  1.05838262  0.05722024]\n",
      "Loss in iteration 6284: 0.43042868873665524\n",
      "Theta: [-1.69649821  1.05845947  0.05721748]\n",
      "Loss in iteration 6285: 0.43042458471518846\n",
      "Theta: [-1.69661028  1.0585363   0.05721471]\n",
      "Loss in iteration 6286: 0.43042048217103923\n",
      "Theta: [-1.69672232  1.05861313  0.05721195]\n",
      "Loss in iteration 6287: 0.4304163811035543\n",
      "Theta: [-1.69683434  1.05868994  0.05720919]\n",
      "Loss in iteration 6288: 0.4304122815120797\n",
      "Theta: [-1.69694634  1.05876674  0.05720643]\n",
      "Loss in iteration 6289: 0.43040818339596276\n",
      "Theta: [-1.69705832  1.05884352  0.05720366]\n",
      "Loss in iteration 6290: 0.4304040867545508\n",
      "Theta: [-1.69717028  1.0589203   0.0572009 ]\n",
      "Loss in iteration 6291: 0.4303999915871912\n",
      "Theta: [-1.69728222  1.05899706  0.05719814]\n",
      "Loss in iteration 6292: 0.4303958978932322\n",
      "Theta: [-1.69739413  1.05907381  0.05719538]\n",
      "Loss in iteration 6293: 0.43039180567202195\n",
      "Theta: [-1.69750603  1.05915054  0.05719262]\n",
      "Loss in iteration 6294: 0.43038771492290956\n",
      "Theta: [-1.69761791  1.05922726  0.05718985]\n",
      "Loss in iteration 6295: 0.43038362564524363\n",
      "Theta: [-1.69772976  1.05930397  0.05718709]\n",
      "Loss in iteration 6296: 0.4303795378383738\n",
      "Theta: [-1.69784159  1.05938067  0.05718433]\n",
      "Loss in iteration 6297: 0.43037545150165\n",
      "Theta: [-1.69795341  1.05945735  0.05718157]\n",
      "Loss in iteration 6298: 0.4303713666344222\n",
      "Theta: [-1.6980652   1.05953402  0.05717881]\n",
      "Loss in iteration 6299: 0.4303672832360408\n",
      "Theta: [-1.69817697  1.05961068  0.05717605]\n",
      "Loss in iteration 6300: 0.4303632013058568\n",
      "Theta: [-1.69828872  1.05968733  0.05717329]\n",
      "Loss in iteration 6301: 0.43035912084322125\n",
      "Theta: [-1.69840045  1.05976396  0.05717053]\n",
      "Loss in iteration 6302: 0.43035504184748574\n",
      "Theta: [-1.69851216  1.05984058  0.05716778]\n",
      "Loss in iteration 6303: 0.4303509643180021\n",
      "Theta: [-1.69862385  1.05991719  0.05716502]\n",
      "Loss in iteration 6304: 0.43034688825412276\n",
      "Theta: [-1.69873552  1.05999378  0.05716226]\n",
      "Loss in iteration 6305: 0.43034281365520016\n",
      "Theta: [-1.69884716  1.06007036  0.0571595 ]\n",
      "Loss in iteration 6306: 0.43033874052058707\n",
      "Theta: [-1.69895879  1.06014693  0.05715674]\n",
      "Loss in iteration 6307: 0.430334668849637\n",
      "Theta: [-1.69907039  1.06022349  0.05715399]\n",
      "Loss in iteration 6308: 0.43033059864170364\n",
      "Theta: [-1.69918198  1.06030003  0.05715123]\n",
      "Loss in iteration 6309: 0.4303265298961408\n",
      "Theta: [-1.69929354  1.06037656  0.05714847]\n",
      "Loss in iteration 6310: 0.430322462612303\n",
      "Theta: [-1.69940508  1.06045308  0.05714572]\n",
      "Loss in iteration 6311: 0.43031839678954464\n",
      "Theta: [-1.69951661  1.06052959  0.05714296]\n",
      "Loss in iteration 6312: 0.4303143324272211\n",
      "Theta: [-1.69962811  1.06060608  0.0571402 ]\n",
      "Loss in iteration 6313: 0.4303102695246875\n",
      "Theta: [-1.69973959  1.06068256  0.05713745]\n",
      "Loss in iteration 6314: 0.43030620808129966\n",
      "Theta: [-1.69985105  1.06075903  0.05713469]\n",
      "Loss in iteration 6315: 0.43030214809641365\n",
      "Theta: [-1.69996249  1.06083548  0.05713194]\n",
      "Loss in iteration 6316: 0.43029808956938587\n",
      "Theta: [-1.70007391  1.06091192  0.05712918]\n",
      "Loss in iteration 6317: 0.43029403249957326\n",
      "Theta: [-1.70018531  1.06098835  0.05712643]\n",
      "Loss in iteration 6318: 0.4302899768863329\n",
      "Theta: [-1.70029668  1.06106477  0.05712367]\n",
      "Loss in iteration 6319: 0.43028592272902194\n",
      "Theta: [-1.70040804  1.06114117  0.05712092]\n",
      "Loss in iteration 6320: 0.4302818700269985\n",
      "Theta: [-1.70051938  1.06121756  0.05711817]\n",
      "Loss in iteration 6321: 0.43027781877962085\n",
      "Theta: [-1.70063069  1.06129394  0.05711541]\n",
      "Loss in iteration 6322: 0.43027376898624725\n",
      "Theta: [-1.70074198  1.0613703   0.05711266]\n",
      "Loss in iteration 6323: 0.4302697206462365\n",
      "Theta: [-1.70085326  1.06144666  0.05710991]\n",
      "Loss in iteration 6324: 0.4302656737589481\n",
      "Theta: [-1.70096451  1.061523    0.05710715]\n",
      "Loss in iteration 6325: 0.4302616283237415\n",
      "Theta: [-1.70107574  1.06159932  0.0571044 ]\n",
      "Loss in iteration 6326: 0.4302575843399765\n",
      "Theta: [-1.70118696  1.06167564  0.05710165]\n",
      "Loss in iteration 6327: 0.43025354180701325\n",
      "Theta: [-1.70129815  1.06175194  0.0570989 ]\n",
      "Loss in iteration 6328: 0.4302495007242125\n",
      "Theta: [-1.70140932  1.06182823  0.05709615]\n",
      "Loss in iteration 6329: 0.4302454610909352\n",
      "Theta: [-1.70152047  1.0619045   0.05709339]\n",
      "Loss in iteration 6330: 0.4302414229065426\n",
      "Theta: [-1.7016316   1.06198077  0.05709064]\n",
      "Loss in iteration 6331: 0.4302373861703963\n",
      "Theta: [-1.70174271  1.06205702  0.05708789]\n",
      "Loss in iteration 6332: 0.4302333508818583\n",
      "Theta: [-1.70185379  1.06213326  0.05708514]\n",
      "Loss in iteration 6333: 0.43022931704029077\n",
      "Theta: [-1.70196486  1.06220948  0.05708239]\n",
      "Loss in iteration 6334: 0.4302252846450566\n",
      "Theta: [-1.70207591  1.0622857   0.05707964]\n",
      "Loss in iteration 6335: 0.43022125369551856\n",
      "Theta: [-1.70218694  1.0623619   0.05707689]\n",
      "Loss in iteration 6336: 0.43021722419104025\n",
      "Theta: [-1.70229794  1.06243808  0.05707414]\n",
      "Loss in iteration 6337: 0.43021319613098497\n",
      "Theta: [-1.70240893  1.06251426  0.0570714 ]\n",
      "Loss in iteration 6338: 0.43020916951471727\n",
      "Theta: [-1.70251989  1.06259042  0.05706865]\n",
      "Loss in iteration 6339: 0.43020514434160106\n",
      "Theta: [-1.70263084  1.06266657  0.0570659 ]\n",
      "Loss in iteration 6340: 0.43020112061100124\n",
      "Theta: [-1.70274176  1.06274271  0.05706315]\n",
      "Loss in iteration 6341: 0.4301970983222828\n",
      "Theta: [-1.70285266  1.06281883  0.0570604 ]\n",
      "Loss in iteration 6342: 0.4301930774748113\n",
      "Theta: [-1.70296354  1.06289494  0.05705766]\n",
      "Loss in iteration 6343: 0.4301890580679523\n",
      "Theta: [-1.70307441  1.06297104  0.05705491]\n",
      "Loss in iteration 6344: 0.43018504010107195\n",
      "Theta: [-1.70318525  1.06304713  0.05705216]\n",
      "Loss in iteration 6345: 0.4301810235735366\n",
      "Theta: [-1.70329607  1.0631232   0.05704941]\n",
      "Loss in iteration 6346: 0.4301770084847132\n",
      "Theta: [-1.70340687  1.06319926  0.05704667]\n",
      "Loss in iteration 6347: 0.4301729948339688\n",
      "Theta: [-1.70351765  1.06327531  0.05704392]\n",
      "Loss in iteration 6348: 0.4301689826206708\n",
      "Theta: [-1.70362841  1.06335135  0.05704118]\n",
      "Loss in iteration 6349: 0.43016497184418684\n",
      "Theta: [-1.70373915  1.06342737  0.05703843]\n",
      "Loss in iteration 6350: 0.4301609625038854\n",
      "Theta: [-1.70384986  1.06350338  0.05703569]\n",
      "Loss in iteration 6351: 0.4301569545991346\n",
      "Theta: [-1.70396056  1.06357938  0.05703294]\n",
      "Loss in iteration 6352: 0.4301529481293034\n",
      "Theta: [-1.70407124  1.06365536  0.0570302 ]\n",
      "Loss in iteration 6353: 0.43014894309376084\n",
      "Theta: [-1.7041819   1.06373134  0.05702745]\n",
      "Loss in iteration 6354: 0.43014493949187665\n",
      "Theta: [-1.70429253  1.0638073   0.05702471]\n",
      "Loss in iteration 6355: 0.4301409373230205\n",
      "Theta: [-1.70440315  1.06388325  0.05702196]\n",
      "Loss in iteration 6356: 0.43013693658656266\n",
      "Theta: [-1.70451374  1.06395918  0.05701922]\n",
      "Loss in iteration 6357: 0.4301329372818734\n",
      "Theta: [-1.70462432  1.0640351   0.05701648]\n",
      "Loss in iteration 6358: 0.43012893940832386\n",
      "Theta: [-1.70473487  1.06411101  0.05701373]\n",
      "Loss in iteration 6359: 0.4301249429652851\n",
      "Theta: [-1.7048454   1.06418691  0.05701099]\n",
      "Loss in iteration 6360: 0.4301209479521285\n",
      "Theta: [-1.70495592  1.06426279  0.05700825]\n",
      "Loss in iteration 6361: 0.43011695436822595\n",
      "Theta: [-1.70506641  1.06433867  0.05700551]\n",
      "Loss in iteration 6362: 0.4301129622129499\n",
      "Theta: [-1.70517688  1.06441452  0.05700277]\n",
      "Loss in iteration 6363: 0.4301089714856727\n",
      "Theta: [-1.70528734  1.06449037  0.05700002]\n",
      "Loss in iteration 6364: 0.4301049821857672\n",
      "Theta: [-1.70539777  1.06456621  0.05699728]\n",
      "Loss in iteration 6365: 0.4301009943126068\n",
      "Theta: [-1.70550818  1.06464203  0.05699454]\n",
      "Loss in iteration 6366: 0.43009700786556465\n",
      "Theta: [-1.70561857  1.06471784  0.0569918 ]\n",
      "Loss in iteration 6367: 0.4300930228440152\n",
      "Theta: [-1.70572894  1.06479363  0.05698906]\n",
      "Loss in iteration 6368: 0.43008903924733216\n",
      "Theta: [-1.70583929  1.06486942  0.05698632]\n",
      "Loss in iteration 6369: 0.4300850570748903\n",
      "Theta: [-1.70594962  1.06494519  0.05698358]\n",
      "Loss in iteration 6370: 0.43008107632606446\n",
      "Theta: [-1.70605993  1.06502095  0.05698084]\n",
      "Loss in iteration 6371: 0.43007709700023\n",
      "Theta: [-1.70617022  1.06509669  0.0569781 ]\n",
      "Loss in iteration 6372: 0.4300731190967625\n",
      "Theta: [-1.70628048  1.06517243  0.05697536]\n",
      "Loss in iteration 6373: 0.43006914261503754\n",
      "Theta: [-1.70639073  1.06524815  0.05697262]\n",
      "Loss in iteration 6374: 0.4300651675544316\n",
      "Theta: [-1.70650096  1.06532386  0.05696989]\n",
      "Loss in iteration 6375: 0.43006119391432124\n",
      "Theta: [-1.70661117  1.06539955  0.05696715]\n",
      "Loss in iteration 6376: 0.4300572216940833\n",
      "Theta: [-1.70672135  1.06547523  0.05696441]\n",
      "Loss in iteration 6377: 0.4300532508930952\n",
      "Theta: [-1.70683152  1.06555091  0.05696167]\n",
      "Loss in iteration 6378: 0.43004928151073424\n",
      "Theta: [-1.70694167  1.06562656  0.05695893]\n",
      "Loss in iteration 6379: 0.43004531354637854\n",
      "Theta: [-1.70705179  1.06570221  0.0569562 ]\n",
      "Loss in iteration 6380: 0.4300413469994062\n",
      "Theta: [-1.7071619   1.06577784  0.05695346]\n",
      "Loss in iteration 6381: 0.43003738186919593\n",
      "Theta: [-1.70727198  1.06585346  0.05695072]\n",
      "Loss in iteration 6382: 0.43003341815512647\n",
      "Theta: [-1.70738205  1.06592907  0.05694799]\n",
      "Loss in iteration 6383: 0.43002945585657726\n",
      "Theta: [-1.70749209  1.06600467  0.05694525]\n",
      "Loss in iteration 6384: 0.43002549497292775\n",
      "Theta: [-1.70760212  1.06608025  0.05694252]\n",
      "Loss in iteration 6385: 0.43002153550355776\n",
      "Theta: [-1.70771212  1.06615582  0.05693978]\n",
      "Loss in iteration 6386: 0.4300175774478479\n",
      "Theta: [-1.7078221   1.06623138  0.05693705]\n",
      "Loss in iteration 6387: 0.4300136208051783\n",
      "Theta: [-1.70793207  1.06630692  0.05693431]\n",
      "Loss in iteration 6388: 0.4300096655749301\n",
      "Theta: [-1.70804201  1.06638246  0.05693158]\n",
      "Loss in iteration 6389: 0.43000571175648455\n",
      "Theta: [-1.70815193  1.06645798  0.05692884]\n",
      "Loss in iteration 6390: 0.43000175934922297\n",
      "Theta: [-1.70826183  1.06653348  0.05692611]\n",
      "Loss in iteration 6391: 0.4299978083525277\n",
      "Theta: [-1.70837172  1.06660898  0.05692338]\n",
      "Loss in iteration 6392: 0.4299938587657806\n",
      "Theta: [-1.70848158  1.06668446  0.05692064]\n",
      "Loss in iteration 6393: 0.42998991058836433\n",
      "Theta: [-1.70859142  1.06675993  0.05691791]\n",
      "Loss in iteration 6394: 0.4299859638196619\n",
      "Theta: [-1.70870124  1.06683539  0.05691518]\n",
      "Loss in iteration 6395: 0.42998201845905654\n",
      "Theta: [-1.70881104  1.06691084  0.05691244]\n",
      "Loss in iteration 6396: 0.4299780745059316\n",
      "Theta: [-1.70892082  1.06698627  0.05690971]\n",
      "Loss in iteration 6397: 0.42997413195967105\n",
      "Theta: [-1.70903058  1.06706169  0.05690698]\n",
      "Loss in iteration 6398: 0.4299701908196593\n",
      "Theta: [-1.70914032  1.0671371   0.05690425]\n",
      "Loss in iteration 6399: 0.4299662510852806\n",
      "Theta: [-1.70925004  1.06721249  0.05690152]\n",
      "Loss in iteration 6400: 0.42996231275592\n",
      "Theta: [-1.70935974  1.06728788  0.05689879]\n",
      "Loss in iteration 6401: 0.4299583758309627\n",
      "Theta: [-1.70946942  1.06736325  0.05689606]\n",
      "Loss in iteration 6402: 0.42995444030979413\n",
      "Theta: [-1.70957908  1.06743861  0.05689333]\n",
      "Loss in iteration 6403: 0.42995050619180036\n",
      "Theta: [-1.70968872  1.06751395  0.05689059]\n",
      "Loss in iteration 6404: 0.42994657347636733\n",
      "Theta: [-1.70979834  1.06758928  0.05688787]\n",
      "Loss in iteration 6405: 0.42994264216288175\n",
      "Theta: [-1.70990794  1.0676646   0.05688514]\n",
      "Loss in iteration 6406: 0.4299387122507304\n",
      "Theta: [-1.71001751  1.06773991  0.05688241]\n",
      "Loss in iteration 6407: 0.4299347837393004\n",
      "Theta: [-1.71012707  1.06781521  0.05687968]\n",
      "Loss in iteration 6408: 0.42993085662797936\n",
      "Theta: [-1.71023661  1.06789049  0.05687695]\n",
      "Loss in iteration 6409: 0.4299269309161552\n",
      "Theta: [-1.71034613  1.06796576  0.05687422]\n",
      "Loss in iteration 6410: 0.42992300660321575\n",
      "Theta: [-1.71045563  1.06804102  0.05687149]\n",
      "Loss in iteration 6411: 0.42991908368854986\n",
      "Theta: [-1.7105651   1.06811627  0.05686876]\n",
      "Loss in iteration 6412: 0.4299151621715462\n",
      "Theta: [-1.71067456  1.0681915   0.05686604]\n",
      "Loss in iteration 6413: 0.42991124205159376\n",
      "Theta: [-1.710784    1.06826672  0.05686331]\n",
      "Loss in iteration 6414: 0.4299073233280823\n",
      "Theta: [-1.71089341  1.06834193  0.05686058]\n",
      "Loss in iteration 6415: 0.42990340600040133\n",
      "Theta: [-1.71100281  1.06841713  0.05685785]\n",
      "Loss in iteration 6416: 0.42989949006794126\n",
      "Theta: [-1.71111219  1.06849231  0.05685513]\n",
      "Loss in iteration 6417: 0.42989557553009233\n",
      "Theta: [-1.71122154  1.06856748  0.0568524 ]\n",
      "Loss in iteration 6418: 0.42989166238624543\n",
      "Theta: [-1.71133088  1.06864264  0.05684968]\n",
      "Loss in iteration 6419: 0.4298877506357915\n",
      "Theta: [-1.7114402   1.06871779  0.05684695]\n",
      "Loss in iteration 6420: 0.42988384027812215\n",
      "Theta: [-1.71154949  1.06879292  0.05684423]\n",
      "Loss in iteration 6421: 0.42987993131262914\n",
      "Theta: [-1.71165877  1.06886804  0.0568415 ]\n",
      "Loss in iteration 6422: 0.42987602373870426\n",
      "Theta: [-1.71176802  1.06894315  0.05683878]\n",
      "Loss in iteration 6423: 0.42987211755574023\n",
      "Theta: [-1.71187726  1.06901825  0.05683605]\n",
      "Loss in iteration 6424: 0.42986821276312964\n",
      "Theta: [-1.71198648  1.06909333  0.05683333]\n",
      "Loss in iteration 6425: 0.4298643093602656\n",
      "Theta: [-1.71209567  1.0691684   0.0568306 ]\n",
      "Loss in iteration 6426: 0.4298604073465414\n",
      "Theta: [-1.71220485  1.06924346  0.05682788]\n",
      "Loss in iteration 6427: 0.42985650672135073\n",
      "Theta: [-1.712314    1.06931851  0.05682516]\n",
      "Loss in iteration 6428: 0.42985260748408777\n",
      "Theta: [-1.71242314  1.06939355  0.05682243]\n",
      "Loss in iteration 6429: 0.42984870963414673\n",
      "Theta: [-1.71253225  1.06946857  0.05681971]\n",
      "Loss in iteration 6430: 0.42984481317092227\n",
      "Theta: [-1.71264135  1.06954358  0.05681699]\n",
      "Loss in iteration 6431: 0.4298409180938095\n",
      "Theta: [-1.71275042  1.06961857  0.05681426]\n",
      "Loss in iteration 6432: 0.42983702440220356\n",
      "Theta: [-1.71285948  1.06969356  0.05681154]\n",
      "Loss in iteration 6433: 0.42983313209550017\n",
      "Theta: [-1.71296851  1.06976853  0.05680882]\n",
      "Loss in iteration 6434: 0.42982924117309546\n",
      "Theta: [-1.71307753  1.06984349  0.0568061 ]\n",
      "Loss in iteration 6435: 0.4298253516343855\n",
      "Theta: [-1.71318652  1.06991844  0.05680338]\n",
      "Loss in iteration 6436: 0.42982146347876693\n",
      "Theta: [-1.7132955   1.06999338  0.05680066]\n",
      "Loss in iteration 6437: 0.4298175767056366\n",
      "Theta: [-1.71340445  1.0700683   0.05679794]\n",
      "Loss in iteration 6438: 0.42981369131439195\n",
      "Theta: [-1.71351339  1.07014321  0.05679522]\n",
      "Loss in iteration 6439: 0.42980980730443064\n",
      "Theta: [-1.7136223   1.07021811  0.0567925 ]\n",
      "Loss in iteration 6440: 0.4298059246751501\n",
      "Theta: [-1.7137312   1.070293    0.05678978]\n",
      "Loss in iteration 6441: 0.429802043425949\n",
      "Theta: [-1.71384007  1.07036787  0.05678706]\n",
      "Loss in iteration 6442: 0.4297981635562257\n",
      "Theta: [-1.71394893  1.07044273  0.05678434]\n",
      "Loss in iteration 6443: 0.42979428506537887\n",
      "Theta: [-1.71405776  1.07051758  0.05678162]\n",
      "Loss in iteration 6444: 0.42979040795280826\n",
      "Theta: [-1.71416657  1.07059242  0.0567789 ]\n",
      "Loss in iteration 6445: 0.4297865322179127\n",
      "Theta: [-1.71427537  1.07066724  0.05677618]\n",
      "Loss in iteration 6446: 0.4297826578600921\n",
      "Theta: [-1.71438414  1.07074205  0.05677346]\n",
      "Loss in iteration 6447: 0.4297787848787472\n",
      "Theta: [-1.7144929   1.07081685  0.05677075]\n",
      "Loss in iteration 6448: 0.4297749132732778\n",
      "Theta: [-1.71460163  1.07089164  0.05676803]\n",
      "Loss in iteration 6449: 0.429771043043085\n",
      "Theta: [-1.71471035  1.07096641  0.05676531]\n",
      "Loss in iteration 6450: 0.4297671741875698\n",
      "Theta: [-1.71481904  1.07104118  0.0567626 ]\n",
      "Loss in iteration 6451: 0.4297633067061335\n",
      "Theta: [-1.71492772  1.07111593  0.05675988]\n",
      "Loss in iteration 6452: 0.429759440598178\n",
      "Theta: [-1.71503637  1.07119067  0.05675716]\n",
      "Loss in iteration 6453: 0.42975557586310537\n",
      "Theta: [-1.71514501  1.07126539  0.05675445]\n",
      "Loss in iteration 6454: 0.4297517125003179\n",
      "Theta: [-1.71525362  1.0713401   0.05675173]\n",
      "Loss in iteration 6455: 0.4297478505092183\n",
      "Theta: [-1.71536222  1.07141481  0.05674902]\n",
      "Loss in iteration 6456: 0.42974398988920953\n",
      "Theta: [-1.71547079  1.07148949  0.0567463 ]\n",
      "Loss in iteration 6457: 0.429740130639695\n",
      "Theta: [-1.71557935  1.07156417  0.05674359]\n",
      "Loss in iteration 6458: 0.4297362727600783\n",
      "Theta: [-1.71568788  1.07163883  0.05674087]\n",
      "Loss in iteration 6459: 0.42973241624976327\n",
      "Theta: [-1.7157964   1.07171349  0.05673816]\n",
      "Loss in iteration 6460: 0.42972856110815444\n",
      "Theta: [-1.71590489  1.07178813  0.05673544]\n",
      "Loss in iteration 6461: 0.4297247073346563\n",
      "Theta: [-1.71601337  1.07186275  0.05673273]\n",
      "Loss in iteration 6462: 0.42972085492867357\n",
      "Theta: [-1.71612183  1.07193737  0.05673002]\n",
      "Loss in iteration 6463: 0.42971700388961165\n",
      "Theta: [-1.71623026  1.07201197  0.0567273 ]\n",
      "Loss in iteration 6464: 0.4297131542168761\n",
      "Theta: [-1.71633868  1.07208656  0.05672459]\n",
      "Loss in iteration 6465: 0.4297093059098729\n",
      "Theta: [-1.71644707  1.07216114  0.05672188]\n",
      "Loss in iteration 6466: 0.4297054589680079\n",
      "Theta: [-1.71655545  1.0722357   0.05671916]\n",
      "Loss in iteration 6467: 0.42970161339068796\n",
      "Theta: [-1.71666381  1.07231026  0.05671645]\n",
      "Loss in iteration 6468: 0.42969776917731933\n",
      "Theta: [-1.71677214  1.0723848   0.05671374]\n",
      "Loss in iteration 6469: 0.4296939263273098\n",
      "Theta: [-1.71688046  1.07245933  0.05671103]\n",
      "Loss in iteration 6470: 0.4296900848400665\n",
      "Theta: [-1.71698876  1.07253384  0.05670832]\n",
      "Loss in iteration 6471: 0.429686244714997\n",
      "Theta: [-1.71709703  1.07260835  0.05670561]\n",
      "Loss in iteration 6472: 0.42968240595150964\n",
      "Theta: [-1.71720529  1.07268284  0.0567029 ]\n",
      "Loss in iteration 6473: 0.4296785685490129\n",
      "Theta: [-1.71731353  1.07275732  0.05670019]\n",
      "Loss in iteration 6474: 0.42967473250691496\n",
      "Theta: [-1.71742174  1.07283179  0.05669748]\n",
      "Loss in iteration 6475: 0.4296708978246254\n",
      "Theta: [-1.71752994  1.07290624  0.05669477]\n",
      "Loss in iteration 6476: 0.42966706450155323\n",
      "Theta: [-1.71763812  1.07298068  0.05669206]\n",
      "Loss in iteration 6477: 0.42966323253710814\n",
      "Theta: [-1.71774628  1.07305511  0.05668935]\n",
      "Loss in iteration 6478: 0.4296594019307001\n",
      "Theta: [-1.71785442  1.07312953  0.05668664]\n",
      "Loss in iteration 6479: 0.4296555726817394\n",
      "Theta: [-1.71796253  1.07320394  0.05668393]\n",
      "Loss in iteration 6480: 0.42965174478963675\n",
      "Theta: [-1.71807063  1.07327833  0.05668122]\n",
      "Loss in iteration 6481: 0.42964791825380266\n",
      "Theta: [-1.71817871  1.07335271  0.05667851]\n",
      "Loss in iteration 6482: 0.4296440930736486\n",
      "Theta: [-1.71828677  1.07342708  0.05667581]\n",
      "Loss in iteration 6483: 0.4296402692485862\n",
      "Theta: [-1.71839481  1.07350144  0.0566731 ]\n",
      "Loss in iteration 6484: 0.42963644677802715\n",
      "Theta: [-1.71850283  1.07357579  0.05667039]\n",
      "Loss in iteration 6485: 0.42963262566138355\n",
      "Theta: [-1.71861083  1.07365012  0.05666768]\n",
      "Loss in iteration 6486: 0.4296288058980678\n",
      "Theta: [-1.71871881  1.07372444  0.05666498]\n",
      "Loss in iteration 6487: 0.4296249874874929\n",
      "Theta: [-1.71882677  1.07379875  0.05666227]\n",
      "Loss in iteration 6488: 0.42962117042907166\n",
      "Theta: [-1.71893471  1.07387304  0.05665956]\n",
      "Loss in iteration 6489: 0.4296173547222176\n",
      "Theta: [-1.71904263  1.07394733  0.05665686]\n",
      "Loss in iteration 6490: 0.42961354036634447\n",
      "Theta: [-1.71915053  1.0740216   0.05665415]\n",
      "Loss in iteration 6491: 0.42960972736086633\n",
      "Theta: [-1.71925841  1.07409586  0.05665145]\n",
      "Loss in iteration 6492: 0.4296059157051972\n",
      "Theta: [-1.71936627  1.0741701   0.05664874]\n",
      "Loss in iteration 6493: 0.42960210539875204\n",
      "Theta: [-1.71947411  1.07424434  0.05664604]\n",
      "Loss in iteration 6494: 0.4295982964409456\n",
      "Theta: [-1.71958193  1.07431856  0.05664333]\n",
      "Loss in iteration 6495: 0.4295944888311933\n",
      "Theta: [-1.71968974  1.07439277  0.05664063]\n",
      "Loss in iteration 6496: 0.42959068256891053\n",
      "Theta: [-1.71979752  1.07446697  0.05663793]\n",
      "Loss in iteration 6497: 0.4295868776535132\n",
      "Theta: [-1.71990528  1.07454116  0.05663522]\n",
      "Loss in iteration 6498: 0.4295830740844176\n",
      "Theta: [-1.72001302  1.07461533  0.05663252]\n",
      "Loss in iteration 6499: 0.42957927186104017\n",
      "Theta: [-1.72012075  1.07468949  0.05662982]\n",
      "Loss in iteration 6500: 0.4295754709827977\n",
      "Theta: [-1.72022845  1.07476364  0.05662711]\n",
      "Loss in iteration 6501: 0.4295716714491072\n",
      "Theta: [-1.72033613  1.07483778  0.05662441]\n",
      "Loss in iteration 6502: 0.42956787325938633\n",
      "Theta: [-1.7204438   1.0749119   0.05662171]\n",
      "Loss in iteration 6503: 0.42956407641305266\n",
      "Theta: [-1.72055144  1.07498601  0.05661901]\n",
      "Loss in iteration 6504: 0.4295602809095243\n",
      "Theta: [-1.72065907  1.07506012  0.05661631]\n",
      "Loss in iteration 6505: 0.4295564867482194\n",
      "Theta: [-1.72076667  1.0751342   0.0566136 ]\n",
      "Loss in iteration 6506: 0.4295526939285568\n",
      "Theta: [-1.72087426  1.07520828  0.0566109 ]\n",
      "Loss in iteration 6507: 0.4295489024499553\n",
      "Theta: [-1.72098182  1.07528234  0.0566082 ]\n",
      "Loss in iteration 6508: 0.42954511231183445\n",
      "Theta: [-1.72108937  1.0753564   0.0566055 ]\n",
      "Loss in iteration 6509: 0.4295413235136137\n",
      "Theta: [-1.7211969   1.07543044  0.0566028 ]\n",
      "Loss in iteration 6510: 0.4295375360547129\n",
      "Theta: [-1.7213044   1.07550446  0.0566001 ]\n",
      "Loss in iteration 6511: 0.4295337499345521\n",
      "Theta: [-1.72141189  1.07557848  0.0565974 ]\n",
      "Loss in iteration 6512: 0.42952996515255193\n",
      "Theta: [-1.72151936  1.07565248  0.0565947 ]\n",
      "Loss in iteration 6513: 0.4295261817081332\n",
      "Theta: [-1.7216268   1.07572647  0.056592  ]\n",
      "Loss in iteration 6514: 0.4295223996007172\n",
      "Theta: [-1.72173423  1.07580045  0.05658931]\n",
      "Loss in iteration 6515: 0.4295186188297251\n",
      "Theta: [-1.72184164  1.07587442  0.05658661]\n",
      "Loss in iteration 6516: 0.42951483939457874\n",
      "Theta: [-1.72194903  1.07594837  0.05658391]\n",
      "Loss in iteration 6517: 0.4295110612946999\n",
      "Theta: [-1.7220564   1.07602231  0.05658121]\n",
      "Loss in iteration 6518: 0.42950728452951137\n",
      "Theta: [-1.72216375  1.07609625  0.05657851]\n",
      "Loss in iteration 6519: 0.42950350909843543\n",
      "Theta: [-1.72227108  1.07617016  0.05657582]\n",
      "Loss in iteration 6520: 0.42949973500089506\n",
      "Theta: [-1.72237839  1.07624407  0.05657312]\n",
      "Loss in iteration 6521: 0.4294959622363137\n",
      "Theta: [-1.72248568  1.07631796  0.05657042]\n",
      "Loss in iteration 6522: 0.4294921908041148\n",
      "Theta: [-1.72259295  1.07639184  0.05656773]\n",
      "Loss in iteration 6523: 0.42948842070372223\n",
      "Theta: [-1.7227002   1.07646571  0.05656503]\n",
      "Loss in iteration 6524: 0.42948465193456015\n",
      "Theta: [-1.72280744  1.07653957  0.05656233]\n",
      "Loss in iteration 6525: 0.42948088449605293\n",
      "Theta: [-1.72291465  1.07661342  0.05655964]\n",
      "Loss in iteration 6526: 0.42947711838762553\n",
      "Theta: [-1.72302184  1.07668725  0.05655694]\n",
      "Loss in iteration 6527: 0.4294733536087029\n",
      "Theta: [-1.72312902  1.07676107  0.05655425]\n",
      "Loss in iteration 6528: 0.4294695901587106\n",
      "Theta: [-1.72323617  1.07683488  0.05655155]\n",
      "Loss in iteration 6529: 0.429465828037074\n",
      "Theta: [-1.72334331  1.07690868  0.05654886]\n",
      "Loss in iteration 6530: 0.4294620672432194\n",
      "Theta: [-1.72345042  1.07698246  0.05654616]\n",
      "Loss in iteration 6531: 0.4294583077765729\n",
      "Theta: [-1.72355752  1.07705623  0.05654347]\n",
      "Loss in iteration 6532: 0.42945454963656116\n",
      "Theta: [-1.72366459  1.07713     0.05654078]\n",
      "Loss in iteration 6533: 0.4294507928226111\n",
      "Theta: [-1.72377165  1.07720374  0.05653808]\n",
      "Loss in iteration 6534: 0.4294470373341499\n",
      "Theta: [-1.72387869  1.07727748  0.05653539]\n",
      "Loss in iteration 6535: 0.42944328317060504\n",
      "Theta: [-1.7239857  1.0773512  0.0565327]\n",
      "Loss in iteration 6536: 0.42943953033140436\n",
      "Theta: [-1.7240927   1.07742492  0.05653   ]\n",
      "Loss in iteration 6537: 0.4294357788159761\n",
      "Theta: [-1.72419968  1.07749862  0.05652731]\n",
      "Loss in iteration 6538: 0.4294320286237484\n",
      "Theta: [-1.72430664  1.0775723   0.05652462]\n",
      "Loss in iteration 6539: 0.42942827975415016\n",
      "Theta: [-1.72441358  1.07764598  0.05652193]\n",
      "Loss in iteration 6540: 0.4294245322066102\n",
      "Theta: [-1.7245205   1.07771964  0.05651924]\n",
      "Loss in iteration 6541: 0.4294207859805581\n",
      "Theta: [-1.7246274   1.0777933   0.05651655]\n",
      "Loss in iteration 6542: 0.42941704107542333\n",
      "Theta: [-1.72473428  1.07786693  0.05651386]\n",
      "Loss in iteration 6543: 0.42941329749063584\n",
      "Theta: [-1.72484114  1.07794056  0.05651116]\n",
      "Loss in iteration 6544: 0.4294095552256259\n",
      "Theta: [-1.72494798  1.07801418  0.05650847]\n",
      "Loss in iteration 6545: 0.4294058142798237\n",
      "Theta: [-1.7250548   1.07808778  0.05650578]\n",
      "Loss in iteration 6546: 0.42940207465266056\n",
      "Theta: [-1.72516161  1.07816137  0.05650309]\n",
      "Loss in iteration 6547: 0.4293983363435674\n",
      "Theta: [-1.72526839  1.07823495  0.05650041]\n",
      "Loss in iteration 6548: 0.4293945993519755\n",
      "Theta: [-1.72537516  1.07830852  0.05649772]\n",
      "Loss in iteration 6549: 0.4293908636773167\n",
      "Theta: [-1.7254819   1.07838207  0.05649503]\n",
      "Loss in iteration 6550: 0.42938712931902295\n",
      "Theta: [-1.72558863  1.07845562  0.05649234]\n",
      "Loss in iteration 6551: 0.4293833962765267\n",
      "Theta: [-1.72569533  1.07852915  0.05648965]\n",
      "Loss in iteration 6552: 0.4293796645492604\n",
      "Theta: [-1.72580202  1.07860267  0.05648696]\n",
      "Loss in iteration 6553: 0.42937593413665714\n",
      "Theta: [-1.72590868  1.07867617  0.05648427]\n",
      "Loss in iteration 6554: 0.42937220503815\n",
      "Theta: [-1.72601533  1.07874967  0.05648159]\n",
      "Loss in iteration 6555: 0.4293684772531726\n",
      "Theta: [-1.72612196  1.07882315  0.0564789 ]\n",
      "Loss in iteration 6556: 0.4293647507811586\n",
      "Theta: [-1.72622857  1.07889662  0.05647621]\n",
      "Loss in iteration 6557: 0.42936102562154227\n",
      "Theta: [-1.72633516  1.07897008  0.05647353]\n",
      "Loss in iteration 6558: 0.4293573017737581\n",
      "Theta: [-1.72644173  1.07904353  0.05647084]\n",
      "Loss in iteration 6559: 0.42935357923724043\n",
      "Theta: [-1.72654828  1.07911696  0.05646815]\n",
      "Loss in iteration 6560: 0.42934985801142445\n",
      "Theta: [-1.72665481  1.07919038  0.05646547]\n",
      "Loss in iteration 6561: 0.42934613809574573\n",
      "Theta: [-1.72676132  1.0792638   0.05646278]\n",
      "Loss in iteration 6562: 0.42934241948963936\n",
      "Theta: [-1.72686781  1.07933719  0.0564601 ]\n",
      "Loss in iteration 6563: 0.42933870219254167\n",
      "Theta: [-1.72697429  1.07941058  0.05645741]\n",
      "Loss in iteration 6564: 0.42933498620388877\n",
      "Theta: [-1.72708074  1.07948395  0.05645473]\n",
      "Loss in iteration 6565: 0.4293312715231169\n",
      "Theta: [-1.72718718  1.07955732  0.05645204]\n",
      "Loss in iteration 6566: 0.4293275581496632\n",
      "Theta: [-1.72729359  1.07963067  0.05644936]\n",
      "Loss in iteration 6567: 0.42932384608296437\n",
      "Theta: [-1.72739999  1.07970401  0.05644668]\n",
      "Loss in iteration 6568: 0.42932013532245833\n",
      "Theta: [-1.72750636  1.07977733  0.05644399]\n",
      "Loss in iteration 6569: 0.42931642586758223\n",
      "Theta: [-1.72761272  1.07985065  0.05644131]\n",
      "Loss in iteration 6570: 0.4293127177177742\n",
      "Theta: [-1.72771906  1.07992395  0.05643863]\n",
      "Loss in iteration 6571: 0.4293090108724727\n",
      "Theta: [-1.72782538  1.07999724  0.05643594]\n",
      "Loss in iteration 6572: 0.42930530533111605\n",
      "Theta: [-1.72793167  1.08007052  0.05643326]\n",
      "Loss in iteration 6573: 0.42930160109314314\n",
      "Theta: [-1.72803795  1.08014378  0.05643058]\n",
      "Loss in iteration 6574: 0.4292978981579932\n",
      "Theta: [-1.72814421  1.08021704  0.0564279 ]\n",
      "Loss in iteration 6575: 0.4292941965251057\n",
      "Theta: [-1.72825046  1.08029028  0.05642522]\n",
      "Loss in iteration 6576: 0.42929049619392023\n",
      "Theta: [-1.72835668  1.08036351  0.05642254]\n",
      "Loss in iteration 6577: 0.4292867971638771\n",
      "Theta: [-1.72846288  1.08043673  0.05641986]\n",
      "Loss in iteration 6578: 0.4292830994344163\n",
      "Theta: [-1.72856906  1.08050994  0.05641717]\n",
      "Loss in iteration 6579: 0.42927940300497874\n",
      "Theta: [-1.72867523  1.08058313  0.05641449]\n",
      "Loss in iteration 6580: 0.4292757078750053\n",
      "Theta: [-1.72878137  1.08065631  0.05641181]\n",
      "Loss in iteration 6581: 0.429272014043937\n",
      "Theta: [-1.7288875   1.08072948  0.05640913]\n",
      "Loss in iteration 6582: 0.4292683215112156\n",
      "Theta: [-1.7289936   1.08080264  0.05640645]\n",
      "Loss in iteration 6583: 0.42926463027628275\n",
      "Theta: [-1.72909969  1.08087579  0.05640378]\n",
      "Loss in iteration 6584: 0.4292609403385806\n",
      "Theta: [-1.72920576  1.08094892  0.0564011 ]\n",
      "Loss in iteration 6585: 0.4292572516975514\n",
      "Theta: [-1.72931181  1.08102205  0.05639842]\n",
      "Loss in iteration 6586: 0.42925356435263806\n",
      "Theta: [-1.72941783  1.08109516  0.05639574]\n",
      "Loss in iteration 6587: 0.4292498783032835\n",
      "Theta: [-1.72952384  1.08116826  0.05639306]\n",
      "Loss in iteration 6588: 0.4292461935489306\n",
      "Theta: [-1.72962984  1.08124134  0.05639038]\n",
      "Loss in iteration 6589: 0.42924251008902353\n",
      "Theta: [-1.72973581  1.08131442  0.05638771]\n",
      "Loss in iteration 6590: 0.4292388279230057\n",
      "Theta: [-1.72984176  1.08138748  0.05638503]\n",
      "Loss in iteration 6591: 0.4292351470503216\n",
      "Theta: [-1.72994769  1.08146053  0.05638235]\n",
      "Loss in iteration 6592: 0.4292314674704153\n",
      "Theta: [-1.7300536   1.08153357  0.05637968]\n",
      "Loss in iteration 6593: 0.42922778918273174\n",
      "Theta: [-1.7301595  1.0816066  0.056377 ]\n",
      "Loss in iteration 6594: 0.4292241121867159\n",
      "Theta: [-1.73026537  1.08167961  0.05637432]\n",
      "Loss in iteration 6595: 0.429220436481813\n",
      "Theta: [-1.73037123  1.08175262  0.05637165]\n",
      "Loss in iteration 6596: 0.4292167620674689\n",
      "Theta: [-1.73047707  1.08182561  0.05636897]\n",
      "Loss in iteration 6597: 0.4292130889431291\n",
      "Theta: [-1.73058288  1.08189859  0.0563663 ]\n",
      "Loss in iteration 6598: 0.42920941710823995\n",
      "Theta: [-1.73068868  1.08197155  0.05636362]\n",
      "Loss in iteration 6599: 0.42920574656224825\n",
      "Theta: [-1.73079446  1.08204451  0.05636095]\n",
      "Loss in iteration 6600: 0.4292020773046003\n",
      "Theta: [-1.73090022  1.08211745  0.05635827]\n",
      "Loss in iteration 6601: 0.42919840933474335\n",
      "Theta: [-1.73100596  1.08219039  0.0563556 ]\n",
      "Loss in iteration 6602: 0.4291947426521246\n",
      "Theta: [-1.73111169  1.08226331  0.05635292]\n",
      "Loss in iteration 6603: 0.429191077256192\n",
      "Theta: [-1.73121739  1.08233621  0.05635025]\n",
      "Loss in iteration 6604: 0.42918741314639314\n",
      "Theta: [-1.73132307  1.08240911  0.05634758]\n",
      "Loss in iteration 6605: 0.4291837503221763\n",
      "Theta: [-1.73142874  1.08248199  0.0563449 ]\n",
      "Loss in iteration 6606: 0.42918008878299013\n",
      "Theta: [-1.73153438  1.08255487  0.05634223]\n",
      "Loss in iteration 6607: 0.4291764285282833\n",
      "Theta: [-1.73164001  1.08262773  0.05633956]\n",
      "Loss in iteration 6608: 0.4291727695575049\n",
      "Theta: [-1.73174561  1.08270057  0.05633689]\n",
      "Loss in iteration 6609: 0.42916911187010426\n",
      "Theta: [-1.7318512   1.08277341  0.05633422]\n",
      "Loss in iteration 6610: 0.4291654554655313\n",
      "Theta: [-1.73195677  1.08284623  0.05633154]\n",
      "Loss in iteration 6611: 0.42916180034323564\n",
      "Theta: [-1.73206232  1.08291905  0.05632887]\n",
      "Loss in iteration 6612: 0.4291581465026675\n",
      "Theta: [-1.73216785  1.08299185  0.0563262 ]\n",
      "Loss in iteration 6613: 0.4291544939432776\n",
      "Theta: [-1.73227336  1.08306464  0.05632353]\n",
      "Loss in iteration 6614: 0.4291508426645167\n",
      "Theta: [-1.73237885  1.08313741  0.05632086]\n",
      "Loss in iteration 6615: 0.42914719266583584\n",
      "Theta: [-1.73248433  1.08321018  0.05631819]\n",
      "Loss in iteration 6616: 0.42914354394668647\n",
      "Theta: [-1.73258978  1.08328293  0.05631552]\n",
      "Loss in iteration 6617: 0.4291398965065201\n",
      "Theta: [-1.73269521  1.08335567  0.05631285]\n",
      "Loss in iteration 6618: 0.4291362503447889\n",
      "Theta: [-1.73280063  1.0834284   0.05631018]\n",
      "Loss in iteration 6619: 0.429132605460945\n",
      "Theta: [-1.73290603  1.08350112  0.05630751]\n",
      "Loss in iteration 6620: 0.429128961854441\n",
      "Theta: [-1.7330114   1.08357383  0.05630484]\n",
      "Loss in iteration 6621: 0.4291253195247296\n",
      "Theta: [-1.73311676  1.08364652  0.05630217]\n",
      "Loss in iteration 6622: 0.4291216784712639\n",
      "Theta: [-1.7332221   1.0837192   0.05629951]\n",
      "Loss in iteration 6623: 0.4291180386934974\n",
      "Theta: [-1.73332742  1.08379187  0.05629684]\n",
      "Loss in iteration 6624: 0.42911440019088387\n",
      "Theta: [-1.73343272  1.08386453  0.05629417]\n",
      "Loss in iteration 6625: 0.42911076296287703\n",
      "Theta: [-1.73353801  1.08393718  0.0562915 ]\n",
      "Loss in iteration 6626: 0.42910712700893106\n",
      "Theta: [-1.73364327  1.08400981  0.05628884]\n",
      "Loss in iteration 6627: 0.4291034923285008\n",
      "Theta: [-1.73374851  1.08408243  0.05628617]\n",
      "Loss in iteration 6628: 0.4290998589210409\n",
      "Theta: [-1.73385374  1.08415504  0.0562835 ]\n",
      "Loss in iteration 6629: 0.4290962267860066\n",
      "Theta: [-1.73395894  1.08422764  0.05628084]\n",
      "Loss in iteration 6630: 0.4290925959228531\n",
      "Theta: [-1.73406413  1.08430023  0.05627817]\n",
      "Loss in iteration 6631: 0.42908896633103616\n",
      "Theta: [-1.7341693   1.08437281  0.05627551]\n",
      "Loss in iteration 6632: 0.42908533801001175\n",
      "Theta: [-1.73427445  1.08444537  0.05627284]\n",
      "Loss in iteration 6633: 0.4290817109592361\n",
      "Theta: [-1.73437958  1.08451792  0.05627018]\n",
      "Loss in iteration 6634: 0.42907808517816565\n",
      "Theta: [-1.73448469  1.08459046  0.05626751]\n",
      "Loss in iteration 6635: 0.42907446066625726\n",
      "Theta: [-1.73458978  1.08466299  0.05626485]\n",
      "Loss in iteration 6636: 0.42907083742296814\n",
      "Theta: [-1.73469485  1.08473551  0.05626218]\n",
      "Loss in iteration 6637: 0.42906721544775556\n",
      "Theta: [-1.73479991  1.08480801  0.05625952]\n",
      "Loss in iteration 6638: 0.4290635947400771\n",
      "Theta: [-1.73490494  1.0848805   0.05625685]\n",
      "Loss in iteration 6639: 0.4290599752993908\n",
      "Theta: [-1.73500996  1.08495298  0.05625419]\n",
      "Loss in iteration 6640: 0.42905635712515505\n",
      "Theta: [-1.73511496  1.08502545  0.05625153]\n",
      "Loss in iteration 6641: 0.429052740216828\n",
      "Theta: [-1.73521993  1.08509791  0.05624886]\n",
      "Loss in iteration 6642: 0.42904912457386857\n",
      "Theta: [-1.73532489  1.08517035  0.0562462 ]\n",
      "Loss in iteration 6643: 0.42904551019573617\n",
      "Theta: [-1.73542983  1.08524279  0.05624354]\n",
      "Loss in iteration 6644: 0.4290418970818898\n",
      "Theta: [-1.73553475  1.08531521  0.05624088]\n",
      "Loss in iteration 6645: 0.42903828523178916\n",
      "Theta: [-1.73563966  1.08538762  0.05623822]\n",
      "Loss in iteration 6646: 0.4290346746448941\n",
      "Theta: [-1.73574454  1.08546002  0.05623556]\n",
      "Loss in iteration 6647: 0.42903106532066504\n",
      "Theta: [-1.7358494   1.0855324   0.05623289]\n",
      "Loss in iteration 6648: 0.4290274572585623\n",
      "Theta: [-1.73595425  1.08560478  0.05623023]\n",
      "Loss in iteration 6649: 0.4290238504580468\n",
      "Theta: [-1.73605908  1.08567714  0.05622757]\n",
      "Loss in iteration 6650: 0.4290202449185793\n",
      "Theta: [-1.73616388  1.08574949  0.05622491]\n",
      "Loss in iteration 6651: 0.4290166406396214\n",
      "Theta: [-1.73626867  1.08582183  0.05622225]\n",
      "Loss in iteration 6652: 0.42901303762063464\n",
      "Theta: [-1.73637344  1.08589416  0.05621959]\n",
      "Loss in iteration 6653: 0.42900943586108087\n",
      "Theta: [-1.73647819  1.08596647  0.05621693]\n",
      "Loss in iteration 6654: 0.42900583536042225\n",
      "Theta: [-1.73658292  1.08603878  0.05621427]\n",
      "Loss in iteration 6655: 0.42900223611812144\n",
      "Theta: [-1.73668764  1.08611107  0.05621162]\n",
      "Loss in iteration 6656: 0.4289986381336408\n",
      "Theta: [-1.73679233  1.08618335  0.05620896]\n",
      "Loss in iteration 6657: 0.4289950414064436\n",
      "Theta: [-1.73689701  1.08625562  0.0562063 ]\n",
      "Loss in iteration 6658: 0.42899144593599314\n",
      "Theta: [-1.73700166  1.08632787  0.05620364]\n",
      "Loss in iteration 6659: 0.42898785172175286\n",
      "Theta: [-1.7371063   1.08640012  0.05620098]\n",
      "Loss in iteration 6660: 0.42898425876318674\n",
      "Theta: [-1.73721092  1.08647235  0.05619833]\n",
      "Loss in iteration 6661: 0.4289806670597588\n",
      "Theta: [-1.73731552  1.08654457  0.05619567]\n",
      "Loss in iteration 6662: 0.4289770766109335\n",
      "Theta: [-1.7374201   1.08661678  0.05619301]\n",
      "Loss in iteration 6663: 0.4289734874161756\n",
      "Theta: [-1.73752466  1.08668898  0.05619035]\n",
      "Loss in iteration 6664: 0.42896989947494996\n",
      "Theta: [-1.7376292   1.08676117  0.0561877 ]\n",
      "Loss in iteration 6665: 0.42896631278672187\n",
      "Theta: [-1.73773373  1.08683334  0.05618504]\n",
      "Loss in iteration 6666: 0.4289627273509569\n",
      "Theta: [-1.73783823  1.0869055   0.05618239]\n",
      "Loss in iteration 6667: 0.4289591431671208\n",
      "Theta: [-1.73794272  1.08697766  0.05617973]\n",
      "Loss in iteration 6668: 0.4289555602346797\n",
      "Theta: [-1.73804719  1.0870498   0.05617708]\n",
      "Loss in iteration 6669: 0.42895197855309986\n",
      "Theta: [-1.73815164  1.08712192  0.05617442]\n",
      "Loss in iteration 6670: 0.428948398121848\n",
      "Theta: [-1.73825607  1.08719404  0.05617177]\n",
      "Loss in iteration 6671: 0.42894481894039105\n",
      "Theta: [-1.73836048  1.08726614  0.05616911]\n",
      "Loss in iteration 6672: 0.42894124100819625\n",
      "Theta: [-1.73846487  1.08733823  0.05616646]\n",
      "Loss in iteration 6673: 0.42893766432473085\n",
      "Theta: [-1.73856924  1.08741031  0.0561638 ]\n",
      "Loss in iteration 6674: 0.4289340888894628\n",
      "Theta: [-1.7386736   1.08748238  0.05616115]\n",
      "Loss in iteration 6675: 0.4289305147018601\n",
      "Theta: [-1.73877793  1.08755444  0.0561585 ]\n",
      "Loss in iteration 6676: 0.428926941761391\n",
      "Theta: [-1.73888225  1.08762649  0.05615584]\n",
      "Loss in iteration 6677: 0.4289233700675241\n",
      "Theta: [-1.73898655  1.08769852  0.05615319]\n",
      "Loss in iteration 6678: 0.4289197996197282\n",
      "Theta: [-1.73909083  1.08777054  0.05615054]\n",
      "Loss in iteration 6679: 0.4289162304174725\n",
      "Theta: [-1.73919509  1.08784255  0.05614789]\n",
      "Loss in iteration 6680: 0.4289126624602266\n",
      "Theta: [-1.73929933  1.08791455  0.05614524]\n",
      "Loss in iteration 6681: 0.42890909574746006\n",
      "Theta: [-1.73940356  1.08798654  0.05614258]\n",
      "Loss in iteration 6682: 0.4289055302786424\n",
      "Theta: [-1.73950776  1.08805851  0.05613993]\n",
      "Loss in iteration 6683: 0.4289019660532443\n",
      "Theta: [-1.73961195  1.08813048  0.05613728]\n",
      "Loss in iteration 6684: 0.4288984030707364\n",
      "Theta: [-1.73971611  1.08820243  0.05613463]\n",
      "Loss in iteration 6685: 0.42889484133058914\n",
      "Theta: [-1.73982026  1.08827437  0.05613198]\n",
      "Loss in iteration 6686: 0.4288912808322737\n",
      "Theta: [-1.73992439  1.0883463   0.05612933]\n",
      "Loss in iteration 6687: 0.4288877215752614\n",
      "Theta: [-1.7400285   1.08841821  0.05612668]\n",
      "Loss in iteration 6688: 0.4288841635590241\n",
      "Theta: [-1.74013259  1.08849012  0.05612403]\n",
      "Loss in iteration 6689: 0.42888060678303325\n",
      "Theta: [-1.74023667  1.08856201  0.05612138]\n",
      "Loss in iteration 6690: 0.42887705124676123\n",
      "Theta: [-1.74034072  1.08863389  0.05611873]\n",
      "Loss in iteration 6691: 0.42887349694968063\n",
      "Theta: [-1.74044476  1.08870576  0.05611608]\n",
      "Loss in iteration 6692: 0.4288699438912639\n",
      "Theta: [-1.74054877  1.08877762  0.05611344]\n",
      "Loss in iteration 6693: 0.42886639207098426\n",
      "Theta: [-1.74065277  1.08884947  0.05611079]\n",
      "Loss in iteration 6694: 0.4288628414883147\n",
      "Theta: [-1.74075675  1.0889213   0.05610814]\n",
      "Loss in iteration 6695: 0.42885929214272894\n",
      "Theta: [-1.74086071  1.08899312  0.05610549]\n",
      "Loss in iteration 6696: 0.42885574403370064\n",
      "Theta: [-1.74096465  1.08906494  0.05610284]\n",
      "Loss in iteration 6697: 0.428852197160704\n",
      "Theta: [-1.74106858  1.08913674  0.0561002 ]\n",
      "Loss in iteration 6698: 0.4288486515232134\n",
      "Theta: [-1.74117248  1.08920852  0.05609755]\n",
      "Loss in iteration 6699: 0.4288451071207033\n",
      "Theta: [-1.74127637  1.0892803   0.0560949 ]\n",
      "Loss in iteration 6700: 0.4288415639526487\n",
      "Theta: [-1.74138024  1.08935206  0.05609226]\n",
      "Loss in iteration 6701: 0.4288380220185248\n",
      "Theta: [-1.74148409  1.08942382  0.05608961]\n",
      "Loss in iteration 6702: 0.4288344813178071\n",
      "Theta: [-1.74158792  1.08949556  0.05608697]\n",
      "Loss in iteration 6703: 0.4288309418499709\n",
      "Theta: [-1.74169173  1.08956729  0.05608432]\n",
      "Loss in iteration 6704: 0.4288274036144928\n",
      "Theta: [-1.74179552  1.08963901  0.05608168]\n",
      "Loss in iteration 6705: 0.42882386661084865\n",
      "Theta: [-1.74189929  1.08971071  0.05607903]\n",
      "Loss in iteration 6706: 0.428820330838515\n",
      "Theta: [-1.74200305  1.08978241  0.05607639]\n",
      "Loss in iteration 6707: 0.42881679629696884\n",
      "Theta: [-1.74210679  1.08985409  0.05607374]\n",
      "Loss in iteration 6708: 0.428813262985687\n",
      "Theta: [-1.7422105   1.08992576  0.0560711 ]\n",
      "Loss in iteration 6709: 0.42880973090414704\n",
      "Theta: [-1.7423142   1.08999742  0.05606846]\n",
      "Loss in iteration 6710: 0.4288062000518264\n",
      "Theta: [-1.74241788  1.09006907  0.05606581]\n",
      "Loss in iteration 6711: 0.428802670428203\n",
      "Theta: [-1.74252155  1.09014071  0.05606317]\n",
      "Loss in iteration 6712: 0.42879914203275526\n",
      "Theta: [-1.74262519  1.09021233  0.05606053]\n",
      "Loss in iteration 6713: 0.4287956148649614\n",
      "Theta: [-1.74272882  1.09028395  0.05605788]\n",
      "Loss in iteration 6714: 0.4287920889243\n",
      "Theta: [-1.74283242  1.09035555  0.05605524]\n",
      "Loss in iteration 6715: 0.42878856421024997\n",
      "Theta: [-1.74293601  1.09042714  0.0560526 ]\n",
      "Loss in iteration 6716: 0.4287850407222909\n",
      "Theta: [-1.74303958  1.09049872  0.05604996]\n",
      "Loss in iteration 6717: 0.4287815184599021\n",
      "Theta: [-1.74314313  1.09057029  0.05604732]\n",
      "Loss in iteration 6718: 0.42877799742256334\n",
      "Theta: [-1.74324666  1.09064184  0.05604468]\n",
      "Loss in iteration 6719: 0.4287744776097545\n",
      "Theta: [-1.74335018  1.09071339  0.05604204]\n",
      "Loss in iteration 6720: 0.4287709590209562\n",
      "Theta: [-1.74345367  1.09078492  0.05603939]\n",
      "Loss in iteration 6721: 0.42876744165564873\n",
      "Theta: [-1.74355715  1.09085644  0.05603675]\n",
      "Loss in iteration 6722: 0.4287639255133132\n",
      "Theta: [-1.7436606   1.09092795  0.05603411]\n",
      "Loss in iteration 6723: 0.4287604105934307\n",
      "Theta: [-1.74376404  1.09099945  0.05603147]\n",
      "Loss in iteration 6724: 0.4287568968954824\n",
      "Theta: [-1.74386746  1.09107093  0.05602884]\n",
      "Loss in iteration 6725: 0.4287533844189502\n",
      "Theta: [-1.74397087  1.09114241  0.0560262 ]\n",
      "Loss in iteration 6726: 0.4287498731633159\n",
      "Theta: [-1.74407425  1.09121387  0.05602356]\n",
      "Loss in iteration 6727: 0.42874636312806175\n",
      "Theta: [-1.74417761  1.09128532  0.05602092]\n",
      "Loss in iteration 6728: 0.4287428543126702\n",
      "Theta: [-1.74428096  1.09135676  0.05601828]\n",
      "Loss in iteration 6729: 0.42873934671662395\n",
      "Theta: [-1.74438429  1.09142819  0.05601564]\n",
      "Loss in iteration 6730: 0.42873584033940587\n",
      "Theta: [-1.7444876   1.0914996   0.05601301]\n",
      "Loss in iteration 6731: 0.4287323351804997\n",
      "Theta: [-1.74459089  1.09157101  0.05601037]\n",
      "Loss in iteration 6732: 0.42872883123938843\n",
      "Theta: [-1.74469416  1.0916424   0.05600773]\n",
      "Loss in iteration 6733: 0.4287253285155561\n",
      "Theta: [-1.74479741  1.09171378  0.05600509]\n",
      "Loss in iteration 6734: 0.42872182700848677\n",
      "Theta: [-1.74490065  1.09178515  0.05600246]\n",
      "Loss in iteration 6735: 0.42871832671766485\n",
      "Theta: [-1.74500387  1.09185651  0.05599982]\n",
      "Loss in iteration 6736: 0.42871482764257474\n",
      "Theta: [-1.74510707  1.09192786  0.05599718]\n",
      "Loss in iteration 6737: 0.4287113297827014\n",
      "Theta: [-1.74521024  1.09199919  0.05599455]\n",
      "Loss in iteration 6738: 0.42870783313753\n",
      "Theta: [-1.74531341  1.09207052  0.05599191]\n",
      "Loss in iteration 6739: 0.428704337706546\n",
      "Theta: [-1.74541655  1.09214183  0.05598928]\n",
      "Loss in iteration 6740: 0.42870084348923493\n",
      "Theta: [-1.74551967  1.09221313  0.05598664]\n",
      "Loss in iteration 6741: 0.4286973504850827\n",
      "Theta: [-1.74562278  1.09228442  0.05598401]\n",
      "Loss in iteration 6742: 0.4286938586935756\n",
      "Theta: [-1.74572587  1.0923557   0.05598137]\n",
      "Loss in iteration 6743: 0.42869036811420025\n",
      "Theta: [-1.74582893  1.09242696  0.05597874]\n",
      "Loss in iteration 6744: 0.42868687874644307\n",
      "Theta: [-1.74593199  1.09249822  0.05597611]\n",
      "Loss in iteration 6745: 0.42868339058979127\n",
      "Theta: [-1.74603502  1.09256946  0.05597347]\n",
      "Loss in iteration 6746: 0.428679903643732\n",
      "Theta: [-1.74613803  1.09264069  0.05597084]\n",
      "Loss in iteration 6747: 0.4286764179077529\n",
      "Theta: [-1.74624103  1.09271191  0.05596821]\n",
      "Loss in iteration 6748: 0.4286729333813415\n",
      "Theta: [-1.746344    1.09278312  0.05596557]\n",
      "Loss in iteration 6749: 0.42866945006398616\n",
      "Theta: [-1.74644696  1.09285432  0.05596294]\n",
      "Loss in iteration 6750: 0.428665967955175\n",
      "Theta: [-1.7465499   1.0929255   0.05596031]\n",
      "Loss in iteration 6751: 0.4286624870543966\n",
      "Theta: [-1.74665282  1.09299668  0.05595768]\n",
      "Loss in iteration 6752: 0.42865900736113993\n",
      "Theta: [-1.74675572  1.09306784  0.05595505]\n",
      "Loss in iteration 6753: 0.42865552887489405\n",
      "Theta: [-1.74685861  1.09313899  0.05595242]\n",
      "Loss in iteration 6754: 0.42865205159514835\n",
      "Theta: [-1.74696147  1.09321013  0.05594978]\n",
      "Loss in iteration 6755: 0.42864857552139246\n",
      "Theta: [-1.74706432  1.09328126  0.05594715]\n",
      "Loss in iteration 6756: 0.42864510065311623\n",
      "Theta: [-1.74716715  1.09335237  0.05594452]\n",
      "Loss in iteration 6757: 0.4286416269898099\n",
      "Theta: [-1.74726996  1.09342348  0.05594189]\n",
      "Loss in iteration 6758: 0.4286381545309639\n",
      "Theta: [-1.74737275  1.09349457  0.05593926]\n",
      "Loss in iteration 6759: 0.42863468327606874\n",
      "Theta: [-1.74747553  1.09356565  0.05593663]\n",
      "Loss in iteration 6760: 0.4286312132246155\n",
      "Theta: [-1.74757828  1.09363672  0.05593401]\n",
      "Loss in iteration 6761: 0.42862774437609535\n",
      "Theta: [-1.74768102  1.09370778  0.05593138]\n",
      "Loss in iteration 6762: 0.42862427673\n",
      "Theta: [-1.74778374  1.09377883  0.05592875]\n",
      "Loss in iteration 6763: 0.42862081028582094\n",
      "Theta: [-1.74788644  1.09384986  0.05592612]\n",
      "Loss in iteration 6764: 0.42861734504305027\n",
      "Theta: [-1.74798912  1.09392089  0.05592349]\n",
      "Loss in iteration 6765: 0.4286138810011801\n",
      "Theta: [-1.74809178  1.0939919   0.05592086]\n",
      "Loss in iteration 6766: 0.4286104181597032\n",
      "Theta: [-1.74819443  1.0940629   0.05591824]\n",
      "Loss in iteration 6767: 0.42860695651811215\n",
      "Theta: [-1.74829706  1.09413389  0.05591561]\n",
      "Loss in iteration 6768: 0.4286034960759001\n",
      "Theta: [-1.74839967  1.09420487  0.05591298]\n",
      "Loss in iteration 6769: 0.4286000368325605\n",
      "Theta: [-1.74850226  1.09427584  0.05591035]\n",
      "Loss in iteration 6770: 0.42859657878758656\n",
      "Theta: [-1.74860483  1.09434679  0.05590773]\n",
      "Loss in iteration 6771: 0.42859312194047233\n",
      "Theta: [-1.74870738  1.09441774  0.0559051 ]\n",
      "Loss in iteration 6772: 0.42858966629071205\n",
      "Theta: [-1.74880992  1.09448867  0.05590248]\n",
      "Loss in iteration 6773: 0.42858621183779966\n",
      "Theta: [-1.74891243  1.09455959  0.05589985]\n",
      "Loss in iteration 6774: 0.42858275858123024\n",
      "Theta: [-1.74901493  1.0946305   0.05589723]\n",
      "Loss in iteration 6775: 0.4285793065204983\n",
      "Theta: [-1.74911741  1.0947014   0.0558946 ]\n",
      "Loss in iteration 6776: 0.4285758556550993\n",
      "Theta: [-1.74921987  1.09477228  0.05589198]\n",
      "Loss in iteration 6777: 0.4285724059845283\n",
      "Theta: [-1.74932232  1.09484316  0.05588935]\n",
      "Loss in iteration 6778: 0.42856895750828117\n",
      "Theta: [-1.74942474  1.09491402  0.05588673]\n",
      "Loss in iteration 6779: 0.4285655102258539\n",
      "Theta: [-1.74952715  1.09498488  0.0558841 ]\n",
      "Loss in iteration 6780: 0.4285620641367423\n",
      "Theta: [-1.74962954  1.09505572  0.05588148]\n",
      "Loss in iteration 6781: 0.42855861924044303\n",
      "Theta: [-1.74973191  1.09512655  0.05587886]\n",
      "Loss in iteration 6782: 0.42855517553645295\n",
      "Theta: [-1.74983426  1.09519736  0.05587623]\n",
      "Loss in iteration 6783: 0.42855173302426885\n",
      "Theta: [-1.74993659  1.09526817  0.05587361]\n",
      "Loss in iteration 6784: 0.4285482917033879\n",
      "Theta: [-1.75003891  1.09533896  0.05587099]\n",
      "Loss in iteration 6785: 0.4285448515733076\n",
      "Theta: [-1.75014121  1.09540975  0.05586837]\n",
      "Loss in iteration 6786: 0.4285414126335256\n",
      "Theta: [-1.75024349  1.09548052  0.05586574]\n",
      "Loss in iteration 6787: 0.42853797488353995\n",
      "Theta: [-1.75034575  1.09555128  0.05586312]\n",
      "Loss in iteration 6788: 0.42853453832284916\n",
      "Theta: [-1.75044799  1.09562203  0.0558605 ]\n",
      "Loss in iteration 6789: 0.4285311029509514\n",
      "Theta: [-1.75055021  1.09569277  0.05585788]\n",
      "Loss in iteration 6790: 0.4285276687673453\n",
      "Theta: [-1.75065242  1.09576349  0.05585526]\n",
      "Loss in iteration 6791: 0.42852423577153026\n",
      "Theta: [-1.75075461  1.09583421  0.05585264]\n",
      "Loss in iteration 6792: 0.42852080396300546\n",
      "Theta: [-1.75085678  1.09590491  0.05585002]\n",
      "Loss in iteration 6793: 0.4285173733412702\n",
      "Theta: [-1.75095893  1.0959756   0.0558474 ]\n",
      "Loss in iteration 6794: 0.4285139439058245\n",
      "Theta: [-1.75106106  1.09604629  0.05584478]\n",
      "Loss in iteration 6795: 0.4285105156561684\n",
      "Theta: [-1.75116318  1.09611695  0.05584216]\n",
      "Loss in iteration 6796: 0.42850708859180203\n",
      "Theta: [-1.75126527  1.09618761  0.05583954]\n",
      "Loss in iteration 6797: 0.4285036627122261\n",
      "Theta: [-1.75136735  1.09625826  0.05583692]\n",
      "Loss in iteration 6798: 0.4285002380169415\n",
      "Theta: [-1.75146941  1.09632889  0.0558343 ]\n",
      "Loss in iteration 6799: 0.4284968145054491\n",
      "Theta: [-1.75157145  1.09639952  0.05583168]\n",
      "Loss in iteration 6800: 0.4284933921772503\n",
      "Theta: [-1.75167348  1.09647013  0.05582907]\n",
      "Loss in iteration 6801: 0.4284899710318468\n",
      "Theta: [-1.75177548  1.09654073  0.05582645]\n",
      "Loss in iteration 6802: 0.42848655106874034\n",
      "Theta: [-1.75187747  1.09661132  0.05582383]\n",
      "Loss in iteration 6803: 0.428483132287433\n",
      "Theta: [-1.75197944  1.0966819   0.05582121]\n",
      "Loss in iteration 6804: 0.4284797146874271\n",
      "Theta: [-1.75208139  1.09675247  0.0558186 ]\n",
      "Loss in iteration 6805: 0.4284762982682254\n",
      "Theta: [-1.75218332  1.09682302  0.05581598]\n",
      "Loss in iteration 6806: 0.4284728830293308\n",
      "Theta: [-1.75228524  1.09689356  0.05581336]\n",
      "Loss in iteration 6807: 0.4284694689702462\n",
      "Theta: [-1.75238714  1.0969641   0.05581075]\n",
      "Loss in iteration 6808: 0.42846605609047506\n",
      "Theta: [-1.75248901  1.09703462  0.05580813]\n",
      "Loss in iteration 6809: 0.42846264438952114\n",
      "Theta: [-1.75259087  1.09710513  0.05580552]\n",
      "Loss in iteration 6810: 0.428459233866888\n",
      "Theta: [-1.75269272  1.09717563  0.0558029 ]\n",
      "Loss in iteration 6811: 0.42845582452208025\n",
      "Theta: [-1.75279454  1.09724611  0.05580029]\n",
      "Loss in iteration 6812: 0.4284524163546019\n",
      "Theta: [-1.75289635  1.09731659  0.05579767]\n",
      "Loss in iteration 6813: 0.4284490093639577\n",
      "Theta: [-1.75299813  1.09738705  0.05579506]\n",
      "Loss in iteration 6814: 0.4284456035496527\n",
      "Theta: [-1.7530999   1.09745751  0.05579244]\n",
      "Loss in iteration 6815: 0.42844219891119173\n",
      "Theta: [-1.75320165  1.09752795  0.05578983]\n",
      "Loss in iteration 6816: 0.4284387954480808\n",
      "Theta: [-1.75330339  1.09759838  0.05578722]\n",
      "Loss in iteration 6817: 0.428435393159825\n",
      "Theta: [-1.7534051  1.0976688  0.0557846]\n",
      "Loss in iteration 6818: 0.4284319920459304\n",
      "Theta: [-1.7535068   1.0977392   0.05578199]\n",
      "Loss in iteration 6819: 0.42842859210590317\n",
      "Theta: [-1.75360848  1.0978096   0.05577938]\n",
      "Loss in iteration 6820: 0.4284251933392498\n",
      "Theta: [-1.75371014  1.09787999  0.05577677]\n",
      "Loss in iteration 6821: 0.42842179574547695\n",
      "Theta: [-1.75381178  1.09795036  0.05577415]\n",
      "Loss in iteration 6822: 0.42841839932409165\n",
      "Theta: [-1.75391341  1.09802072  0.05577154]\n",
      "Loss in iteration 6823: 0.4284150040746008\n",
      "Theta: [-1.75401501  1.09809107  0.05576893]\n",
      "Loss in iteration 6824: 0.42841160999651207\n",
      "Theta: [-1.7541166   1.09816141  0.05576632]\n",
      "Loss in iteration 6825: 0.42840821708933313\n",
      "Theta: [-1.75421817  1.09823174  0.05576371]\n",
      "Loss in iteration 6826: 0.42840482535257196\n",
      "Theta: [-1.75431973  1.09830206  0.0557611 ]\n",
      "Loss in iteration 6827: 0.42840143478573667\n",
      "Theta: [-1.75442126  1.09837236  0.05575849]\n",
      "Loss in iteration 6828: 0.42839804538833554\n",
      "Theta: [-1.75452278  1.09844266  0.05575588]\n",
      "Loss in iteration 6829: 0.42839465715987757\n",
      "Theta: [-1.75462427  1.09851294  0.05575327]\n",
      "Loss in iteration 6830: 0.42839127009987155\n",
      "Theta: [-1.75472575  1.09858321  0.05575066]\n",
      "Loss in iteration 6831: 0.42838788420782675\n",
      "Theta: [-1.75482722  1.09865347  0.05574805]\n",
      "Loss in iteration 6832: 0.42838449948325247\n",
      "Theta: [-1.75492866  1.09872372  0.05574544]\n",
      "Loss in iteration 6833: 0.42838111592565853\n",
      "Theta: [-1.75503009  1.09879396  0.05574283]\n",
      "Loss in iteration 6834: 0.42837773353455494\n",
      "Theta: [-1.75513149  1.09886418  0.05574022]\n",
      "Loss in iteration 6835: 0.4283743523094518\n",
      "Theta: [-1.75523288  1.0989344   0.05573761]\n",
      "Loss in iteration 6836: 0.42837097224985976\n",
      "Theta: [-1.75533425  1.0990046   0.05573501]\n",
      "Loss in iteration 6837: 0.4283675933552891\n",
      "Theta: [-1.75543561  1.09907479  0.0557324 ]\n",
      "Loss in iteration 6838: 0.4283642156252511\n",
      "Theta: [-1.75553694  1.09914498  0.05572979]\n",
      "Loss in iteration 6839: 0.42836083905925704\n",
      "Theta: [-1.75563826  1.09921514  0.05572719]\n",
      "Loss in iteration 6840: 0.42835746365681815\n",
      "Theta: [-1.75573956  1.0992853   0.05572458]\n",
      "Loss in iteration 6841: 0.42835408941744624\n",
      "Theta: [-1.75584084  1.09935545  0.05572197]\n",
      "Loss in iteration 6842: 0.4283507163406534\n",
      "Theta: [-1.75594211  1.09942559  0.05571937]\n",
      "Loss in iteration 6843: 0.4283473444259515\n",
      "Theta: [-1.75604335  1.09949571  0.05571676]\n",
      "Loss in iteration 6844: 0.42834397367285326\n",
      "Theta: [-1.75614458  1.09956582  0.05571415]\n",
      "Loss in iteration 6845: 0.4283406040808714\n",
      "Theta: [-1.75624579  1.09963593  0.05571155]\n",
      "Loss in iteration 6846: 0.4283372356495187\n",
      "Theta: [-1.75634698  1.09970602  0.05570894]\n",
      "Loss in iteration 6847: 0.42833386837830856\n",
      "Theta: [-1.75644816  1.0997761   0.05570634]\n",
      "Loss in iteration 6848: 0.4283305022667541\n",
      "Theta: [-1.75654931  1.09984616  0.05570373]\n",
      "Loss in iteration 6849: 0.42832713731436955\n",
      "Theta: [-1.75665045  1.09991622  0.05570113]\n",
      "Loss in iteration 6850: 0.4283237735206684\n",
      "Theta: [-1.75675157  1.09998627  0.05569853]\n",
      "Loss in iteration 6851: 0.42832041088516504\n",
      "Theta: [-1.75685267  1.1000563   0.05569592]\n",
      "Loss in iteration 6852: 0.42831704940737386\n",
      "Theta: [-1.75695375  1.10012632  0.05569332]\n",
      "Loss in iteration 6853: 0.42831368908680945\n",
      "Theta: [-1.75705482  1.10019634  0.05569072]\n",
      "Loss in iteration 6854: 0.4283103299229871\n",
      "Theta: [-1.75715587  1.10026634  0.05568811]\n",
      "Loss in iteration 6855: 0.4283069719154217\n",
      "Theta: [-1.7572569   1.10033632  0.05568551]\n",
      "Loss in iteration 6856: 0.4283036150636287\n",
      "Theta: [-1.75735791  1.1004063   0.05568291]\n",
      "Loss in iteration 6857: 0.42830025936712396\n",
      "Theta: [-1.7574589   1.10047627  0.05568031]\n",
      "Loss in iteration 6858: 0.4282969048254232\n",
      "Theta: [-1.75755988  1.10054622  0.05567771]\n",
      "Loss in iteration 6859: 0.4282935514380427\n",
      "Theta: [-1.75766084  1.10061617  0.0556751 ]\n",
      "Loss in iteration 6860: 0.42829019920449896\n",
      "Theta: [-1.75776178  1.1006861   0.0556725 ]\n",
      "Loss in iteration 6861: 0.42828684812430867\n",
      "Theta: [-1.7578627   1.10075602  0.0556699 ]\n",
      "Loss in iteration 6862: 0.4282834981969884\n",
      "Theta: [-1.75796361  1.10082593  0.0556673 ]\n",
      "Loss in iteration 6863: 0.42828014942205583\n",
      "Theta: [-1.75806449  1.10089583  0.0556647 ]\n",
      "Loss in iteration 6864: 0.42827680179902794\n",
      "Theta: [-1.75816536  1.10096572  0.0556621 ]\n",
      "Loss in iteration 6865: 0.4282734553274228\n",
      "Theta: [-1.75826621  1.1010356   0.0556595 ]\n",
      "Loss in iteration 6866: 0.4282701100067579\n",
      "Theta: [-1.75836705  1.10110546  0.0556569 ]\n",
      "Loss in iteration 6867: 0.4282667658365517\n",
      "Theta: [-1.75846786  1.10117532  0.0556543 ]\n",
      "Loss in iteration 6868: 0.42826342281632246\n",
      "Theta: [-1.75856866  1.10124516  0.0556517 ]\n",
      "Loss in iteration 6869: 0.4282600809455888\n",
      "Theta: [-1.75866944  1.10131499  0.05564911]\n",
      "Loss in iteration 6870: 0.4282567402238697\n",
      "Theta: [-1.7587702   1.10138481  0.05564651]\n",
      "Loss in iteration 6871: 0.42825340065068424\n",
      "Theta: [-1.75887094  1.10145462  0.05564391]\n",
      "Loss in iteration 6872: 0.4282500622255519\n",
      "Theta: [-1.75897167  1.10152442  0.05564131]\n",
      "Loss in iteration 6873: 0.4282467249479921\n",
      "Theta: [-1.75907238  1.10159421  0.05563871]\n",
      "Loss in iteration 6874: 0.4282433888175248\n",
      "Theta: [-1.75917307  1.10166398  0.05563612]\n",
      "Loss in iteration 6875: 0.42824005383367025\n",
      "Theta: [-1.75927374  1.10173375  0.05563352]\n",
      "Loss in iteration 6876: 0.4282367199959488\n",
      "Theta: [-1.75937439  1.1018035   0.05563092]\n",
      "Loss in iteration 6877: 0.4282333873038807\n",
      "Theta: [-1.75947503  1.10187324  0.05562833]\n",
      "Loss in iteration 6878: 0.42823005575698725\n",
      "Theta: [-1.75957565  1.10194297  0.05562573]\n",
      "Loss in iteration 6879: 0.4282267253547893\n",
      "Theta: [-1.75967625  1.10201269  0.05562314]\n",
      "Loss in iteration 6880: 0.4282233960968083\n",
      "Theta: [-1.75977683  1.1020824   0.05562054]\n",
      "Loss in iteration 6881: 0.4282200679825657\n",
      "Theta: [-1.7598774   1.1021521   0.05561794]\n",
      "Loss in iteration 6882: 0.4282167410115834\n",
      "Theta: [-1.75997794  1.10222179  0.05561535]\n",
      "Loss in iteration 6883: 0.42821341518338335\n",
      "Theta: [-1.76007847  1.10229146  0.05561276]\n",
      "Loss in iteration 6884: 0.42821009049748815\n",
      "Theta: [-1.76017899  1.10236112  0.05561016]\n",
      "Loss in iteration 6885: 0.4282067669534201\n",
      "Theta: [-1.76027948  1.10243078  0.05560757]\n",
      "Loss in iteration 6886: 0.4282034445507022\n",
      "Theta: [-1.76037996  1.10250042  0.05560497]\n",
      "Loss in iteration 6887: 0.42820012328885715\n",
      "Theta: [-1.76048041  1.10257005  0.05560238]\n",
      "Loss in iteration 6888: 0.42819680316740866\n",
      "Theta: [-1.76058085  1.10263967  0.05559979]\n",
      "Loss in iteration 6889: 0.42819348418587994\n",
      "Theta: [-1.76068128  1.10270928  0.05559719]\n",
      "Loss in iteration 6890: 0.42819016634379486\n",
      "Theta: [-1.76078168  1.10277887  0.0555946 ]\n",
      "Loss in iteration 6891: 0.4281868496406775\n",
      "Theta: [-1.76088207  1.10284846  0.05559201]\n",
      "Loss in iteration 6892: 0.4281835340760521\n",
      "Theta: [-1.76098244  1.10291803  0.05558942]\n",
      "Loss in iteration 6893: 0.4281802196494431\n",
      "Theta: [-1.76108279  1.1029876   0.05558682]\n",
      "Loss in iteration 6894: 0.4281769063603752\n",
      "Theta: [-1.76118312  1.10305715  0.05558423]\n",
      "Loss in iteration 6895: 0.4281735942083735\n",
      "Theta: [-1.76128344  1.10312669  0.05558164]\n",
      "Loss in iteration 6896: 0.42817028319296313\n",
      "Theta: [-1.76138374  1.10319622  0.05557905]\n",
      "Loss in iteration 6897: 0.4281669733136694\n",
      "Theta: [-1.76148402  1.10326574  0.05557646]\n",
      "Loss in iteration 6898: 0.4281636645700184\n",
      "Theta: [-1.76158428  1.10333524  0.05557387]\n",
      "Loss in iteration 6899: 0.4281603569615358\n",
      "Theta: [-1.76168453  1.10340474  0.05557128]\n",
      "Loss in iteration 6900: 0.4281570504877479\n",
      "Theta: [-1.76178475  1.10347422  0.05556869]\n",
      "Loss in iteration 6901: 0.42815374514818116\n",
      "Theta: [-1.76188496  1.1035437   0.0555661 ]\n",
      "Loss in iteration 6902: 0.428150440942362\n",
      "Theta: [-1.76198516  1.10361316  0.05556351]\n",
      "Loss in iteration 6903: 0.42814713786981756\n",
      "Theta: [-1.76208533  1.10368261  0.05556092]\n",
      "Loss in iteration 6904: 0.428143835930075\n",
      "Theta: [-1.76218549  1.10375205  0.05555833]\n",
      "Loss in iteration 6905: 0.42814053512266165\n",
      "Theta: [-1.76228563  1.10382148  0.05555574]\n",
      "Loss in iteration 6906: 0.4281372354471052\n",
      "Theta: [-1.76238575  1.1038909   0.05555316]\n",
      "Loss in iteration 6907: 0.42813393690293333\n",
      "Theta: [-1.76248585  1.10396031  0.05555057]\n",
      "Loss in iteration 6908: 0.4281306394896744\n",
      "Theta: [-1.76258594  1.1040297   0.05554798]\n",
      "Loss in iteration 6909: 0.4281273432068564\n",
      "Theta: [-1.762686    1.10409909  0.05554539]\n",
      "Loss in iteration 6910: 0.42812404805400844\n",
      "Theta: [-1.76278605  1.10416846  0.05554281]\n",
      "Loss in iteration 6911: 0.4281207540306589\n",
      "Theta: [-1.76288609  1.10423783  0.05554022]\n",
      "Loss in iteration 6912: 0.4281174611363372\n",
      "Theta: [-1.7629861   1.10430718  0.05553763]\n",
      "Loss in iteration 6913: 0.4281141693705724\n",
      "Theta: [-1.7630861   1.10437652  0.05553505]\n",
      "Loss in iteration 6914: 0.42811087873289394\n",
      "Theta: [-1.76318608  1.10444585  0.05553246]\n",
      "Loss in iteration 6915: 0.428107589222832\n",
      "Theta: [-1.76328604  1.10451516  0.05552987]\n",
      "Loss in iteration 6916: 0.4281043008399164\n",
      "Theta: [-1.76338598  1.10458447  0.05552729]\n",
      "Loss in iteration 6917: 0.4281010135836773\n",
      "Theta: [-1.76348591  1.10465377  0.0555247 ]\n",
      "Loss in iteration 6918: 0.42809772745364527\n",
      "Theta: [-1.76358582  1.10472305  0.05552212]\n",
      "Loss in iteration 6919: 0.42809444244935113\n",
      "Theta: [-1.76368571  1.10479233  0.05551953]\n",
      "Loss in iteration 6920: 0.4280911585703258\n",
      "Theta: [-1.76378558  1.10486159  0.05551695]\n",
      "Loss in iteration 6921: 0.42808787581610047\n",
      "Theta: [-1.76388544  1.10493084  0.05551437]\n",
      "Loss in iteration 6922: 0.42808459418620665\n",
      "Theta: [-1.76398528  1.10500008  0.05551178]\n",
      "Loss in iteration 6923: 0.4280813136801762\n",
      "Theta: [-1.7640851   1.10506931  0.0555092 ]\n",
      "Loss in iteration 6924: 0.42807803429754065\n",
      "Theta: [-1.7641849   1.10513853  0.05550662]\n",
      "Loss in iteration 6925: 0.4280747560378326\n",
      "Theta: [-1.76428469  1.10520773  0.05550403]\n",
      "Loss in iteration 6926: 0.428071478900584\n",
      "Theta: [-1.76438446  1.10527693  0.05550145]\n",
      "Loss in iteration 6927: 0.42806820288532776\n",
      "Theta: [-1.76448421  1.10534612  0.05549887]\n",
      "Loss in iteration 6928: 0.42806492799159684\n",
      "Theta: [-1.76458394  1.10541529  0.05549629]\n",
      "Loss in iteration 6929: 0.42806165421892417\n",
      "Theta: [-1.76468365  1.10548445  0.0554937 ]\n",
      "Loss in iteration 6930: 0.42805838156684317\n",
      "Theta: [-1.76478335  1.1055536   0.05549112]\n",
      "Loss in iteration 6931: 0.4280551100348876\n",
      "Theta: [-1.76488303  1.10562274  0.05548854]\n",
      "Loss in iteration 6932: 0.4280518396225909\n",
      "Theta: [-1.76498269  1.10569187  0.05548596]\n",
      "Loss in iteration 6933: 0.42804857032948745\n",
      "Theta: [-1.76508234  1.10576099  0.05548338]\n",
      "Loss in iteration 6934: 0.4280453021551115\n",
      "Theta: [-1.76518197  1.1058301   0.0554808 ]\n",
      "Loss in iteration 6935: 0.4280420350989975\n",
      "Theta: [-1.76528157  1.1058992   0.05547822]\n",
      "Loss in iteration 6936: 0.4280387691606804\n",
      "Theta: [-1.76538117  1.10596828  0.05547564]\n",
      "Loss in iteration 6937: 0.428035504339695\n",
      "Theta: [-1.76548074  1.10603736  0.05547306]\n",
      "Loss in iteration 6938: 0.4280322406355765\n",
      "Theta: [-1.7655803   1.10610642  0.05547048]\n",
      "Loss in iteration 6939: 0.4280289780478606\n",
      "Theta: [-1.76567984  1.10617547  0.0554679 ]\n",
      "Loss in iteration 6940: 0.42802571657608274\n",
      "Theta: [-1.76577936  1.10624451  0.05546532]\n",
      "Loss in iteration 6941: 0.42802245621977925\n",
      "Theta: [-1.76587886  1.10631354  0.05546275]\n",
      "Loss in iteration 6942: 0.4280191969784859\n",
      "Theta: [-1.76597835  1.10638256  0.05546017]\n",
      "Loss in iteration 6943: 0.42801593885173955\n",
      "Theta: [-1.76607782  1.10645157  0.05545759]\n",
      "Loss in iteration 6944: 0.4280126818390764\n",
      "Theta: [-1.76617727  1.10652057  0.05545501]\n",
      "Loss in iteration 6945: 0.42800942594003366\n",
      "Theta: [-1.7662767   1.10658955  0.05545244]\n",
      "Loss in iteration 6946: 0.4280061711541483\n",
      "Theta: [-1.76637612  1.10665853  0.05544986]\n",
      "Loss in iteration 6947: 0.42800291748095765\n",
      "Theta: [-1.76647552  1.10672749  0.05544728]\n",
      "Loss in iteration 6948: 0.42799966491999947\n",
      "Theta: [-1.7665749   1.10679644  0.0554447 ]\n",
      "Loss in iteration 6949: 0.4279964134708113\n",
      "Theta: [-1.76667426  1.10686538  0.05544213]\n",
      "Loss in iteration 6950: 0.42799316313293156\n",
      "Theta: [-1.76677361  1.10693432  0.05543955]\n",
      "Loss in iteration 6951: 0.42798991390589824\n",
      "Theta: [-1.76687294  1.10700324  0.05543698]\n",
      "Loss in iteration 6952: 0.42798666578925\n",
      "Theta: [-1.76697225  1.10707214  0.0554344 ]\n",
      "Loss in iteration 6953: 0.42798341878252566\n",
      "Theta: [-1.76707154  1.10714104  0.05543183]\n",
      "Loss in iteration 6954: 0.4279801728852642\n",
      "Theta: [-1.76717082  1.10720993  0.05542925]\n",
      "Loss in iteration 6955: 0.42797692809700455\n",
      "Theta: [-1.76727008  1.1072788   0.05542668]\n",
      "Loss in iteration 6956: 0.4279736844172865\n",
      "Theta: [-1.76736932  1.10734767  0.0554241 ]\n",
      "Loss in iteration 6957: 0.4279704418456497\n",
      "Theta: [-1.76746854  1.10741652  0.05542153]\n",
      "Loss in iteration 6958: 0.4279672003816339\n",
      "Theta: [-1.76756775  1.10748536  0.05541896]\n",
      "Loss in iteration 6959: 0.42796396002477943\n",
      "Theta: [-1.76766694  1.1075542   0.05541638]\n",
      "Loss in iteration 6960: 0.4279607207746266\n",
      "Theta: [-1.76776611  1.10762302  0.05541381]\n",
      "Loss in iteration 6961: 0.4279574826307161\n",
      "Theta: [-1.76786527  1.10769183  0.05541124]\n",
      "Loss in iteration 6962: 0.4279542455925886\n",
      "Theta: [-1.7679644   1.10776062  0.05540866]\n",
      "Loss in iteration 6963: 0.4279510096597856\n",
      "Theta: [-1.76806352  1.10782941  0.05540609]\n",
      "Loss in iteration 6964: 0.4279477748318478\n",
      "Theta: [-1.76816262  1.10789819  0.05540352]\n",
      "Loss in iteration 6965: 0.4279445411083174\n",
      "Theta: [-1.76826171  1.10796695  0.05540095]\n",
      "Loss in iteration 6966: 0.42794130848873574\n",
      "Theta: [-1.76836077  1.10803571  0.05539838]\n",
      "Loss in iteration 6967: 0.42793807697264497\n",
      "Theta: [-1.76845982  1.10810445  0.05539581]\n",
      "Loss in iteration 6968: 0.4279348465595873\n",
      "Theta: [-1.76855886  1.10817319  0.05539324]\n",
      "Loss in iteration 6969: 0.4279316172491053\n",
      "Theta: [-1.76865787  1.10824191  0.05539066]\n",
      "Loss in iteration 6970: 0.42792838904074154\n",
      "Theta: [-1.76875687  1.10831062  0.05538809]\n",
      "Loss in iteration 6971: 0.42792516193403907\n",
      "Theta: [-1.76885585  1.10837932  0.05538552]\n",
      "Loss in iteration 6972: 0.427921935928541\n",
      "Theta: [-1.76895481  1.10844801  0.05538295]\n",
      "Loss in iteration 6973: 0.4279187110237907\n",
      "Theta: [-1.76905375  1.10851668  0.05538039]\n",
      "Loss in iteration 6974: 0.427915487219332\n",
      "Theta: [-1.76915268  1.10858535  0.05537782]\n",
      "Loss in iteration 6975: 0.42791226451470854\n",
      "Theta: [-1.76925159  1.10865401  0.05537525]\n",
      "Loss in iteration 6976: 0.4279090429094644\n",
      "Theta: [-1.76935048  1.10872265  0.05537268]\n",
      "Loss in iteration 6977: 0.42790582240314395\n",
      "Theta: [-1.76944936  1.10879128  0.05537011]\n",
      "Loss in iteration 6978: 0.4279026029952919\n",
      "Theta: [-1.76954822  1.10885991  0.05536754]\n",
      "Loss in iteration 6979: 0.42789938468545297\n",
      "Theta: [-1.76964706  1.10892852  0.05536497]\n",
      "Loss in iteration 6980: 0.4278961674731719\n",
      "Theta: [-1.76974588  1.10899712  0.05536241]\n",
      "Loss in iteration 6981: 0.42789295135799416\n",
      "Theta: [-1.76984469  1.10906571  0.05535984]\n",
      "Loss in iteration 6982: 0.4278897363394652\n",
      "Theta: [-1.76994347  1.10913429  0.05535727]\n",
      "Loss in iteration 6983: 0.4278865224171307\n",
      "Theta: [-1.77004225  1.10920286  0.05535471]\n",
      "Loss in iteration 6984: 0.4278833095905366\n",
      "Theta: [-1.770141    1.10927141  0.05535214]\n",
      "Loss in iteration 6985: 0.4278800978592291\n",
      "Theta: [-1.77023974  1.10933996  0.05534957]\n",
      "Loss in iteration 6986: 0.42787688722275463\n",
      "Theta: [-1.77033845  1.1094085   0.05534701]\n",
      "Loss in iteration 6987: 0.4278736776806595\n",
      "Theta: [-1.77043716  1.10947702  0.05534444]\n",
      "Loss in iteration 6988: 0.42787046923249084\n",
      "Theta: [-1.77053584  1.10954553  0.05534188]\n",
      "Loss in iteration 6989: 0.42786726187779556\n",
      "Theta: [-1.77063451  1.10961404  0.05533931]\n",
      "Loss in iteration 6990: 0.42786405561612123\n",
      "Theta: [-1.77073316  1.10968253  0.05533675]\n",
      "Loss in iteration 6991: 0.427860850447015\n",
      "Theta: [-1.77083179  1.10975101  0.05533418]\n",
      "Loss in iteration 6992: 0.42785764637002494\n",
      "Theta: [-1.7709304   1.10981948  0.05533162]\n",
      "Loss in iteration 6993: 0.4278544433846988\n",
      "Theta: [-1.771029    1.10988794  0.05532906]\n",
      "Loss in iteration 6994: 0.42785124149058484\n",
      "Theta: [-1.77112758  1.10995639  0.05532649]\n",
      "Loss in iteration 6995: 0.4278480406872317\n",
      "Theta: [-1.77122614  1.11002482  0.05532393]\n",
      "Loss in iteration 6996: 0.42784484097418773\n",
      "Theta: [-1.77132469  1.11009325  0.05532137]\n",
      "Loss in iteration 6997: 0.42784164235100214\n",
      "Theta: [-1.77142322  1.11016166  0.0553188 ]\n",
      "Loss in iteration 6998: 0.4278384448172239\n",
      "Theta: [-1.77152173  1.11023007  0.05531624]\n",
      "Loss in iteration 6999: 0.42783524837240244\n",
      "Theta: [-1.77162022  1.11029846  0.05531368]\n",
      "Loss in iteration 7000: 0.4278320530160872\n",
      "Theta: [-1.7717187   1.11036684  0.05531112]\n",
      "Loss in iteration 7001: 0.42782885874782794\n",
      "Theta: [-1.77181716  1.11043521  0.05530856]\n",
      "Loss in iteration 7002: 0.4278256655671748\n",
      "Theta: [-1.7719156   1.11050358  0.05530599]\n",
      "Loss in iteration 7003: 0.4278224734736781\n",
      "Theta: [-1.77201403  1.11057192  0.05530343]\n",
      "Loss in iteration 7004: 0.42781928246688805\n",
      "Theta: [-1.77211243  1.11064026  0.05530087]\n",
      "Loss in iteration 7005: 0.42781609254635583\n",
      "Theta: [-1.77221082  1.11070859  0.05529831]\n",
      "Loss in iteration 7006: 0.4278129037116319\n",
      "Theta: [-1.7723092   1.11077691  0.05529575]\n",
      "Loss in iteration 7007: 0.4278097159622677\n",
      "Theta: [-1.77240755  1.11084521  0.05529319]\n",
      "Loss in iteration 7008: 0.42780652929781454\n",
      "Theta: [-1.77250589  1.11091351  0.05529063]\n",
      "Loss in iteration 7009: 0.4278033437178238\n",
      "Theta: [-1.77260421  1.11098179  0.05528807]\n",
      "Loss in iteration 7010: 0.4278001592218477\n",
      "Theta: [-1.77270251  1.11105007  0.05528551]\n",
      "Loss in iteration 7011: 0.4277969758094382\n",
      "Theta: [-1.7728008   1.11111833  0.05528295]\n",
      "Loss in iteration 7012: 0.42779379348014746\n",
      "Theta: [-1.77289907  1.11118658  0.0552804 ]\n",
      "Loss in iteration 7013: 0.42779061223352804\n",
      "Theta: [-1.77299732  1.11125482  0.05527784]\n",
      "Loss in iteration 7014: 0.42778743206913267\n",
      "Theta: [-1.77309556  1.11132305  0.05527528]\n",
      "Loss in iteration 7015: 0.42778425298651435\n",
      "Theta: [-1.77319377  1.11139127  0.05527272]\n",
      "Loss in iteration 7016: 0.4277810749852262\n",
      "Theta: [-1.77329198  1.11145948  0.05527016]\n",
      "Loss in iteration 7017: 0.42777789806482197\n",
      "Theta: [-1.77339016  1.11152768  0.05526761]\n",
      "Loss in iteration 7018: 0.4277747222248546\n",
      "Theta: [-1.77348832  1.11159586  0.05526505]\n",
      "Loss in iteration 7019: 0.42777154746487867\n",
      "Theta: [-1.77358647  1.11166404  0.05526249]\n",
      "Loss in iteration 7020: 0.42776837378444776\n",
      "Theta: [-1.7736846   1.1117322   0.05525994]\n",
      "Loss in iteration 7021: 0.4277652011831164\n",
      "Theta: [-1.77378272  1.11180036  0.05525738]\n",
      "Loss in iteration 7022: 0.42776202966043914\n",
      "Theta: [-1.77388082  1.1118685   0.05525483]\n",
      "Loss in iteration 7023: 0.4277588592159707\n",
      "Theta: [-1.7739789   1.11193663  0.05525227]\n",
      "Loss in iteration 7024: 0.4277556898492661\n",
      "Theta: [-1.77407696  1.11200475  0.05524972]\n",
      "Loss in iteration 7025: 0.4277525215598804\n",
      "Theta: [-1.77417501  1.11207286  0.05524716]\n",
      "Loss in iteration 7026: 0.42774935434736916\n",
      "Theta: [-1.77427303  1.11214096  0.05524461]\n",
      "Loss in iteration 7027: 0.4277461882112879\n",
      "Theta: [-1.77437104  1.11220905  0.05524205]\n",
      "Loss in iteration 7028: 0.4277430231511928\n",
      "Theta: [-1.77446904  1.11227713  0.0552395 ]\n",
      "Loss in iteration 7029: 0.4277398591666396\n",
      "Theta: [-1.77456702  1.1123452   0.05523694]\n",
      "Loss in iteration 7030: 0.42773669625718475\n",
      "Theta: [-1.77466498  1.11241325  0.05523439]\n",
      "Loss in iteration 7031: 0.4277335344223848\n",
      "Theta: [-1.77476292  1.1124813   0.05523184]\n",
      "Loss in iteration 7032: 0.4277303736617965\n",
      "Theta: [-1.77486084  1.11254933  0.05522928]\n",
      "Loss in iteration 7033: 0.4277272139749771\n",
      "Theta: [-1.77495875  1.11261736  0.05522673]\n",
      "Loss in iteration 7034: 0.4277240553614833\n",
      "Theta: [-1.77505664  1.11268537  0.05522418]\n",
      "Loss in iteration 7035: 0.4277208978208729\n",
      "Theta: [-1.77515452  1.11275337  0.05522163]\n",
      "Loss in iteration 7036: 0.4277177413527034\n",
      "Theta: [-1.77525237  1.11282136  0.05521908]\n",
      "Loss in iteration 7037: 0.42771458595653283\n",
      "Theta: [-1.77535021  1.11288934  0.05521652]\n",
      "Loss in iteration 7038: 0.42771143163191894\n",
      "Theta: [-1.77544804  1.11295731  0.05521397]\n",
      "Loss in iteration 7039: 0.42770827837842057\n",
      "Theta: [-1.77554584  1.11302527  0.05521142]\n",
      "Loss in iteration 7040: 0.4277051261955959\n",
      "Theta: [-1.77564363  1.11309322  0.05520887]\n",
      "Loss in iteration 7041: 0.4277019750830037\n",
      "Theta: [-1.7757414   1.11316116  0.05520632]\n",
      "Loss in iteration 7042: 0.4276988250402032\n",
      "Theta: [-1.77583916  1.11322908  0.05520377]\n",
      "Loss in iteration 7043: 0.4276956760667532\n",
      "Theta: [-1.77593689  1.113297    0.05520122]\n",
      "Loss in iteration 7044: 0.42769252816221337\n",
      "Theta: [-1.77603461  1.11336491  0.05519867]\n",
      "Loss in iteration 7045: 0.42768938132614354\n",
      "Theta: [-1.77613232  1.1134328   0.05519612]\n",
      "Loss in iteration 7046: 0.42768623555810314\n",
      "Theta: [-1.77623     1.11350068  0.05519357]\n",
      "Loss in iteration 7047: 0.42768309085765277\n",
      "Theta: [-1.77632767  1.11356855  0.05519102]\n",
      "Loss in iteration 7048: 0.4276799472243523\n",
      "Theta: [-1.77642532  1.11363642  0.05518848]\n",
      "Loss in iteration 7049: 0.42767680465776253\n",
      "Theta: [-1.77652296  1.11370427  0.05518593]\n",
      "Loss in iteration 7050: 0.42767366315744404\n",
      "Theta: [-1.77662058  1.11377211  0.05518338]\n",
      "Loss in iteration 7051: 0.4276705227229579\n",
      "Theta: [-1.77671818  1.11383994  0.05518083]\n",
      "Loss in iteration 7052: 0.42766738335386534\n",
      "Theta: [-1.77681576  1.11390775  0.05517828]\n",
      "Loss in iteration 7053: 0.4276642450497274\n",
      "Theta: [-1.77691333  1.11397556  0.05517574]\n",
      "Loss in iteration 7054: 0.4276611078101063\n",
      "Theta: [-1.77701088  1.11404336  0.05517319]\n",
      "Loss in iteration 7055: 0.4276579716345635\n",
      "Theta: [-1.77710841  1.11411115  0.05517064]\n",
      "Loss in iteration 7056: 0.4276548365226611\n",
      "Theta: [-1.77720592  1.11417892  0.0551681 ]\n",
      "Loss in iteration 7057: 0.4276517024739615\n",
      "Theta: [-1.77730342  1.11424669  0.05516555]\n",
      "Loss in iteration 7058: 0.42764856948802715\n",
      "Theta: [-1.7774009   1.11431444  0.05516301]\n",
      "Loss in iteration 7059: 0.42764543756442064\n",
      "Theta: [-1.77749837  1.11438218  0.05516046]\n",
      "Loss in iteration 7060: 0.4276423067027053\n",
      "Theta: [-1.77759581  1.11444991  0.05515792]\n",
      "Loss in iteration 7061: 0.42763917690244385\n",
      "Theta: [-1.77769324  1.11451764  0.05515537]\n",
      "Loss in iteration 7062: 0.42763604816319983\n",
      "Theta: [-1.77779066  1.11458535  0.05515283]\n",
      "Loss in iteration 7063: 0.4276329204845368\n",
      "Theta: [-1.77788805  1.11465305  0.05515028]\n",
      "Loss in iteration 7064: 0.42762979386601896\n",
      "Theta: [-1.77798543  1.11472074  0.05514774]\n",
      "Loss in iteration 7065: 0.4276266683072098\n",
      "Theta: [-1.77808279  1.11478841  0.05514519]\n",
      "Loss in iteration 7066: 0.4276235438076739\n",
      "Theta: [-1.77818014  1.11485608  0.05514265]\n",
      "Loss in iteration 7067: 0.4276204203669757\n",
      "Theta: [-1.77827747  1.11492374  0.05514011]\n",
      "Loss in iteration 7068: 0.4276172979846797\n",
      "Theta: [-1.77837478  1.11499139  0.05513756]\n",
      "Loss in iteration 7069: 0.427614176660351\n",
      "Theta: [-1.77847207  1.11505902  0.05513502]\n",
      "Loss in iteration 7070: 0.4276110563935545\n",
      "Theta: [-1.77856935  1.11512665  0.05513248]\n",
      "Loss in iteration 7071: 0.4276079371838559\n",
      "Theta: [-1.77866661  1.11519426  0.05512994]\n",
      "Loss in iteration 7072: 0.42760481903082054\n",
      "Theta: [-1.77876385  1.11526186  0.0551274 ]\n",
      "Loss in iteration 7073: 0.4276017019340141\n",
      "Theta: [-1.77886108  1.11532946  0.05512485]\n",
      "Loss in iteration 7074: 0.4275985858930028\n",
      "Theta: [-1.77895829  1.11539704  0.05512231]\n",
      "Loss in iteration 7075: 0.4275954709073526\n",
      "Theta: [-1.77905548  1.11546461  0.05511977]\n",
      "Loss in iteration 7076: 0.42759235697663023\n",
      "Theta: [-1.77915265  1.11553217  0.05511723]\n",
      "Loss in iteration 7077: 0.42758924410040217\n",
      "Theta: [-1.77924981  1.11559972  0.05511469]\n",
      "Loss in iteration 7078: 0.42758613227823533\n",
      "Theta: [-1.77934695  1.11566726  0.05511215]\n",
      "Loss in iteration 7079: 0.4275830215096966\n",
      "Theta: [-1.77944408  1.11573478  0.05510961]\n",
      "Loss in iteration 7080: 0.42757991179435345\n",
      "Theta: [-1.77954119  1.1158023   0.05510707]\n",
      "Loss in iteration 7081: 0.4275768031317735\n",
      "Theta: [-1.77963828  1.11586981  0.05510453]\n",
      "Loss in iteration 7082: 0.4275736955215242\n",
      "Theta: [-1.77973535  1.1159373   0.05510199]\n",
      "Loss in iteration 7083: 0.4275705889631736\n",
      "Theta: [-1.77983241  1.11600479  0.05509945]\n",
      "Loss in iteration 7084: 0.4275674834562899\n",
      "Theta: [-1.77992945  1.11607226  0.05509692]\n",
      "Loss in iteration 7085: 0.4275643790004417\n",
      "Theta: [-1.78002647  1.11613973  0.05509438]\n",
      "Loss in iteration 7086: 0.42756127559519713\n",
      "Theta: [-1.78012348  1.11620718  0.05509184]\n",
      "Loss in iteration 7087: 0.4275581732401252\n",
      "Theta: [-1.78022046  1.11627462  0.0550893 ]\n",
      "Loss in iteration 7088: 0.42755507193479503\n",
      "Theta: [-1.78031744  1.11634206  0.05508677]\n",
      "Loss in iteration 7089: 0.42755197167877573\n",
      "Theta: [-1.78041439  1.11640948  0.05508423]\n",
      "Loss in iteration 7090: 0.42754887247163675\n",
      "Theta: [-1.78051133  1.11647689  0.05508169]\n",
      "Loss in iteration 7091: 0.42754577431294793\n",
      "Theta: [-1.78060825  1.11654429  0.05507916]\n",
      "Loss in iteration 7092: 0.42754267720227884\n",
      "Theta: [-1.78070516  1.11661168  0.05507662]\n",
      "Loss in iteration 7093: 0.4275395811391999\n",
      "Theta: [-1.78080204  1.11667905  0.05507408]\n",
      "Loss in iteration 7094: 0.4275364861232812\n",
      "Theta: [-1.78089891  1.11674642  0.05507155]\n",
      "Loss in iteration 7095: 0.42753339215409336\n",
      "Theta: [-1.78099577  1.11681378  0.05506901]\n",
      "Loss in iteration 7096: 0.427530299231207\n",
      "Theta: [-1.7810926   1.11688113  0.05506648]\n",
      "Loss in iteration 7097: 0.4275272073541931\n",
      "Theta: [-1.78118942  1.11694846  0.05506394]\n",
      "Loss in iteration 7098: 0.42752411652262295\n",
      "Theta: [-1.78128623  1.11701579  0.05506141]\n",
      "Loss in iteration 7099: 0.4275210267360679\n",
      "Theta: [-1.78138301  1.1170831   0.05505887]\n",
      "Loss in iteration 7100: 0.42751793799409965\n",
      "Theta: [-1.78147978  1.1171504   0.05505634]\n",
      "Loss in iteration 7101: 0.4275148502962896\n",
      "Theta: [-1.78157654  1.1172177   0.05505381]\n",
      "Loss in iteration 7102: 0.42751176364221005\n",
      "Theta: [-1.78167327  1.11728498  0.05505127]\n",
      "Loss in iteration 7103: 0.4275086780314333\n",
      "Theta: [-1.78176999  1.11735225  0.05504874]\n",
      "Loss in iteration 7104: 0.4275055934635318\n",
      "Theta: [-1.78186669  1.11741951  0.05504621]\n",
      "Loss in iteration 7105: 0.4275025099380778\n",
      "Theta: [-1.78196338  1.11748676  0.05504367]\n",
      "Loss in iteration 7106: 0.42749942745464475\n",
      "Theta: [-1.78206005  1.117554    0.05504114]\n",
      "Loss in iteration 7107: 0.42749634601280556\n",
      "Theta: [-1.7821567   1.11762123  0.05503861]\n",
      "Loss in iteration 7108: 0.42749326561213313\n",
      "Theta: [-1.78225333  1.11768845  0.05503608]\n",
      "Loss in iteration 7109: 0.42749018625220153\n",
      "Theta: [-1.78234995  1.11775566  0.05503355]\n",
      "Loss in iteration 7110: 0.4274871079325841\n",
      "Theta: [-1.78244655  1.11782285  0.05503102]\n",
      "Loss in iteration 7111: 0.427484030652855\n",
      "Theta: [-1.78254314  1.11789004  0.05502848]\n",
      "Loss in iteration 7112: 0.4274809544125881\n",
      "Theta: [-1.7826397   1.11795721  0.05502595]\n",
      "Loss in iteration 7113: 0.4274778792113581\n",
      "Theta: [-1.78273625  1.11802438  0.05502342]\n",
      "Loss in iteration 7114: 0.42747480504873936\n",
      "Theta: [-1.78283279  1.11809153  0.05502089]\n",
      "Loss in iteration 7115: 0.4274717319243067\n",
      "Theta: [-1.78292931  1.11815868  0.05501836]\n",
      "Loss in iteration 7116: 0.4274686598376352\n",
      "Theta: [-1.78302581  1.11822581  0.05501583]\n",
      "Loss in iteration 7117: 0.4274655887883001\n",
      "Theta: [-1.78312229  1.11829293  0.0550133 ]\n",
      "Loss in iteration 7118: 0.42746251877587654\n",
      "Theta: [-1.78321876  1.11836004  0.05501078]\n",
      "Loss in iteration 7119: 0.42745944979994044\n",
      "Theta: [-1.78331521  1.11842715  0.05500825]\n",
      "Loss in iteration 7120: 0.42745638186006735\n",
      "Theta: [-1.78341164  1.11849424  0.05500572]\n",
      "Loss in iteration 7121: 0.42745331495583355\n",
      "Theta: [-1.78350806  1.11856132  0.05500319]\n",
      "Loss in iteration 7122: 0.4274502490868153\n",
      "Theta: [-1.78360445  1.11862839  0.05500066]\n",
      "Loss in iteration 7123: 0.42744718425258904\n",
      "Theta: [-1.78370084  1.11869544  0.05499813]\n",
      "Loss in iteration 7124: 0.4274441204527315\n",
      "Theta: [-1.7837972   1.11876249  0.05499561]\n",
      "Loss in iteration 7125: 0.42744105768681934\n",
      "Theta: [-1.78389355  1.11882953  0.05499308]\n",
      "Loss in iteration 7126: 0.42743799595442994\n",
      "Theta: [-1.78398989  1.11889656  0.05499055]\n",
      "Loss in iteration 7127: 0.42743493525514054\n",
      "Theta: [-1.7840862   1.11896357  0.05498803]\n",
      "Loss in iteration 7128: 0.4274318755885285\n",
      "Theta: [-1.7841825   1.11903058  0.0549855 ]\n",
      "Loss in iteration 7129: 0.42742881695417184\n",
      "Theta: [-1.78427878  1.11909757  0.05498298]\n",
      "Loss in iteration 7130: 0.4274257593516483\n",
      "Theta: [-1.78437505  1.11916456  0.05498045]\n",
      "Loss in iteration 7131: 0.42742270278053596\n",
      "Theta: [-1.7844713   1.11923153  0.05497792]\n",
      "Loss in iteration 7132: 0.4274196472404135\n",
      "Theta: [-1.78456753  1.11929849  0.0549754 ]\n",
      "Loss in iteration 7133: 0.42741659273085914\n",
      "Theta: [-1.78466375  1.11936545  0.05497287]\n",
      "Loss in iteration 7134: 0.4274135392514519\n",
      "Theta: [-1.78475994  1.11943239  0.05497035]\n",
      "Loss in iteration 7135: 0.42741048680177074\n",
      "Theta: [-1.78485613  1.11949932  0.05496783]\n",
      "Loss in iteration 7136: 0.42740743538139475\n",
      "Theta: [-1.78495229  1.11956624  0.0549653 ]\n",
      "Loss in iteration 7137: 0.4274043849899035\n",
      "Theta: [-1.78504844  1.11963315  0.05496278]\n",
      "Loss in iteration 7138: 0.4274013356268766\n",
      "Theta: [-1.78514457  1.11970005  0.05496025]\n",
      "Loss in iteration 7139: 0.42739828729189355\n",
      "Theta: [-1.78524069  1.11976694  0.05495773]\n",
      "Loss in iteration 7140: 0.42739523998453477\n",
      "Theta: [-1.78533679  1.11983382  0.05495521]\n",
      "Loss in iteration 7141: 0.42739219370438053\n",
      "Theta: [-1.78543287  1.11990069  0.05495269]\n",
      "Loss in iteration 7142: 0.42738914845101106\n",
      "Theta: [-1.78552893  1.11996754  0.05495016]\n",
      "Loss in iteration 7143: 0.4273861042240069\n",
      "Theta: [-1.78562498  1.12003439  0.05494764]\n",
      "Loss in iteration 7144: 0.4273830610229492\n",
      "Theta: [-1.78572101  1.12010123  0.05494512]\n",
      "Loss in iteration 7145: 0.42738001884741905\n",
      "Theta: [-1.78581703  1.12016805  0.0549426 ]\n",
      "Loss in iteration 7146: 0.42737697769699773\n",
      "Theta: [-1.78591303  1.12023487  0.05494008]\n",
      "Loss in iteration 7147: 0.42737393757126646\n",
      "Theta: [-1.78600901  1.12030167  0.05493756]\n",
      "Loss in iteration 7148: 0.42737089846980714\n",
      "Theta: [-1.78610498  1.12036847  0.05493504]\n",
      "Loss in iteration 7149: 0.42736786039220154\n",
      "Theta: [-1.78620092  1.12043525  0.05493252]\n",
      "Loss in iteration 7150: 0.42736482333803216\n",
      "Theta: [-1.78629686  1.12050202  0.05493   ]\n",
      "Loss in iteration 7151: 0.427361787306881\n",
      "Theta: [-1.78639277  1.12056878  0.05492748]\n",
      "Loss in iteration 7152: 0.42735875229833054\n",
      "Theta: [-1.78648867  1.12063554  0.05492496]\n",
      "Loss in iteration 7153: 0.42735571831196373\n",
      "Theta: [-1.78658455  1.12070228  0.05492244]\n",
      "Loss in iteration 7154: 0.42735268534736354\n",
      "Theta: [-1.78668042  1.12076901  0.05491992]\n",
      "Loss in iteration 7155: 0.4273496534041129\n",
      "Theta: [-1.78677627  1.12083573  0.0549174 ]\n",
      "Loss in iteration 7156: 0.42734662248179517\n",
      "Theta: [-1.7868721   1.12090244  0.05491488]\n",
      "Loss in iteration 7157: 0.42734359257999416\n",
      "Theta: [-1.78696791  1.12096914  0.05491236]\n",
      "Loss in iteration 7158: 0.42734056369829354\n",
      "Theta: [-1.78706371  1.12103582  0.05490984]\n",
      "Loss in iteration 7159: 0.42733753583627715\n",
      "Theta: [-1.78715949  1.1211025   0.05490733]\n",
      "Loss in iteration 7160: 0.42733450899352937\n",
      "Theta: [-1.78725526  1.12116917  0.05490481]\n",
      "Loss in iteration 7161: 0.4273314831696345\n",
      "Theta: [-1.78735101  1.12123583  0.05490229]\n",
      "Loss in iteration 7162: 0.42732845836417704\n",
      "Theta: [-1.78744674  1.12130247  0.05489978]\n",
      "Loss in iteration 7163: 0.4273254345767418\n",
      "Theta: [-1.78754246  1.12136911  0.05489726]\n",
      "Loss in iteration 7164: 0.4273224118069141\n",
      "Theta: [-1.78763816  1.12143573  0.05489474]\n",
      "Loss in iteration 7165: 0.4273193900542788\n",
      "Theta: [-1.78773384  1.12150235  0.05489223]\n",
      "Loss in iteration 7166: 0.4273163693184216\n",
      "Theta: [-1.78782951  1.12156895  0.05488971]\n",
      "Loss in iteration 7167: 0.4273133495989279\n",
      "Theta: [-1.78792516  1.12163555  0.0548872 ]\n",
      "Loss in iteration 7168: 0.4273103308953836\n",
      "Theta: [-1.78802079  1.12170213  0.05488468]\n",
      "Loss in iteration 7169: 0.4273073132073748\n",
      "Theta: [-1.78811641  1.1217687   0.05488217]\n",
      "Loss in iteration 7170: 0.4273042965344876\n",
      "Theta: [-1.78821201  1.12183526  0.05487965]\n",
      "Loss in iteration 7171: 0.4273012808763086\n",
      "Theta: [-1.78830759  1.12190182  0.05487714]\n",
      "Loss in iteration 7172: 0.42729826623242423\n",
      "Theta: [-1.78840316  1.12196836  0.05487462]\n",
      "Loss in iteration 7173: 0.42729525260242146\n",
      "Theta: [-1.78849871  1.12203489  0.05487211]\n",
      "Loss in iteration 7174: 0.4272922399858877\n",
      "Theta: [-1.78859424  1.12210141  0.0548696 ]\n",
      "Loss in iteration 7175: 0.42728922838240974\n",
      "Theta: [-1.78868976  1.12216792  0.05486708]\n",
      "Loss in iteration 7176: 0.4272862177915753\n",
      "Theta: [-1.78878526  1.12223442  0.05486457]\n",
      "Loss in iteration 7177: 0.4272832082129719\n",
      "Theta: [-1.78888074  1.1223009   0.05486206]\n",
      "Loss in iteration 7178: 0.4272801996461874\n",
      "Theta: [-1.78897621  1.12236738  0.05485955]\n",
      "Loss in iteration 7179: 0.4272771920908099\n",
      "Theta: [-1.78907166  1.12243385  0.05485703]\n",
      "Loss in iteration 7180: 0.42727418554642776\n",
      "Theta: [-1.78916709  1.12250031  0.05485452]\n",
      "Loss in iteration 7181: 0.4272711800126296\n",
      "Theta: [-1.78926251  1.12256675  0.05485201]\n",
      "Loss in iteration 7182: 0.42726817548900375\n",
      "Theta: [-1.78935791  1.12263319  0.0548495 ]\n",
      "Loss in iteration 7183: 0.4272651719751396\n",
      "Theta: [-1.7894533   1.12269962  0.05484699]\n",
      "Loss in iteration 7184: 0.42726216947062573\n",
      "Theta: [-1.78954867  1.12276603  0.05484448]\n",
      "Loss in iteration 7185: 0.42725916797505165\n",
      "Theta: [-1.78964402  1.12283244  0.05484197]\n",
      "Loss in iteration 7186: 0.42725616748800704\n",
      "Theta: [-1.78973935  1.12289883  0.05483946]\n",
      "Loss in iteration 7187: 0.42725316800908125\n",
      "Theta: [-1.78983467  1.12296521  0.05483695]\n",
      "Loss in iteration 7188: 0.42725016953786443\n",
      "Theta: [-1.78992997  1.12303159  0.05483444]\n",
      "Loss in iteration 7189: 0.4272471720739468\n",
      "Theta: [-1.79002526  1.12309795  0.05483193]\n",
      "Loss in iteration 7190: 0.42724417561691846\n",
      "Theta: [-1.79012053  1.1231643   0.05482942]\n",
      "Loss in iteration 7191: 0.4272411801663699\n",
      "Theta: [-1.79021578  1.12323064  0.05482691]\n",
      "Loss in iteration 7192: 0.42723818572189215\n",
      "Theta: [-1.79031102  1.12329698  0.0548244 ]\n",
      "Loss in iteration 7193: 0.4272351922830758\n",
      "Theta: [-1.79040624  1.1233633   0.05482189]\n",
      "Loss in iteration 7194: 0.427232199849512\n",
      "Theta: [-1.79050144  1.12342961  0.05481939]\n",
      "Loss in iteration 7195: 0.4272292084207923\n",
      "Theta: [-1.79059663  1.12349591  0.05481688]\n",
      "Loss in iteration 7196: 0.427226217996508\n",
      "Theta: [-1.7906918   1.1235622   0.05481437]\n",
      "Loss in iteration 7197: 0.42722322857625095\n",
      "Theta: [-1.79078695  1.12362848  0.05481186]\n",
      "Loss in iteration 7198: 0.4272202401596131\n",
      "Theta: [-1.79088209  1.12369474  0.05480936]\n",
      "Loss in iteration 7199: 0.42721725274618644\n",
      "Theta: [-1.79097721  1.123761    0.05480685]\n",
      "Loss in iteration 7200: 0.4272142663355634\n",
      "Theta: [-1.79107232  1.12382725  0.05480435]\n",
      "Loss in iteration 7201: 0.42721128092733673\n",
      "Theta: [-1.79116741  1.12389349  0.05480184]\n",
      "Loss in iteration 7202: 0.4272082965210987\n",
      "Theta: [-1.79126248  1.12395971  0.05479933]\n",
      "Loss in iteration 7203: 0.4272053131164426\n",
      "Theta: [-1.79135753  1.12402593  0.05479683]\n",
      "Loss in iteration 7204: 0.4272023307129615\n",
      "Theta: [-1.79145257  1.12409214  0.05479432]\n",
      "Loss in iteration 7205: 0.4271993493102487\n",
      "Theta: [-1.7915476   1.12415833  0.05479182]\n",
      "Loss in iteration 7206: 0.4271963689078976\n",
      "Theta: [-1.7916426   1.12422452  0.05478931]\n",
      "Loss in iteration 7207: 0.4271933895055023\n",
      "Theta: [-1.79173759  1.12429069  0.05478681]\n",
      "Loss in iteration 7208: 0.42719041110265643\n",
      "Theta: [-1.79183257  1.12435686  0.05478431]\n",
      "Loss in iteration 7209: 0.4271874336989541\n",
      "Theta: [-1.79192752  1.12442301  0.0547818 ]\n",
      "Loss in iteration 7210: 0.42718445729399007\n",
      "Theta: [-1.79202246  1.12448915  0.0547793 ]\n",
      "Loss in iteration 7211: 0.4271814818873584\n",
      "Theta: [-1.79211739  1.12455529  0.0547768 ]\n",
      "Loss in iteration 7212: 0.4271785074786541\n",
      "Theta: [-1.7922123   1.12462141  0.05477429]\n",
      "Loss in iteration 7213: 0.42717553406747194\n",
      "Theta: [-1.79230719  1.12468752  0.05477179]\n",
      "Loss in iteration 7214: 0.4271725616534073\n",
      "Theta: [-1.79240206  1.12475362  0.05476929]\n",
      "Loss in iteration 7215: 0.42716959023605516\n",
      "Theta: [-1.79249692  1.12481971  0.05476679]\n",
      "Loss in iteration 7216: 0.42716661981501153\n",
      "Theta: [-1.79259176  1.1248858   0.05476428]\n",
      "Loss in iteration 7217: 0.42716365038987175\n",
      "Theta: [-1.79268659  1.12495187  0.05476178]\n",
      "Loss in iteration 7218: 0.42716068196023194\n",
      "Theta: [-1.7927814   1.12501793  0.05475928]\n",
      "Loss in iteration 7219: 0.4271577145256883\n",
      "Theta: [-1.79287619  1.12508398  0.05475678]\n",
      "Loss in iteration 7220: 0.427154748085837\n",
      "Theta: [-1.79297097  1.12515002  0.05475428]\n",
      "Loss in iteration 7221: 0.42715178264027465\n",
      "Theta: [-1.79306573  1.12521604  0.05475178]\n",
      "Loss in iteration 7222: 0.42714881818859785\n",
      "Theta: [-1.79316047  1.12528206  0.05474928]\n",
      "Loss in iteration 7223: 0.4271458547304039\n",
      "Theta: [-1.7932552   1.12534807  0.05474678]\n",
      "Loss in iteration 7224: 0.42714289226528956\n",
      "Theta: [-1.79334991  1.12541407  0.05474428]\n",
      "Loss in iteration 7225: 0.42713993079285223\n",
      "Theta: [-1.79344461  1.12548006  0.05474178]\n",
      "Loss in iteration 7226: 0.42713697031268966\n",
      "Theta: [-1.79353929  1.12554603  0.05473928]\n",
      "Loss in iteration 7227: 0.4271340108243994\n",
      "Theta: [-1.79363395  1.125612    0.05473678]\n",
      "Loss in iteration 7228: 0.42713105232757925\n",
      "Theta: [-1.7937286   1.12567796  0.05473428]\n",
      "Loss in iteration 7229: 0.4271280948218276\n",
      "Theta: [-1.79382322  1.1257439   0.05473179]\n",
      "Loss in iteration 7230: 0.42712513830674276\n",
      "Theta: [-1.79391784  1.12580984  0.05472929]\n",
      "Loss in iteration 7231: 0.4271221827819229\n",
      "Theta: [-1.79401244  1.12587576  0.05472679]\n",
      "Loss in iteration 7232: 0.42711922824696713\n",
      "Theta: [-1.79410702  1.12594168  0.05472429]\n",
      "Loss in iteration 7233: 0.4271162747014742\n",
      "Theta: [-1.79420158  1.12600758  0.0547218 ]\n",
      "Loss in iteration 7234: 0.4271133221450431\n",
      "Theta: [-1.79429613  1.12607347  0.0547193 ]\n",
      "Loss in iteration 7235: 0.42711037057727347\n",
      "Theta: [-1.79439066  1.12613936  0.0547168 ]\n",
      "Loss in iteration 7236: 0.42710741999776447\n",
      "Theta: [-1.79448518  1.12620523  0.05471431]\n",
      "Loss in iteration 7237: 0.4271044704061158\n",
      "Theta: [-1.79457968  1.12627109  0.05471181]\n",
      "Loss in iteration 7238: 0.42710152180192784\n",
      "Theta: [-1.79467416  1.12633695  0.05470931]\n",
      "Loss in iteration 7239: 0.42709857418480013\n",
      "Theta: [-1.79476863  1.12640279  0.05470682]\n",
      "Loss in iteration 7240: 0.42709562755433333\n",
      "Theta: [-1.79486308  1.12646862  0.05470432]\n",
      "Loss in iteration 7241: 0.42709268191012784\n",
      "Theta: [-1.79495751  1.12653444  0.05470183]\n",
      "Loss in iteration 7242: 0.4270897372517841\n",
      "Theta: [-1.79505193  1.12660025  0.05469933]\n",
      "Loss in iteration 7243: 0.42708679357890317\n",
      "Theta: [-1.79514633  1.12666605  0.05469684]\n",
      "Loss in iteration 7244: 0.42708385089108625\n",
      "Theta: [-1.79524072  1.12673184  0.05469435]\n",
      "Loss in iteration 7245: 0.4270809091879346\n",
      "Theta: [-1.79533509  1.12679762  0.05469185]\n",
      "Loss in iteration 7246: 0.4270779684690494\n",
      "Theta: [-1.79542944  1.12686339  0.05468936]\n",
      "Loss in iteration 7247: 0.4270750287340326\n",
      "Theta: [-1.79552377  1.12692915  0.05468687]\n",
      "Loss in iteration 7248: 0.42707208998248597\n",
      "Theta: [-1.7956181   1.1269949   0.05468437]\n",
      "Loss in iteration 7249: 0.4270691522140115\n",
      "Theta: [-1.7957124   1.12706064  0.05468188]\n",
      "Loss in iteration 7250: 0.42706621542821166\n",
      "Theta: [-1.79580669  1.12712637  0.05467939]\n",
      "Loss in iteration 7251: 0.42706327962468876\n",
      "Theta: [-1.79590096  1.12719209  0.0546769 ]\n",
      "Loss in iteration 7252: 0.4270603448030452\n",
      "Theta: [-1.79599521  1.1272578   0.0546744 ]\n",
      "Loss in iteration 7253: 0.4270574109628842\n",
      "Theta: [-1.79608945  1.12732349  0.05467191]\n",
      "Loss in iteration 7254: 0.4270544781038088\n",
      "Theta: [-1.79618368  1.12738918  0.05466942]\n",
      "Loss in iteration 7255: 0.4270515462254218\n",
      "Theta: [-1.79627788  1.12745486  0.05466693]\n",
      "Loss in iteration 7256: 0.4270486153273271\n",
      "Theta: [-1.79637207  1.12752052  0.05466444]\n",
      "Loss in iteration 7257: 0.4270456854091282\n",
      "Theta: [-1.79646625  1.12758618  0.05466195]\n",
      "Loss in iteration 7258: 0.4270427564704286\n",
      "Theta: [-1.79656041  1.12765182  0.05465946]\n",
      "Loss in iteration 7259: 0.4270398285108328\n",
      "Theta: [-1.79665455  1.12771746  0.05465697]\n",
      "Loss in iteration 7260: 0.4270369015299446\n",
      "Theta: [-1.79674867  1.12778308  0.05465448]\n",
      "Loss in iteration 7261: 0.42703397552736844\n",
      "Theta: [-1.79684278  1.1278487   0.05465199]\n",
      "Loss in iteration 7262: 0.4270310505027093\n",
      "Theta: [-1.79693688  1.1279143   0.0546495 ]\n",
      "Loss in iteration 7263: 0.42702812645557153\n",
      "Theta: [-1.79703095  1.1279799   0.05464701]\n",
      "Loss in iteration 7264: 0.4270252033855602\n",
      "Theta: [-1.79712502  1.12804548  0.05464452]\n",
      "Loss in iteration 7265: 0.4270222812922805\n",
      "Theta: [-1.79721906  1.12811106  0.05464204]\n",
      "Loss in iteration 7266: 0.427019360175338\n",
      "Theta: [-1.79731309  1.12817662  0.05463955]\n",
      "Loss in iteration 7267: 0.4270164400343381\n",
      "Theta: [-1.7974071   1.12824217  0.05463706]\n",
      "Loss in iteration 7268: 0.4270135208688864\n",
      "Theta: [-1.7975011   1.12830771  0.05463457]\n",
      "Loss in iteration 7269: 0.42701060267858915\n",
      "Theta: [-1.79759508  1.12837325  0.05463209]\n",
      "Loss in iteration 7270: 0.4270076854630523\n",
      "Theta: [-1.79768904  1.12843877  0.0546296 ]\n",
      "Loss in iteration 7271: 0.4270047692218821\n",
      "Theta: [-1.79778299  1.12850428  0.05462711]\n",
      "Loss in iteration 7272: 0.4270018539546853\n",
      "Theta: [-1.79787692  1.12856978  0.05462463]\n",
      "Loss in iteration 7273: 0.4269989396610685\n",
      "Theta: [-1.79797084  1.12863527  0.05462214]\n",
      "Loss in iteration 7274: 0.42699602634063866\n",
      "Theta: [-1.79806474  1.12870075  0.05461965]\n",
      "Loss in iteration 7275: 0.4269931139930028\n",
      "Theta: [-1.79815862  1.12876623  0.05461717]\n",
      "Loss in iteration 7276: 0.4269902026177684\n",
      "Theta: [-1.79825249  1.12883169  0.05461468]\n",
      "Loss in iteration 7277: 0.4269872922145426\n",
      "Theta: [-1.79834634  1.12889714  0.0546122 ]\n",
      "Loss in iteration 7278: 0.42698438278293355\n",
      "Theta: [-1.79844017  1.12896258  0.05460971]\n",
      "Loss in iteration 7279: 0.4269814743225487\n",
      "Theta: [-1.79853399  1.12902801  0.05460723]\n",
      "Loss in iteration 7280: 0.4269785668329964\n",
      "Theta: [-1.79862779  1.12909342  0.05460475]\n",
      "Loss in iteration 7281: 0.4269756603138848\n",
      "Theta: [-1.79872158  1.12915883  0.05460226]\n",
      "Loss in iteration 7282: 0.42697275476482227\n",
      "Theta: [-1.79881535  1.12922423  0.05459978]\n",
      "Loss in iteration 7283: 0.4269698501854176\n",
      "Theta: [-1.79890911  1.12928962  0.0545973 ]\n",
      "Loss in iteration 7284: 0.42696694657527945\n",
      "Theta: [-1.79900284  1.129355    0.05459481]\n",
      "Loss in iteration 7285: 0.42696404393401716\n",
      "Theta: [-1.79909657  1.12942037  0.05459233]\n",
      "Loss in iteration 7286: 0.42696114226123943\n",
      "Theta: [-1.79919027  1.12948573  0.05458985]\n",
      "Loss in iteration 7287: 0.42695824155655615\n",
      "Theta: [-1.79928396  1.12955107  0.05458736]\n",
      "Loss in iteration 7288: 0.42695534181957684\n",
      "Theta: [-1.79937764  1.12961641  0.05458488]\n",
      "Loss in iteration 7289: 0.42695244304991115\n",
      "Theta: [-1.79947129  1.12968174  0.0545824 ]\n",
      "Loss in iteration 7290: 0.4269495452471691\n",
      "Theta: [-1.79956494  1.12974705  0.05457992]\n",
      "Loss in iteration 7291: 0.4269466484109609\n",
      "Theta: [-1.79965856  1.12981236  0.05457744]\n",
      "Loss in iteration 7292: 0.4269437525408966\n",
      "Theta: [-1.79975217  1.12987766  0.05457496]\n",
      "Loss in iteration 7293: 0.4269408576365874\n",
      "Theta: [-1.79984576  1.12994294  0.05457248]\n",
      "Loss in iteration 7294: 0.4269379636976436\n",
      "Theta: [-1.79993934  1.13000822  0.05457   ]\n",
      "Loss in iteration 7295: 0.4269350707236761\n",
      "Theta: [-1.8000329   1.13007348  0.05456752]\n",
      "Loss in iteration 7296: 0.4269321787142962\n",
      "Theta: [-1.80012645  1.13013874  0.05456504]\n",
      "Loss in iteration 7297: 0.42692928766911514\n",
      "Theta: [-1.80021998  1.13020398  0.05456256]\n",
      "Loss in iteration 7298: 0.4269263975877445\n",
      "Theta: [-1.80031349  1.13026922  0.05456008]\n",
      "Loss in iteration 7299: 0.4269235084697959\n",
      "Theta: [-1.80040699  1.13033444  0.0545576 ]\n",
      "Loss in iteration 7300: 0.4269206203148812\n",
      "Theta: [-1.80050047  1.13039966  0.05455512]\n",
      "Loss in iteration 7301: 0.4269177331226125\n",
      "Theta: [-1.80059393  1.13046486  0.05455264]\n",
      "Loss in iteration 7302: 0.42691484689260223\n",
      "Theta: [-1.80068738  1.13053006  0.05455017]\n",
      "Loss in iteration 7303: 0.4269119616244625\n",
      "Theta: [-1.80078082  1.13059524  0.05454769]\n",
      "Loss in iteration 7304: 0.42690907731780625\n",
      "Theta: [-1.80087423  1.13066041  0.05454521]\n",
      "Loss in iteration 7305: 0.42690619397224616\n",
      "Theta: [-1.80096763  1.13072558  0.05454273]\n",
      "Loss in iteration 7306: 0.42690331158739525\n",
      "Theta: [-1.80106102  1.13079073  0.05454026]\n",
      "Loss in iteration 7307: 0.4269004301628669\n",
      "Theta: [-1.80115439  1.13085587  0.05453778]\n",
      "Loss in iteration 7308: 0.4268975496982743\n",
      "Theta: [-1.80124774  1.13092101  0.0545353 ]\n",
      "Loss in iteration 7309: 0.42689467019323124\n",
      "Theta: [-1.80134108  1.13098613  0.05453283]\n",
      "Loss in iteration 7310: 0.4268917916473516\n",
      "Theta: [-1.8014344   1.13105124  0.05453035]\n",
      "Loss in iteration 7311: 0.4268889140602488\n",
      "Theta: [-1.8015277   1.13111634  0.05452788]\n",
      "Loss in iteration 7312: 0.4268860374315374\n",
      "Theta: [-1.80162099  1.13118143  0.0545254 ]\n",
      "Loss in iteration 7313: 0.4268831617608317\n",
      "Theta: [-1.80171427  1.13124652  0.05452293]\n",
      "Loss in iteration 7314: 0.4268802870477462\n",
      "Theta: [-1.80180752  1.13131159  0.05452045]\n",
      "Loss in iteration 7315: 0.4268774132918957\n",
      "Theta: [-1.80190076  1.13137665  0.05451798]\n",
      "Loss in iteration 7316: 0.42687454049289497\n",
      "Theta: [-1.80199399  1.1314417   0.0545155 ]\n",
      "Loss in iteration 7317: 0.4268716686503592\n",
      "Theta: [-1.8020872   1.13150674  0.05451303]\n",
      "Loss in iteration 7318: 0.42686879776390363\n",
      "Theta: [-1.80218039  1.13157177  0.05451055]\n",
      "Loss in iteration 7319: 0.42686592783314375\n",
      "Theta: [-1.80227357  1.13163679  0.05450808]\n",
      "Loss in iteration 7320: 0.4268630588576954\n",
      "Theta: [-1.80236673  1.1317018   0.05450561]\n",
      "Loss in iteration 7321: 0.426860190837174\n",
      "Theta: [-1.80245987  1.1317668   0.05450314]\n",
      "Loss in iteration 7322: 0.4268573237711958\n",
      "Theta: [-1.802553    1.13183179  0.05450066]\n",
      "Loss in iteration 7323: 0.42685445765937724\n",
      "Theta: [-1.80264612  1.13189677  0.05449819]\n",
      "Loss in iteration 7324: 0.4268515925013345\n",
      "Theta: [-1.80273921  1.13196174  0.05449572]\n",
      "Loss in iteration 7325: 0.4268487282966842\n",
      "Theta: [-1.8028323   1.1320267   0.05449325]\n",
      "Loss in iteration 7326: 0.42684586504504307\n",
      "Theta: [-1.80292536  1.13209165  0.05449078]\n",
      "Loss in iteration 7327: 0.4268430027460282\n",
      "Theta: [-1.80301841  1.13215659  0.0544883 ]\n",
      "Loss in iteration 7328: 0.42684014139925663\n",
      "Theta: [-1.80311144  1.13222152  0.05448583]\n",
      "Loss in iteration 7329: 0.426837281004346\n",
      "Theta: [-1.80320446  1.13228644  0.05448336]\n",
      "Loss in iteration 7330: 0.4268344215609134\n",
      "Theta: [-1.80329746  1.13235135  0.05448089]\n",
      "Loss in iteration 7331: 0.42683156306857684\n",
      "Theta: [-1.80339045  1.13241625  0.05447842]\n",
      "Loss in iteration 7332: 0.4268287055269541\n",
      "Theta: [-1.80348342  1.13248113  0.05447595]\n",
      "Loss in iteration 7333: 0.42682584893566333\n",
      "Theta: [-1.80357637  1.13254601  0.05447348]\n",
      "Loss in iteration 7334: 0.4268229932943229\n",
      "Theta: [-1.80366931  1.13261088  0.05447101]\n",
      "Loss in iteration 7335: 0.4268201386025509\n",
      "Theta: [-1.80376223  1.13267574  0.05446855]\n",
      "Loss in iteration 7336: 0.42681728485996645\n",
      "Theta: [-1.80385514  1.13274059  0.05446608]\n",
      "Loss in iteration 7337: 0.42681443206618824\n",
      "Theta: [-1.80394803  1.13280542  0.05446361]\n",
      "Loss in iteration 7338: 0.426811580220835\n",
      "Theta: [-1.8040409   1.13287025  0.05446114]\n",
      "Loss in iteration 7339: 0.42680872932352626\n",
      "Theta: [-1.80413376  1.13293507  0.05445867]\n",
      "Loss in iteration 7340: 0.42680587937388137\n",
      "Theta: [-1.80422661  1.13299988  0.05445621]\n",
      "Loss in iteration 7341: 0.4268030303715197\n",
      "Theta: [-1.80431943  1.13306467  0.05445374]\n",
      "Loss in iteration 7342: 0.42680018231606126\n",
      "Theta: [-1.80441224  1.13312946  0.05445127]\n",
      "Loss in iteration 7343: 0.4267973352071258\n",
      "Theta: [-1.80450504  1.13319424  0.0544488 ]\n",
      "Loss in iteration 7344: 0.42679448904433365\n",
      "Theta: [-1.80459782  1.133259    0.05444634]\n",
      "Loss in iteration 7345: 0.426791643827305\n",
      "Theta: [-1.80469058  1.13332376  0.05444387]\n",
      "Loss in iteration 7346: 0.4267887995556602\n",
      "Theta: [-1.80478333  1.13338851  0.05444141]\n",
      "Loss in iteration 7347: 0.4267859562290202\n",
      "Theta: [-1.80487606  1.13345324  0.05443894]\n",
      "Loss in iteration 7348: 0.4267831138470059\n",
      "Theta: [-1.80496878  1.13351797  0.05443647]\n",
      "Loss in iteration 7349: 0.4267802724092381\n",
      "Theta: [-1.80506148  1.13358268  0.05443401]\n",
      "Loss in iteration 7350: 0.42677743191533823\n",
      "Theta: [-1.80515416  1.13364739  0.05443154]\n",
      "Loss in iteration 7351: 0.4267745923649276\n",
      "Theta: [-1.80524683  1.13371209  0.05442908]\n",
      "Loss in iteration 7352: 0.42677175375762777\n",
      "Theta: [-1.80533948  1.13377677  0.05442662]\n",
      "Loss in iteration 7353: 0.4267689160930609\n",
      "Theta: [-1.80543212  1.13384145  0.05442415]\n",
      "Loss in iteration 7354: 0.4267660793708483\n",
      "Theta: [-1.80552474  1.13390611  0.05442169]\n",
      "Loss in iteration 7355: 0.42676324359061274\n",
      "Theta: [-1.80561734  1.13397077  0.05441922]\n",
      "Loss in iteration 7356: 0.4267604087519764\n",
      "Theta: [-1.80570993  1.13403541  0.05441676]\n",
      "Loss in iteration 7357: 0.4267575748545617\n",
      "Theta: [-1.80580251  1.13410005  0.0544143 ]\n",
      "Loss in iteration 7358: 0.42675474189799145\n",
      "Theta: [-1.80589506  1.13416467  0.05441184]\n",
      "Loss in iteration 7359: 0.42675190988188844\n",
      "Theta: [-1.80598761  1.13422929  0.05440937]\n",
      "Loss in iteration 7360: 0.42674907880587576\n",
      "Theta: [-1.80608013  1.13429389  0.05440691]\n",
      "Loss in iteration 7361: 0.4267462486695768\n",
      "Theta: [-1.80617264  1.13435849  0.05440445]\n",
      "Loss in iteration 7362: 0.4267434194726149\n",
      "Theta: [-1.80626514  1.13442307  0.05440199]\n",
      "Loss in iteration 7363: 0.4267405912146138\n",
      "Theta: [-1.80635761  1.13448765  0.05439953]\n",
      "Loss in iteration 7364: 0.4267377638951971\n",
      "Theta: [-1.80645008  1.13455221  0.05439707]\n",
      "Loss in iteration 7365: 0.4267349375139889\n",
      "Theta: [-1.80654252  1.13461677  0.05439461]\n",
      "Loss in iteration 7366: 0.4267321120706134\n",
      "Theta: [-1.80663496  1.13468131  0.05439215]\n",
      "Loss in iteration 7367: 0.426729287564695\n",
      "Theta: [-1.80672737  1.13474585  0.05438969]\n",
      "Loss in iteration 7368: 0.42672646399585806\n",
      "Theta: [-1.80681977  1.13481037  0.05438723]\n",
      "Loss in iteration 7369: 0.42672364136372765\n",
      "Theta: [-1.80691215  1.13487488  0.05438477]\n",
      "Loss in iteration 7370: 0.42672081966792824\n",
      "Theta: [-1.80700452  1.13493939  0.05438231]\n",
      "Loss in iteration 7371: 0.4267179989080852\n",
      "Theta: [-1.80709687  1.13500388  0.05437985]\n",
      "Loss in iteration 7372: 0.4267151790838237\n",
      "Theta: [-1.80718921  1.13506837  0.05437739]\n",
      "Loss in iteration 7373: 0.42671236019476927\n",
      "Theta: [-1.80728153  1.13513284  0.05437493]\n",
      "Loss in iteration 7374: 0.42670954224054747\n",
      "Theta: [-1.80737384  1.1351973   0.05437247]\n",
      "Loss in iteration 7375: 0.4267067252207841\n",
      "Theta: [-1.80746613  1.13526176  0.05437001]\n",
      "Loss in iteration 7376: 0.42670390913510525\n",
      "Theta: [-1.8075584   1.1353262   0.05436756]\n",
      "Loss in iteration 7377: 0.42670109398313705\n",
      "Theta: [-1.80765066  1.13539063  0.0543651 ]\n",
      "Loss in iteration 7378: 0.4266982797645059\n",
      "Theta: [-1.8077429   1.13545506  0.05436264]\n",
      "Loss in iteration 7379: 0.4266954664788382\n",
      "Theta: [-1.80783513  1.13551947  0.05436019]\n",
      "Loss in iteration 7380: 0.42669265412576074\n",
      "Theta: [-1.80792734  1.13558387  0.05435773]\n",
      "Loss in iteration 7381: 0.4266898427049004\n",
      "Theta: [-1.80801953  1.13564827  0.05435527]\n",
      "Loss in iteration 7382: 0.4266870322158845\n",
      "Theta: [-1.80811171  1.13571265  0.05435282]\n",
      "Loss in iteration 7383: 0.4266842226583401\n",
      "Theta: [-1.80820387  1.13577702  0.05435036]\n",
      "Loss in iteration 7384: 0.4266814140318945\n",
      "Theta: [-1.80829602  1.13584139  0.0543479 ]\n",
      "Loss in iteration 7385: 0.4266786063361755\n",
      "Theta: [-1.80838815  1.13590574  0.05434545]\n",
      "Loss in iteration 7386: 0.4266757995708111\n",
      "Theta: [-1.80848027  1.13597008  0.05434299]\n",
      "Loss in iteration 7387: 0.42667299373542905\n",
      "Theta: [-1.80857237  1.13603442  0.05434054]\n",
      "Loss in iteration 7388: 0.4266701888296574\n",
      "Theta: [-1.80866446  1.13609874  0.05433809]\n",
      "Loss in iteration 7389: 0.4266673848531247\n",
      "Theta: [-1.80875653  1.13616305  0.05433563]\n",
      "Loss in iteration 7390: 0.4266645818054595\n",
      "Theta: [-1.80884858  1.13622736  0.05433318]\n",
      "Loss in iteration 7391: 0.42666177968629027\n",
      "Theta: [-1.80894062  1.13629165  0.05433072]\n",
      "Loss in iteration 7392: 0.4266589784952463\n",
      "Theta: [-1.80903264  1.13635593  0.05432827]\n",
      "Loss in iteration 7393: 0.4266561782319564\n",
      "Theta: [-1.80912465  1.13642021  0.05432582]\n",
      "Loss in iteration 7394: 0.4266533788960497\n",
      "Theta: [-1.80921664  1.13648447  0.05432337]\n",
      "Loss in iteration 7395: 0.42665058048715593\n",
      "Theta: [-1.80930861  1.13654872  0.05432091]\n",
      "Loss in iteration 7396: 0.42664778300490447\n",
      "Theta: [-1.80940057  1.13661296  0.05431846]\n",
      "Loss in iteration 7397: 0.4266449864489251\n",
      "Theta: [-1.80949252  1.1366772   0.05431601]\n",
      "Loss in iteration 7398: 0.42664219081884797\n",
      "Theta: [-1.80958444  1.13674142  0.05431356]\n",
      "Loss in iteration 7399: 0.4266393961143031\n",
      "Theta: [-1.80967636  1.13680563  0.05431111]\n",
      "Loss in iteration 7400: 0.42663660233492073\n",
      "Theta: [-1.80976825  1.13686983  0.05430865]\n",
      "Loss in iteration 7401: 0.4266338094803317\n",
      "Theta: [-1.80986013  1.13693403  0.0543062 ]\n",
      "Loss in iteration 7402: 0.4266310175501662\n",
      "Theta: [-1.809952    1.13699821  0.05430375]\n",
      "Loss in iteration 7403: 0.42662822654405547\n",
      "Theta: [-1.81004385  1.13706238  0.0543013 ]\n",
      "Loss in iteration 7404: 0.42662543646163054\n",
      "Theta: [-1.81013568  1.13712655  0.05429885]\n",
      "Loss in iteration 7405: 0.4266226473025225\n",
      "Theta: [-1.8102275  1.1371907  0.0542964]\n",
      "Loss in iteration 7406: 0.4266198590663627\n",
      "Theta: [-1.81031931  1.13725484  0.05429395]\n",
      "Loss in iteration 7407: 0.42661707175278274\n",
      "Theta: [-1.81041109  1.13731897  0.0542915 ]\n",
      "Loss in iteration 7408: 0.42661428536141444\n",
      "Theta: [-1.81050287  1.1373831   0.05428906]\n",
      "Loss in iteration 7409: 0.42661149989188973\n",
      "Theta: [-1.81059462  1.13744721  0.05428661]\n",
      "Loss in iteration 7410: 0.4266087153438407\n",
      "Theta: [-1.81068636  1.13751131  0.05428416]\n",
      "Loss in iteration 7411: 0.42660593171689953\n",
      "Theta: [-1.81077809  1.13757541  0.05428171]\n",
      "Loss in iteration 7412: 0.426603149010699\n",
      "Theta: [-1.8108698   1.13763949  0.05427926]\n",
      "Loss in iteration 7413: 0.4266003672248715\n",
      "Theta: [-1.81096149  1.13770356  0.05427682]\n",
      "Loss in iteration 7414: 0.42659758635904976\n",
      "Theta: [-1.81105317  1.13776762  0.05427437]\n",
      "Loss in iteration 7415: 0.42659480641286707\n",
      "Theta: [-1.81114483  1.13783168  0.05427192]\n",
      "Loss in iteration 7416: 0.4265920273859565\n",
      "Theta: [-1.81123648  1.13789572  0.05426947]\n",
      "Loss in iteration 7417: 0.42658924927795133\n",
      "Theta: [-1.81132811  1.13795975  0.05426703]\n",
      "Loss in iteration 7418: 0.42658647208848505\n",
      "Theta: [-1.81141973  1.13802378  0.05426458]\n",
      "Loss in iteration 7419: 0.42658369581719163\n",
      "Theta: [-1.81151133  1.13808779  0.05426214]\n",
      "Loss in iteration 7420: 0.42658092046370455\n",
      "Theta: [-1.81160291  1.13815179  0.05425969]\n",
      "Loss in iteration 7421: 0.42657814602765826\n",
      "Theta: [-1.81169448  1.13821579  0.05425725]\n",
      "Loss in iteration 7422: 0.4265753725086867\n",
      "Theta: [-1.81178603  1.13827977  0.0542548 ]\n",
      "Loss in iteration 7423: 0.42657259990642443\n",
      "Theta: [-1.81187757  1.13834374  0.05425236]\n",
      "Loss in iteration 7424: 0.4265698282205062\n",
      "Theta: [-1.81196909  1.1384077   0.05424991]\n",
      "Loss in iteration 7425: 0.4265670574505664\n",
      "Theta: [-1.8120606   1.13847166  0.05424747]\n",
      "Loss in iteration 7426: 0.42656428759624015\n",
      "Theta: [-1.81215209  1.1385356   0.05424502]\n",
      "Loss in iteration 7427: 0.4265615186571628\n",
      "Theta: [-1.81224357  1.13859953  0.05424258]\n",
      "Loss in iteration 7428: 0.42655875063296944\n",
      "Theta: [-1.81233503  1.13866346  0.05424014]\n",
      "Loss in iteration 7429: 0.4265559835232956\n",
      "Theta: [-1.81242647  1.13872737  0.05423769]\n",
      "Loss in iteration 7430: 0.4265532173277768\n",
      "Theta: [-1.8125179   1.13879127  0.05423525]\n",
      "Loss in iteration 7431: 0.42655045204604897\n",
      "Theta: [-1.81260931  1.13885517  0.05423281]\n",
      "Loss in iteration 7432: 0.4265476876777481\n",
      "Theta: [-1.81270071  1.13891905  0.05423037]\n",
      "Loss in iteration 7433: 0.4265449242225104\n",
      "Theta: [-1.8127921   1.13898293  0.05422792]\n",
      "Loss in iteration 7434: 0.4265421616799722\n",
      "Theta: [-1.81288346  1.13904679  0.05422548]\n",
      "Loss in iteration 7435: 0.42653940004977003\n",
      "Theta: [-1.81297481  1.13911064  0.05422304]\n",
      "Loss in iteration 7436: 0.4265366393315406\n",
      "Theta: [-1.81306615  1.13917449  0.0542206 ]\n",
      "Loss in iteration 7437: 0.42653387952492083\n",
      "Theta: [-1.81315747  1.13923832  0.05421816]\n",
      "Loss in iteration 7438: 0.4265311206295476\n",
      "Theta: [-1.81324878  1.13930214  0.05421572]\n",
      "Loss in iteration 7439: 0.4265283626450584\n",
      "Theta: [-1.81334006  1.13936596  0.05421328]\n",
      "Loss in iteration 7440: 0.4265256055710904\n",
      "Theta: [-1.81343134  1.13942976  0.05421084]\n",
      "Loss in iteration 7441: 0.42652284940728136\n",
      "Theta: [-1.8135226   1.13949356  0.0542084 ]\n",
      "Loss in iteration 7442: 0.4265200941532691\n",
      "Theta: [-1.81361384  1.13955734  0.05420596]\n",
      "Loss in iteration 7443: 0.42651733980869133\n",
      "Theta: [-1.81370507  1.13962112  0.05420352]\n",
      "Loss in iteration 7444: 0.42651458637318607\n",
      "Theta: [-1.81379628  1.13968488  0.05420108]\n",
      "Loss in iteration 7445: 0.4265118338463918\n",
      "Theta: [-1.81388748  1.13974863  0.05419864]\n",
      "Loss in iteration 7446: 0.42650908222794703\n",
      "Theta: [-1.81397866  1.13981238  0.0541962 ]\n",
      "Loss in iteration 7447: 0.42650633151749034\n",
      "Theta: [-1.81406982  1.13987611  0.05419376]\n",
      "Loss in iteration 7448: 0.4265035817146605\n",
      "Theta: [-1.81416097  1.13993984  0.05419133]\n",
      "Loss in iteration 7449: 0.4265008328190964\n",
      "Theta: [-1.81425211  1.14000355  0.05418889]\n",
      "Loss in iteration 7450: 0.4264980848304373\n",
      "Theta: [-1.81434323  1.14006726  0.05418645]\n",
      "Loss in iteration 7451: 0.42649533774832254\n",
      "Theta: [-1.81443433  1.14013095  0.05418401]\n",
      "Loss in iteration 7452: 0.42649259157239156\n",
      "Theta: [-1.81452542  1.14019464  0.05418158]\n",
      "Loss in iteration 7453: 0.42648984630228404\n",
      "Theta: [-1.81461649  1.14025831  0.05417914]\n",
      "Loss in iteration 7454: 0.42648710193763995\n",
      "Theta: [-1.81470755  1.14032198  0.0541767 ]\n",
      "Loss in iteration 7455: 0.426484358478099\n",
      "Theta: [-1.81479859  1.14038563  0.05417427]\n",
      "Loss in iteration 7456: 0.42648161592330164\n",
      "Theta: [-1.81488962  1.14044928  0.05417183]\n",
      "Loss in iteration 7457: 0.4264788742728882\n",
      "Theta: [-1.81498063  1.14051292  0.0541694 ]\n",
      "Loss in iteration 7458: 0.42647613352649905\n",
      "Theta: [-1.81507162  1.14057654  0.05416696]\n",
      "Loss in iteration 7459: 0.42647339368377535\n",
      "Theta: [-1.8151626   1.14064016  0.05416453]\n",
      "Loss in iteration 7460: 0.4264706547443576\n",
      "Theta: [-1.81525357  1.14070376  0.05416209]\n",
      "Loss in iteration 7461: 0.42646791670788675\n",
      "Theta: [-1.81534452  1.14076736  0.05415966]\n",
      "Loss in iteration 7462: 0.4264651795740043\n",
      "Theta: [-1.81543545  1.14083095  0.05415722]\n",
      "Loss in iteration 7463: 0.42646244334235156\n",
      "Theta: [-1.81552637  1.14089452  0.05415479]\n",
      "Loss in iteration 7464: 0.42645970801257027\n",
      "Theta: [-1.81561727  1.14095809  0.05415236]\n",
      "Loss in iteration 7465: 0.4264569735843019\n",
      "Theta: [-1.81570816  1.14102165  0.05414992]\n",
      "Loss in iteration 7466: 0.42645424005718857\n",
      "Theta: [-1.81579903  1.14108519  0.05414749]\n",
      "Loss in iteration 7467: 0.4264515074308723\n",
      "Theta: [-1.81588989  1.14114873  0.05414506]\n",
      "Loss in iteration 7468: 0.42644877570499523\n",
      "Theta: [-1.81598073  1.14121226  0.05414262]\n",
      "Loss in iteration 7469: 0.4264460448792001\n",
      "Theta: [-1.81607156  1.14127577  0.05414019]\n",
      "Loss in iteration 7470: 0.42644331495312926\n",
      "Theta: [-1.81616237  1.14133928  0.05413776]\n",
      "Loss in iteration 7471: 0.4264405859264258\n",
      "Theta: [-1.81625316  1.14140278  0.05413533]\n",
      "Loss in iteration 7472: 0.4264378577987323\n",
      "Theta: [-1.81634394  1.14146627  0.0541329 ]\n",
      "Loss in iteration 7473: 0.42643513056969196\n",
      "Theta: [-1.81643471  1.14152974  0.05413047]\n",
      "Loss in iteration 7474: 0.4264324042389484\n",
      "Theta: [-1.81652546  1.14159321  0.05412803]\n",
      "Loss in iteration 7475: 0.42642967880614463\n",
      "Theta: [-1.81661619  1.14165667  0.0541256 ]\n",
      "Loss in iteration 7476: 0.42642695427092453\n",
      "Theta: [-1.81670691  1.14172012  0.05412317]\n",
      "Loss in iteration 7477: 0.42642423063293217\n",
      "Theta: [-1.81679761  1.14178356  0.05412074]\n",
      "Loss in iteration 7478: 0.4264215078918108\n",
      "Theta: [-1.8168883   1.14184698  0.05411831]\n",
      "Loss in iteration 7479: 0.4264187860472053\n",
      "Theta: [-1.81697897  1.1419104   0.05411588]\n",
      "Loss in iteration 7480: 0.4264160650987599\n",
      "Theta: [-1.81706963  1.14197381  0.05411346]\n",
      "Loss in iteration 7481: 0.4264133450461188\n",
      "Theta: [-1.81716027  1.14203721  0.05411103]\n",
      "Loss in iteration 7482: 0.42641062588892664\n",
      "Theta: [-1.8172509  1.1421006  0.0541086]\n",
      "Loss in iteration 7483: 0.42640790762682845\n",
      "Theta: [-1.81734151  1.14216398  0.05410617]\n",
      "Loss in iteration 7484: 0.42640519025946944\n",
      "Theta: [-1.81743211  1.14222735  0.05410374]\n",
      "Loss in iteration 7485: 0.42640247378649443\n",
      "Theta: [-1.81752269  1.14229071  0.05410131]\n",
      "Loss in iteration 7486: 0.42639975820754883\n",
      "Theta: [-1.81761325  1.14235406  0.05409889]\n",
      "Loss in iteration 7487: 0.42639704352227825\n",
      "Theta: [-1.8177038   1.1424174   0.05409646]\n",
      "Loss in iteration 7488: 0.42639432973032826\n",
      "Theta: [-1.81779434  1.14248073  0.05409403]\n",
      "Loss in iteration 7489: 0.4263916168313451\n",
      "Theta: [-1.81788485  1.14254405  0.05409161]\n",
      "Loss in iteration 7490: 0.4263889048249742\n",
      "Theta: [-1.81797536  1.14260736  0.05408918]\n",
      "Loss in iteration 7491: 0.42638619371086234\n",
      "Theta: [-1.81806585  1.14267066  0.05408675]\n",
      "Loss in iteration 7492: 0.4263834834886554\n",
      "Theta: [-1.81815632  1.14273395  0.05408433]\n",
      "Loss in iteration 7493: 0.4263807741580004\n",
      "Theta: [-1.81824678  1.14279723  0.0540819 ]\n",
      "Loss in iteration 7494: 0.4263780657185434\n",
      "Theta: [-1.81833722  1.1428605   0.05407948]\n",
      "Loss in iteration 7495: 0.42637535816993205\n",
      "Theta: [-1.81842765  1.14292376  0.05407705]\n",
      "Loss in iteration 7496: 0.4263726515118129\n",
      "Theta: [-1.81851806  1.14298701  0.05407463]\n",
      "Loss in iteration 7497: 0.42636994574383347\n",
      "Theta: [-1.81860846  1.14305026  0.0540722 ]\n",
      "Loss in iteration 7498: 0.4263672408656406\n",
      "Theta: [-1.81869884  1.14311349  0.05406978]\n",
      "Loss in iteration 7499: 0.4263645368768825\n",
      "Theta: [-1.8187892   1.14317671  0.05406735]\n",
      "Loss in iteration 7500: 0.42636183377720643\n",
      "Theta: [-1.81887955  1.14323992  0.05406493]\n",
      "Loss in iteration 7501: 0.42635913156626065\n",
      "Theta: [-1.81896989  1.14330313  0.05406251]\n",
      "Loss in iteration 7502: 0.42635643024369296\n",
      "Theta: [-1.81906021  1.14336632  0.05406008]\n",
      "Loss in iteration 7503: 0.4263537298091517\n",
      "Theta: [-1.81915052  1.1434295   0.05405766]\n",
      "Loss in iteration 7504: 0.42635103026228527\n",
      "Theta: [-1.81924081  1.14349267  0.05405524]\n",
      "Loss in iteration 7505: 0.4263483316027421\n",
      "Theta: [-1.81933108  1.14355584  0.05405281]\n",
      "Loss in iteration 7506: 0.4263456338301712\n",
      "Theta: [-1.81942134  1.14361899  0.05405039]\n",
      "Loss in iteration 7507: 0.4263429369442213\n",
      "Theta: [-1.81951158  1.14368214  0.05404797]\n",
      "Loss in iteration 7508: 0.42634024094454154\n",
      "Theta: [-1.81960181  1.14374527  0.05404555]\n",
      "Loss in iteration 7509: 0.4263375458307811\n",
      "Theta: [-1.81969203  1.14380839  0.05404313]\n",
      "Loss in iteration 7510: 0.42633485160258927\n",
      "Theta: [-1.81978222  1.14387151  0.05404071]\n",
      "Loss in iteration 7511: 0.42633215825961585\n",
      "Theta: [-1.81987241  1.14393461  0.05403829]\n",
      "Loss in iteration 7512: 0.42632946580151065\n",
      "Theta: [-1.81996257  1.14399771  0.05403587]\n",
      "Loss in iteration 7513: 0.4263267742279233\n",
      "Theta: [-1.82005273  1.14406079  0.05403345]\n",
      "Loss in iteration 7514: 0.4263240835385041\n",
      "Theta: [-1.82014286  1.14412387  0.05403103]\n",
      "Loss in iteration 7515: 0.42632139373290323\n",
      "Theta: [-1.82023299  1.14418693  0.05402861]\n",
      "Loss in iteration 7516: 0.42631870481077105\n",
      "Theta: [-1.82032309  1.14424999  0.05402619]\n",
      "Loss in iteration 7517: 0.42631601677175845\n",
      "Theta: [-1.82041319  1.14431303  0.05402377]\n",
      "Loss in iteration 7518: 0.4263133296155157\n",
      "Theta: [-1.82050326  1.14437607  0.05402135]\n",
      "Loss in iteration 7519: 0.42631064334169394\n",
      "Theta: [-1.82059332  1.1444391   0.05401893]\n",
      "Loss in iteration 7520: 0.4263079579499444\n",
      "Theta: [-1.82068337  1.14450211  0.05401651]\n",
      "Loss in iteration 7521: 0.4263052734399182\n",
      "Theta: [-1.8207734   1.14456512  0.05401409]\n",
      "Loss in iteration 7522: 0.4263025898112669\n",
      "Theta: [-1.82086342  1.14462812  0.05401168]\n",
      "Loss in iteration 7523: 0.42629990706364174\n",
      "Theta: [-1.82095342  1.14469111  0.05400926]\n",
      "Loss in iteration 7524: 0.4262972251966947\n",
      "Theta: [-1.8210434   1.14475408  0.05400684]\n",
      "Loss in iteration 7525: 0.426294544210078\n",
      "Theta: [-1.82113337  1.14481705  0.05400442]\n",
      "Loss in iteration 7526: 0.42629186410344333\n",
      "Theta: [-1.82122333  1.14488001  0.05400201]\n",
      "Loss in iteration 7527: 0.4262891848764429\n",
      "Theta: [-1.82131327  1.14494296  0.05399959]\n",
      "Loss in iteration 7528: 0.42628650652872935\n",
      "Theta: [-1.82140319  1.1450059   0.05399717]\n",
      "Loss in iteration 7529: 0.42628382905995515\n",
      "Theta: [-1.8214931   1.14506883  0.05399476]\n",
      "Loss in iteration 7530: 0.42628115246977333\n",
      "Theta: [-1.821583    1.14513174  0.05399234]\n",
      "Loss in iteration 7531: 0.4262784767578364\n",
      "Theta: [-1.82167287  1.14519465  0.05398993]\n",
      "Loss in iteration 7532: 0.4262758019237976\n",
      "Theta: [-1.82176274  1.14525755  0.05398751]\n",
      "Loss in iteration 7533: 0.42627312796731026\n",
      "Theta: [-1.82185259  1.14532044  0.0539851 ]\n",
      "Loss in iteration 7534: 0.4262704548880278\n",
      "Theta: [-1.82194242  1.14538332  0.05398268]\n",
      "Loss in iteration 7535: 0.4262677826856038\n",
      "Theta: [-1.82203224  1.14544619  0.05398027]\n",
      "Loss in iteration 7536: 0.42626511135969186\n",
      "Theta: [-1.82212204  1.14550906  0.05397786]\n",
      "Loss in iteration 7537: 0.4262624409099461\n",
      "Theta: [-1.82221183  1.14557191  0.05397544]\n",
      "Loss in iteration 7538: 0.42625977133602044\n",
      "Theta: [-1.8223016   1.14563475  0.05397303]\n",
      "Loss in iteration 7539: 0.4262571026375692\n",
      "Theta: [-1.82239136  1.14569758  0.05397062]\n",
      "Loss in iteration 7540: 0.4262544348142467\n",
      "Theta: [-1.8224811  1.1457604  0.0539682]\n",
      "Loss in iteration 7541: 0.4262517678657077\n",
      "Theta: [-1.82257083  1.14582321  0.05396579]\n",
      "Loss in iteration 7542: 0.4262491017916069\n",
      "Theta: [-1.82266055  1.14588602  0.05396338]\n",
      "Loss in iteration 7543: 0.42624643659159905\n",
      "Theta: [-1.82275024  1.14594881  0.05396097]\n",
      "Loss in iteration 7544: 0.4262437722653394\n",
      "Theta: [-1.82283992  1.14601159  0.05395855]\n",
      "Loss in iteration 7545: 0.426241108812483\n",
      "Theta: [-1.82292959  1.14607437  0.05395614]\n",
      "Loss in iteration 7546: 0.42623844623268536\n",
      "Theta: [-1.82301924  1.14613713  0.05395373]\n",
      "Loss in iteration 7547: 0.4262357845256022\n",
      "Theta: [-1.82310888  1.14619988  0.05395132]\n",
      "Loss in iteration 7548: 0.42623312369088895\n",
      "Theta: [-1.8231985   1.14626263  0.05394891]\n",
      "Loss in iteration 7549: 0.4262304637282017\n",
      "Theta: [-1.82328811  1.14632536  0.0539465 ]\n",
      "Loss in iteration 7550: 0.4262278046371965\n",
      "Theta: [-1.8233777   1.14638809  0.05394409]\n",
      "Loss in iteration 7551: 0.42622514641752945\n",
      "Theta: [-1.82346728  1.1464508   0.05394168]\n",
      "Loss in iteration 7552: 0.426222489068857\n",
      "Theta: [-1.82355684  1.14651351  0.05393927]\n",
      "Loss in iteration 7553: 0.4262198325908358\n",
      "Theta: [-1.82364639  1.1465762   0.05393686]\n",
      "Loss in iteration 7554: 0.42621717698312245\n",
      "Theta: [-1.82373592  1.14663889  0.05393445]\n",
      "Loss in iteration 7555: 0.42621452224537376\n",
      "Theta: [-1.82382543  1.14670157  0.05393204]\n",
      "Loss in iteration 7556: 0.426211868377247\n",
      "Theta: [-1.82391494  1.14676423  0.05392963]\n",
      "Loss in iteration 7557: 0.4262092153783992\n",
      "Theta: [-1.82400442  1.14682689  0.05392723]\n",
      "Loss in iteration 7558: 0.4262065632484878\n",
      "Theta: [-1.82409389  1.14688954  0.05392482]\n",
      "Loss in iteration 7559: 0.42620391198717045\n",
      "Theta: [-1.82418335  1.14695217  0.05392241]\n",
      "Loss in iteration 7560: 0.4262012615941045\n",
      "Theta: [-1.82427279  1.1470148   0.05392   ]\n",
      "Loss in iteration 7561: 0.426198612068948\n",
      "Theta: [-1.82436222  1.14707742  0.0539176 ]\n",
      "Loss in iteration 7562: 0.42619596341135924\n",
      "Theta: [-1.82445163  1.14714003  0.05391519]\n",
      "Loss in iteration 7563: 0.42619331562099594\n",
      "Theta: [-1.82454102  1.14720263  0.05391278]\n",
      "Loss in iteration 7564: 0.42619066869751693\n",
      "Theta: [-1.8246304   1.14726522  0.05391038]\n",
      "Loss in iteration 7565: 0.4261880226405803\n",
      "Theta: [-1.82471977  1.1473278   0.05390797]\n",
      "Loss in iteration 7566: 0.4261853774498448\n",
      "Theta: [-1.82480912  1.14739037  0.05390556]\n",
      "Loss in iteration 7567: 0.4261827331249694\n",
      "Theta: [-1.82489846  1.14745293  0.05390316]\n",
      "Loss in iteration 7568: 0.42618008966561327\n",
      "Theta: [-1.82498778  1.14751548  0.05390075]\n",
      "Loss in iteration 7569: 0.4261774470714352\n",
      "Theta: [-1.82507708  1.14757802  0.05389835]\n",
      "Loss in iteration 7570: 0.4261748053420947\n",
      "Theta: [-1.82516637  1.14764055  0.05389594]\n",
      "Loss in iteration 7571: 0.4261721644772512\n",
      "Theta: [-1.82525565  1.14770307  0.05389354]\n",
      "Loss in iteration 7572: 0.42616952447656453\n",
      "Theta: [-1.82534491  1.14776558  0.05389113]\n",
      "Loss in iteration 7573: 0.4261668853396943\n",
      "Theta: [-1.82543415  1.14782808  0.05388873]\n",
      "Loss in iteration 7574: 0.4261642470663004\n",
      "Theta: [-1.82552338  1.14789058  0.05388633]\n",
      "Loss in iteration 7575: 0.42616160965604316\n",
      "Theta: [-1.8256126   1.14795306  0.05388392]\n",
      "Loss in iteration 7576: 0.42615897310858286\n",
      "Theta: [-1.8257018   1.14801553  0.05388152]\n",
      "Loss in iteration 7577: 0.42615633742358006\n",
      "Theta: [-1.82579099  1.148078    0.05387912]\n",
      "Loss in iteration 7578: 0.42615370260069513\n",
      "Theta: [-1.82588016  1.14814045  0.05387672]\n",
      "Loss in iteration 7579: 0.42615106863958907\n",
      "Theta: [-1.82596931  1.1482029   0.05387431]\n",
      "Loss in iteration 7580: 0.4261484355399227\n",
      "Theta: [-1.82605845  1.14826533  0.05387191]\n",
      "Loss in iteration 7581: 0.4261458033013572\n",
      "Theta: [-1.82614758  1.14832776  0.05386951]\n",
      "Loss in iteration 7582: 0.4261431719235539\n",
      "Theta: [-1.82623669  1.14839017  0.05386711]\n",
      "Loss in iteration 7583: 0.42614054140617386\n",
      "Theta: [-1.82632579  1.14845258  0.05386471]\n",
      "Loss in iteration 7584: 0.42613791174887905\n",
      "Theta: [-1.82641487  1.14851497  0.05386231]\n",
      "Loss in iteration 7585: 0.4261352829513311\n",
      "Theta: [-1.82650393  1.14857736  0.05385991]\n",
      "Loss in iteration 7586: 0.426132655013192\n",
      "Theta: [-1.82659298  1.14863974  0.0538575 ]\n",
      "Loss in iteration 7587: 0.42613002793412386\n",
      "Theta: [-1.82668202  1.1487021   0.0538551 ]\n",
      "Loss in iteration 7588: 0.42612740171378855\n",
      "Theta: [-1.82677104  1.14876446  0.05385271]\n",
      "Loss in iteration 7589: 0.426124776351849\n",
      "Theta: [-1.82686005  1.14882681  0.05385031]\n",
      "Loss in iteration 7590: 0.42612215184796726\n",
      "Theta: [-1.82694904  1.14888915  0.05384791]\n",
      "Loss in iteration 7591: 0.4261195282018065\n",
      "Theta: [-1.82703801  1.14895148  0.05384551]\n",
      "Loss in iteration 7592: 0.4261169054130292\n",
      "Theta: [-1.82712697  1.1490138   0.05384311]\n",
      "Loss in iteration 7593: 0.4261142834812987\n",
      "Theta: [-1.82721592  1.14907611  0.05384071]\n",
      "Loss in iteration 7594: 0.426111662406278\n",
      "Theta: [-1.82730485  1.14913841  0.05383831]\n",
      "Loss in iteration 7595: 0.4261090421876305\n",
      "Theta: [-1.82739377  1.1492007   0.05383591]\n",
      "Loss in iteration 7596: 0.42610642282502\n",
      "Theta: [-1.82748267  1.14926298  0.05383352]\n",
      "Loss in iteration 7597: 0.42610380431810957\n",
      "Theta: [-1.82757156  1.14932525  0.05383112]\n",
      "Loss in iteration 7598: 0.42610118666656355\n",
      "Theta: [-1.82766043  1.14938751  0.05382872]\n",
      "Loss in iteration 7599: 0.4260985698700459\n",
      "Theta: [-1.82774928  1.14944976  0.05382632]\n",
      "Loss in iteration 7600: 0.4260959539282206\n",
      "Theta: [-1.82783813  1.149512    0.05382393]\n",
      "Loss in iteration 7601: 0.4260933388407521\n",
      "Theta: [-1.82792695  1.14957424  0.05382153]\n",
      "Loss in iteration 7602: 0.42609072460730474\n",
      "Theta: [-1.82801576  1.14963646  0.05381914]\n",
      "Loss in iteration 7603: 0.42608811122754325\n",
      "Theta: [-1.82810456  1.14969867  0.05381674]\n",
      "Loss in iteration 7604: 0.42608549870113244\n",
      "Theta: [-1.82819334  1.14976088  0.05381434]\n",
      "Loss in iteration 7605: 0.4260828870277371\n",
      "Theta: [-1.82828211  1.14982307  0.05381195]\n",
      "Loss in iteration 7606: 0.4260802762070226\n",
      "Theta: [-1.82837086  1.14988526  0.05380955]\n",
      "Loss in iteration 7607: 0.426077666238654\n",
      "Theta: [-1.8284596   1.14994743  0.05380716]\n",
      "Loss in iteration 7608: 0.4260750571222969\n",
      "Theta: [-1.82854832  1.1500096   0.05380477]\n",
      "Loss in iteration 7609: 0.42607244885761675\n",
      "Theta: [-1.82863703  1.15007175  0.05380237]\n",
      "Loss in iteration 7610: 0.4260698414442794\n",
      "Theta: [-1.82872572  1.1501339   0.05379998]\n",
      "Loss in iteration 7611: 0.42606723488195064\n",
      "Theta: [-1.8288144   1.15019604  0.05379758]\n",
      "Loss in iteration 7612: 0.4260646291702968\n",
      "Theta: [-1.82890306  1.15025816  0.05379519]\n",
      "Loss in iteration 7613: 0.4260620243089837\n",
      "Theta: [-1.82899171  1.15032028  0.0537928 ]\n",
      "Loss in iteration 7614: 0.426059420297678\n",
      "Theta: [-1.82908034  1.15038239  0.0537904 ]\n",
      "Loss in iteration 7615: 0.42605681713604626\n",
      "Theta: [-1.82916896  1.15044449  0.05378801]\n",
      "Loss in iteration 7616: 0.42605421482375505\n",
      "Theta: [-1.82925757  1.15050658  0.05378562]\n",
      "Loss in iteration 7617: 0.4260516133604712\n",
      "Theta: [-1.82934616  1.15056866  0.05378323]\n",
      "Loss in iteration 7618: 0.4260490127458619\n",
      "Theta: [-1.82943473  1.15063073  0.05378084]\n",
      "Loss in iteration 7619: 0.4260464129795944\n",
      "Theta: [-1.82952329  1.15069279  0.05377844]\n",
      "Loss in iteration 7620: 0.4260438140613357\n",
      "Theta: [-1.82961183  1.15075484  0.05377605]\n",
      "Loss in iteration 7621: 0.4260412159907534\n",
      "Theta: [-1.82970036  1.15081688  0.05377366]\n",
      "Loss in iteration 7622: 0.4260386187675153\n",
      "Theta: [-1.82978888  1.15087891  0.05377127]\n",
      "Loss in iteration 7623: 0.42603602239128896\n",
      "Theta: [-1.82987738  1.15094093  0.05376888]\n",
      "Loss in iteration 7624: 0.42603342686174256\n",
      "Theta: [-1.82996586  1.15100294  0.05376649]\n",
      "Loss in iteration 7625: 0.42603083217854426\n",
      "Theta: [-1.83005433  1.15106495  0.0537641 ]\n",
      "Loss in iteration 7626: 0.42602823834136216\n",
      "Theta: [-1.83014279  1.15112694  0.05376171]\n",
      "Loss in iteration 7627: 0.42602564534986476\n",
      "Theta: [-1.83023123  1.15118892  0.05375932]\n",
      "Loss in iteration 7628: 0.4260230532037208\n",
      "Theta: [-1.83031965  1.1512509   0.05375693]\n",
      "Loss in iteration 7629: 0.42602046190259885\n",
      "Theta: [-1.83040806  1.15131286  0.05375455]\n",
      "Loss in iteration 7630: 0.4260178714461677\n",
      "Theta: [-1.83049646  1.15137482  0.05375216]\n",
      "Loss in iteration 7631: 0.42601528183409665\n",
      "Theta: [-1.83058484  1.15143677  0.05374977]\n",
      "Loss in iteration 7632: 0.4260126930660547\n",
      "Theta: [-1.83067321  1.1514987   0.05374738]\n",
      "Loss in iteration 7633: 0.42601010514171167\n",
      "Theta: [-1.83076156  1.15156063  0.05374499]\n",
      "Loss in iteration 7634: 0.42600751806073667\n",
      "Theta: [-1.83084989  1.15162254  0.05374261]\n",
      "Loss in iteration 7635: 0.42600493182279947\n",
      "Theta: [-1.83093822  1.15168445  0.05374022]\n",
      "Loss in iteration 7636: 0.4260023464275698\n",
      "Theta: [-1.83102652  1.15174635  0.05373783]\n",
      "Loss in iteration 7637: 0.4259997618747181\n",
      "Theta: [-1.83111482  1.15180824  0.05373545]\n",
      "Loss in iteration 7638: 0.42599717816391425\n",
      "Theta: [-1.83120309  1.15187012  0.05373306]\n",
      "Loss in iteration 7639: 0.4259945952948284\n",
      "Theta: [-1.83129136  1.15193199  0.05373067]\n",
      "Loss in iteration 7640: 0.42599201326713126\n",
      "Theta: [-1.8313796   1.15199385  0.05372829]\n",
      "Loss in iteration 7641: 0.4259894320804934\n",
      "Theta: [-1.83146784  1.1520557   0.0537259 ]\n",
      "Loss in iteration 7642: 0.42598685173458556\n",
      "Theta: [-1.83155606  1.15211754  0.05372352]\n",
      "Loss in iteration 7643: 0.4259842722290788\n",
      "Theta: [-1.83164426  1.15217937  0.05372113]\n",
      "Loss in iteration 7644: 0.42598169356364407\n",
      "Theta: [-1.83173245  1.15224119  0.05371875]\n",
      "Loss in iteration 7645: 0.42597911573795266\n",
      "Theta: [-1.83182062  1.152303    0.05371636]\n",
      "Loss in iteration 7646: 0.425976538751676\n",
      "Theta: [-1.83190878  1.15236481  0.05371398]\n",
      "Loss in iteration 7647: 0.4259739626044858\n",
      "Theta: [-1.83199693  1.1524266   0.05371159]\n",
      "Loss in iteration 7648: 0.4259713872960534\n",
      "Theta: [-1.83208506  1.15248838  0.05370921]\n",
      "Loss in iteration 7649: 0.4259688128260511\n",
      "Theta: [-1.83217317  1.15255016  0.05370683]\n",
      "Loss in iteration 7650: 0.4259662391941506\n",
      "Theta: [-1.83226127  1.15261192  0.05370444]\n",
      "Loss in iteration 7651: 0.4259636664000242\n",
      "Theta: [-1.83234936  1.15267368  0.05370206]\n",
      "Loss in iteration 7652: 0.4259610944433444\n",
      "Theta: [-1.83243743  1.15273543  0.05369968]\n",
      "Loss in iteration 7653: 0.42595852332378337\n",
      "Theta: [-1.83252549  1.15279716  0.0536973 ]\n",
      "Loss in iteration 7654: 0.425955953041014\n",
      "Theta: [-1.83261353  1.15285889  0.05369492]\n",
      "Loss in iteration 7655: 0.425953383594709\n",
      "Theta: [-1.83270156  1.15292061  0.05369253]\n",
      "Loss in iteration 7656: 0.4259508149845414\n",
      "Theta: [-1.83278957  1.15298231  0.05369015]\n",
      "Loss in iteration 7657: 0.4259482472101844\n",
      "Theta: [-1.83287757  1.15304401  0.05368777]\n",
      "Loss in iteration 7658: 0.42594568027131097\n",
      "Theta: [-1.83296555  1.1531057   0.05368539]\n",
      "Loss in iteration 7659: 0.42594311416759484\n",
      "Theta: [-1.83305352  1.15316738  0.05368301]\n",
      "Loss in iteration 7660: 0.4259405488987093\n",
      "Theta: [-1.83314147  1.15322905  0.05368063]\n",
      "Loss in iteration 7661: 0.4259379844643284\n",
      "Theta: [-1.83322941  1.15329071  0.05367825]\n",
      "Loss in iteration 7662: 0.42593542086412567\n",
      "Theta: [-1.83331733  1.15335236  0.05367587]\n",
      "Loss in iteration 7663: 0.4259328580977753\n",
      "Theta: [-1.83340524  1.153414    0.05367349]\n",
      "Loss in iteration 7664: 0.42593029616495165\n",
      "Theta: [-1.83349314  1.15347564  0.05367111]\n",
      "Loss in iteration 7665: 0.42592773506532894\n",
      "Theta: [-1.83358102  1.15353726  0.05366873]\n",
      "Loss in iteration 7666: 0.42592517479858166\n",
      "Theta: [-1.83366888  1.15359887  0.05366635]\n",
      "Loss in iteration 7667: 0.42592261536438436\n",
      "Theta: [-1.83375673  1.15366047  0.05366397]\n",
      "Loss in iteration 7668: 0.4259200567624121\n",
      "Theta: [-1.83384457  1.15372207  0.0536616 ]\n",
      "Loss in iteration 7669: 0.42591749899233944\n",
      "Theta: [-1.83393239  1.15378365  0.05365922]\n",
      "Loss in iteration 7670: 0.425914942053842\n",
      "Theta: [-1.8340202   1.15384523  0.05365684]\n",
      "Loss in iteration 7671: 0.42591238594659486\n",
      "Theta: [-1.83410799  1.15390679  0.05365446]\n",
      "Loss in iteration 7672: 0.42590983067027316\n",
      "Theta: [-1.83419577  1.15396835  0.05365209]\n",
      "Loss in iteration 7673: 0.42590727622455277\n",
      "Theta: [-1.83428353  1.1540299   0.05364971]\n",
      "Loss in iteration 7674: 0.42590472260910933\n",
      "Theta: [-1.83437128  1.15409144  0.05364733]\n",
      "Loss in iteration 7675: 0.4259021698236188\n",
      "Theta: [-1.83445901  1.15415296  0.05364496]\n",
      "Loss in iteration 7676: 0.42589961786775715\n",
      "Theta: [-1.83454673  1.15421448  0.05364258]\n",
      "Loss in iteration 7677: 0.4258970667412004\n",
      "Theta: [-1.83463443  1.15427599  0.0536402 ]\n",
      "Loss in iteration 7678: 0.42589451644362536\n",
      "Theta: [-1.83472212  1.15433749  0.05363783]\n",
      "Loss in iteration 7679: 0.425891966974708\n",
      "Theta: [-1.8348098   1.15439898  0.05363545]\n",
      "Loss in iteration 7680: 0.42588941833412525\n",
      "Theta: [-1.83489746  1.15446046  0.05363308]\n",
      "Loss in iteration 7681: 0.4258868705215539\n",
      "Theta: [-1.8349851   1.15452193  0.0536307 ]\n",
      "Loss in iteration 7682: 0.4258843235366707\n",
      "Theta: [-1.83507273  1.15458339  0.05362833]\n",
      "Loss in iteration 7683: 0.42588177737915295\n",
      "Theta: [-1.83516035  1.15464485  0.05362596]\n",
      "Loss in iteration 7684: 0.425879232048678\n",
      "Theta: [-1.83524795  1.15470629  0.05362358]\n",
      "Loss in iteration 7685: 0.4258766875449229\n",
      "Theta: [-1.83533554  1.15476772  0.05362121]\n",
      "Loss in iteration 7686: 0.4258741438675656\n",
      "Theta: [-1.83542311  1.15482915  0.05361883]\n",
      "Loss in iteration 7687: 0.42587160101628363\n",
      "Theta: [-1.83551067  1.15489056  0.05361646]\n",
      "Loss in iteration 7688: 0.4258690589907548\n",
      "Theta: [-1.83559821  1.15495197  0.05361409]\n",
      "Loss in iteration 7689: 0.42586651779065704\n",
      "Theta: [-1.83568574  1.15501336  0.05361172]\n",
      "Loss in iteration 7690: 0.4258639774156688\n",
      "Theta: [-1.83577325  1.15507475  0.05360934]\n",
      "Loss in iteration 7691: 0.4258614378654682\n",
      "Theta: [-1.83586075  1.15513613  0.05360697]\n",
      "Loss in iteration 7692: 0.42585889913973396\n",
      "Theta: [-1.83594824  1.15519749  0.0536046 ]\n",
      "Loss in iteration 7693: 0.4258563612381444\n",
      "Theta: [-1.83603571  1.15525885  0.05360223]\n",
      "Loss in iteration 7694: 0.42585382416037837\n",
      "Theta: [-1.83612316  1.1553202   0.05359986]\n",
      "Loss in iteration 7695: 0.42585128790611476\n",
      "Theta: [-1.8362106   1.15538154  0.05359749]\n",
      "Loss in iteration 7696: 0.4258487524750328\n",
      "Theta: [-1.83629803  1.15544287  0.05359512]\n",
      "Loss in iteration 7697: 0.4258462178668117\n",
      "Theta: [-1.83638544  1.15550419  0.05359275]\n",
      "Loss in iteration 7698: 0.42584368408113066\n",
      "Theta: [-1.83647284  1.1555655   0.05359038]\n",
      "Loss in iteration 7699: 0.4258411511176694\n",
      "Theta: [-1.83656022  1.1556268   0.05358801]\n",
      "Loss in iteration 7700: 0.42583861897610753\n",
      "Theta: [-1.83664759  1.1556881   0.05358564]\n",
      "Loss in iteration 7701: 0.4258360876561249\n",
      "Theta: [-1.83673494  1.15574938  0.05358327]\n",
      "Loss in iteration 7702: 0.42583355715740123\n",
      "Theta: [-1.83682228  1.15581065  0.0535809 ]\n",
      "Loss in iteration 7703: 0.42583102747961715\n",
      "Theta: [-1.83690961  1.15587192  0.05357853]\n",
      "Loss in iteration 7704: 0.4258284986224527\n",
      "Theta: [-1.83699692  1.15593317  0.05357616]\n",
      "Loss in iteration 7705: 0.4258259705855882\n",
      "Theta: [-1.83708421  1.15599442  0.05357379]\n",
      "Loss in iteration 7706: 0.4258234433687042\n",
      "Theta: [-1.83717149  1.15605565  0.05357142]\n",
      "Loss in iteration 7707: 0.4258209169714818\n",
      "Theta: [-1.83725876  1.15611688  0.05356906]\n",
      "Loss in iteration 7708: 0.4258183913936015\n",
      "Theta: [-1.83734601  1.1561781   0.05356669]\n",
      "Loss in iteration 7709: 0.42581586663474463\n",
      "Theta: [-1.83743325  1.1562393   0.05356432]\n",
      "Loss in iteration 7710: 0.425813342694592\n",
      "Theta: [-1.83752047  1.1563005   0.05356195]\n",
      "Loss in iteration 7711: 0.4258108195728252\n",
      "Theta: [-1.83760768  1.15636169  0.05355959]\n",
      "Loss in iteration 7712: 0.4258082972691259\n",
      "Theta: [-1.83769487  1.15642287  0.05355722]\n",
      "Loss in iteration 7713: 0.4258057757831756\n",
      "Theta: [-1.83778205  1.15648404  0.05355486]\n",
      "Loss in iteration 7714: 0.4258032551146557\n",
      "Theta: [-1.83786922  1.1565452   0.05355249]\n",
      "Loss in iteration 7715: 0.4258007352632485\n",
      "Theta: [-1.83795637  1.15660635  0.05355012]\n",
      "Loss in iteration 7716: 0.4257982162286363\n",
      "Theta: [-1.8380435   1.1566675   0.05354776]\n",
      "Loss in iteration 7717: 0.42579569801050077\n",
      "Theta: [-1.83813063  1.15672863  0.05354539]\n",
      "Loss in iteration 7718: 0.4257931806085248\n",
      "Theta: [-1.83821773  1.15678975  0.05354303]\n",
      "Loss in iteration 7719: 0.4257906640223906\n",
      "Theta: [-1.83830482  1.15685087  0.05354066]\n",
      "Loss in iteration 7720: 0.4257881482517808\n",
      "Theta: [-1.8383919   1.15691197  0.0535383 ]\n",
      "Loss in iteration 7721: 0.42578563329637864\n",
      "Theta: [-1.83847896  1.15697307  0.05353594]\n",
      "Loss in iteration 7722: 0.4257831191558668\n",
      "Theta: [-1.83856601  1.15703415  0.05353357]\n",
      "Loss in iteration 7723: 0.4257806058299285\n",
      "Theta: [-1.83865305  1.15709523  0.05353121]\n",
      "Loss in iteration 7724: 0.42577809331824684\n",
      "Theta: [-1.83874007  1.1571563   0.05352885]\n",
      "Loss in iteration 7725: 0.42577558162050544\n",
      "Theta: [-1.83882707  1.15721735  0.05352648]\n",
      "Loss in iteration 7726: 0.42577307073638776\n",
      "Theta: [-1.83891406  1.1572784   0.05352412]\n",
      "Loss in iteration 7727: 0.42577056066557767\n",
      "Theta: [-1.83900104  1.15733944  0.05352176]\n",
      "Loss in iteration 7728: 0.42576805140775886\n",
      "Theta: [-1.839088    1.15740047  0.0535194 ]\n",
      "Loss in iteration 7729: 0.4257655429626155\n",
      "Theta: [-1.83917495  1.15746149  0.05351703]\n",
      "Loss in iteration 7730: 0.42576303532983173\n",
      "Theta: [-1.83926188  1.1575225   0.05351467]\n",
      "Loss in iteration 7731: 0.4257605285090918\n",
      "Theta: [-1.8393488   1.1575835   0.05351231]\n",
      "Loss in iteration 7732: 0.42575802250008027\n",
      "Theta: [-1.8394357   1.1576445   0.05350995]\n",
      "Loss in iteration 7733: 0.4257555173024816\n",
      "Theta: [-1.83952259  1.15770548  0.05350759]\n",
      "Loss in iteration 7734: 0.4257530129159807\n",
      "Theta: [-1.83960947  1.15776645  0.05350523]\n",
      "Loss in iteration 7735: 0.42575050934026265\n",
      "Theta: [-1.83969633  1.15782742  0.05350287]\n",
      "Loss in iteration 7736: 0.42574800657501205\n",
      "Theta: [-1.83978318  1.15788837  0.05350051]\n",
      "Loss in iteration 7737: 0.42574550461991434\n",
      "Theta: [-1.83987001  1.15794932  0.05349815]\n",
      "Loss in iteration 7738: 0.4257430034746548\n",
      "Theta: [-1.83995683  1.15801025  0.05349579]\n",
      "Loss in iteration 7739: 0.4257405031389193\n",
      "Theta: [-1.84004363  1.15807118  0.05349343]\n",
      "Loss in iteration 7740: 0.42573800361239306\n",
      "Theta: [-1.84013042  1.1581321   0.05349107]\n",
      "Loss in iteration 7741: 0.42573550489476203\n",
      "Theta: [-1.84021719  1.15819301  0.05348871]\n",
      "Loss in iteration 7742: 0.4257330069857121\n",
      "Theta: [-1.84030395  1.15825391  0.05348636]\n",
      "Loss in iteration 7743: 0.4257305098849294\n",
      "Theta: [-1.8403907  1.1583148  0.053484 ]\n",
      "Loss in iteration 7744: 0.4257280135921003\n",
      "Theta: [-1.84047743  1.15837568  0.05348164]\n",
      "Loss in iteration 7745: 0.42572551810691084\n",
      "Theta: [-1.84056414  1.15843655  0.05347928]\n",
      "Loss in iteration 7746: 0.425723023429048\n",
      "Theta: [-1.84065085  1.15849741  0.05347693]\n",
      "Loss in iteration 7747: 0.42572052955819806\n",
      "Theta: [-1.84073753  1.15855826  0.05347457]\n",
      "Loss in iteration 7748: 0.42571803649404805\n",
      "Theta: [-1.84082421  1.15861911  0.05347221]\n",
      "Loss in iteration 7749: 0.42571554423628494\n",
      "Theta: [-1.84091086  1.15867994  0.05346986]\n",
      "Loss in iteration 7750: 0.42571305278459576\n",
      "Theta: [-1.84099751  1.15874076  0.0534675 ]\n",
      "Loss in iteration 7751: 0.42571056213866787\n",
      "Theta: [-1.84108414  1.15880158  0.05346514]\n",
      "Loss in iteration 7752: 0.4257080722981887\n",
      "Theta: [-1.84117076  1.15886238  0.05346279]\n",
      "Loss in iteration 7753: 0.42570558326284574\n",
      "Theta: [-1.84125736  1.15892318  0.05346043]\n",
      "Loss in iteration 7754: 0.4257030950323266\n",
      "Theta: [-1.84134394  1.15898397  0.05345808]\n",
      "Loss in iteration 7755: 0.42570060760631934\n",
      "Theta: [-1.84143052  1.15904475  0.05345572]\n",
      "Loss in iteration 7756: 0.4256981209845119\n",
      "Theta: [-1.84151707  1.15910552  0.05345337]\n",
      "Loss in iteration 7757: 0.42569563516659237\n",
      "Theta: [-1.84160362  1.15916628  0.05345101]\n",
      "Loss in iteration 7758: 0.42569315015224896\n",
      "Theta: [-1.84169015  1.15922703  0.05344866]\n",
      "Loss in iteration 7759: 0.4256906659411704\n",
      "Theta: [-1.84177666  1.15928777  0.05344631]\n",
      "Loss in iteration 7760: 0.4256881825330448\n",
      "Theta: [-1.84186316  1.1593485   0.05344395]\n",
      "Loss in iteration 7761: 0.42568569992756145\n",
      "Theta: [-1.84194965  1.15940922  0.0534416 ]\n",
      "Loss in iteration 7762: 0.4256832181244089\n",
      "Theta: [-1.84203612  1.15946993  0.05343925]\n",
      "Loss in iteration 7763: 0.4256807371232762\n",
      "Theta: [-1.84212258  1.15953064  0.05343689]\n",
      "Loss in iteration 7764: 0.4256782569238524\n",
      "Theta: [-1.84220902  1.15959133  0.05343454]\n",
      "Loss in iteration 7765: 0.4256757775258272\n",
      "Theta: [-1.84229545  1.15965202  0.05343219]\n",
      "Loss in iteration 7766: 0.42567329892888955\n",
      "Theta: [-1.84238187  1.15971269  0.05342984]\n",
      "Loss in iteration 7767: 0.42567082113272936\n",
      "Theta: [-1.84246827  1.15977336  0.05342749]\n",
      "Loss in iteration 7768: 0.42566834413703636\n",
      "Theta: [-1.84255465  1.15983402  0.05342513]\n",
      "Loss in iteration 7769: 0.4256658679415004\n",
      "Theta: [-1.84264102  1.15989466  0.05342278]\n",
      "Loss in iteration 7770: 0.4256633925458116\n",
      "Theta: [-1.84272738  1.1599553   0.05342043]\n",
      "Loss in iteration 7771: 0.4256609179496598\n",
      "Theta: [-1.84281372  1.16001593  0.05341808]\n",
      "Loss in iteration 7772: 0.42565844415273596\n",
      "Theta: [-1.84290005  1.16007655  0.05341573]\n",
      "Loss in iteration 7773: 0.4256559711547301\n",
      "Theta: [-1.84298637  1.16013716  0.05341338]\n",
      "Loss in iteration 7774: 0.42565349895533267\n",
      "Theta: [-1.84307267  1.16019777  0.05341103]\n",
      "Loss in iteration 7775: 0.4256510275542349\n",
      "Theta: [-1.84315895  1.16025836  0.05340868]\n",
      "Loss in iteration 7776: 0.4256485569511275\n",
      "Theta: [-1.84324522  1.16031894  0.05340633]\n",
      "Loss in iteration 7777: 0.4256460871457014\n",
      "Theta: [-1.84333148  1.16037952  0.05340398]\n",
      "Loss in iteration 7778: 0.42564361813764806\n",
      "Theta: [-1.84341772  1.16044008  0.05340164]\n",
      "Loss in iteration 7779: 0.4256411499266585\n",
      "Theta: [-1.84350395  1.16050064  0.05339929]\n",
      "Loss in iteration 7780: 0.4256386825124243\n",
      "Theta: [-1.84359017  1.16056118  0.05339694]\n",
      "Loss in iteration 7781: 0.4256362158946373\n",
      "Theta: [-1.84367637  1.16062172  0.05339459]\n",
      "Loss in iteration 7782: 0.4256337500729892\n",
      "Theta: [-1.84376255  1.16068225  0.05339224]\n",
      "Loss in iteration 7783: 0.4256312850471716\n",
      "Theta: [-1.84384872  1.16074276  0.0533899 ]\n",
      "Loss in iteration 7784: 0.42562882081687703\n",
      "Theta: [-1.84393488  1.16080327  0.05338755]\n",
      "Loss in iteration 7785: 0.4256263573817974\n",
      "Theta: [-1.84402102  1.16086377  0.0533852 ]\n",
      "Loss in iteration 7786: 0.4256238947416251\n",
      "Theta: [-1.84410715  1.16092426  0.05338286]\n",
      "Loss in iteration 7787: 0.4256214328960528\n",
      "Theta: [-1.84419327  1.16098475  0.05338051]\n",
      "Loss in iteration 7788: 0.4256189718447729\n",
      "Theta: [-1.84427937  1.16104522  0.05337816]\n",
      "Loss in iteration 7789: 0.4256165115874782\n",
      "Theta: [-1.84436545  1.16110568  0.05337582]\n",
      "Loss in iteration 7790: 0.4256140521238616\n",
      "Theta: [-1.84445153  1.16116614  0.05337347]\n",
      "Loss in iteration 7791: 0.4256115934536166\n",
      "Theta: [-1.84453758  1.16122658  0.05337113]\n",
      "Loss in iteration 7792: 0.42560913557643587\n",
      "Theta: [-1.84462363  1.16128702  0.05336878]\n",
      "Loss in iteration 7793: 0.4256066784920129\n",
      "Theta: [-1.84470965  1.16134744  0.05336644]\n",
      "Loss in iteration 7794: 0.4256042222000414\n",
      "Theta: [-1.84479567  1.16140786  0.05336409]\n",
      "Loss in iteration 7795: 0.4256017667002148\n",
      "Theta: [-1.84488167  1.16146827  0.05336175]\n",
      "Loss in iteration 7796: 0.42559931199222695\n",
      "Theta: [-1.84496766  1.16152866  0.05335941]\n",
      "Loss in iteration 7797: 0.4255968580757719\n",
      "Theta: [-1.84505363  1.16158905  0.05335706]\n",
      "Loss in iteration 7798: 0.42559440495054324\n",
      "Theta: [-1.84513959  1.16164943  0.05335472]\n",
      "Loss in iteration 7799: 0.4255919526162357\n",
      "Theta: [-1.84522553  1.1617098   0.05335238]\n",
      "Loss in iteration 7800: 0.42558950107254356\n",
      "Theta: [-1.84531146  1.16177017  0.05335003]\n",
      "Loss in iteration 7801: 0.4255870503191611\n",
      "Theta: [-1.84539737  1.16183052  0.05334769]\n",
      "Loss in iteration 7802: 0.4255846003557832\n",
      "Theta: [-1.84548327  1.16189086  0.05334535]\n",
      "Loss in iteration 7803: 0.42558215118210446\n",
      "Theta: [-1.84556916  1.1619512   0.05334301]\n",
      "Loss in iteration 7804: 0.4255797027978199\n",
      "Theta: [-1.84565503  1.16201152  0.05334066]\n",
      "Loss in iteration 7805: 0.42557725520262457\n",
      "Theta: [-1.84574089  1.16207184  0.05333832]\n",
      "Loss in iteration 7806: 0.4255748083962137\n",
      "Theta: [-1.84582673  1.16213214  0.05333598]\n",
      "Loss in iteration 7807: 0.4255723623782825\n",
      "Theta: [-1.84591256  1.16219244  0.05333364]\n",
      "Loss in iteration 7808: 0.4255699171485265\n",
      "Theta: [-1.84599838  1.16225273  0.0533313 ]\n",
      "Loss in iteration 7809: 0.4255674727066415\n",
      "Theta: [-1.84608418  1.16231301  0.05332896]\n",
      "Loss in iteration 7810: 0.4255650290523232\n",
      "Theta: [-1.84616997  1.16237328  0.05332662]\n",
      "Loss in iteration 7811: 0.42556258618526754\n",
      "Theta: [-1.84625574  1.16243354  0.05332428]\n",
      "Loss in iteration 7812: 0.42556014410517046\n",
      "Theta: [-1.8463415   1.16249379  0.05332194]\n",
      "Loss in iteration 7813: 0.4255577028117283\n",
      "Theta: [-1.84642724  1.16255403  0.0533196 ]\n",
      "Loss in iteration 7814: 0.42555526230463736\n",
      "Theta: [-1.84651297  1.16261426  0.05331726]\n",
      "Loss in iteration 7815: 0.4255528225835941\n",
      "Theta: [-1.84659869  1.16267449  0.05331492]\n",
      "Loss in iteration 7816: 0.42555038364829506\n",
      "Theta: [-1.84668439  1.1627347   0.05331259]\n",
      "Loss in iteration 7817: 0.4255479454984371\n",
      "Theta: [-1.84677008  1.16279491  0.05331025]\n",
      "Loss in iteration 7818: 0.42554550813371717\n",
      "Theta: [-1.84685575  1.1628551   0.05330791]\n",
      "Loss in iteration 7819: 0.42554307155383236\n",
      "Theta: [-1.84694141  1.16291529  0.05330557]\n",
      "Loss in iteration 7820: 0.42554063575847983\n",
      "Theta: [-1.84702706  1.16297547  0.05330323]\n",
      "Loss in iteration 7821: 0.42553820074735677\n",
      "Theta: [-1.84711269  1.16303563  0.0533009 ]\n",
      "Loss in iteration 7822: 0.4255357665201608\n",
      "Theta: [-1.84719831  1.16309579  0.05329856]\n",
      "Loss in iteration 7823: 0.42553333307658947\n",
      "Theta: [-1.84728391  1.16315594  0.05329622]\n",
      "Loss in iteration 7824: 0.42553090041634045\n",
      "Theta: [-1.8473695   1.16321609  0.05329389]\n",
      "Loss in iteration 7825: 0.4255284685391119\n",
      "Theta: [-1.84745507  1.16327622  0.05329155]\n",
      "Loss in iteration 7826: 0.42552603744460155\n",
      "Theta: [-1.84754064  1.16333634  0.05328922]\n",
      "Loss in iteration 7827: 0.42552360713250775\n",
      "Theta: [-1.84762618  1.16339645  0.05328688]\n",
      "Loss in iteration 7828: 0.425521177602529\n",
      "Theta: [-1.84771171  1.16345656  0.05328454]\n",
      "Loss in iteration 7829: 0.42551874885436336\n",
      "Theta: [-1.84779723  1.16351665  0.05328221]\n",
      "Loss in iteration 7830: 0.4255163208877095\n",
      "Theta: [-1.84788274  1.16357674  0.05327987]\n",
      "Loss in iteration 7831: 0.42551389370226667\n",
      "Theta: [-1.84796823  1.16363682  0.05327754]\n",
      "Loss in iteration 7832: 0.4255114672977331\n",
      "Theta: [-1.8480537   1.16369688  0.05327521]\n",
      "Loss in iteration 7833: 0.4255090416738081\n",
      "Theta: [-1.84813916  1.16375694  0.05327287]\n",
      "Loss in iteration 7834: 0.42550661683019086\n",
      "Theta: [-1.84822461  1.16381699  0.05327054]\n",
      "Loss in iteration 7835: 0.42550419276658047\n",
      "Theta: [-1.84831004  1.16387703  0.0532682 ]\n",
      "Loss in iteration 7836: 0.4255017694826767\n",
      "Theta: [-1.84839546  1.16393706  0.05326587]\n",
      "Loss in iteration 7837: 0.42549934697817876\n",
      "Theta: [-1.84848087  1.16399709  0.05326354]\n",
      "Loss in iteration 7838: 0.4254969252527866\n",
      "Theta: [-1.84856626  1.1640571   0.05326121]\n",
      "Loss in iteration 7839: 0.42549450430620017\n",
      "Theta: [-1.84865164  1.1641171   0.05325887]\n",
      "Loss in iteration 7840: 0.42549208413811923\n",
      "Theta: [-1.848737    1.1641771   0.05325654]\n",
      "Loss in iteration 7841: 0.42548966474824396\n",
      "Theta: [-1.84882235  1.16423708  0.05325421]\n",
      "Loss in iteration 7842: 0.42548724613627475\n",
      "Theta: [-1.84890768  1.16429706  0.05325188]\n",
      "Loss in iteration 7843: 0.42548482830191203\n",
      "Theta: [-1.848993    1.16435703  0.05324955]\n",
      "Loss in iteration 7844: 0.4254824112448562\n",
      "Theta: [-1.84907831  1.16441698  0.05324722]\n",
      "Loss in iteration 7845: 0.42547999496480815\n",
      "Theta: [-1.8491636   1.16447693  0.05324488]\n",
      "Loss in iteration 7846: 0.4254775794614685\n",
      "Theta: [-1.84924888  1.16453687  0.05324255]\n",
      "Loss in iteration 7847: 0.4254751647345384\n",
      "Theta: [-1.84933415  1.1645968   0.05324022]\n",
      "Loss in iteration 7848: 0.4254727507837188\n",
      "Theta: [-1.8494194   1.16465673  0.05323789]\n",
      "Loss in iteration 7849: 0.42547033760871117\n",
      "Theta: [-1.84950463  1.16471664  0.05323556]\n",
      "Loss in iteration 7850: 0.4254679252092168\n",
      "Theta: [-1.84958986  1.16477654  0.05323324]\n",
      "Loss in iteration 7851: 0.42546551358493706\n",
      "Theta: [-1.84967506  1.16483644  0.05323091]\n",
      "Loss in iteration 7852: 0.4254631027355737\n",
      "Theta: [-1.84976026  1.16489632  0.05322858]\n",
      "Loss in iteration 7853: 0.4254606926608286\n",
      "Theta: [-1.84984544  1.1649562   0.05322625]\n",
      "Loss in iteration 7854: 0.4254582833604037\n",
      "Theta: [-1.8499306   1.16501606  0.05322392]\n",
      "Loss in iteration 7855: 0.42545587483400127\n",
      "Theta: [-1.85001576  1.16507592  0.05322159]\n",
      "Loss in iteration 7856: 0.4254534670813231\n",
      "Theta: [-1.85010089  1.16513577  0.05321926]\n",
      "Loss in iteration 7857: 0.42545106010207173\n",
      "Theta: [-1.85018602  1.16519561  0.05321694]\n",
      "Loss in iteration 7858: 0.4254486538959498\n",
      "Theta: [-1.85027113  1.16525544  0.05321461]\n",
      "Loss in iteration 7859: 0.4254462484626598\n",
      "Theta: [-1.85035622  1.16531526  0.05321228]\n",
      "Loss in iteration 7860: 0.42544384380190453\n",
      "Theta: [-1.85044131  1.16537507  0.05320996]\n",
      "Loss in iteration 7861: 0.425441439913387\n",
      "Theta: [-1.85052637  1.16543488  0.05320763]\n",
      "Loss in iteration 7862: 0.4254390367968101\n",
      "Theta: [-1.85061143  1.16549467  0.0532053 ]\n",
      "Loss in iteration 7863: 0.425436634451877\n",
      "Theta: [-1.85069647  1.16555446  0.05320298]\n",
      "Loss in iteration 7864: 0.4254342328782913\n",
      "Theta: [-1.85078149  1.16561423  0.05320065]\n",
      "Loss in iteration 7865: 0.4254318320757562\n",
      "Theta: [-1.85086651  1.165674    0.05319833]\n",
      "Loss in iteration 7866: 0.42542943204397543\n",
      "Theta: [-1.8509515   1.16573376  0.053196  ]\n",
      "Loss in iteration 7867: 0.42542703278265265\n",
      "Theta: [-1.85103649  1.1657935   0.05319368]\n",
      "Loss in iteration 7868: 0.42542463429149163\n",
      "Theta: [-1.85112146  1.16585324  0.05319135]\n",
      "Loss in iteration 7869: 0.4254222365701966\n",
      "Theta: [-1.85120641  1.16591297  0.05318903]\n",
      "Loss in iteration 7870: 0.4254198396184716\n",
      "Theta: [-1.85129135  1.1659727   0.0531867 ]\n",
      "Loss in iteration 7871: 0.42541744343602106\n",
      "Theta: [-1.85137628  1.16603241  0.05318438]\n",
      "Loss in iteration 7872: 0.42541504802254915\n",
      "Theta: [-1.8514612   1.16609211  0.05318205]\n",
      "Loss in iteration 7873: 0.42541265337776063\n",
      "Theta: [-1.8515461   1.16615181  0.05317973]\n",
      "Loss in iteration 7874: 0.4254102595013602\n",
      "Theta: [-1.85163098  1.16621149  0.05317741]\n",
      "Loss in iteration 7875: 0.4254078663930524\n",
      "Theta: [-1.85171585  1.16627117  0.05317509]\n",
      "Loss in iteration 7876: 0.42540547405254253\n",
      "Theta: [-1.85180071  1.16633083  0.05317276]\n",
      "Loss in iteration 7877: 0.4254030824795356\n",
      "Theta: [-1.85188556  1.16639049  0.05317044]\n",
      "Loss in iteration 7878: 0.425400691673737\n",
      "Theta: [-1.85197039  1.16645014  0.05316812]\n",
      "Loss in iteration 7879: 0.42539830163485176\n",
      "Theta: [-1.8520552   1.16650978  0.0531658 ]\n",
      "Loss in iteration 7880: 0.4253959123625857\n",
      "Theta: [-1.85214     1.16656941  0.05316348]\n",
      "Loss in iteration 7881: 0.4253935238566443\n",
      "Theta: [-1.85222479  1.16662903  0.05316115]\n",
      "Loss in iteration 7882: 0.42539113611673346\n",
      "Theta: [-1.85230957  1.16668864  0.05315883]\n",
      "Loss in iteration 7883: 0.4253887491425591\n",
      "Theta: [-1.85239433  1.16674825  0.05315651]\n",
      "Loss in iteration 7884: 0.42538636293382726\n",
      "Theta: [-1.85247907  1.16680784  0.05315419]\n",
      "Loss in iteration 7885: 0.42538397749024404\n",
      "Theta: [-1.8525638   1.16686743  0.05315187]\n",
      "Loss in iteration 7886: 0.4253815928115159\n",
      "Theta: [-1.85264852  1.166927    0.05314955]\n",
      "Loss in iteration 7887: 0.42537920889734926\n",
      "Theta: [-1.85273323  1.16698657  0.05314723]\n",
      "Loss in iteration 7888: 0.42537682574745084\n",
      "Theta: [-1.85281792  1.16704613  0.05314491]\n",
      "Loss in iteration 7889: 0.42537444336152724\n",
      "Theta: [-1.85290259  1.16710568  0.05314259]\n",
      "Loss in iteration 7890: 0.42537206173928555\n",
      "Theta: [-1.85298726  1.16716522  0.05314028]\n",
      "Loss in iteration 7891: 0.4253696808804323\n",
      "Theta: [-1.85307191  1.16722475  0.05313796]\n",
      "Loss in iteration 7892: 0.4253673007846752\n",
      "Theta: [-1.85315654  1.16728427  0.05313564]\n",
      "Loss in iteration 7893: 0.42536492145172106\n",
      "Theta: [-1.85324116  1.16734378  0.05313332]\n",
      "Loss in iteration 7894: 0.4253625428812778\n",
      "Theta: [-1.85332577  1.16740329  0.053131  ]\n",
      "Loss in iteration 7895: 0.4253601650730526\n",
      "Theta: [-1.85341036  1.16746278  0.05312869]\n",
      "Loss in iteration 7896: 0.4253577880267534\n",
      "Theta: [-1.85349494  1.16752227  0.05312637]\n",
      "Loss in iteration 7897: 0.4253554117420877\n",
      "Theta: [-1.85357951  1.16758175  0.05312405]\n",
      "Loss in iteration 7898: 0.42535303621876375\n",
      "Theta: [-1.85366406  1.16764121  0.05312173]\n",
      "Loss in iteration 7899: 0.42535066145648953\n",
      "Theta: [-1.85374859  1.16770067  0.05311942]\n",
      "Loss in iteration 7900: 0.4253482874549734\n",
      "Theta: [-1.85383312  1.16776012  0.0531171 ]\n",
      "Loss in iteration 7901: 0.42534591421392354\n",
      "Theta: [-1.85391763  1.16781956  0.05311479]\n",
      "Loss in iteration 7902: 0.4253435417330484\n",
      "Theta: [-1.85400212  1.16787899  0.05311247]\n",
      "Loss in iteration 7903: 0.42534117001205696\n",
      "Theta: [-1.8540866   1.16793842  0.05311016]\n",
      "Loss in iteration 7904: 0.42533879905065775\n",
      "Theta: [-1.85417107  1.16799783  0.05310784]\n",
      "Loss in iteration 7905: 0.4253364288485596\n",
      "Theta: [-1.85425553  1.16805723  0.05310553]\n",
      "Loss in iteration 7906: 0.4253340594054717\n",
      "Theta: [-1.85433997  1.16811663  0.05310321]\n",
      "Loss in iteration 7907: 0.4253316907211033\n",
      "Theta: [-1.85442439  1.16817602  0.0531009 ]\n",
      "Loss in iteration 7908: 0.42532932279516344\n",
      "Theta: [-1.85450881  1.16823539  0.05309858]\n",
      "Loss in iteration 7909: 0.4253269556273617\n",
      "Theta: [-1.8545932   1.16829476  0.05309627]\n",
      "Loss in iteration 7910: 0.4253245892174079\n",
      "Theta: [-1.85467759  1.16835412  0.05309396]\n",
      "Loss in iteration 7911: 0.4253222235650113\n",
      "Theta: [-1.85476196  1.16841347  0.05309164]\n",
      "Loss in iteration 7912: 0.42531985866988214\n",
      "Theta: [-1.85484632  1.16847281  0.05308933]\n",
      "Loss in iteration 7913: 0.4253174945317302\n",
      "Theta: [-1.85493066  1.16853215  0.05308702]\n",
      "Loss in iteration 7914: 0.42531513115026576\n",
      "Theta: [-1.85501499  1.16859147  0.0530847 ]\n",
      "Loss in iteration 7915: 0.4253127685251985\n",
      "Theta: [-1.85509931  1.16865079  0.05308239]\n",
      "Loss in iteration 7916: 0.42531040665623976\n",
      "Theta: [-1.85518361  1.16871009  0.05308008]\n",
      "Loss in iteration 7917: 0.4253080455430993\n",
      "Theta: [-1.85526789  1.16876939  0.05307777]\n",
      "Loss in iteration 7918: 0.42530568518548795\n",
      "Theta: [-1.85535217  1.16882867  0.05307546]\n",
      "Loss in iteration 7919: 0.4253033255831167\n",
      "Theta: [-1.85543643  1.16888795  0.05307315]\n",
      "Loss in iteration 7920: 0.4253009667356962\n",
      "Theta: [-1.85552068  1.16894722  0.05307083]\n",
      "Loss in iteration 7921: 0.4252986086429377\n",
      "Theta: [-1.85560491  1.16900648  0.05306852]\n",
      "Loss in iteration 7922: 0.4252962513045524\n",
      "Theta: [-1.85568913  1.16906574  0.05306621]\n",
      "Loss in iteration 7923: 0.4252938947202513\n",
      "Theta: [-1.85577333  1.16912498  0.0530639 ]\n",
      "Loss in iteration 7924: 0.4252915388897462\n",
      "Theta: [-1.85585752  1.16918421  0.05306159]\n",
      "Loss in iteration 7925: 0.42528918381274855\n",
      "Theta: [-1.8559417   1.16924344  0.05305928]\n",
      "Loss in iteration 7926: 0.42528682948896995\n",
      "Theta: [-1.85602586  1.16930265  0.05305698]\n",
      "Loss in iteration 7927: 0.4252844759181226\n",
      "Theta: [-1.85611001  1.16936186  0.05305467]\n",
      "Loss in iteration 7928: 0.42528212309991814\n",
      "Theta: [-1.85619415  1.16942106  0.05305236]\n",
      "Loss in iteration 7929: 0.4252797710340688\n",
      "Theta: [-1.85627827  1.16948024  0.05305005]\n",
      "Loss in iteration 7930: 0.4252774197202869\n",
      "Theta: [-1.85636238  1.16953942  0.05304774]\n",
      "Loss in iteration 7931: 0.42527506915828456\n",
      "Theta: [-1.85644647  1.1695986   0.05304543]\n",
      "Loss in iteration 7932: 0.4252727193477746\n",
      "Theta: [-1.85653055  1.16965776  0.05304313]\n",
      "Loss in iteration 7933: 0.4252703702884695\n",
      "Theta: [-1.85661462  1.16971691  0.05304082]\n",
      "Loss in iteration 7934: 0.42526802198008207\n",
      "Theta: [-1.85669867  1.16977605  0.05303851]\n",
      "Loss in iteration 7935: 0.4252656744223253\n",
      "Theta: [-1.85678271  1.16983519  0.0530362 ]\n",
      "Loss in iteration 7936: 0.4252633276149121\n",
      "Theta: [-1.85686674  1.16989431  0.0530339 ]\n",
      "Loss in iteration 7937: 0.42526098155755593\n",
      "Theta: [-1.85695075  1.16995343  0.05303159]\n",
      "Loss in iteration 7938: 0.42525863624996957\n",
      "Theta: [-1.85703475  1.17001254  0.05302928]\n",
      "Loss in iteration 7939: 0.425256291691867\n",
      "Theta: [-1.85711873  1.17007164  0.05302698]\n",
      "Loss in iteration 7940: 0.42525394788296156\n",
      "Theta: [-1.8572027   1.17013073  0.05302467]\n",
      "Loss in iteration 7941: 0.4252516048229669\n",
      "Theta: [-1.85728666  1.17018981  0.05302237]\n",
      "Loss in iteration 7942: 0.42524926251159684\n",
      "Theta: [-1.8573706   1.17024888  0.05302006]\n",
      "Loss in iteration 7943: 0.42524692094856553\n",
      "Theta: [-1.85745453  1.17030795  0.05301776]\n",
      "Loss in iteration 7944: 0.4252445801335869\n",
      "Theta: [-1.85753845  1.170367    0.05301545]\n",
      "Loss in iteration 7945: 0.42524224006637523\n",
      "Theta: [-1.85762235  1.17042605  0.05301315]\n",
      "Loss in iteration 7946: 0.425239900746645\n",
      "Theta: [-1.85770624  1.17048508  0.05301085]\n",
      "Loss in iteration 7947: 0.4252375621741106\n",
      "Theta: [-1.85779011  1.17054411  0.05300854]\n",
      "Loss in iteration 7948: 0.4252352243484865\n",
      "Theta: [-1.85787397  1.17060313  0.05300624]\n",
      "Loss in iteration 7949: 0.42523288726948777\n",
      "Theta: [-1.85795782  1.17066214  0.05300394]\n",
      "Loss in iteration 7950: 0.42523055093682915\n",
      "Theta: [-1.85804165  1.17072114  0.05300163]\n",
      "Loss in iteration 7951: 0.4252282153502256\n",
      "Theta: [-1.85812547  1.17078013  0.05299933]\n",
      "Loss in iteration 7952: 0.42522588050939225\n",
      "Theta: [-1.85820927  1.17083911  0.05299703]\n",
      "Loss in iteration 7953: 0.42522354641404464\n",
      "Theta: [-1.85829307  1.17089809  0.05299473]\n",
      "Loss in iteration 7954: 0.4252212130638979\n",
      "Theta: [-1.85837684  1.17095705  0.05299242]\n",
      "Loss in iteration 7955: 0.4252188804586677\n",
      "Theta: [-1.85846061  1.17101601  0.05299012]\n",
      "Loss in iteration 7956: 0.4252165485980697\n",
      "Theta: [-1.85854436  1.17107495  0.05298782]\n",
      "Loss in iteration 7957: 0.4252142174818195\n",
      "Theta: [-1.8586281   1.17113389  0.05298552]\n",
      "Loss in iteration 7958: 0.4252118871096334\n",
      "Theta: [-1.85871182  1.17119282  0.05298322]\n",
      "Loss in iteration 7959: 0.42520955748122735\n",
      "Theta: [-1.85879553  1.17125174  0.05298092]\n",
      "Loss in iteration 7960: 0.42520722859631754\n",
      "Theta: [-1.85887922  1.17131065  0.05297862]\n",
      "Loss in iteration 7961: 0.42520490045462006\n",
      "Theta: [-1.85896291  1.17136956  0.05297632]\n",
      "Loss in iteration 7962: 0.42520257305585174\n",
      "Theta: [-1.85904657  1.17142845  0.05297402]\n",
      "Loss in iteration 7963: 0.425200246399729\n",
      "Theta: [-1.85913023  1.17148733  0.05297172]\n",
      "Loss in iteration 7964: 0.4251979204859683\n",
      "Theta: [-1.85921387  1.17154621  0.05296942]\n",
      "Loss in iteration 7965: 0.425195595314287\n",
      "Theta: [-1.8592975   1.17160508  0.05296712]\n",
      "Loss in iteration 7966: 0.4251932708844018\n",
      "Theta: [-1.85938111  1.17166394  0.05296482]\n",
      "Loss in iteration 7967: 0.4251909471960299\n",
      "Theta: [-1.85946471  1.17172278  0.05296252]\n",
      "Loss in iteration 7968: 0.42518862424888826\n",
      "Theta: [-1.8595483   1.17178162  0.05296023]\n",
      "Loss in iteration 7969: 0.4251863020426946\n",
      "Theta: [-1.85963187  1.17184046  0.05295793]\n",
      "Loss in iteration 7970: 0.4251839805771662\n",
      "Theta: [-1.85971543  1.17189928  0.05295563]\n",
      "Loss in iteration 7971: 0.42518165985202094\n",
      "Theta: [-1.85979897  1.17195809  0.05295333]\n",
      "Loss in iteration 7972: 0.4251793398669765\n",
      "Theta: [-1.8598825   1.1720169   0.05295104]\n",
      "Loss in iteration 7973: 0.4251770206217504\n",
      "Theta: [-1.85996602  1.17207569  0.05294874]\n",
      "Loss in iteration 7974: 0.425174702116061\n",
      "Theta: [-1.86004953  1.17213448  0.05294644]\n",
      "Loss in iteration 7975: 0.4251723843496265\n",
      "Theta: [-1.86013302  1.17219326  0.05294415]\n",
      "Loss in iteration 7976: 0.42517006732216506\n",
      "Theta: [-1.86021649  1.17225203  0.05294185]\n",
      "Loss in iteration 7977: 0.4251677510333952\n",
      "Theta: [-1.86029996  1.17231079  0.05293955]\n",
      "Loss in iteration 7978: 0.42516543548303515\n",
      "Theta: [-1.86038341  1.17236954  0.05293726]\n",
      "Loss in iteration 7979: 0.4251631206708039\n",
      "Theta: [-1.86046684  1.17242828  0.05293496]\n",
      "Loss in iteration 7980: 0.42516080659642014\n",
      "Theta: [-1.86055027  1.17248701  0.05293267]\n",
      "Loss in iteration 7981: 0.42515849325960287\n",
      "Theta: [-1.86063367  1.17254574  0.05293037]\n",
      "Loss in iteration 7982: 0.42515618066007077\n",
      "Theta: [-1.86071707  1.17260445  0.05292808]\n",
      "Loss in iteration 7983: 0.42515386879754374\n",
      "Theta: [-1.86080045  1.17266316  0.05292578]\n",
      "Loss in iteration 7984: 0.42515155767174045\n",
      "Theta: [-1.86088382  1.17272186  0.05292349]\n",
      "Loss in iteration 7985: 0.42514924728238035\n",
      "Theta: [-1.86096717  1.17278055  0.0529212 ]\n",
      "Loss in iteration 7986: 0.42514693762918365\n",
      "Theta: [-1.86105051  1.17283923  0.0529189 ]\n",
      "Loss in iteration 7987: 0.4251446287118693\n",
      "Theta: [-1.86113384  1.1728979   0.05291661]\n",
      "Loss in iteration 7988: 0.42514232053015755\n",
      "Theta: [-1.86121715  1.17295656  0.05291432]\n",
      "Loss in iteration 7989: 0.4251400130837682\n",
      "Theta: [-1.86130045  1.17301521  0.05291202]\n",
      "Loss in iteration 7990: 0.4251377063724215\n",
      "Theta: [-1.86138374  1.17307386  0.05290973]\n",
      "Loss in iteration 7991: 0.4251354003958373\n",
      "Theta: [-1.86146701  1.17313249  0.05290744]\n",
      "Loss in iteration 7992: 0.42513309515373643\n",
      "Theta: [-1.86155027  1.17319112  0.05290515]\n",
      "Loss in iteration 7993: 0.425130790645839\n",
      "Theta: [-1.86163352  1.17324974  0.05290286]\n",
      "Loss in iteration 7994: 0.42512848687186566\n",
      "Theta: [-1.86171675  1.17330835  0.05290057]\n",
      "Loss in iteration 7995: 0.4251261838315373\n",
      "Theta: [-1.86179997  1.17336695  0.05289827]\n",
      "Loss in iteration 7996: 0.4251238815245747\n",
      "Theta: [-1.86188317  1.17342554  0.05289598]\n",
      "Loss in iteration 7997: 0.42512157995069866\n",
      "Theta: [-1.86196636  1.17348412  0.05289369]\n",
      "Loss in iteration 7998: 0.42511927910963054\n",
      "Theta: [-1.86204954  1.1735427   0.0528914 ]\n",
      "Loss in iteration 7999: 0.4251169790010916\n",
      "Theta: [-1.8621327   1.17360126  0.05288911]\n",
      "Loss in iteration 8000: 0.42511467962480265\n",
      "Theta: [-1.86221585  1.17365982  0.05288682]\n",
      "Loss in iteration 8001: 0.425112380980486\n",
      "Theta: [-1.86229899  1.17371837  0.05288453]\n",
      "Loss in iteration 8002: 0.42511008306786285\n",
      "Theta: [-1.86238211  1.1737769   0.05288224]\n",
      "Loss in iteration 8003: 0.4251077858866548\n",
      "Theta: [-1.86246522  1.17383543  0.05287996]\n",
      "Loss in iteration 8004: 0.425105489436584\n",
      "Theta: [-1.86254832  1.17389395  0.05287767]\n",
      "Loss in iteration 8005: 0.42510319371737254\n",
      "Theta: [-1.8626314   1.17395247  0.05287538]\n",
      "Loss in iteration 8006: 0.4251008987287421\n",
      "Theta: [-1.86271447  1.17401097  0.05287309]\n",
      "Loss in iteration 8007: 0.42509860447041525\n",
      "Theta: [-1.86279752  1.17406946  0.0528708 ]\n",
      "Loss in iteration 8008: 0.42509631094211436\n",
      "Theta: [-1.86288056  1.17412795  0.05286851]\n",
      "Loss in iteration 8009: 0.425094018143562\n",
      "Theta: [-1.86296359  1.17418643  0.05286623]\n",
      "Loss in iteration 8010: 0.42509172607448065\n",
      "Theta: [-1.86304661  1.17424489  0.05286394]\n",
      "Loss in iteration 8011: 0.4250894347345931\n",
      "Theta: [-1.86312961  1.17430335  0.05286165]\n",
      "Loss in iteration 8012: 0.4250871441236223\n",
      "Theta: [-1.8632126   1.1743618   0.05285937]\n",
      "Loss in iteration 8013: 0.4250848542412912\n",
      "Theta: [-1.86329557  1.17442024  0.05285708]\n",
      "Loss in iteration 8014: 0.4250825650873231\n",
      "Theta: [-1.86337853  1.17447868  0.05285479]\n",
      "Loss in iteration 8015: 0.4250802766614412\n",
      "Theta: [-1.86346148  1.1745371   0.05285251]\n",
      "Loss in iteration 8016: 0.4250779889633687\n",
      "Theta: [-1.86354441  1.17459551  0.05285022]\n",
      "Loss in iteration 8017: 0.4250757019928297\n",
      "Theta: [-1.86362733  1.17465392  0.05284794]\n",
      "Loss in iteration 8018: 0.42507341574954716\n",
      "Theta: [-1.86371024  1.17471232  0.05284565]\n",
      "Loss in iteration 8019: 0.42507113023324505\n",
      "Theta: [-1.86379313  1.17477071  0.05284337]\n",
      "Loss in iteration 8020: 0.42506884544364754\n",
      "Theta: [-1.86387601  1.17482909  0.05284108]\n",
      "Loss in iteration 8021: 0.4250665613804785\n",
      "Theta: [-1.86395887  1.17488746  0.0528388 ]\n",
      "Loss in iteration 8022: 0.4250642780434621\n",
      "Theta: [-1.86404173  1.17494582  0.05283652]\n",
      "Loss in iteration 8023: 0.4250619954323225\n",
      "Theta: [-1.86412457  1.17500417  0.05283423]\n",
      "Loss in iteration 8024: 0.42505971354678446\n",
      "Theta: [-1.86420739  1.17506252  0.05283195]\n",
      "Loss in iteration 8025: 0.4250574323865722\n",
      "Theta: [-1.8642902   1.17512085  0.05282967]\n",
      "Loss in iteration 8026: 0.42505515195141036\n",
      "Theta: [-1.864373    1.17517918  0.05282738]\n",
      "Loss in iteration 8027: 0.4250528722410237\n",
      "Theta: [-1.86445579  1.1752375   0.0528251 ]\n",
      "Loss in iteration 8028: 0.4250505932551376\n",
      "Theta: [-1.86453856  1.17529581  0.05282282]\n",
      "Loss in iteration 8029: 0.4250483149934767\n",
      "Theta: [-1.86462131  1.17535411  0.05282054]\n",
      "Loss in iteration 8030: 0.425046037455766\n",
      "Theta: [-1.86470406  1.1754124   0.05281825]\n",
      "Loss in iteration 8031: 0.4250437606417312\n",
      "Theta: [-1.86478679  1.17547068  0.05281597]\n",
      "Loss in iteration 8032: 0.42504148455109764\n",
      "Theta: [-1.86486951  1.17552895  0.05281369]\n",
      "Loss in iteration 8033: 0.42503920918359056\n",
      "Theta: [-1.86495221  1.17558722  0.05281141]\n",
      "Loss in iteration 8034: 0.42503693453893604\n",
      "Theta: [-1.8650349   1.17564548  0.05280913]\n",
      "Loss in iteration 8035: 0.4250346606168596\n",
      "Theta: [-1.86511758  1.17570372  0.05280685]\n",
      "Loss in iteration 8036: 0.4250323874170872\n",
      "Theta: [-1.86520024  1.17576196  0.05280457]\n",
      "Loss in iteration 8037: 0.4250301149393449\n",
      "Theta: [-1.86528289  1.17582019  0.05280229]\n",
      "Loss in iteration 8038: 0.4250278431833589\n",
      "Theta: [-1.86536553  1.17587841  0.05280001]\n",
      "Loss in iteration 8039: 0.4250255721488556\n",
      "Theta: [-1.86544815  1.17593663  0.05279773]\n",
      "Loss in iteration 8040: 0.4250233018355612\n",
      "Theta: [-1.86553076  1.17599483  0.05279545]\n",
      "Loss in iteration 8041: 0.4250210322432023\n",
      "Theta: [-1.86561336  1.17605302  0.05279317]\n",
      "Loss in iteration 8042: 0.42501876337150557\n",
      "Theta: [-1.86569594  1.17611121  0.05279089]\n",
      "Loss in iteration 8043: 0.4250164952201979\n",
      "Theta: [-1.86577851  1.17616939  0.05278861]\n",
      "Loss in iteration 8044: 0.4250142277890061\n",
      "Theta: [-1.86586107  1.17622756  0.05278634]\n",
      "Loss in iteration 8045: 0.42501196107765743\n",
      "Theta: [-1.86594361  1.17628572  0.05278406]\n",
      "Loss in iteration 8046: 0.4250096950858789\n",
      "Theta: [-1.86602614  1.17634387  0.05278178]\n",
      "Loss in iteration 8047: 0.4250074298133976\n",
      "Theta: [-1.86610865  1.17640201  0.0527795 ]\n",
      "Loss in iteration 8048: 0.42500516525994114\n",
      "Theta: [-1.86619115  1.17646014  0.05277723]\n",
      "Loss in iteration 8049: 0.4250029014252372\n",
      "Theta: [-1.86627364  1.17651827  0.05277495]\n",
      "Loss in iteration 8050: 0.4250006383090133\n",
      "Theta: [-1.86635612  1.17657638  0.05277267]\n",
      "Loss in iteration 8051: 0.4249983759109973\n",
      "Theta: [-1.86643858  1.17663449  0.0527704 ]\n",
      "Loss in iteration 8052: 0.4249961142309169\n",
      "Theta: [-1.86652103  1.17669259  0.05276812]\n",
      "Loss in iteration 8053: 0.42499385326850037\n",
      "Theta: [-1.86660346  1.17675068  0.05276584]\n",
      "Loss in iteration 8054: 0.42499159302347594\n",
      "Theta: [-1.86668589  1.17680876  0.05276357]\n",
      "Loss in iteration 8055: 0.42498933349557155\n",
      "Theta: [-1.86676829  1.17686683  0.05276129]\n",
      "Loss in iteration 8056: 0.42498707468451596\n",
      "Theta: [-1.86685069  1.1769249   0.05275902]\n",
      "Loss in iteration 8057: 0.42498481659003745\n",
      "Theta: [-1.86693307  1.17698295  0.05275674]\n",
      "Loss in iteration 8058: 0.4249825592118649\n",
      "Theta: [-1.86701544  1.177041    0.05275447]\n",
      "Loss in iteration 8059: 0.4249803025497269\n",
      "Theta: [-1.86709779  1.17709904  0.05275219]\n",
      "Loss in iteration 8060: 0.4249780466033525\n",
      "Theta: [-1.86718013  1.17715706  0.05274992]\n",
      "Loss in iteration 8061: 0.4249757913724706\n",
      "Theta: [-1.86726246  1.17721508  0.05274765]\n",
      "Loss in iteration 8062: 0.42497353685681033\n",
      "Theta: [-1.86734478  1.1772731   0.05274537]\n",
      "Loss in iteration 8063: 0.42497128305610127\n",
      "Theta: [-1.86742708  1.1773311   0.0527431 ]\n",
      "Loss in iteration 8064: 0.4249690299700724\n",
      "Theta: [-1.86750936  1.17738909  0.05274083]\n",
      "Loss in iteration 8065: 0.4249667775984535\n",
      "Theta: [-1.86759164  1.17744708  0.05273855]\n",
      "Loss in iteration 8066: 0.42496452594097434\n",
      "Theta: [-1.8676739   1.17750505  0.05273628]\n",
      "Loss in iteration 8067: 0.42496227499736433\n",
      "Theta: [-1.86775615  1.17756302  0.05273401]\n",
      "Loss in iteration 8068: 0.42496002476735356\n",
      "Theta: [-1.86783838  1.17762098  0.05273174]\n",
      "Loss in iteration 8069: 0.424957775250672\n",
      "Theta: [-1.8679206   1.17767893  0.05272947]\n",
      "Loss in iteration 8070: 0.4249555264470501\n",
      "Theta: [-1.86800281  1.17773687  0.0527272 ]\n",
      "Loss in iteration 8071: 0.4249532783562176\n",
      "Theta: [-1.868085    1.1777948   0.05272492]\n",
      "Loss in iteration 8072: 0.4249510309779051\n",
      "Theta: [-1.86816718  1.17785273  0.05272265]\n",
      "Loss in iteration 8073: 0.42494878431184335\n",
      "Theta: [-1.86824935  1.17791064  0.05272038]\n",
      "Loss in iteration 8074: 0.4249465383577625\n",
      "Theta: [-1.86833151  1.17796855  0.05271811]\n",
      "Loss in iteration 8075: 0.4249442931153937\n",
      "Theta: [-1.86841365  1.17802645  0.05271584]\n",
      "Loss in iteration 8076: 0.42494204858446766\n",
      "Theta: [-1.86849577  1.17808433  0.05271357]\n",
      "Loss in iteration 8077: 0.4249398047647155\n",
      "Theta: [-1.86857789  1.17814221  0.0527113 ]\n",
      "Loss in iteration 8078: 0.4249375616558681\n",
      "Theta: [-1.86865999  1.17820009  0.05270903]\n",
      "Loss in iteration 8079: 0.4249353192576571\n",
      "Theta: [-1.86874208  1.17825795  0.05270676]\n",
      "Loss in iteration 8080: 0.42493307756981347\n",
      "Theta: [-1.86882415  1.1783158   0.0527045 ]\n",
      "Loss in iteration 8081: 0.42493083659206876\n",
      "Theta: [-1.86890621  1.17837365  0.05270223]\n",
      "Loss in iteration 8082: 0.4249285963241548\n",
      "Theta: [-1.86898826  1.17843149  0.05269996]\n",
      "Loss in iteration 8083: 0.42492635676580315\n",
      "Theta: [-1.86907029  1.17848931  0.05269769]\n",
      "Loss in iteration 8084: 0.42492411791674556\n",
      "Theta: [-1.86915231  1.17854713  0.05269542]\n",
      "Loss in iteration 8085: 0.42492187977671425\n",
      "Theta: [-1.86923432  1.17860494  0.05269316]\n",
      "Loss in iteration 8086: 0.4249196423454413\n",
      "Theta: [-1.86931631  1.17866275  0.05269089]\n",
      "Loss in iteration 8087: 0.42491740562265884\n",
      "Theta: [-1.8693983   1.17872054  0.05268862]\n",
      "Loss in iteration 8088: 0.42491516960809916\n",
      "Theta: [-1.86948026  1.17877832  0.05268636]\n",
      "Loss in iteration 8089: 0.42491293430149485\n",
      "Theta: [-1.86956222  1.1788361   0.05268409]\n",
      "Loss in iteration 8090: 0.42491069970257833\n",
      "Theta: [-1.86964416  1.17889387  0.05268182]\n",
      "Loss in iteration 8091: 0.42490846581108244\n",
      "Theta: [-1.86972609  1.17895162  0.05267956]\n",
      "Loss in iteration 8092: 0.4249062326267399\n",
      "Theta: [-1.869808    1.17900937  0.05267729]\n",
      "Loss in iteration 8093: 0.42490400014928376\n",
      "Theta: [-1.8698899   1.17906712  0.05267503]\n",
      "Loss in iteration 8094: 0.42490176837844723\n",
      "Theta: [-1.86997179  1.17912485  0.05267276]\n",
      "Loss in iteration 8095: 0.4248995373139631\n",
      "Theta: [-1.87005366  1.17918257  0.0526705 ]\n",
      "Loss in iteration 8096: 0.42489730695556505\n",
      "Theta: [-1.87013552  1.17924029  0.05266823]\n",
      "Loss in iteration 8097: 0.42489507730298626\n",
      "Theta: [-1.87021737  1.17929799  0.05266597]\n",
      "Loss in iteration 8098: 0.4248928483559606\n",
      "Theta: [-1.87029921  1.17935569  0.0526637 ]\n",
      "Loss in iteration 8099: 0.4248906201142214\n",
      "Theta: [-1.87038103  1.17941338  0.05266144]\n",
      "Loss in iteration 8100: 0.42488839257750266\n",
      "Theta: [-1.87046284  1.17947106  0.05265918]\n",
      "Loss in iteration 8101: 0.4248861657455383\n",
      "Theta: [-1.87054463  1.17952873  0.05265691]\n",
      "Loss in iteration 8102: 0.42488393961806226\n",
      "Theta: [-1.87062641  1.17958639  0.05265465]\n",
      "Loss in iteration 8103: 0.4248817141948088\n",
      "Theta: [-1.87070818  1.17964405  0.05265239]\n",
      "Loss in iteration 8104: 0.424879489475512\n",
      "Theta: [-1.87078994  1.17970169  0.05265012]\n",
      "Loss in iteration 8105: 0.4248772654599067\n",
      "Theta: [-1.87087168  1.17975933  0.05264786]\n",
      "Loss in iteration 8106: 0.42487504214772676\n",
      "Theta: [-1.87095341  1.17981696  0.0526456 ]\n",
      "Loss in iteration 8107: 0.4248728195387074\n",
      "Theta: [-1.87103512  1.17987458  0.05264334]\n",
      "Loss in iteration 8108: 0.4248705976325833\n",
      "Theta: [-1.87111682  1.17993219  0.05264108]\n",
      "Loss in iteration 8109: 0.4248683764290891\n",
      "Theta: [-1.87119851  1.17998979  0.05263882]\n",
      "Loss in iteration 8110: 0.4248661559279598\n",
      "Theta: [-1.87128019  1.18004739  0.05263656]\n",
      "Loss in iteration 8111: 0.4248639361289308\n",
      "Theta: [-1.87136185  1.18010497  0.05263429]\n",
      "Loss in iteration 8112: 0.42486171703173725\n",
      "Theta: [-1.8714435   1.18016255  0.05263203]\n",
      "Loss in iteration 8113: 0.42485949863611444\n",
      "Theta: [-1.87152514  1.18022012  0.05262977]\n",
      "Loss in iteration 8114: 0.424857280941798\n",
      "Theta: [-1.87160676  1.18027768  0.05262751]\n",
      "Loss in iteration 8115: 0.42485506394852324\n",
      "Theta: [-1.87168837  1.18033523  0.05262525]\n",
      "Loss in iteration 8116: 0.42485284765602604\n",
      "Theta: [-1.87176996  1.18039277  0.052623  ]\n",
      "Loss in iteration 8117: 0.42485063206404233\n",
      "Theta: [-1.87185155  1.1804503   0.05262074]\n",
      "Loss in iteration 8118: 0.424848417172308\n",
      "Theta: [-1.87193312  1.18050783  0.05261848]\n",
      "Loss in iteration 8119: 0.4248462029805593\n",
      "Theta: [-1.87201467  1.18056534  0.05261622]\n",
      "Loss in iteration 8120: 0.42484398948853214\n",
      "Theta: [-1.87209622  1.18062285  0.05261396]\n",
      "Loss in iteration 8121: 0.4248417766959629\n",
      "Theta: [-1.87217775  1.18068035  0.0526117 ]\n",
      "Loss in iteration 8122: 0.4248395646025883\n",
      "Theta: [-1.87225926  1.18073784  0.05260944]\n",
      "Loss in iteration 8123: 0.4248373532081446\n",
      "Theta: [-1.87234077  1.18079532  0.05260719]\n",
      "Loss in iteration 8124: 0.4248351425123687\n",
      "Theta: [-1.87242226  1.18085279  0.05260493]\n",
      "Loss in iteration 8125: 0.42483293251499715\n",
      "Theta: [-1.87250373  1.18091026  0.05260267]\n",
      "Loss in iteration 8126: 0.424830723215767\n",
      "Theta: [-1.8725852   1.18096771  0.05260042]\n",
      "Loss in iteration 8127: 0.4248285146144155\n",
      "Theta: [-1.87266665  1.18102516  0.05259816]\n",
      "Loss in iteration 8128: 0.4248263067106795\n",
      "Theta: [-1.87274809  1.1810826   0.0525959 ]\n",
      "Loss in iteration 8129: 0.4248240995042965\n",
      "Theta: [-1.87282951  1.18114003  0.05259365]\n",
      "Loss in iteration 8130: 0.4248218929950038\n",
      "Theta: [-1.87291092  1.18119745  0.05259139]\n",
      "Loss in iteration 8131: 0.4248196871825388\n",
      "Theta: [-1.87299232  1.18125486  0.05258914]\n",
      "Loss in iteration 8132: 0.4248174820666393\n",
      "Theta: [-1.87307371  1.18131226  0.05258688]\n",
      "Loss in iteration 8133: 0.4248152776470431\n",
      "Theta: [-1.87315508  1.18136966  0.05258463]\n",
      "Loss in iteration 8134: 0.4248130739234878\n",
      "Theta: [-1.87323644  1.18142705  0.05258237]\n",
      "Loss in iteration 8135: 0.4248108708957117\n",
      "Theta: [-1.87331778  1.18148442  0.05258012]\n",
      "Loss in iteration 8136: 0.4248086685634528\n",
      "Theta: [-1.87339911  1.18154179  0.05257786]\n",
      "Loss in iteration 8137: 0.4248064669264493\n",
      "Theta: [-1.87348043  1.18159915  0.05257561]\n",
      "Loss in iteration 8138: 0.4248042659844395\n",
      "Theta: [-1.87356174  1.18165651  0.05257336]\n",
      "Loss in iteration 8139: 0.42480206573716195\n",
      "Theta: [-1.87364303  1.18171385  0.0525711 ]\n",
      "Loss in iteration 8140: 0.42479986618435517\n",
      "Theta: [-1.87372431  1.18177118  0.05256885]\n",
      "Loss in iteration 8141: 0.42479766732575813\n",
      "Theta: [-1.87380558  1.18182851  0.0525666 ]\n",
      "Loss in iteration 8142: 0.4247954691611093\n",
      "Theta: [-1.87388683  1.18188583  0.05256434]\n",
      "Loss in iteration 8143: 0.4247932716901475\n",
      "Theta: [-1.87396807  1.18194314  0.05256209]\n",
      "Loss in iteration 8144: 0.42479107491261237\n",
      "Theta: [-1.8740493   1.18200044  0.05255984]\n",
      "Loss in iteration 8145: 0.4247888788282427\n",
      "Theta: [-1.87413051  1.18205773  0.05255759]\n",
      "Loss in iteration 8146: 0.42478668343677783\n",
      "Theta: [-1.87421171  1.18211501  0.05255534]\n",
      "Loss in iteration 8147: 0.42478448873795704\n",
      "Theta: [-1.8742929   1.18217229  0.05255309]\n",
      "Loss in iteration 8148: 0.4247822947315202\n",
      "Theta: [-1.87437408  1.18222955  0.05255083]\n",
      "Loss in iteration 8149: 0.42478010141720657\n",
      "Theta: [-1.87445524  1.18228681  0.05254858]\n",
      "Loss in iteration 8150: 0.4247779087947562\n",
      "Theta: [-1.87453639  1.18234406  0.05254633]\n",
      "Loss in iteration 8151: 0.42477571686390886\n",
      "Theta: [-1.87461752  1.1824013   0.05254408]\n",
      "Loss in iteration 8152: 0.4247735256244047\n",
      "Theta: [-1.87469864  1.18245853  0.05254183]\n",
      "Loss in iteration 8153: 0.4247713350759835\n",
      "Theta: [-1.87477975  1.18251576  0.05253958]\n",
      "Loss in iteration 8154: 0.4247691452183858\n",
      "Theta: [-1.87486085  1.18257297  0.05253733]\n",
      "Loss in iteration 8155: 0.424766956051352\n",
      "Theta: [-1.87494193  1.18263018  0.05253508]\n",
      "Loss in iteration 8156: 0.4247647675746224\n",
      "Theta: [-1.875023    1.18268738  0.05253284]\n",
      "Loss in iteration 8157: 0.42476257978793747\n",
      "Theta: [-1.87510406  1.18274456  0.05253059]\n",
      "Loss in iteration 8158: 0.42476039269103816\n",
      "Theta: [-1.8751851   1.18280174  0.05252834]\n",
      "Loss in iteration 8159: 0.424758206283665\n",
      "Theta: [-1.87526613  1.18285892  0.05252609]\n",
      "Loss in iteration 8160: 0.4247560205655595\n",
      "Theta: [-1.87534715  1.18291608  0.05252384]\n",
      "Loss in iteration 8161: 0.4247538355364621\n",
      "Theta: [-1.87542815  1.18297323  0.05252159]\n",
      "Loss in iteration 8162: 0.4247516511961144\n",
      "Theta: [-1.87550915  1.18303038  0.05251935]\n",
      "Loss in iteration 8163: 0.4247494675442573\n",
      "Theta: [-1.87559012  1.18308752  0.0525171 ]\n",
      "Loss in iteration 8164: 0.42474728458063254\n",
      "Theta: [-1.87567109  1.18314465  0.05251485]\n",
      "Loss in iteration 8165: 0.42474510230498164\n",
      "Theta: [-1.87575204  1.18320177  0.05251261]\n",
      "Loss in iteration 8166: 0.4247429207170459\n",
      "Theta: [-1.87583298  1.18325888  0.05251036]\n",
      "Loss in iteration 8167: 0.42474073981656735\n",
      "Theta: [-1.87591391  1.18331598  0.05250811]\n",
      "Loss in iteration 8168: 0.424738559603288\n",
      "Theta: [-1.87599482  1.18337308  0.05250587]\n",
      "Loss in iteration 8169: 0.4247363800769496\n",
      "Theta: [-1.87607572  1.18343016  0.05250362]\n",
      "Loss in iteration 8170: 0.4247342012372943\n",
      "Theta: [-1.8761566   1.18348724  0.05250138]\n",
      "Loss in iteration 8171: 0.42473202308406427\n",
      "Theta: [-1.87623748  1.18354431  0.05249913]\n",
      "Loss in iteration 8172: 0.4247298456170021\n",
      "Theta: [-1.87631834  1.18360137  0.05249689]\n",
      "Loss in iteration 8173: 0.42472766883584984\n",
      "Theta: [-1.87639919  1.18365842  0.05249464]\n",
      "Loss in iteration 8174: 0.4247254927403505\n",
      "Theta: [-1.87648002  1.18371547  0.0524924 ]\n",
      "Loss in iteration 8175: 0.4247233173302466\n",
      "Theta: [-1.87656084  1.1837725   0.05249016]\n",
      "Loss in iteration 8176: 0.4247211426052808\n",
      "Theta: [-1.87664165  1.18382953  0.05248791]\n",
      "Loss in iteration 8177: 0.42471896856519614\n",
      "Theta: [-1.87672245  1.18388655  0.05248567]\n",
      "Loss in iteration 8178: 0.4247167952097357\n",
      "Theta: [-1.87680323  1.18394355  0.05248342]\n",
      "Loss in iteration 8179: 0.42471462253864267\n",
      "Theta: [-1.876884    1.18400056  0.05248118]\n",
      "Loss in iteration 8180: 0.42471245055166007\n",
      "Theta: [-1.87696475  1.18405755  0.05247894]\n",
      "Loss in iteration 8181: 0.4247102792485316\n",
      "Theta: [-1.8770455   1.18411453  0.0524767 ]\n",
      "Loss in iteration 8182: 0.42470810862900066\n",
      "Theta: [-1.87712623  1.18417151  0.05247445]\n",
      "Loss in iteration 8183: 0.42470593869281076\n",
      "Theta: [-1.87720694  1.18422847  0.05247221]\n",
      "Loss in iteration 8184: 0.4247037694397057\n",
      "Theta: [-1.87728765  1.18428543  0.05246997]\n",
      "Loss in iteration 8185: 0.4247016008694295\n",
      "Theta: [-1.87736834  1.18434238  0.05246773]\n",
      "Loss in iteration 8186: 0.4246994329817257\n",
      "Theta: [-1.87744902  1.18439932  0.05246549]\n",
      "Loss in iteration 8187: 0.42469726577633865\n",
      "Theta: [-1.87752968  1.18445625  0.05246325]\n",
      "Loss in iteration 8188: 0.42469509925301274\n",
      "Theta: [-1.87761033  1.18451318  0.05246101]\n",
      "Loss in iteration 8189: 0.42469293341149184\n",
      "Theta: [-1.87769097  1.18457009  0.05245877]\n",
      "Loss in iteration 8190: 0.4246907682515208\n",
      "Theta: [-1.8777716   1.184627    0.05245653]\n",
      "Loss in iteration 8191: 0.42468860377284384\n",
      "Theta: [-1.87785221  1.1846839   0.05245429]\n",
      "Loss in iteration 8192: 0.4246864399752058\n",
      "Theta: [-1.87793281  1.18474079  0.05245205]\n",
      "Loss in iteration 8193: 0.42468427685835136\n",
      "Theta: [-1.8780134   1.18479767  0.05244981]\n",
      "Loss in iteration 8194: 0.4246821144220255\n",
      "Theta: [-1.87809397  1.18485454  0.05244757]\n",
      "Loss in iteration 8195: 0.42467995266597336\n",
      "Theta: [-1.87817454  1.18491141  0.05244533]\n",
      "Loss in iteration 8196: 0.4246777915899396\n",
      "Theta: [-1.87825508  1.18496826  0.05244309]\n",
      "Loss in iteration 8197: 0.4246756311936697\n",
      "Theta: [-1.87833562  1.18502511  0.05244085]\n",
      "Loss in iteration 8198: 0.4246734714769091\n",
      "Theta: [-1.87841614  1.18508195  0.05243861]\n",
      "Loss in iteration 8199: 0.4246713124394032\n",
      "Theta: [-1.87849665  1.18513878  0.05243638]\n",
      "Loss in iteration 8200: 0.42466915408089756\n",
      "Theta: [-1.87857715  1.1851956   0.05243414]\n",
      "Loss in iteration 8201: 0.42466699640113764\n",
      "Theta: [-1.87865763  1.18525242  0.0524319 ]\n",
      "Loss in iteration 8202: 0.42466483939986976\n",
      "Theta: [-1.8787381   1.18530922  0.05242967]\n",
      "Loss in iteration 8203: 0.4246626830768395\n",
      "Theta: [-1.87881856  1.18536602  0.05242743]\n",
      "Loss in iteration 8204: 0.4246605274317928\n",
      "Theta: [-1.878899    1.18542281  0.05242519]\n",
      "Loss in iteration 8205: 0.4246583724644761\n",
      "Theta: [-1.87897943  1.18547959  0.05242296]\n",
      "Loss in iteration 8206: 0.42465621817463534\n",
      "Theta: [-1.87905985  1.18553636  0.05242072]\n",
      "Loss in iteration 8207: 0.4246540645620172\n",
      "Theta: [-1.87914026  1.18559312  0.05241848]\n",
      "Loss in iteration 8208: 0.424651911626368\n",
      "Theta: [-1.87922065  1.18564987  0.05241625]\n",
      "Loss in iteration 8209: 0.42464975936743443\n",
      "Theta: [-1.87930103  1.18570662  0.05241401]\n",
      "Loss in iteration 8210: 0.4246476077849631\n",
      "Theta: [-1.8793814   1.18576336  0.05241178]\n",
      "Loss in iteration 8211: 0.4246454568787009\n",
      "Theta: [-1.87946175  1.18582008  0.05240954]\n",
      "Loss in iteration 8212: 0.4246433066483949\n",
      "Theta: [-1.87954209  1.1858768   0.05240731]\n",
      "Loss in iteration 8213: 0.4246411570937918\n",
      "Theta: [-1.87962242  1.18593352  0.05240508]\n",
      "Loss in iteration 8214: 0.4246390082146392\n",
      "Theta: [-1.87970273  1.18599022  0.05240284]\n",
      "Loss in iteration 8215: 0.4246368600106842\n",
      "Theta: [-1.87978303  1.18604691  0.05240061]\n",
      "Loss in iteration 8216: 0.424634712481674\n",
      "Theta: [-1.87986332  1.1861036   0.05239837]\n",
      "Loss in iteration 8217: 0.4246325656273565\n",
      "Theta: [-1.8799436   1.18616028  0.05239614]\n",
      "Loss in iteration 8218: 0.42463041944747915\n",
      "Theta: [-1.88002386  1.18621695  0.05239391]\n",
      "Loss in iteration 8219: 0.4246282739417896\n",
      "Theta: [-1.88010411  1.18627361  0.05239168]\n",
      "Loss in iteration 8220: 0.4246261291100359\n",
      "Theta: [-1.88018435  1.18633026  0.05238944]\n",
      "Loss in iteration 8221: 0.4246239849519659\n",
      "Theta: [-1.88026457  1.1863869   0.05238721]\n",
      "Loss in iteration 8222: 0.4246218414673276\n",
      "Theta: [-1.88034479  1.18644354  0.05238498]\n",
      "Loss in iteration 8223: 0.42461969865586935\n",
      "Theta: [-1.88042499  1.18650017  0.05238275]\n",
      "Loss in iteration 8224: 0.4246175565173394\n",
      "Theta: [-1.88050517  1.18655678  0.05238052]\n",
      "Loss in iteration 8225: 0.42461541505148603\n",
      "Theta: [-1.88058534  1.18661339  0.05237829]\n",
      "Loss in iteration 8226: 0.4246132742580581\n",
      "Theta: [-1.8806655   1.18667     0.05237606]\n",
      "Loss in iteration 8227: 0.424611134136804\n",
      "Theta: [-1.88074565  1.18672659  0.05237382]\n",
      "Loss in iteration 8228: 0.4246089946874726\n",
      "Theta: [-1.88082579  1.18678317  0.05237159]\n",
      "Loss in iteration 8229: 0.42460685590981273\n",
      "Theta: [-1.88090591  1.18683975  0.05236936]\n",
      "Loss in iteration 8230: 0.4246047178035733\n",
      "Theta: [-1.88098601  1.18689632  0.05236713]\n",
      "Loss in iteration 8231: 0.4246025803685036\n",
      "Theta: [-1.88106611  1.18695288  0.05236491]\n",
      "Loss in iteration 8232: 0.4246004436043527\n",
      "Theta: [-1.88114619  1.18700943  0.05236268]\n",
      "Loss in iteration 8233: 0.42459830751086997\n",
      "Theta: [-1.88122626  1.18706597  0.05236045]\n",
      "Loss in iteration 8234: 0.42459617208780487\n",
      "Theta: [-1.88130632  1.1871225   0.05235822]\n",
      "Loss in iteration 8235: 0.42459403733490675\n",
      "Theta: [-1.88138636  1.18717903  0.05235599]\n",
      "Loss in iteration 8236: 0.4245919032519256\n",
      "Theta: [-1.88146639  1.18723555  0.05235376]\n",
      "Loss in iteration 8237: 0.42458976983861096\n",
      "Theta: [-1.88154641  1.18729205  0.05235153]\n",
      "Loss in iteration 8238: 0.42458763709471276\n",
      "Theta: [-1.88162642  1.18734855  0.05234931]\n",
      "Loss in iteration 8239: 0.42458550501998116\n",
      "Theta: [-1.88170641  1.18740505  0.05234708]\n",
      "Loss in iteration 8240: 0.4245833736141661\n",
      "Theta: [-1.88178639  1.18746153  0.05234485]\n",
      "Loss in iteration 8241: 0.42458124287701776\n",
      "Theta: [-1.88186636  1.187518    0.05234262]\n",
      "Loss in iteration 8242: 0.4245791128082867\n",
      "Theta: [-1.88194631  1.18757447  0.0523404 ]\n",
      "Loss in iteration 8243: 0.4245769834077231\n",
      "Theta: [-1.88202625  1.18763093  0.05233817]\n",
      "Loss in iteration 8244: 0.42457485467507766\n",
      "Theta: [-1.88210618  1.18768738  0.05233595]\n",
      "Loss in iteration 8245: 0.42457272661010104\n",
      "Theta: [-1.8821861   1.18774382  0.05233372]\n",
      "Loss in iteration 8246: 0.42457059921254403\n",
      "Theta: [-1.882266    1.18780025  0.05233149]\n",
      "Loss in iteration 8247: 0.4245684724821577\n",
      "Theta: [-1.88234589  1.18785668  0.05232927]\n",
      "Loss in iteration 8248: 0.42456634641869256\n",
      "Theta: [-1.88242577  1.18791309  0.05232704]\n",
      "Loss in iteration 8249: 0.42456422102190017\n",
      "Theta: [-1.88250563  1.1879695   0.05232482]\n",
      "Loss in iteration 8250: 0.42456209629153163\n",
      "Theta: [-1.88258548  1.1880259   0.05232259]\n",
      "Loss in iteration 8251: 0.4245599722273385\n",
      "Theta: [-1.88266532  1.18808229  0.05232037]\n",
      "Loss in iteration 8252: 0.4245578488290718\n",
      "Theta: [-1.88274515  1.18813867  0.05231815]\n",
      "Loss in iteration 8253: 0.4245557260964833\n",
      "Theta: [-1.88282496  1.18819505  0.05231592]\n",
      "Loss in iteration 8254: 0.4245536040293248\n",
      "Theta: [-1.88290476  1.18825141  0.0523137 ]\n",
      "Loss in iteration 8255: 0.42455148262734804\n",
      "Theta: [-1.88298455  1.18830777  0.05231147]\n",
      "Loss in iteration 8256: 0.4245493618903048\n",
      "Theta: [-1.88306432  1.18836412  0.05230925]\n",
      "Loss in iteration 8257: 0.424547241817947\n",
      "Theta: [-1.88314408  1.18842046  0.05230703]\n",
      "Loss in iteration 8258: 0.424545122410027\n",
      "Theta: [-1.88322383  1.18847679  0.05230481]\n",
      "Loss in iteration 8259: 0.42454300366629694\n",
      "Theta: [-1.88330357  1.18853311  0.05230258]\n",
      "Loss in iteration 8260: 0.4245408855865092\n",
      "Theta: [-1.88338329  1.18858943  0.05230036]\n",
      "Loss in iteration 8261: 0.4245387681704162\n",
      "Theta: [-1.883463    1.18864573  0.05229814]\n",
      "Loss in iteration 8262: 0.4245366514177704\n",
      "Theta: [-1.8835427   1.18870203  0.05229592]\n",
      "Loss in iteration 8263: 0.42453453532832486\n",
      "Theta: [-1.88362238  1.18875832  0.0522937 ]\n",
      "Loss in iteration 8264: 0.4245324199018317\n",
      "Theta: [-1.88370206  1.1888146   0.05229148]\n",
      "Loss in iteration 8265: 0.4245303051380446\n",
      "Theta: [-1.88378171  1.18887088  0.05228926]\n",
      "Loss in iteration 8266: 0.42452819103671596\n",
      "Theta: [-1.88386136  1.18892714  0.05228704]\n",
      "Loss in iteration 8267: 0.42452607759759914\n",
      "Theta: [-1.88394099  1.1889834   0.05228482]\n",
      "Loss in iteration 8268: 0.4245239648204474\n",
      "Theta: [-1.88402062  1.18903964  0.0522826 ]\n",
      "Loss in iteration 8269: 0.4245218527050138\n",
      "Theta: [-1.88410022  1.18909588  0.05228038]\n",
      "Loss in iteration 8270: 0.4245197412510523\n",
      "Theta: [-1.88417982  1.18915211  0.05227816]\n",
      "Loss in iteration 8271: 0.42451763045831614\n",
      "Theta: [-1.8842594   1.18920834  0.05227594]\n",
      "Loss in iteration 8272: 0.424515520326559\n",
      "Theta: [-1.88433897  1.18926455  0.05227372]\n",
      "Loss in iteration 8273: 0.4245134108555345\n",
      "Theta: [-1.88441853  1.18932076  0.0522715 ]\n",
      "Loss in iteration 8274: 0.424511302044997\n",
      "Theta: [-1.88449807  1.18937695  0.05226928]\n",
      "Loss in iteration 8275: 0.4245091938947001\n",
      "Theta: [-1.8845776   1.18943314  0.05226706]\n",
      "Loss in iteration 8276: 0.42450708640439794\n",
      "Theta: [-1.88465712  1.18948932  0.05226485]\n",
      "Loss in iteration 8277: 0.4245049795738449\n",
      "Theta: [-1.88473663  1.1895455   0.05226263]\n",
      "Loss in iteration 8278: 0.4245028734027953\n",
      "Theta: [-1.88481612  1.18960166  0.05226041]\n",
      "Loss in iteration 8279: 0.42450076789100355\n",
      "Theta: [-1.8848956   1.18965782  0.05225819]\n",
      "Loss in iteration 8280: 0.4244986630382241\n",
      "Theta: [-1.88497507  1.18971396  0.05225598]\n",
      "Loss in iteration 8281: 0.42449655884421167\n",
      "Theta: [-1.88505453  1.1897701   0.05225376]\n",
      "Loss in iteration 8282: 0.4244944553087212\n",
      "Theta: [-1.88513397  1.18982623  0.05225154]\n",
      "Loss in iteration 8283: 0.4244923524315074\n",
      "Theta: [-1.8852134   1.18988236  0.05224933]\n",
      "Loss in iteration 8284: 0.42449025021232506\n",
      "Theta: [-1.88529282  1.18993847  0.05224711]\n",
      "Loss in iteration 8285: 0.42448814865092976\n",
      "Theta: [-1.88537222  1.18999458  0.0522449 ]\n",
      "Loss in iteration 8286: 0.4244860477470764\n",
      "Theta: [-1.88545161  1.19005067  0.05224268]\n",
      "Loss in iteration 8287: 0.42448394750052043\n",
      "Theta: [-1.88553099  1.19010676  0.05224047]\n",
      "Loss in iteration 8288: 0.42448184791101695\n",
      "Theta: [-1.88561036  1.19016284  0.05223825]\n",
      "Loss in iteration 8289: 0.42447974897832197\n",
      "Theta: [-1.88568971  1.19021891  0.05223604]\n",
      "Loss in iteration 8290: 0.42447765070219085\n",
      "Theta: [-1.88576905  1.19027498  0.05223382]\n",
      "Loss in iteration 8291: 0.42447555308237944\n",
      "Theta: [-1.88584838  1.19033103  0.05223161]\n",
      "Loss in iteration 8292: 0.42447345611864357\n",
      "Theta: [-1.88592769  1.19038708  0.05222939]\n",
      "Loss in iteration 8293: 0.4244713598107392\n",
      "Theta: [-1.886007    1.19044312  0.05222718]\n",
      "Loss in iteration 8294: 0.4244692641584224\n",
      "Theta: [-1.88608629  1.19049915  0.05222497]\n",
      "Loss in iteration 8295: 0.4244671691614495\n",
      "Theta: [-1.88616556  1.19055517  0.05222275]\n",
      "Loss in iteration 8296: 0.4244650748195766\n",
      "Theta: [-1.88624483  1.19061118  0.05222054]\n",
      "Loss in iteration 8297: 0.4244629811325604\n",
      "Theta: [-1.88632408  1.19066719  0.05221833]\n",
      "Loss in iteration 8298: 0.424460888100157\n",
      "Theta: [-1.88640332  1.19072319  0.05221612]\n",
      "Loss in iteration 8299: 0.4244587957221234\n",
      "Theta: [-1.88648254  1.19077918  0.0522139 ]\n",
      "Loss in iteration 8300: 0.42445670399821617\n",
      "Theta: [-1.88656176  1.19083516  0.05221169]\n",
      "Loss in iteration 8301: 0.42445461292819225\n",
      "Theta: [-1.88664096  1.19089113  0.05220948]\n",
      "Loss in iteration 8302: 0.42445252251180837\n",
      "Theta: [-1.88672015  1.19094709  0.05220727]\n",
      "Loss in iteration 8303: 0.4244504327488218\n",
      "Theta: [-1.88679932  1.19100305  0.05220506]\n",
      "Loss in iteration 8304: 0.42444834363898987\n",
      "Theta: [-1.88687849  1.19105899  0.05220285]\n",
      "Loss in iteration 8305: 0.42444625518206924\n",
      "Theta: [-1.88695764  1.19111493  0.05220064]\n",
      "Loss in iteration 8306: 0.4244441673778181\n",
      "Theta: [-1.88703677  1.19117086  0.05219843]\n",
      "Loss in iteration 8307: 0.4244420802259933\n",
      "Theta: [-1.8871159   1.19122679  0.05219622]\n",
      "Loss in iteration 8308: 0.42443999372635266\n",
      "Theta: [-1.88719501  1.1912827   0.05219401]\n",
      "Loss in iteration 8309: 0.42443790787865415\n",
      "Theta: [-1.88727411  1.1913386   0.0521918 ]\n",
      "Loss in iteration 8310: 0.4244358226826554\n",
      "Theta: [-1.8873532   1.1913945   0.05218959]\n",
      "Loss in iteration 8311: 0.424433738138114\n",
      "Theta: [-1.88743227  1.19145039  0.05218738]\n",
      "Loss in iteration 8312: 0.4244316542447885\n",
      "Theta: [-1.88751133  1.19150627  0.05218517]\n",
      "Loss in iteration 8313: 0.4244295710024369\n",
      "Theta: [-1.88759038  1.19156214  0.05218296]\n",
      "Loss in iteration 8314: 0.42442748841081723\n",
      "Theta: [-1.88766942  1.19161801  0.05218076]\n",
      "Loss in iteration 8315: 0.42442540646968807\n",
      "Theta: [-1.88774844  1.19167386  0.05217855]\n",
      "Loss in iteration 8316: 0.4244233251788077\n",
      "Theta: [-1.88782745  1.19172971  0.05217634]\n",
      "Loss in iteration 8317: 0.42442124453793495\n",
      "Theta: [-1.88790645  1.19178555  0.05217413]\n",
      "Loss in iteration 8318: 0.42441916454682854\n",
      "Theta: [-1.88798544  1.19184138  0.05217193]\n",
      "Loss in iteration 8319: 0.42441708520524685\n",
      "Theta: [-1.88806441  1.1918972   0.05216972]\n",
      "Loss in iteration 8320: 0.424415006512949\n",
      "Theta: [-1.88814337  1.19195301  0.05216751]\n",
      "Loss in iteration 8321: 0.42441292846969425\n",
      "Theta: [-1.88822232  1.19200882  0.05216531]\n",
      "Loss in iteration 8322: 0.42441085107524124\n",
      "Theta: [-1.88830126  1.19206462  0.0521631 ]\n",
      "Loss in iteration 8323: 0.42440877432934976\n",
      "Theta: [-1.88838018  1.19212041  0.05216089]\n",
      "Loss in iteration 8324: 0.4244066982317785\n",
      "Theta: [-1.88845909  1.19217619  0.05215869]\n",
      "Loss in iteration 8325: 0.4244046227822874\n",
      "Theta: [-1.88853799  1.19223196  0.05215648]\n",
      "Loss in iteration 8326: 0.42440254798063565\n",
      "Theta: [-1.88861687  1.19228772  0.05215428]\n",
      "Loss in iteration 8327: 0.4244004738265831\n",
      "Theta: [-1.88869574  1.19234348  0.05215207]\n",
      "Loss in iteration 8328: 0.4243984003198895\n",
      "Theta: [-1.8887746   1.19239923  0.05214987]\n",
      "Loss in iteration 8329: 0.4243963274603147\n",
      "Theta: [-1.88885345  1.19245497  0.05214766]\n",
      "Loss in iteration 8330: 0.42439425524761865\n",
      "Theta: [-1.88893228  1.1925107   0.05214546]\n",
      "Loss in iteration 8331: 0.42439218368156134\n",
      "Theta: [-1.88901111  1.19256642  0.05214326]\n",
      "Loss in iteration 8332: 0.4243901127619032\n",
      "Theta: [-1.88908992  1.19262214  0.05214105]\n",
      "Loss in iteration 8333: 0.42438804248840417\n",
      "Theta: [-1.88916871  1.19267784  0.05213885]\n",
      "Loss in iteration 8334: 0.424385972860825\n",
      "Theta: [-1.8892475   1.19273354  0.05213665]\n",
      "Loss in iteration 8335: 0.42438390387892594\n",
      "Theta: [-1.88932627  1.19278923  0.05213444]\n",
      "Loss in iteration 8336: 0.4243818355424678\n",
      "Theta: [-1.88940503  1.19284491  0.05213224]\n",
      "Loss in iteration 8337: 0.42437976785121095\n",
      "Theta: [-1.88948377  1.19290058  0.05213004]\n",
      "Loss in iteration 8338: 0.4243777008049166\n",
      "Theta: [-1.88956251  1.19295625  0.05212784]\n",
      "Loss in iteration 8339: 0.4243756344033457\n",
      "Theta: [-1.88964123  1.19301191  0.05212564]\n",
      "Loss in iteration 8340: 0.4243735686462589\n",
      "Theta: [-1.88971994  1.19306755  0.05212343]\n",
      "Loss in iteration 8341: 0.4243715035334178\n",
      "Theta: [-1.88979863  1.19312319  0.05212123]\n",
      "Loss in iteration 8342: 0.4243694390645832\n",
      "Theta: [-1.88987732  1.19317883  0.05211903]\n",
      "Loss in iteration 8343: 0.4243673752395168\n",
      "Theta: [-1.88995599  1.19323445  0.05211683]\n",
      "Loss in iteration 8344: 0.4243653120579798\n",
      "Theta: [-1.89003465  1.19329006  0.05211463]\n",
      "Loss in iteration 8345: 0.42436324951973403\n",
      "Theta: [-1.89011329  1.19334567  0.05211243]\n",
      "Loss in iteration 8346: 0.424361187624541\n",
      "Theta: [-1.89019193  1.19340127  0.05211023]\n",
      "Loss in iteration 8347: 0.42435912637216255\n",
      "Theta: [-1.89027055  1.19345686  0.05210803]\n",
      "Loss in iteration 8348: 0.4243570657623605\n",
      "Theta: [-1.89034915  1.19351244  0.05210583]\n",
      "Loss in iteration 8349: 0.424355005794897\n",
      "Theta: [-1.89042775  1.19356802  0.05210363]\n",
      "Loss in iteration 8350: 0.42435294646953386\n",
      "Theta: [-1.89050633  1.19362358  0.05210143]\n",
      "Loss in iteration 8351: 0.42435088778603364\n",
      "Theta: [-1.8905849   1.19367914  0.05209924]\n",
      "Loss in iteration 8352: 0.4243488297441583\n",
      "Theta: [-1.89066346  1.19373469  0.05209704]\n",
      "Loss in iteration 8353: 0.4243467723436706\n",
      "Theta: [-1.89074201  1.19379023  0.05209484]\n",
      "Loss in iteration 8354: 0.42434471558433273\n",
      "Theta: [-1.89082054  1.19384576  0.05209264]\n",
      "Loss in iteration 8355: 0.42434265946590766\n",
      "Theta: [-1.89089906  1.19390129  0.05209044]\n",
      "Loss in iteration 8356: 0.42434060398815776\n",
      "Theta: [-1.89097757  1.1939568   0.05208825]\n",
      "Loss in iteration 8357: 0.42433854915084607\n",
      "Theta: [-1.89105606  1.19401231  0.05208605]\n",
      "Loss in iteration 8358: 0.4243364949537356\n",
      "Theta: [-1.89113455  1.19406781  0.05208385]\n",
      "Loss in iteration 8359: 0.42433444139658916\n",
      "Theta: [-1.89121302  1.1941233   0.05208166]\n",
      "Loss in iteration 8360: 0.42433238847917015\n",
      "Theta: [-1.89129147  1.19417879  0.05207946]\n",
      "Loss in iteration 8361: 0.4243303362012418\n",
      "Theta: [-1.89136992  1.19423426  0.05207726]\n",
      "Loss in iteration 8362: 0.4243282845625672\n",
      "Theta: [-1.89144835  1.19428973  0.05207507]\n",
      "Loss in iteration 8363: 0.42432623356291027\n",
      "Theta: [-1.89152677  1.19434519  0.05207287]\n",
      "Loss in iteration 8364: 0.42432418320203413\n",
      "Theta: [-1.89160518  1.19440064  0.05207068]\n",
      "Loss in iteration 8365: 0.4243221334797026\n",
      "Theta: [-1.89168358  1.19445608  0.05206848]\n",
      "Loss in iteration 8366: 0.42432008439567975\n",
      "Theta: [-1.89176196  1.19451151  0.05206629]\n",
      "Loss in iteration 8367: 0.42431803594972917\n",
      "Theta: [-1.89184033  1.19456694  0.05206409]\n",
      "Loss in iteration 8368: 0.42431598814161475\n",
      "Theta: [-1.89191869  1.19462236  0.0520619 ]\n",
      "Loss in iteration 8369: 0.42431394097110087\n",
      "Theta: [-1.89199703  1.19467776  0.0520597 ]\n",
      "Loss in iteration 8370: 0.42431189443795175\n",
      "Theta: [-1.89207537  1.19473317  0.05205751]\n",
      "Loss in iteration 8371: 0.42430984854193154\n",
      "Theta: [-1.89215369  1.19478856  0.05205532]\n",
      "Loss in iteration 8372: 0.4243078032828047\n",
      "Theta: [-1.89223199  1.19484394  0.05205312]\n",
      "Loss in iteration 8373: 0.42430575866033565\n",
      "Theta: [-1.89231029  1.19489932  0.05205093]\n",
      "Loss in iteration 8374: 0.42430371467428907\n",
      "Theta: [-1.89238857  1.19495469  0.05204874]\n",
      "Loss in iteration 8375: 0.4243016713244298\n",
      "Theta: [-1.89246684  1.19501005  0.05204654]\n",
      "Loss in iteration 8376: 0.42429962861052245\n",
      "Theta: [-1.8925451   1.1950654   0.05204435]\n",
      "Loss in iteration 8377: 0.4242975865323323\n",
      "Theta: [-1.89262335  1.19512074  0.05204216]\n",
      "Loss in iteration 8378: 0.42429554508962414\n",
      "Theta: [-1.89270158  1.19517608  0.05203997]\n",
      "Loss in iteration 8379: 0.4242935042821631\n",
      "Theta: [-1.8927798   1.1952314   0.05203778]\n",
      "Loss in iteration 8380: 0.42429146410971436\n",
      "Theta: [-1.89285801  1.19528672  0.05203559]\n",
      "Loss in iteration 8381: 0.42428942457204366\n",
      "Theta: [-1.8929362   1.19534203  0.05203339]\n",
      "Loss in iteration 8382: 0.42428738566891594\n",
      "Theta: [-1.89301439  1.19539734  0.0520312 ]\n",
      "Loss in iteration 8383: 0.42428534740009716\n",
      "Theta: [-1.89309256  1.19545263  0.05202901]\n",
      "Loss in iteration 8384: 0.4242833097653527\n",
      "Theta: [-1.89317072  1.19550792  0.05202682]\n",
      "Loss in iteration 8385: 0.4242812727644485\n",
      "Theta: [-1.89324886  1.19556319  0.05202463]\n",
      "Loss in iteration 8386: 0.4242792363971505\n",
      "Theta: [-1.893327    1.19561846  0.05202244]\n",
      "Loss in iteration 8387: 0.4242772006632244\n",
      "Theta: [-1.89340512  1.19567373  0.05202025]\n",
      "Loss in iteration 8388: 0.4242751655624364\n",
      "Theta: [-1.89348322  1.19572898  0.05201806]\n",
      "Loss in iteration 8389: 0.4242731310945529\n",
      "Theta: [-1.89356132  1.19578422  0.05201588]\n",
      "Loss in iteration 8390: 0.42427109725934004\n",
      "Theta: [-1.8936394   1.19583946  0.05201369]\n",
      "Loss in iteration 8391: 0.42426906405656395\n",
      "Theta: [-1.89371748  1.19589469  0.0520115 ]\n",
      "Loss in iteration 8392: 0.4242670314859916\n",
      "Theta: [-1.89379553  1.19594991  0.05200931]\n",
      "Loss in iteration 8393: 0.42426499954738905\n",
      "Theta: [-1.89387358  1.19600512  0.05200712]\n",
      "Loss in iteration 8394: 0.4242629682405237\n",
      "Theta: [-1.89395161  1.19606033  0.05200493]\n",
      "Loss in iteration 8395: 0.42426093756516164\n",
      "Theta: [-1.89402964  1.19611552  0.05200275]\n",
      "Loss in iteration 8396: 0.4242589075210703\n",
      "Theta: [-1.89410765  1.19617071  0.05200056]\n",
      "Loss in iteration 8397: 0.42425687810801627\n",
      "Theta: [-1.89418564  1.19622589  0.05199837]\n",
      "Loss in iteration 8398: 0.42425484932576685\n",
      "Theta: [-1.89426363  1.19628106  0.05199619]\n",
      "Loss in iteration 8399: 0.42425282117408936\n",
      "Theta: [-1.8943416   1.19633623  0.051994  ]\n",
      "Loss in iteration 8400: 0.42425079365275103\n",
      "Theta: [-1.89441956  1.19639138  0.05199181]\n",
      "Loss in iteration 8401: 0.42424876676151924\n",
      "Theta: [-1.89449751  1.19644653  0.05198963]\n",
      "Loss in iteration 8402: 0.4242467405001616\n",
      "Theta: [-1.89457544  1.19650167  0.05198744]\n",
      "Loss in iteration 8403: 0.4242447148684456\n",
      "Theta: [-1.89465336  1.1965568   0.05198526]\n",
      "Loss in iteration 8404: 0.4242426898661392\n",
      "Theta: [-1.89473127  1.19661192  0.05198307]\n",
      "Loss in iteration 8405: 0.42424066549301004\n",
      "Theta: [-1.89480917  1.19666703  0.05198089]\n",
      "Loss in iteration 8406: 0.4242386417488261\n",
      "Theta: [-1.89488706  1.19672214  0.0519787 ]\n",
      "Loss in iteration 8407: 0.4242366186333556\n",
      "Theta: [-1.89496493  1.19677724  0.05197652]\n",
      "Loss in iteration 8408: 0.4242345961463663\n",
      "Theta: [-1.89504279  1.19683233  0.05197433]\n",
      "Loss in iteration 8409: 0.42423257428762673\n",
      "Theta: [-1.89512064  1.19688741  0.05197215]\n",
      "Loss in iteration 8410: 0.4242305530569053\n",
      "Theta: [-1.89519847  1.19694248  0.05196997]\n",
      "Loss in iteration 8411: 0.42422853245397013\n",
      "Theta: [-1.8952763   1.19699755  0.05196778]\n",
      "Loss in iteration 8412: 0.42422651247859006\n",
      "Theta: [-1.89535411  1.19705261  0.0519656 ]\n",
      "Loss in iteration 8413: 0.4242244931305337\n",
      "Theta: [-1.8954319   1.19710765  0.05196342]\n",
      "Loss in iteration 8414: 0.42422247440956967\n",
      "Theta: [-1.89550969  1.1971627   0.05196123]\n",
      "Loss in iteration 8415: 0.424220456315467\n",
      "Theta: [-1.89558746  1.19721773  0.05195905]\n",
      "Loss in iteration 8416: 0.4242184388479945\n",
      "Theta: [-1.89566523  1.19727275  0.05195687]\n",
      "Loss in iteration 8417: 0.4242164220069215\n",
      "Theta: [-1.89574298  1.19732777  0.05195469]\n",
      "Loss in iteration 8418: 0.4242144057920168\n",
      "Theta: [-1.89582071  1.19738278  0.05195251]\n",
      "Loss in iteration 8419: 0.4242123902030498\n",
      "Theta: [-1.89589844  1.19743778  0.05195033]\n",
      "Loss in iteration 8420: 0.42421037523978994\n",
      "Theta: [-1.89597615  1.19749277  0.05194814]\n",
      "Loss in iteration 8421: 0.42420836090200686\n",
      "Theta: [-1.89605385  1.19754775  0.05194596]\n",
      "Loss in iteration 8422: 0.42420634718946987\n",
      "Theta: [-1.89613154  1.19760273  0.05194378]\n",
      "Loss in iteration 8423: 0.4242043341019485\n",
      "Theta: [-1.89620921  1.1976577   0.0519416 ]\n",
      "Loss in iteration 8424: 0.424202321639213\n",
      "Theta: [-1.89628687  1.19771266  0.05193942]\n",
      "Loss in iteration 8425: 0.4242003098010327\n",
      "Theta: [-1.89636452  1.19776761  0.05193724]\n",
      "Loss in iteration 8426: 0.4241982985871781\n",
      "Theta: [-1.89644216  1.19782255  0.05193506]\n",
      "Loss in iteration 8427: 0.424196287997419\n",
      "Theta: [-1.89651979  1.19787749  0.05193288]\n",
      "Loss in iteration 8428: 0.4241942780315256\n",
      "Theta: [-1.8965974   1.19793241  0.05193071]\n",
      "Loss in iteration 8429: 0.4241922686892681\n",
      "Theta: [-1.896675    1.19798733  0.05192853]\n",
      "Loss in iteration 8430: 0.42419025997041737\n",
      "Theta: [-1.89675259  1.19804224  0.05192635]\n",
      "Loss in iteration 8431: 0.4241882518747431\n",
      "Theta: [-1.89683017  1.19809714  0.05192417]\n",
      "Loss in iteration 8432: 0.4241862444020167\n",
      "Theta: [-1.89690773  1.19815204  0.05192199]\n",
      "Loss in iteration 8433: 0.4241842375520083\n",
      "Theta: [-1.89698528  1.19820693  0.05191981]\n",
      "Loss in iteration 8434: 0.4241822313244888\n",
      "Theta: [-1.89706282  1.1982618   0.05191764]\n",
      "Loss in iteration 8435: 0.42418022571922925\n",
      "Theta: [-1.89714035  1.19831667  0.05191546]\n",
      "Loss in iteration 8436: 0.42417822073600064\n",
      "Theta: [-1.89721786  1.19837154  0.05191328]\n",
      "Loss in iteration 8437: 0.4241762163745737\n",
      "Theta: [-1.89729537  1.19842639  0.05191111]\n",
      "Loss in iteration 8438: 0.42417421263472016\n",
      "Theta: [-1.89737286  1.19848124  0.05190893]\n",
      "Loss in iteration 8439: 0.424172209516211\n",
      "Theta: [-1.89745033  1.19853607  0.05190675]\n",
      "Loss in iteration 8440: 0.4241702070188175\n",
      "Theta: [-1.8975278   1.1985909   0.05190458]\n",
      "Loss in iteration 8441: 0.4241682051423117\n",
      "Theta: [-1.89760525  1.19864572  0.0519024 ]\n",
      "Loss in iteration 8442: 0.4241662038864646\n",
      "Theta: [-1.89768269  1.19870054  0.05190023]\n",
      "Loss in iteration 8443: 0.42416420325104814\n",
      "Theta: [-1.89776012  1.19875534  0.05189805]\n",
      "Loss in iteration 8444: 0.42416220323583426\n",
      "Theta: [-1.89783754  1.19881014  0.05189588]\n",
      "Loss in iteration 8445: 0.42416020384059466\n",
      "Theta: [-1.89791494  1.19886493  0.0518937 ]\n",
      "Loss in iteration 8446: 0.4241582050651013\n",
      "Theta: [-1.89799234  1.19891971  0.05189153]\n",
      "Loss in iteration 8447: 0.4241562069091265\n",
      "Theta: [-1.89806972  1.19897448  0.05188935]\n",
      "Loss in iteration 8448: 0.42415420937244236\n",
      "Theta: [-1.89814708  1.19902925  0.05188718]\n",
      "Loss in iteration 8449: 0.42415221245482115\n",
      "Theta: [-1.89822444  1.199084    0.051885  ]\n",
      "Loss in iteration 8450: 0.4241502161560354\n",
      "Theta: [-1.89830178  1.19913875  0.05188283]\n",
      "Loss in iteration 8451: 0.42414822047585743\n",
      "Theta: [-1.89837911  1.19919349  0.05188066]\n",
      "Loss in iteration 8452: 0.42414622541406\n",
      "Theta: [-1.89845643  1.19924822  0.05187848]\n",
      "Loss in iteration 8453: 0.42414423097041565\n",
      "Theta: [-1.89853374  1.19930295  0.05187631]\n",
      "Loss in iteration 8454: 0.42414223714469734\n",
      "Theta: [-1.89861103  1.19935767  0.05187414]\n",
      "Loss in iteration 8455: 0.4241402439366779\n",
      "Theta: [-1.89868831  1.19941237  0.05187197]\n",
      "Loss in iteration 8456: 0.4241382513461304\n",
      "Theta: [-1.89876558  1.19946707  0.0518698 ]\n",
      "Loss in iteration 8457: 0.42413625937282795\n",
      "Theta: [-1.89884284  1.19952177  0.05186762]\n",
      "Loss in iteration 8458: 0.4241342680165435\n",
      "Theta: [-1.89892008  1.19957645  0.05186545]\n",
      "Loss in iteration 8459: 0.42413227727705083\n",
      "Theta: [-1.89899731  1.19963113  0.05186328]\n",
      "Loss in iteration 8460: 0.4241302871541229\n",
      "Theta: [-1.89907453  1.19968579  0.05186111]\n",
      "Loss in iteration 8461: 0.42412829764753357\n",
      "Theta: [-1.89915174  1.19974045  0.05185894]\n",
      "Loss in iteration 8462: 0.42412630875705615\n",
      "Theta: [-1.89922894  1.1997951   0.05185677]\n",
      "Loss in iteration 8463: 0.42412432048246457\n",
      "Theta: [-1.89930612  1.19984975  0.0518546 ]\n",
      "Loss in iteration 8464: 0.4241223328235325\n",
      "Theta: [-1.89938329  1.19990438  0.05185243]\n",
      "Loss in iteration 8465: 0.42412034578003394\n",
      "Theta: [-1.89946045  1.19995901  0.05185026]\n",
      "Loss in iteration 8466: 0.4241183593517427\n",
      "Theta: [-1.8995376   1.20001363  0.05184809]\n",
      "Loss in iteration 8467: 0.4241163735384331\n",
      "Theta: [-1.89961473  1.20006824  0.05184592]\n",
      "Loss in iteration 8468: 0.4241143883398793\n",
      "Theta: [-1.89969186  1.20012284  0.05184375]\n",
      "Loss in iteration 8469: 0.42411240375585557\n",
      "Theta: [-1.89976897  1.20017744  0.05184158]\n",
      "Loss in iteration 8470: 0.42411041978613606\n",
      "Theta: [-1.89984607  1.20023203  0.05183941]\n",
      "Loss in iteration 8471: 0.4241084364304957\n",
      "Theta: [-1.89992315  1.2002866   0.05183725]\n",
      "Loss in iteration 8472: 0.42410645368870903\n",
      "Theta: [-1.90000022  1.20034118  0.05183508]\n",
      "Loss in iteration 8473: 0.4241044715605505\n",
      "Theta: [-1.90007729  1.20039574  0.05183291]\n",
      "Loss in iteration 8474: 0.424102490045795\n",
      "Theta: [-1.90015434  1.20045029  0.05183074]\n",
      "Loss in iteration 8475: 0.42410050914421754\n",
      "Theta: [-1.90023137  1.20050484  0.05182858]\n",
      "Loss in iteration 8476: 0.4240985288555931\n",
      "Theta: [-1.9003084   1.20055938  0.05182641]\n",
      "Loss in iteration 8477: 0.4240965491796965\n",
      "Theta: [-1.90038541  1.20061391  0.05182424]\n",
      "Loss in iteration 8478: 0.42409457011630336\n",
      "Theta: [-1.90046241  1.20066843  0.05182208]\n",
      "Loss in iteration 8479: 0.4240925916651887\n",
      "Theta: [-1.9005394   1.20072295  0.05181991]\n",
      "Loss in iteration 8480: 0.424090613826128\n",
      "Theta: [-1.90061637  1.20077745  0.05181774]\n",
      "Loss in iteration 8481: 0.4240886365988967\n",
      "Theta: [-1.90069334  1.20083195  0.05181558]\n",
      "Loss in iteration 8482: 0.42408665998327044\n",
      "Theta: [-1.90077029  1.20088644  0.05181341]\n",
      "Loss in iteration 8483: 0.4240846839790249\n",
      "Theta: [-1.90084723  1.20094092  0.05181125]\n",
      "Loss in iteration 8484: 0.42408270858593583\n",
      "Theta: [-1.90092416  1.2009954   0.05180908]\n",
      "Loss in iteration 8485: 0.42408073380377914\n",
      "Theta: [-1.90100107  1.20104986  0.05180692]\n",
      "Loss in iteration 8486: 0.4240787596323308\n",
      "Theta: [-1.90107798  1.20110432  0.05180475]\n",
      "Loss in iteration 8487: 0.424076786071367\n",
      "Theta: [-1.90115487  1.20115877  0.05180259]\n",
      "Loss in iteration 8488: 0.42407481312066375\n",
      "Theta: [-1.90123175  1.20121322  0.05180043]\n",
      "Loss in iteration 8489: 0.4240728407799974\n",
      "Theta: [-1.90130861  1.20126765  0.05179826]\n",
      "Loss in iteration 8490: 0.42407086904914437\n",
      "Theta: [-1.90138547  1.20132208  0.0517961 ]\n",
      "Loss in iteration 8491: 0.42406889792788116\n",
      "Theta: [-1.90146231  1.20137649  0.05179394]\n",
      "Loss in iteration 8492: 0.4240669274159843\n",
      "Theta: [-1.90153914  1.2014309   0.05179177]\n",
      "Loss in iteration 8493: 0.42406495751323026\n",
      "Theta: [-1.90161596  1.20148531  0.05178961]\n",
      "Loss in iteration 8494: 0.4240629882193963\n",
      "Theta: [-1.90169276  1.2015397   0.05178745]\n",
      "Loss in iteration 8495: 0.42406101953425884\n",
      "Theta: [-1.90176956  1.20159409  0.05178529]\n",
      "Loss in iteration 8496: 0.42405905145759504\n",
      "Theta: [-1.90184634  1.20164846  0.05178313]\n",
      "Loss in iteration 8497: 0.4240570839891818\n",
      "Theta: [-1.90192311  1.20170283  0.05178096]\n",
      "Loss in iteration 8498: 0.4240551171287965\n",
      "Theta: [-1.90199986  1.2017572   0.0517788 ]\n",
      "Loss in iteration 8499: 0.42405315087621637\n",
      "Theta: [-1.90207661  1.20181155  0.05177664]\n",
      "Loss in iteration 8500: 0.42405118523121865\n",
      "Theta: [-1.90215334  1.2018659   0.05177448]\n",
      "Loss in iteration 8501: 0.42404922019358066\n",
      "Theta: [-1.90223006  1.20192023  0.05177232]\n",
      "Loss in iteration 8502: 0.42404725576308044\n",
      "Theta: [-1.90230677  1.20197456  0.05177016]\n",
      "Loss in iteration 8503: 0.4240452919394953\n",
      "Theta: [-1.90238347  1.20202888  0.051768  ]\n",
      "Loss in iteration 8504: 0.4240433287226029\n",
      "Theta: [-1.90246015  1.2020832   0.05176584]\n",
      "Loss in iteration 8505: 0.42404136611218135\n",
      "Theta: [-1.90253682  1.2021375   0.05176368]\n",
      "Loss in iteration 8506: 0.42403940410800844\n",
      "Theta: [-1.90261348  1.2021918   0.05176152]\n",
      "Loss in iteration 8507: 0.42403744270986216\n",
      "Theta: [-1.90269013  1.20224609  0.05175936]\n",
      "Loss in iteration 8508: 0.4240354819175209\n",
      "Theta: [-1.90276677  1.20230037  0.0517572 ]\n",
      "Loss in iteration 8509: 0.4240335217307626\n",
      "Theta: [-1.90284339  1.20235465  0.05175504]\n",
      "Loss in iteration 8510: 0.4240315621493657\n",
      "Theta: [-1.90292     1.20240891  0.05175289]\n",
      "Loss in iteration 8511: 0.4240296031731087\n",
      "Theta: [-1.9029966   1.20246317  0.05175073]\n",
      "Loss in iteration 8512: 0.42402764480177013\n",
      "Theta: [-1.90307319  1.20251742  0.05174857]\n",
      "Loss in iteration 8513: 0.42402568703512844\n",
      "Theta: [-1.90314977  1.20257166  0.05174641]\n",
      "Loss in iteration 8514: 0.4240237298729626\n",
      "Theta: [-1.90322633  1.2026259   0.05174426]\n",
      "Loss in iteration 8515: 0.42402177331505136\n",
      "Theta: [-1.90330288  1.20268012  0.0517421 ]\n",
      "Loss in iteration 8516: 0.4240198173611733\n",
      "Theta: [-1.90337942  1.20273434  0.05173994]\n",
      "Loss in iteration 8517: 0.42401786201110797\n",
      "Theta: [-1.90345595  1.20278855  0.05173779]\n",
      "Loss in iteration 8518: 0.4240159072646342\n",
      "Theta: [-1.90353246  1.20284275  0.05173563]\n",
      "Loss in iteration 8519: 0.4240139531215311\n",
      "Theta: [-1.90360897  1.20289695  0.05173347]\n",
      "Loss in iteration 8520: 0.42401199958157826\n",
      "Theta: [-1.90368546  1.20295113  0.05173132]\n",
      "Loss in iteration 8521: 0.4240100466445548\n",
      "Theta: [-1.90376193  1.20300531  0.05172916]\n",
      "Loss in iteration 8522: 0.42400809431024045\n",
      "Theta: [-1.9038384   1.20305948  0.05172701]\n",
      "Loss in iteration 8523: 0.4240061425784147\n",
      "Theta: [-1.90391486  1.20311364  0.05172485]\n",
      "Loss in iteration 8524: 0.4240041914488571\n",
      "Theta: [-1.9039913  1.2031678  0.0517227]\n",
      "Loss in iteration 8525: 0.42400224092134764\n",
      "Theta: [-1.90406773  1.20322194  0.05172054]\n",
      "Loss in iteration 8526: 0.424000290995666\n",
      "Theta: [-1.90414415  1.20327608  0.05171839]\n",
      "Loss in iteration 8527: 0.4239983416715925\n",
      "Theta: [-1.90422055  1.20333021  0.05171623]\n",
      "Loss in iteration 8528: 0.4239963929489069\n",
      "Theta: [-1.90429695  1.20338433  0.05171408]\n",
      "Loss in iteration 8529: 0.4239944448273895\n",
      "Theta: [-1.90437333  1.20343845  0.05171193]\n",
      "Loss in iteration 8530: 0.42399249730682065\n",
      "Theta: [-1.9044497   1.20349255  0.05170977]\n",
      "Loss in iteration 8531: 0.42399055038698064\n",
      "Theta: [-1.90452606  1.20354665  0.05170762]\n",
      "Loss in iteration 8532: 0.42398860406764965\n",
      "Theta: [-1.9046024   1.20360074  0.05170547]\n",
      "Loss in iteration 8533: 0.42398665834860855\n",
      "Theta: [-1.90467874  1.20365482  0.05170332]\n",
      "Loss in iteration 8534: 0.423984713229638\n",
      "Theta: [-1.90475506  1.2037089   0.05170116]\n",
      "Loss in iteration 8535: 0.42398276871051876\n",
      "Theta: [-1.90483137  1.20376296  0.05169901]\n",
      "Loss in iteration 8536: 0.4239808247910316\n",
      "Theta: [-1.90490767  1.20381702  0.05169686]\n",
      "Loss in iteration 8537: 0.4239788814709574\n",
      "Theta: [-1.90498395  1.20387107  0.05169471]\n",
      "Loss in iteration 8538: 0.4239769387500773\n",
      "Theta: [-1.90506023  1.20392512  0.05169256]\n",
      "Loss in iteration 8539: 0.42397499662817223\n",
      "Theta: [-1.90513649  1.20397915  0.05169041]\n",
      "Loss in iteration 8540: 0.42397305510502387\n",
      "Theta: [-1.90521274  1.20403318  0.05168825]\n",
      "Loss in iteration 8541: 0.4239711141804131\n",
      "Theta: [-1.90528898  1.2040872   0.0516861 ]\n",
      "Loss in iteration 8542: 0.4239691738541216\n",
      "Theta: [-1.9053652   1.20414121  0.05168395]\n",
      "Loss in iteration 8543: 0.42396723412593074\n",
      "Theta: [-1.90544142  1.20419521  0.0516818 ]\n",
      "Loss in iteration 8544: 0.42396529499562213\n",
      "Theta: [-1.90551762  1.2042492   0.05167965]\n",
      "Loss in iteration 8545: 0.42396335646297756\n",
      "Theta: [-1.90559381  1.20430319  0.0516775 ]\n",
      "Loss in iteration 8546: 0.42396141852777874\n",
      "Theta: [-1.90566999  1.20435717  0.05167536]\n",
      "Loss in iteration 8547: 0.4239594811898077\n",
      "Theta: [-1.90574615  1.20441114  0.05167321]\n",
      "Loss in iteration 8548: 0.4239575444488464\n",
      "Theta: [-1.90582231  1.2044651   0.05167106]\n",
      "Loss in iteration 8549: 0.4239556083046769\n",
      "Theta: [-1.90589845  1.20451906  0.05166891]\n",
      "Loss in iteration 8550: 0.42395367275708135\n",
      "Theta: [-1.90597458  1.20457301  0.05166676]\n",
      "Loss in iteration 8551: 0.423951737805842\n",
      "Theta: [-1.90605069  1.20462694  0.05166461]\n",
      "Loss in iteration 8552: 0.4239498034507413\n",
      "Theta: [-1.9061268   1.20468088  0.05166247]\n",
      "Loss in iteration 8553: 0.42394786969156156\n",
      "Theta: [-1.90620289  1.2047348   0.05166032]\n",
      "Loss in iteration 8554: 0.4239459365280858\n",
      "Theta: [-1.90627898  1.20478871  0.05165817]\n",
      "Loss in iteration 8555: 0.42394400396009607\n",
      "Theta: [-1.90635505  1.20484262  0.05165602]\n",
      "Loss in iteration 8556: 0.42394207198737566\n",
      "Theta: [-1.9064311   1.20489652  0.05165388]\n",
      "Loss in iteration 8557: 0.42394014060970703\n",
      "Theta: [-1.90650715  1.20495041  0.05165173]\n",
      "Loss in iteration 8558: 0.42393820982687347\n",
      "Theta: [-1.90658318  1.2050043   0.05164958]\n",
      "Loss in iteration 8559: 0.4239362796386575\n",
      "Theta: [-1.9066592   1.20505817  0.05164744]\n",
      "Loss in iteration 8560: 0.4239343500448428\n",
      "Theta: [-1.90673521  1.20511204  0.05164529]\n",
      "Loss in iteration 8561: 0.42393242104521245\n",
      "Theta: [-1.90681121  1.2051659   0.05164315]\n",
      "Loss in iteration 8562: 0.4239304926395495\n",
      "Theta: [-1.9068872   1.20521975  0.051641  ]\n",
      "Loss in iteration 8563: 0.42392856482763774\n",
      "Theta: [-1.90696317  1.2052736   0.05163886]\n",
      "Loss in iteration 8564: 0.42392663760926047\n",
      "Theta: [-1.90703913  1.20532743  0.05163671]\n",
      "Loss in iteration 8565: 0.42392471098420115\n",
      "Theta: [-1.90711508  1.20538126  0.05163457]\n",
      "Loss in iteration 8566: 0.4239227849522439\n",
      "Theta: [-1.90719102  1.20543508  0.05163242]\n",
      "Loss in iteration 8567: 0.4239208595131722\n",
      "Theta: [-1.90726695  1.20548889  0.05163028]\n",
      "Loss in iteration 8568: 0.42391893466677005\n",
      "Theta: [-1.90734286  1.2055427   0.05162814]\n",
      "Loss in iteration 8569: 0.42391701041282154\n",
      "Theta: [-1.90741876  1.2055965   0.05162599]\n",
      "Loss in iteration 8570: 0.4239150867511105\n",
      "Theta: [-1.90749465  1.20565028  0.05162385]\n",
      "Loss in iteration 8571: 0.4239131636814213\n",
      "Theta: [-1.90757053  1.20570406  0.05162171]\n",
      "Loss in iteration 8572: 0.423911241203538\n",
      "Theta: [-1.9076464   1.20575784  0.05161956]\n",
      "Loss in iteration 8573: 0.4239093193172452\n",
      "Theta: [-1.90772225  1.2058116   0.05161742]\n",
      "Loss in iteration 8574: 0.42390739802232724\n",
      "Theta: [-1.9077981   1.20586536  0.05161528]\n",
      "Loss in iteration 8575: 0.4239054773185687\n",
      "Theta: [-1.90787393  1.20591911  0.05161314]\n",
      "Loss in iteration 8576: 0.42390355720575423\n",
      "Theta: [-1.90794974  1.20597285  0.051611  ]\n",
      "Loss in iteration 8577: 0.42390163768366856\n",
      "Theta: [-1.90802555  1.20602658  0.05160885]\n",
      "Loss in iteration 8578: 0.4238997187520965\n",
      "Theta: [-1.90810135  1.20608031  0.05160671]\n",
      "Loss in iteration 8579: 0.423897800410823\n",
      "Theta: [-1.90817713  1.20613403  0.05160457]\n",
      "Loss in iteration 8580: 0.42389588265963296\n",
      "Theta: [-1.9082529   1.20618774  0.05160243]\n",
      "Loss in iteration 8581: 0.42389396549831176\n",
      "Theta: [-1.90832866  1.20624144  0.05160029]\n",
      "Loss in iteration 8582: 0.4238920489266444\n",
      "Theta: [-1.90840441  1.20629513  0.05159815]\n",
      "Loss in iteration 8583: 0.4238901329444162\n",
      "Theta: [-1.90848014  1.20634882  0.05159601]\n",
      "Loss in iteration 8584: 0.4238882175514126\n",
      "Theta: [-1.90855586  1.2064025   0.05159387]\n",
      "Loss in iteration 8585: 0.42388630274741923\n",
      "Theta: [-1.90863158  1.20645617  0.05159173]\n",
      "Loss in iteration 8586: 0.42388438853222127\n",
      "Theta: [-1.90870728  1.20650983  0.05158959]\n",
      "Loss in iteration 8587: 0.4238824749056047\n",
      "Theta: [-1.90878296  1.20656348  0.05158745]\n",
      "Loss in iteration 8588: 0.42388056186735545\n",
      "Theta: [-1.90885864  1.20661713  0.05158531]\n",
      "Loss in iteration 8589: 0.4238786494172589\n",
      "Theta: [-1.9089343   1.20667077  0.05158318]\n",
      "Loss in iteration 8590: 0.42387673755510136\n",
      "Theta: [-1.90900995  1.2067244   0.05158104]\n",
      "Loss in iteration 8591: 0.42387482628066886\n",
      "Theta: [-1.90908559  1.20677802  0.0515789 ]\n",
      "Loss in iteration 8592: 0.42387291559374746\n",
      "Theta: [-1.90916122  1.20683164  0.05157676]\n",
      "Loss in iteration 8593: 0.4238710054941234\n",
      "Theta: [-1.90923684  1.20688525  0.05157462]\n",
      "Loss in iteration 8594: 0.42386909598158296\n",
      "Theta: [-1.90931244  1.20693885  0.05157249]\n",
      "Loss in iteration 8595: 0.4238671870559127\n",
      "Theta: [-1.90938803  1.20699244  0.05157035]\n",
      "Loss in iteration 8596: 0.423865278716899\n",
      "Theta: [-1.90946361  1.20704602  0.05156821]\n",
      "Loss in iteration 8597: 0.42386337096432847\n",
      "Theta: [-1.90953918  1.2070996   0.05156608]\n",
      "Loss in iteration 8598: 0.42386146379798795\n",
      "Theta: [-1.90961474  1.20715316  0.05156394]\n",
      "Loss in iteration 8599: 0.42385955721766416\n",
      "Theta: [-1.90969029  1.20720672  0.05156181]\n",
      "Loss in iteration 8600: 0.4238576512231439\n",
      "Theta: [-1.90976582  1.20726028  0.05155967]\n",
      "Loss in iteration 8601: 0.4238557458142143\n",
      "Theta: [-1.90984134  1.20731382  0.05155753]\n",
      "Loss in iteration 8602: 0.4238538409906623\n",
      "Theta: [-1.90991685  1.20736736  0.0515554 ]\n",
      "Loss in iteration 8603: 0.42385193675227506\n",
      "Theta: [-1.90999235  1.20742089  0.05155326]\n",
      "Loss in iteration 8604: 0.42385003309884\n",
      "Theta: [-1.91006783  1.20747441  0.05155113]\n",
      "Loss in iteration 8605: 0.42384813003014427\n",
      "Theta: [-1.91014331  1.20752792  0.05154899]\n",
      "Loss in iteration 8606: 0.42384622754597545\n",
      "Theta: [-1.91021877  1.20758142  0.05154686]\n",
      "Loss in iteration 8607: 0.42384432564612107\n",
      "Theta: [-1.91029422  1.20763492  0.05154473]\n",
      "Loss in iteration 8608: 0.4238424243303687\n",
      "Theta: [-1.91036965  1.20768841  0.05154259]\n",
      "Loss in iteration 8609: 0.42384052359850616\n",
      "Theta: [-1.91044508  1.20774189  0.05154046]\n",
      "Loss in iteration 8610: 0.4238386234503209\n",
      "Theta: [-1.9105205   1.20779537  0.05153833]\n",
      "Loss in iteration 8611: 0.4238367238856013\n",
      "Theta: [-1.9105959   1.20784883  0.05153619]\n",
      "Loss in iteration 8612: 0.42383482490413515\n",
      "Theta: [-1.91067129  1.20790229  0.05153406]\n",
      "Loss in iteration 8613: 0.4238329265057105\n",
      "Theta: [-1.91074667  1.20795574  0.05153193]\n",
      "Loss in iteration 8614: 0.4238310286901157\n",
      "Theta: [-1.91082203  1.20800918  0.0515298 ]\n",
      "Loss in iteration 8615: 0.42382913145713874\n",
      "Theta: [-1.91089739  1.20806262  0.05152766]\n",
      "Loss in iteration 8616: 0.4238272348065682\n",
      "Theta: [-1.91097273  1.20811604  0.05152553]\n",
      "Loss in iteration 8617: 0.42382533873819256\n",
      "Theta: [-1.91104807  1.20816946  0.0515234 ]\n",
      "Loss in iteration 8618: 0.42382344325180027\n",
      "Theta: [-1.91112339  1.20822287  0.05152127]\n",
      "Loss in iteration 8619: 0.42382154834717994\n",
      "Theta: [-1.91119869  1.20827628  0.05151914]\n",
      "Loss in iteration 8620: 0.4238196540241204\n",
      "Theta: [-1.91127399  1.20832967  0.05151701]\n",
      "Loss in iteration 8621: 0.4238177602824104\n",
      "Theta: [-1.91134927  1.20838306  0.05151488]\n",
      "Loss in iteration 8622: 0.42381586712183894\n",
      "Theta: [-1.91142455  1.20843644  0.05151275]\n",
      "Loss in iteration 8623: 0.42381397454219505\n",
      "Theta: [-1.91149981  1.20848981  0.05151062]\n",
      "Loss in iteration 8624: 0.4238120825432676\n",
      "Theta: [-1.91157506  1.20854318  0.05150849]\n",
      "Loss in iteration 8625: 0.4238101911248461\n",
      "Theta: [-1.91165029  1.20859653  0.05150636]\n",
      "Loss in iteration 8626: 0.4238083002867195\n",
      "Theta: [-1.91172552  1.20864988  0.05150423]\n",
      "Loss in iteration 8627: 0.4238064100286774\n",
      "Theta: [-1.91180073  1.20870322  0.0515021 ]\n",
      "Loss in iteration 8628: 0.4238045203505093\n",
      "Theta: [-1.91187593  1.20875655  0.05149997]\n",
      "Loss in iteration 8629: 0.4238026312520046\n",
      "Theta: [-1.91195112  1.20880988  0.05149784]\n",
      "Loss in iteration 8630: 0.42380074273295315\n",
      "Theta: [-1.9120263   1.2088632   0.05149571]\n",
      "Loss in iteration 8631: 0.4237988547931444\n",
      "Theta: [-1.91210147  1.2089165   0.05149359]\n",
      "Loss in iteration 8632: 0.4237969674323685\n",
      "Theta: [-1.91217662  1.20896981  0.05149146]\n",
      "Loss in iteration 8633: 0.423795080650415\n",
      "Theta: [-1.91225176  1.2090231   0.05148933]\n",
      "Loss in iteration 8634: 0.42379319444707425\n",
      "Theta: [-1.9123269   1.20907639  0.0514872 ]\n",
      "Loss in iteration 8635: 0.4237913088221363\n",
      "Theta: [-1.91240201  1.20912966  0.05148508]\n",
      "Loss in iteration 8636: 0.4237894237753913\n",
      "Theta: [-1.91247712  1.20918293  0.05148295]\n",
      "Loss in iteration 8637: 0.4237875393066294\n",
      "Theta: [-1.91255222  1.2092362   0.05148082]\n",
      "Loss in iteration 8638: 0.4237856554156412\n",
      "Theta: [-1.9126273   1.20928945  0.0514787 ]\n",
      "Loss in iteration 8639: 0.42378377210221707\n",
      "Theta: [-1.91270237  1.2093427   0.05147657]\n",
      "Loss in iteration 8640: 0.4237818893661477\n",
      "Theta: [-1.91277743  1.20939594  0.05147445]\n",
      "Loss in iteration 8641: 0.4237800072072235\n",
      "Theta: [-1.91285248  1.20944917  0.05147232]\n",
      "Loss in iteration 8642: 0.42377812562523515\n",
      "Theta: [-1.91292752  1.20950239  0.0514702 ]\n",
      "Loss in iteration 8643: 0.4237762446199739\n",
      "Theta: [-1.91300254  1.20955561  0.05146807]\n",
      "Loss in iteration 8644: 0.42377436419123027\n",
      "Theta: [-1.91307756  1.20960881  0.05146595]\n",
      "Loss in iteration 8645: 0.42377248433879566\n",
      "Theta: [-1.91315256  1.20966201  0.05146382]\n",
      "Loss in iteration 8646: 0.42377060506246084\n",
      "Theta: [-1.91322755  1.20971521  0.0514617 ]\n",
      "Loss in iteration 8647: 0.4237687263620171\n",
      "Theta: [-1.91330253  1.20976839  0.05145957]\n",
      "Loss in iteration 8648: 0.42376684823725574\n",
      "Theta: [-1.91337749  1.20982157  0.05145745]\n",
      "Loss in iteration 8649: 0.42376497068796815\n",
      "Theta: [-1.91345245  1.20987474  0.05145533]\n",
      "Loss in iteration 8650: 0.4237630937139458\n",
      "Theta: [-1.91352739  1.2099279   0.0514532 ]\n",
      "Loss in iteration 8651: 0.4237612173149804\n",
      "Theta: [-1.91360232  1.20998105  0.05145108]\n",
      "Loss in iteration 8652: 0.42375934149086336\n",
      "Theta: [-1.91367724  1.2100342   0.05144896]\n",
      "Loss in iteration 8653: 0.42375746624138627\n",
      "Theta: [-1.91375215  1.21008733  0.05144683]\n",
      "Loss in iteration 8654: 0.4237555915663415\n",
      "Theta: [-1.91382704  1.21014046  0.05144471]\n",
      "Loss in iteration 8655: 0.4237537174655206\n",
      "Theta: [-1.91390193  1.21019359  0.05144259]\n",
      "Loss in iteration 8656: 0.42375184393871557\n",
      "Theta: [-1.9139768   1.2102467   0.05144047]\n",
      "Loss in iteration 8657: 0.42374997098571854\n",
      "Theta: [-1.91405166  1.21029981  0.05143835]\n",
      "Loss in iteration 8658: 0.42374809860632184\n",
      "Theta: [-1.91412651  1.21035291  0.05143623]\n",
      "Loss in iteration 8659: 0.4237462268003177\n",
      "Theta: [-1.91420135  1.210406    0.05143411]\n",
      "Loss in iteration 8660: 0.4237443555674984\n",
      "Theta: [-1.91427617  1.21045908  0.05143198]\n",
      "Loss in iteration 8661: 0.4237424849076564\n",
      "Theta: [-1.91435099  1.21051216  0.05142986]\n",
      "Loss in iteration 8662: 0.4237406148205843\n",
      "Theta: [-1.91442579  1.21056522  0.05142774]\n",
      "Loss in iteration 8663: 0.42373874530607464\n",
      "Theta: [-1.91450058  1.21061828  0.05142562]\n",
      "Loss in iteration 8664: 0.4237368763639203\n",
      "Theta: [-1.91457536  1.21067134  0.0514235 ]\n",
      "Loss in iteration 8665: 0.42373500799391417\n",
      "Theta: [-1.91465012  1.21072438  0.05142138]\n",
      "Loss in iteration 8666: 0.42373314019584896\n",
      "Theta: [-1.91472488  1.21077742  0.05141927]\n",
      "Loss in iteration 8667: 0.4237312729695176\n",
      "Theta: [-1.91479962  1.21083045  0.05141715]\n",
      "Loss in iteration 8668: 0.4237294063147135\n",
      "Theta: [-1.91487436  1.21088347  0.05141503]\n",
      "Loss in iteration 8669: 0.4237275402312297\n",
      "Theta: [-1.91494908  1.21093648  0.05141291]\n",
      "Loss in iteration 8670: 0.42372567471885936\n",
      "Theta: [-1.91502378  1.21098949  0.05141079]\n",
      "Loss in iteration 8671: 0.42372380977739577\n",
      "Theta: [-1.91509848  1.21104249  0.05140867]\n",
      "Loss in iteration 8672: 0.4237219454066326\n",
      "Theta: [-1.91517317  1.21109548  0.05140655]\n",
      "Loss in iteration 8673: 0.42372008160636326\n",
      "Theta: [-1.91524784  1.21114846  0.05140444]\n",
      "Loss in iteration 8674: 0.42371821837638146\n",
      "Theta: [-1.9153225   1.21120143  0.05140232]\n",
      "Loss in iteration 8675: 0.4237163557164807\n",
      "Theta: [-1.91539715  1.2112544   0.0514002 ]\n",
      "Loss in iteration 8676: 0.4237144936264552\n",
      "Theta: [-1.91547179  1.21130736  0.05139809]\n",
      "Loss in iteration 8677: 0.42371263210609855\n",
      "Theta: [-1.91554642  1.21136031  0.05139597]\n",
      "Loss in iteration 8678: 0.4237107711552047\n",
      "Theta: [-1.91562103  1.21141325  0.05139385]\n",
      "Loss in iteration 8679: 0.4237089107735678\n",
      "Theta: [-1.91569563  1.21146619  0.05139174]\n",
      "Loss in iteration 8680: 0.42370705096098205\n",
      "Theta: [-1.91577023  1.21151912  0.05138962]\n",
      "Loss in iteration 8681: 0.42370519171724164\n",
      "Theta: [-1.91584481  1.21157204  0.05138751]\n",
      "Loss in iteration 8682: 0.4237033330421409\n",
      "Theta: [-1.91591938  1.21162495  0.05138539]\n",
      "Loss in iteration 8683: 0.42370147493547444\n",
      "Theta: [-1.91599393  1.21167786  0.05138328]\n",
      "Loss in iteration 8684: 0.4236996173970365\n",
      "Theta: [-1.91606848  1.21173075  0.05138116]\n",
      "Loss in iteration 8685: 0.42369776042662183\n",
      "Theta: [-1.91614301  1.21178364  0.05137905]\n",
      "Loss in iteration 8686: 0.42369590402402524\n",
      "Theta: [-1.91621753  1.21183652  0.05137693]\n",
      "Loss in iteration 8687: 0.42369404818904116\n",
      "Theta: [-1.91629204  1.2118894   0.05137482]\n",
      "Loss in iteration 8688: 0.42369219292146476\n",
      "Theta: [-1.91636654  1.21194227  0.0513727 ]\n",
      "Loss in iteration 8689: 0.42369033822109087\n",
      "Theta: [-1.91644103  1.21199512  0.05137059]\n",
      "Loss in iteration 8690: 0.42368848408771476\n",
      "Theta: [-1.9165155   1.21204797  0.05136848]\n",
      "Loss in iteration 8691: 0.42368663052113126\n",
      "Theta: [-1.91658997  1.21210082  0.05136636]\n",
      "Loss in iteration 8692: 0.42368477752113587\n",
      "Theta: [-1.91666442  1.21215365  0.05136425]\n",
      "Loss in iteration 8693: 0.42368292508752353\n",
      "Theta: [-1.91673886  1.21220648  0.05136214]\n",
      "Loss in iteration 8694: 0.4236810732200902\n",
      "Theta: [-1.91681329  1.2122593   0.05136003]\n",
      "Loss in iteration 8695: 0.4236792219186308\n",
      "Theta: [-1.9168877   1.21231211  0.05135791]\n",
      "Loss in iteration 8696: 0.4236773711829413\n",
      "Theta: [-1.91696211  1.21236492  0.0513558 ]\n",
      "Loss in iteration 8697: 0.42367552101281725\n",
      "Theta: [-1.9170365   1.21241771  0.05135369]\n",
      "Loss in iteration 8698: 0.42367367140805423\n",
      "Theta: [-1.91711089  1.2124705   0.05135158]\n",
      "Loss in iteration 8699: 0.42367182236844836\n",
      "Theta: [-1.91718526  1.21252329  0.05134947]\n",
      "Loss in iteration 8700: 0.42366997389379546\n",
      "Theta: [-1.91725962  1.21257606  0.05134736]\n",
      "Loss in iteration 8701: 0.4236681259838917\n",
      "Theta: [-1.91733396  1.21262882  0.05134525]\n",
      "Loss in iteration 8702: 0.4236662786385327\n",
      "Theta: [-1.9174083   1.21268158  0.05134314]\n",
      "Loss in iteration 8703: 0.42366443185751523\n",
      "Theta: [-1.91748262  1.21273433  0.05134103]\n",
      "Loss in iteration 8704: 0.4236625856406353\n",
      "Theta: [-1.91755693  1.21278708  0.05133892]\n",
      "Loss in iteration 8705: 0.4236607399876891\n",
      "Theta: [-1.91763124  1.21283981  0.05133681]\n",
      "Loss in iteration 8706: 0.42365889489847364\n",
      "Theta: [-1.91770553  1.21289254  0.0513347 ]\n",
      "Loss in iteration 8707: 0.423657050372785\n",
      "Theta: [-1.9177798   1.21294526  0.05133259]\n",
      "Loss in iteration 8708: 0.42365520641041987\n",
      "Theta: [-1.91785407  1.21299797  0.05133048]\n",
      "Loss in iteration 8709: 0.4236533630111752\n",
      "Theta: [-1.91792832  1.21305068  0.05132837]\n",
      "Loss in iteration 8710: 0.4236515201748475\n",
      "Theta: [-1.91800257  1.21310337  0.05132626]\n",
      "Loss in iteration 8711: 0.4236496779012341\n",
      "Theta: [-1.9180768   1.21315606  0.05132416]\n",
      "Loss in iteration 8712: 0.4236478361901315\n",
      "Theta: [-1.91815102  1.21320874  0.05132205]\n",
      "Loss in iteration 8713: 0.4236459950413371\n",
      "Theta: [-1.91822523  1.21326142  0.05131994]\n",
      "Loss in iteration 8714: 0.423644154454648\n",
      "Theta: [-1.91829942  1.21331408  0.05131783]\n",
      "Loss in iteration 8715: 0.4236423144298612\n",
      "Theta: [-1.91837361  1.21336674  0.05131573]\n",
      "Loss in iteration 8716: 0.4236404749667744\n",
      "Theta: [-1.91844778  1.21341939  0.05131362]\n",
      "Loss in iteration 8717: 0.4236386360651849\n",
      "Theta: [-1.91852194  1.21347203  0.05131151]\n",
      "Loss in iteration 8718: 0.42363679772489005\n",
      "Theta: [-1.91859609  1.21352467  0.05130941]\n",
      "Loss in iteration 8719: 0.42363495994568773\n",
      "Theta: [-1.91867023  1.2135773   0.0513073 ]\n",
      "Loss in iteration 8720: 0.42363312272737547\n",
      "Theta: [-1.91874436  1.21362992  0.05130519]\n",
      "Loss in iteration 8721: 0.423631286069751\n",
      "Theta: [-1.91881847  1.21368253  0.05130309]\n",
      "Loss in iteration 8722: 0.42362944997261226\n",
      "Theta: [-1.91889258  1.21373513  0.05130098]\n",
      "Loss in iteration 8723: 0.4236276144357571\n",
      "Theta: [-1.91896667  1.21378773  0.05129888]\n",
      "Loss in iteration 8724: 0.4236257794589838\n",
      "Theta: [-1.91904075  1.21384032  0.05129677]\n",
      "Loss in iteration 8725: 0.42362394504209017\n",
      "Theta: [-1.91911482  1.2138929   0.05129467]\n",
      "Loss in iteration 8726: 0.4236221111848746\n",
      "Theta: [-1.91918888  1.21394547  0.05129256]\n",
      "Loss in iteration 8727: 0.42362027788713524\n",
      "Theta: [-1.91926293  1.21399804  0.05129046]\n",
      "Loss in iteration 8728: 0.4236184451486708\n",
      "Theta: [-1.91933696  1.2140506   0.05128836]\n",
      "Loss in iteration 8729: 0.42361661296927944\n",
      "Theta: [-1.91941098  1.21410315  0.05128625]\n",
      "Loss in iteration 8730: 0.42361478134875974\n",
      "Theta: [-1.91948499  1.21415569  0.05128415]\n",
      "Loss in iteration 8731: 0.4236129502869104\n",
      "Theta: [-1.919559    1.21420823  0.05128205]\n",
      "Loss in iteration 8732: 0.4236111197835302\n",
      "Theta: [-1.91963298  1.21426075  0.05127994]\n",
      "Loss in iteration 8733: 0.423609289838418\n",
      "Theta: [-1.91970696  1.21431327  0.05127784]\n",
      "Loss in iteration 8734: 0.4236074604513726\n",
      "Theta: [-1.91978093  1.21436579  0.05127574]\n",
      "Loss in iteration 8735: 0.42360563162219306\n",
      "Theta: [-1.91985488  1.21441829  0.05127364]\n",
      "Loss in iteration 8736: 0.42360380335067843\n",
      "Theta: [-1.91992882  1.21447079  0.05127153]\n",
      "Loss in iteration 8737: 0.4236019756366277\n",
      "Theta: [-1.92000275  1.21452328  0.05126943]\n",
      "Loss in iteration 8738: 0.42360014847984045\n",
      "Theta: [-1.92007667  1.21457576  0.05126733]\n",
      "Loss in iteration 8739: 0.42359832188011565\n",
      "Theta: [-1.92015058  1.21462823  0.05126523]\n",
      "Loss in iteration 8740: 0.4235964958372531\n",
      "Theta: [-1.92022448  1.2146807   0.05126313]\n",
      "Loss in iteration 8741: 0.423594670351052\n",
      "Theta: [-1.92029836  1.21473316  0.05126103]\n",
      "Loss in iteration 8742: 0.4235928454213122\n",
      "Theta: [-1.92037224  1.21478561  0.05125893]\n",
      "Loss in iteration 8743: 0.4235910210478331\n",
      "Theta: [-1.9204461   1.21483805  0.05125683]\n",
      "Loss in iteration 8744: 0.4235891972304148\n",
      "Theta: [-1.92051995  1.21489049  0.05125473]\n",
      "Loss in iteration 8745: 0.42358737396885693\n",
      "Theta: [-1.92059379  1.21494292  0.05125263]\n",
      "Loss in iteration 8746: 0.4235855512629593\n",
      "Theta: [-1.92066761  1.21499534  0.05125053]\n",
      "Loss in iteration 8747: 0.4235837291125224\n",
      "Theta: [-1.92074143  1.21504775  0.05124843]\n",
      "Loss in iteration 8748: 0.4235819075173459\n",
      "Theta: [-1.92081523  1.21510016  0.05124633]\n",
      "Loss in iteration 8749: 0.42358008647723006\n",
      "Theta: [-1.92088903  1.21515255  0.05124423]\n",
      "Loss in iteration 8750: 0.42357826599197546\n",
      "Theta: [-1.92096281  1.21520494  0.05124213]\n",
      "Loss in iteration 8751: 0.42357644606138223\n",
      "Theta: [-1.92103658  1.21525733  0.05124003]\n",
      "Loss in iteration 8752: 0.42357462668525075\n",
      "Theta: [-1.92111034  1.2153097   0.05123794]\n",
      "Loss in iteration 8753: 0.4235728078633818\n",
      "Theta: [-1.92118408  1.21536207  0.05123584]\n",
      "Loss in iteration 8754: 0.4235709895955758\n",
      "Theta: [-1.92125782  1.21541443  0.05123374]\n",
      "Loss in iteration 8755: 0.4235691718816335\n",
      "Theta: [-1.92133154  1.21546678  0.05123164]\n",
      "Loss in iteration 8756: 0.423567354721356\n",
      "Theta: [-1.92140526  1.21551912  0.05122955]\n",
      "Loss in iteration 8757: 0.4235655381145439\n",
      "Theta: [-1.92147896  1.21557146  0.05122745]\n",
      "Loss in iteration 8758: 0.423563722060998\n",
      "Theta: [-1.92155265  1.21562379  0.05122535]\n",
      "Loss in iteration 8759: 0.42356190656051973\n",
      "Theta: [-1.92162632  1.21567611  0.05122326]\n",
      "Loss in iteration 8760: 0.42356009161290986\n",
      "Theta: [-1.92169999  1.21572842  0.05122116]\n",
      "Loss in iteration 8761: 0.42355827721797\n",
      "Theta: [-1.92177365  1.21578073  0.05121907]\n",
      "Loss in iteration 8762: 0.4235564633755013\n",
      "Theta: [-1.92184729  1.21583303  0.05121697]\n",
      "Loss in iteration 8763: 0.423554650085305\n",
      "Theta: [-1.92192092  1.21588532  0.05121487]\n",
      "Loss in iteration 8764: 0.4235528373471828\n",
      "Theta: [-1.92199454  1.2159376   0.05121278]\n",
      "Loss in iteration 8765: 0.42355102516093623\n",
      "Theta: [-1.92206815  1.21598988  0.05121069]\n",
      "Loss in iteration 8766: 0.4235492135263668\n",
      "Theta: [-1.92214175  1.21604215  0.05120859]\n",
      "Loss in iteration 8767: 0.4235474024432765\n",
      "Theta: [-1.92221534  1.21609441  0.0512065 ]\n",
      "Loss in iteration 8768: 0.4235455919114669\n",
      "Theta: [-1.92228891  1.21614666  0.0512044 ]\n",
      "Loss in iteration 8769: 0.4235437819307402\n",
      "Theta: [-1.92236247  1.2161989   0.05120231]\n",
      "Loss in iteration 8770: 0.42354197250089803\n",
      "Theta: [-1.92243603  1.21625114  0.05120021]\n",
      "Loss in iteration 8771: 0.4235401636217427\n",
      "Theta: [-1.92250957  1.21630337  0.05119812]\n",
      "Loss in iteration 8772: 0.42353835529307643\n",
      "Theta: [-1.9225831   1.21635559  0.05119603]\n",
      "Loss in iteration 8773: 0.42353654751470116\n",
      "Theta: [-1.92265661  1.21640781  0.05119394]\n",
      "Loss in iteration 8774: 0.4235347402864196\n",
      "Theta: [-1.92273012  1.21646002  0.05119184]\n",
      "Loss in iteration 8775: 0.423532933608034\n",
      "Theta: [-1.92280362  1.21651222  0.05118975]\n",
      "Loss in iteration 8776: 0.42353112747934674\n",
      "Theta: [-1.9228771   1.21656441  0.05118766]\n",
      "Loss in iteration 8777: 0.4235293219001607\n",
      "Theta: [-1.92295057  1.21661659  0.05118557]\n",
      "Loss in iteration 8778: 0.4235275168702782\n",
      "Theta: [-1.92302403  1.21666877  0.05118348]\n",
      "Loss in iteration 8779: 0.4235257123895022\n",
      "Theta: [-1.92309748  1.21672094  0.05118138]\n",
      "Loss in iteration 8780: 0.42352390845763566\n",
      "Theta: [-1.92317092  1.2167731   0.05117929]\n",
      "Loss in iteration 8781: 0.42352210507448135\n",
      "Theta: [-1.92324435  1.21682525  0.0511772 ]\n",
      "Loss in iteration 8782: 0.42352030223984216\n",
      "Theta: [-1.92331776  1.2168774   0.05117511]\n",
      "Loss in iteration 8783: 0.4235184999535215\n",
      "Theta: [-1.92339116  1.21692954  0.05117302]\n",
      "Loss in iteration 8784: 0.4235166982153224\n",
      "Theta: [-1.92346456  1.21698167  0.05117093]\n",
      "Loss in iteration 8785: 0.4235148970250481\n",
      "Theta: [-1.92353794  1.21703379  0.05116884]\n",
      "Loss in iteration 8786: 0.42351309638250184\n",
      "Theta: [-1.92361131  1.21708591  0.05116675]\n",
      "Loss in iteration 8787: 0.4235112962874873\n",
      "Theta: [-1.92368466  1.21713802  0.05116466]\n",
      "Loss in iteration 8788: 0.4235094967398077\n",
      "Theta: [-1.92375801  1.21719012  0.05116257]\n",
      "Loss in iteration 8789: 0.42350769773926694\n",
      "Theta: [-1.92383135  1.21724221  0.05116048]\n",
      "Loss in iteration 8790: 0.42350589928566856\n",
      "Theta: [-1.92390467  1.2172943   0.0511584 ]\n",
      "Loss in iteration 8791: 0.4235041013788162\n",
      "Theta: [-1.92397798  1.21734638  0.05115631]\n",
      "Loss in iteration 8792: 0.4235023040185142\n",
      "Theta: [-1.92405128  1.21739845  0.05115422]\n",
      "Loss in iteration 8793: 0.4235005072045659\n",
      "Theta: [-1.92412457  1.21745051  0.05115213]\n",
      "Loss in iteration 8794: 0.4234987109367757\n",
      "Theta: [-1.92419785  1.21750256  0.05115004]\n",
      "Loss in iteration 8795: 0.42349691521494753\n",
      "Theta: [-1.92427112  1.21755461  0.05114796]\n",
      "Loss in iteration 8796: 0.4234951200388857\n",
      "Theta: [-1.92434437  1.21760665  0.05114587]\n",
      "Loss in iteration 8797: 0.42349332540839446\n",
      "Theta: [-1.92441762  1.21765869  0.05114378]\n",
      "Loss in iteration 8798: 0.42349153132327816\n",
      "Theta: [-1.92449085  1.21771071  0.0511417 ]\n",
      "Loss in iteration 8799: 0.423489737783341\n",
      "Theta: [-1.92456407  1.21776273  0.05113961]\n",
      "Loss in iteration 8800: 0.4234879447883879\n",
      "Theta: [-1.92463728  1.21781474  0.05113752]\n",
      "Loss in iteration 8801: 0.42348615233822345\n",
      "Theta: [-1.92471048  1.21786674  0.05113544]\n",
      "Loss in iteration 8802: 0.42348436043265186\n",
      "Theta: [-1.92478367  1.21791873  0.05113335]\n",
      "Loss in iteration 8803: 0.4234825690714785\n",
      "Theta: [-1.92485684  1.21797072  0.05113127]\n",
      "Loss in iteration 8804: 0.4234807782545078\n",
      "Theta: [-1.92493001  1.2180227   0.05112918]\n",
      "Loss in iteration 8805: 0.42347898798154504\n",
      "Theta: [-1.92500316  1.21807467  0.0511271 ]\n",
      "Loss in iteration 8806: 0.4234771982523948\n",
      "Theta: [-1.9250763   1.21812664  0.05112501]\n",
      "Loss in iteration 8807: 0.42347540906686293\n",
      "Theta: [-1.92514943  1.2181786   0.05112293]\n",
      "Loss in iteration 8808: 0.42347362042475384\n",
      "Theta: [-1.92522255  1.21823055  0.05112084]\n",
      "Loss in iteration 8809: 0.42347183232587327\n",
      "Theta: [-1.92529566  1.21828249  0.05111876]\n",
      "Loss in iteration 8810: 0.42347004477002625\n",
      "Theta: [-1.92536876  1.21833442  0.05111667]\n",
      "Loss in iteration 8811: 0.4234682577570186\n",
      "Theta: [-1.92544184  1.21838635  0.05111459]\n",
      "Loss in iteration 8812: 0.4234664712866557\n",
      "Theta: [-1.92551492  1.21843827  0.05111251]\n",
      "Loss in iteration 8813: 0.423464685358743\n",
      "Theta: [-1.92558798  1.21849018  0.05111042]\n",
      "Loss in iteration 8814: 0.4234628999730864\n",
      "Theta: [-1.92566103  1.21854208  0.05110834]\n",
      "Loss in iteration 8815: 0.4234611151294917\n",
      "Theta: [-1.92573407  1.21859398  0.05110626]\n",
      "Loss in iteration 8816: 0.42345933082776455\n",
      "Theta: [-1.9258071   1.21864587  0.05110418]\n",
      "Loss in iteration 8817: 0.42345754706771127\n",
      "Theta: [-1.92588011  1.21869775  0.0511021 ]\n",
      "Loss in iteration 8818: 0.42345576384913725\n",
      "Theta: [-1.92595312  1.21874962  0.05110001]\n",
      "Loss in iteration 8819: 0.4234539811718492\n",
      "Theta: [-1.92602611  1.21880149  0.05109793]\n",
      "Loss in iteration 8820: 0.42345219903565307\n",
      "Theta: [-1.9260991   1.21885335  0.05109585]\n",
      "Loss in iteration 8821: 0.42345041744035505\n",
      "Theta: [-1.92617207  1.2189052   0.05109377]\n",
      "Loss in iteration 8822: 0.4234486363857617\n",
      "Theta: [-1.92624503  1.21895705  0.05109169]\n",
      "Loss in iteration 8823: 0.42344685587167946\n",
      "Theta: [-1.92631798  1.21900888  0.05108961]\n",
      "Loss in iteration 8824: 0.4234450758979147\n",
      "Theta: [-1.92639092  1.21906071  0.05108753]\n",
      "Loss in iteration 8825: 0.42344329646427403\n",
      "Theta: [-1.92646384  1.21911253  0.05108545]\n",
      "Loss in iteration 8826: 0.4234415175705643\n",
      "Theta: [-1.92653676  1.21916435  0.05108337]\n",
      "Loss in iteration 8827: 0.4234397392165923\n",
      "Theta: [-1.92660966  1.21921615  0.05108129]\n",
      "Loss in iteration 8828: 0.42343796140216455\n",
      "Theta: [-1.92668256  1.21926795  0.05107921]\n",
      "Loss in iteration 8829: 0.4234361841270882\n",
      "Theta: [-1.92675544  1.21931974  0.05107713]\n",
      "Loss in iteration 8830: 0.42343440739117044\n",
      "Theta: [-1.92682831  1.21937153  0.05107505]\n",
      "Loss in iteration 8831: 0.42343263119421815\n",
      "Theta: [-1.92690117  1.2194233   0.05107297]\n",
      "Loss in iteration 8832: 0.42343085553603854\n",
      "Theta: [-1.92697401  1.21947507  0.05107089]\n",
      "Loss in iteration 8833: 0.42342908041643895\n",
      "Theta: [-1.92704685  1.21952683  0.05106882]\n",
      "Loss in iteration 8834: 0.42342730583522675\n",
      "Theta: [-1.92711968  1.21957858  0.05106674]\n",
      "Loss in iteration 8835: 0.4234255317922092\n",
      "Theta: [-1.92719249  1.21963033  0.05106466]\n",
      "Loss in iteration 8836: 0.42342375828719403\n",
      "Theta: [-1.92726529  1.21968207  0.05106258]\n",
      "Loss in iteration 8837: 0.4234219853199887\n",
      "Theta: [-1.92733808  1.2197338   0.05106051]\n",
      "Loss in iteration 8838: 0.4234202128904009\n",
      "Theta: [-1.92741086  1.21978552  0.05105843]\n",
      "Loss in iteration 8839: 0.42341844099823844\n",
      "Theta: [-1.92748363  1.21983724  0.05105635]\n",
      "Loss in iteration 8840: 0.42341666964330926\n",
      "Theta: [-1.92755639  1.21988895  0.05105428]\n",
      "Loss in iteration 8841: 0.423414898825421\n",
      "Theta: [-1.92762913  1.21994065  0.0510522 ]\n",
      "Loss in iteration 8842: 0.42341312854438184\n",
      "Theta: [-1.92770187  1.21999234  0.05105012]\n",
      "Loss in iteration 8843: 0.4234113587999999\n",
      "Theta: [-1.92777459  1.22004403  0.05104805]\n",
      "Loss in iteration 8844: 0.4234095895920833\n",
      "Theta: [-1.9278473   1.22009571  0.05104597]\n",
      "Loss in iteration 8845: 0.42340782092044044\n",
      "Theta: [-1.92792001  1.22014738  0.0510439 ]\n",
      "Loss in iteration 8846: 0.4234060527848793\n",
      "Theta: [-1.9279927   1.22019904  0.05104182]\n",
      "Loss in iteration 8847: 0.4234042851852087\n",
      "Theta: [-1.92806537  1.2202507   0.05103975]\n",
      "Loss in iteration 8848: 0.4234025181212368\n",
      "Theta: [-1.92813804  1.22030235  0.05103767]\n",
      "Loss in iteration 8849: 0.4234007515927724\n",
      "Theta: [-1.9282107   1.22035399  0.0510356 ]\n",
      "Loss in iteration 8850: 0.42339898559962413\n",
      "Theta: [-1.92828334  1.22040562  0.05103353]\n",
      "Loss in iteration 8851: 0.4233972201416006\n",
      "Theta: [-1.92835597  1.22045725  0.05103145]\n",
      "Loss in iteration 8852: 0.42339545521851085\n",
      "Theta: [-1.9284286   1.22050886  0.05102938]\n",
      "Loss in iteration 8853: 0.42339369083016365\n",
      "Theta: [-1.92850121  1.22056048  0.05102731]\n",
      "Loss in iteration 8854: 0.4233919269763681\n",
      "Theta: [-1.92857381  1.22061208  0.05102523]\n",
      "Loss in iteration 8855: 0.4233901636569329\n",
      "Theta: [-1.9286464   1.22066368  0.05102316]\n",
      "Loss in iteration 8856: 0.42338840087166785\n",
      "Theta: [-1.92871897  1.22071526  0.05102109]\n",
      "Loss in iteration 8857: 0.42338663862038145\n",
      "Theta: [-1.92879154  1.22076685  0.05101902]\n",
      "Loss in iteration 8858: 0.4233848769028836\n",
      "Theta: [-1.92886409  1.22081842  0.05101694]\n",
      "Loss in iteration 8859: 0.42338311571898346\n",
      "Theta: [-1.92893664  1.22086998  0.05101487]\n",
      "Loss in iteration 8860: 0.4233813550684905\n",
      "Theta: [-1.92900917  1.22092154  0.0510128 ]\n",
      "Loss in iteration 8861: 0.4233795949512142\n",
      "Theta: [-1.92908169  1.22097309  0.05101073]\n",
      "Loss in iteration 8862: 0.42337783536696444\n",
      "Theta: [-1.9291542   1.22102464  0.05100866]\n",
      "Loss in iteration 8863: 0.42337607631555074\n",
      "Theta: [-1.9292267   1.22107617  0.05100659]\n",
      "Loss in iteration 8864: 0.42337431779678275\n",
      "Theta: [-1.92929919  1.2211277   0.05100452]\n",
      "Loss in iteration 8865: 0.42337255981047095\n",
      "Theta: [-1.92937166  1.22117922  0.05100245]\n",
      "Loss in iteration 8866: 0.42337080235642466\n",
      "Theta: [-1.92944413  1.22123074  0.05100038]\n",
      "Loss in iteration 8867: 0.42336904543445414\n",
      "Theta: [-1.92951658  1.22128224  0.05099831]\n",
      "Loss in iteration 8868: 0.4233672890443696\n",
      "Theta: [-1.92958903  1.22133374  0.05099624]\n",
      "Loss in iteration 8869: 0.4233655331859813\n",
      "Theta: [-1.92966146  1.22138523  0.05099417]\n",
      "Loss in iteration 8870: 0.42336377785909923\n",
      "Theta: [-1.92973388  1.22143672  0.0509921 ]\n",
      "Loss in iteration 8871: 0.42336202306353404\n",
      "Theta: [-1.92980629  1.22148819  0.05099003]\n",
      "Loss in iteration 8872: 0.4233602687990961\n",
      "Theta: [-1.92987868  1.22153966  0.05098796]\n",
      "Loss in iteration 8873: 0.423358515065596\n",
      "Theta: [-1.92995107  1.22159113  0.05098589]\n",
      "Loss in iteration 8874: 0.4233567618628441\n",
      "Theta: [-1.93002345  1.22164258  0.05098382]\n",
      "Loss in iteration 8875: 0.4233550091906514\n",
      "Theta: [-1.93009581  1.22169403  0.05098176]\n",
      "Loss in iteration 8876: 0.4233532570488283\n",
      "Theta: [-1.93016816  1.22174547  0.05097969]\n",
      "Loss in iteration 8877: 0.42335150543718636\n",
      "Theta: [-1.93024051  1.2217969   0.05097762]\n",
      "Loss in iteration 8878: 0.4233497543555357\n",
      "Theta: [-1.93031284  1.22184832  0.05097555]\n",
      "Loss in iteration 8879: 0.42334800380368753\n",
      "Theta: [-1.93038516  1.22189974  0.05097349]\n",
      "Loss in iteration 8880: 0.4233462537814534\n",
      "Theta: [-1.93045746  1.22195115  0.05097142]\n",
      "Loss in iteration 8881: 0.42334450428864406\n",
      "Theta: [-1.93052976  1.22200255  0.05096935]\n",
      "Loss in iteration 8882: 0.4233427553250709\n",
      "Theta: [-1.93060205  1.22205394  0.05096729]\n",
      "Loss in iteration 8883: 0.42334100689054516\n",
      "Theta: [-1.93067432  1.22210533  0.05096522]\n",
      "Loss in iteration 8884: 0.42333925898487834\n",
      "Theta: [-1.93074659  1.22215671  0.05096316]\n",
      "Loss in iteration 8885: 0.42333751160788197\n",
      "Theta: [-1.93081884  1.22220808  0.05096109]\n",
      "Loss in iteration 8886: 0.4233357647593674\n",
      "Theta: [-1.93089108  1.22225945  0.05095903]\n",
      "Loss in iteration 8887: 0.42333401843914653\n",
      "Theta: [-1.93096331  1.2223108   0.05095696]\n",
      "Loss in iteration 8888: 0.4233322726470312\n",
      "Theta: [-1.93103553  1.22236215  0.0509549 ]\n",
      "Loss in iteration 8889: 0.42333052738283294\n",
      "Theta: [-1.93110774  1.2224135   0.05095283]\n",
      "Loss in iteration 8890: 0.42332878264636364\n",
      "Theta: [-1.93117993  1.22246483  0.05095077]\n",
      "Loss in iteration 8891: 0.42332703843743535\n",
      "Theta: [-1.93125212  1.22251616  0.0509487 ]\n",
      "Loss in iteration 8892: 0.42332529475586045\n",
      "Theta: [-1.93132429  1.22256748  0.05094664]\n",
      "Loss in iteration 8893: 0.42332355160145047\n",
      "Theta: [-1.93139646  1.22261879  0.05094458]\n",
      "Loss in iteration 8894: 0.42332180897401805\n",
      "Theta: [-1.93146861  1.2226701   0.05094251]\n",
      "Loss in iteration 8895: 0.4233200668733755\n",
      "Theta: [-1.93154075  1.22272139  0.05094045]\n",
      "Loss in iteration 8896: 0.423318325299335\n",
      "Theta: [-1.93161288  1.22277268  0.05093839]\n",
      "Loss in iteration 8897: 0.4233165842517089\n",
      "Theta: [-1.931685    1.22282397  0.05093633]\n",
      "Loss in iteration 8898: 0.42331484373031025\n",
      "Theta: [-1.93175711  1.22287524  0.05093426]\n",
      "Loss in iteration 8899: 0.423313103734951\n",
      "Theta: [-1.9318292   1.22292651  0.0509322 ]\n",
      "Loss in iteration 8900: 0.4233113642654444\n",
      "Theta: [-1.93190129  1.22297777  0.05093014]\n",
      "Loss in iteration 8901: 0.42330962532160266\n",
      "Theta: [-1.93197336  1.22302902  0.05092808]\n",
      "Loss in iteration 8902: 0.4233078869032392\n",
      "Theta: [-1.93204543  1.22308027  0.05092602]\n",
      "Loss in iteration 8903: 0.42330614901016683\n",
      "Theta: [-1.93211748  1.22313151  0.05092396]\n",
      "Loss in iteration 8904: 0.42330441164219823\n",
      "Theta: [-1.93218952  1.22318274  0.0509219 ]\n",
      "Loss in iteration 8905: 0.4233026747991467\n",
      "Theta: [-1.93226155  1.22323396  0.05091983]\n",
      "Loss in iteration 8906: 0.4233009384808254\n",
      "Theta: [-1.93233357  1.22328518  0.05091777]\n",
      "Loss in iteration 8907: 0.4232992026870479\n",
      "Theta: [-1.93240558  1.22333639  0.05091571]\n",
      "Loss in iteration 8908: 0.42329746741762697\n",
      "Theta: [-1.93247757  1.22338759  0.05091365]\n",
      "Loss in iteration 8909: 0.4232957326723762\n",
      "Theta: [-1.93254956  1.22343878  0.05091159]\n",
      "Loss in iteration 8910: 0.4232939984511093\n",
      "Theta: [-1.93262153  1.22348997  0.05090954]\n",
      "Loss in iteration 8911: 0.42329226475363974\n",
      "Theta: [-1.9326935   1.22354115  0.05090748]\n",
      "Loss in iteration 8912: 0.42329053157978086\n",
      "Theta: [-1.93276545  1.22359232  0.05090542]\n",
      "Loss in iteration 8913: 0.4232887989293468\n",
      "Theta: [-1.93283739  1.22364348  0.05090336]\n",
      "Loss in iteration 8914: 0.4232870668021512\n",
      "Theta: [-1.93290932  1.22369464  0.0509013 ]\n",
      "Loss in iteration 8915: 0.42328533519800793\n",
      "Theta: [-1.93298124  1.22374579  0.05089924]\n",
      "Loss in iteration 8916: 0.42328360411673094\n",
      "Theta: [-1.93305315  1.22379693  0.05089718]\n",
      "Loss in iteration 8917: 0.4232818735581344\n",
      "Theta: [-1.93312504  1.22384807  0.05089513]\n",
      "Loss in iteration 8918: 0.42328014352203225\n",
      "Theta: [-1.93319693  1.22389919  0.05089307]\n",
      "Loss in iteration 8919: 0.4232784140082386\n",
      "Theta: [-1.9332688   1.22395031  0.05089101]\n",
      "Loss in iteration 8920: 0.4232766850165683\n",
      "Theta: [-1.93334067  1.22400143  0.05088896]\n",
      "Loss in iteration 8921: 0.42327495654683495\n",
      "Theta: [-1.93341252  1.22405253  0.0508869 ]\n",
      "Loss in iteration 8922: 0.42327322859885347\n",
      "Theta: [-1.93348436  1.22410363  0.05088484]\n",
      "Loss in iteration 8923: 0.42327150117243834\n",
      "Theta: [-1.93355619  1.22415472  0.05088279]\n",
      "Loss in iteration 8924: 0.42326977426740386\n",
      "Theta: [-1.93362801  1.2242058   0.05088073]\n",
      "Loss in iteration 8925: 0.423268047883565\n",
      "Theta: [-1.93369982  1.22425688  0.05087867]\n",
      "Loss in iteration 8926: 0.4232663220207363\n",
      "Theta: [-1.93377161  1.22430794  0.05087662]\n",
      "Loss in iteration 8927: 0.4232645966787329\n",
      "Theta: [-1.9338434   1.22435901  0.05087456]\n",
      "Loss in iteration 8928: 0.4232628718573693\n",
      "Theta: [-1.93391517  1.22441006  0.05087251]\n",
      "Loss in iteration 8929: 0.4232611475564608\n",
      "Theta: [-1.93398694  1.2244611   0.05087045]\n",
      "Loss in iteration 8930: 0.4232594237758223\n",
      "Theta: [-1.93405869  1.22451214  0.0508684 ]\n",
      "Loss in iteration 8931: 0.42325770051526895\n",
      "Theta: [-1.93413043  1.22456317  0.05086635]\n",
      "Loss in iteration 8932: 0.42325597777461604\n",
      "Theta: [-1.93420216  1.2246142   0.05086429]\n",
      "Loss in iteration 8933: 0.4232542555536789\n",
      "Theta: [-1.93427388  1.22466521  0.05086224]\n",
      "Loss in iteration 8934: 0.42325253385227285\n",
      "Theta: [-1.93434559  1.22471622  0.05086018]\n",
      "Loss in iteration 8935: 0.4232508126702133\n",
      "Theta: [-1.93441729  1.22476722  0.05085813]\n",
      "Loss in iteration 8936: 0.4232490920073158\n",
      "Theta: [-1.93448897  1.22481822  0.05085608]\n",
      "Loss in iteration 8937: 0.42324737186339606\n",
      "Theta: [-1.93456065  1.22486921  0.05085402]\n",
      "Loss in iteration 8938: 0.42324565223826965\n",
      "Theta: [-1.93463231  1.22492019  0.05085197]\n",
      "Loss in iteration 8939: 0.4232439331317525\n",
      "Theta: [-1.93470397  1.22497116  0.05084992]\n",
      "Loss in iteration 8940: 0.4232422145436601\n",
      "Theta: [-1.93477561  1.22502212  0.05084787]\n",
      "Loss in iteration 8941: 0.42324049647380874\n",
      "Theta: [-1.93484724  1.22507308  0.05084582]\n",
      "Loss in iteration 8942: 0.4232387789220145\n",
      "Theta: [-1.93491886  1.22512403  0.05084376]\n",
      "Loss in iteration 8943: 0.4232370618880931\n",
      "Theta: [-1.93499047  1.22517497  0.05084171]\n",
      "Loss in iteration 8944: 0.42323534537186086\n",
      "Theta: [-1.93506207  1.22522591  0.05083966]\n",
      "Loss in iteration 8945: 0.423233629373134\n",
      "Theta: [-1.93513365  1.22527684  0.05083761]\n",
      "Loss in iteration 8946: 0.4232319138917288\n",
      "Theta: [-1.93520523  1.22532776  0.05083556]\n",
      "Loss in iteration 8947: 0.42323019892746183\n",
      "Theta: [-1.9352768   1.22537867  0.05083351]\n",
      "Loss in iteration 8948: 0.4232284844801494\n",
      "Theta: [-1.93534835  1.22542958  0.05083146]\n",
      "Loss in iteration 8949: 0.42322677054960806\n",
      "Theta: [-1.93541989  1.22548047  0.05082941]\n",
      "Loss in iteration 8950: 0.4232250571356544\n",
      "Theta: [-1.93549142  1.22553137  0.05082736]\n",
      "Loss in iteration 8951: 0.42322334423810526\n",
      "Theta: [-1.93556295  1.22558225  0.05082531]\n",
      "Loss in iteration 8952: 0.4232216318567773\n",
      "Theta: [-1.93563446  1.22563313  0.05082326]\n",
      "Loss in iteration 8953: 0.42321991999148745\n",
      "Theta: [-1.93570595  1.22568399  0.05082121]\n",
      "Loss in iteration 8954: 0.42321820864205256\n",
      "Theta: [-1.93577744  1.22573486  0.05081916]\n",
      "Loss in iteration 8955: 0.4232164978082898\n",
      "Theta: [-1.93584892  1.22578571  0.05081712]\n",
      "Loss in iteration 8956: 0.4232147874900161\n",
      "Theta: [-1.93592039  1.22583656  0.05081507]\n",
      "Loss in iteration 8957: 0.42321307768704874\n",
      "Theta: [-1.93599184  1.2258874   0.05081302]\n",
      "Loss in iteration 8958: 0.42321136839920487\n",
      "Theta: [-1.93606329  1.22593823  0.05081097]\n",
      "Loss in iteration 8959: 0.42320965962630175\n",
      "Theta: [-1.93613472  1.22598906  0.05080892]\n",
      "Loss in iteration 8960: 0.42320795136815703\n",
      "Theta: [-1.93620614  1.22603987  0.05080688]\n",
      "Loss in iteration 8961: 0.4232062436245879\n",
      "Theta: [-1.93627755  1.22609068  0.05080483]\n",
      "Loss in iteration 8962: 0.4232045363954121\n",
      "Theta: [-1.93634895  1.22614149  0.05080278]\n",
      "Loss in iteration 8963: 0.4232028296804473\n",
      "Theta: [-1.93642034  1.22619228  0.05080074]\n",
      "Loss in iteration 8964: 0.4232011234795111\n",
      "Theta: [-1.93649172  1.22624307  0.05079869]\n",
      "Loss in iteration 8965: 0.4231994177924214\n",
      "Theta: [-1.93656309  1.22629385  0.05079664]\n",
      "Loss in iteration 8966: 0.4231977126189957\n",
      "Theta: [-1.93663444  1.22634463  0.0507946 ]\n",
      "Loss in iteration 8967: 0.4231960079590523\n",
      "Theta: [-1.93670579  1.22639539  0.05079255]\n",
      "Loss in iteration 8968: 0.4231943038124092\n",
      "Theta: [-1.93677712  1.22644615  0.05079051]\n",
      "Loss in iteration 8969: 0.4231926001788844\n",
      "Theta: [-1.93684844  1.2264969   0.05078846]\n",
      "Loss in iteration 8970: 0.423190897058296\n",
      "Theta: [-1.93691976  1.22654765  0.05078642]\n",
      "Loss in iteration 8971: 0.42318919445046244\n",
      "Theta: [-1.93699106  1.22659838  0.05078437]\n",
      "Loss in iteration 8972: 0.4231874923552017\n",
      "Theta: [-1.93706235  1.22664911  0.05078233]\n",
      "Loss in iteration 8973: 0.42318579077233265\n",
      "Theta: [-1.93713363  1.22669984  0.05078028]\n",
      "Loss in iteration 8974: 0.42318408970167354\n",
      "Theta: [-1.9372049   1.22675055  0.05077824]\n",
      "Loss in iteration 8975: 0.42318238914304274\n",
      "Theta: [-1.93727615  1.22680126  0.0507762 ]\n",
      "Loss in iteration 8976: 0.42318068909625906\n",
      "Theta: [-1.9373474   1.22685196  0.05077415]\n",
      "Loss in iteration 8977: 0.4231789895611414\n",
      "Theta: [-1.93741864  1.22690265  0.05077211]\n",
      "Loss in iteration 8978: 0.4231772905375082\n",
      "Theta: [-1.93748986  1.22695334  0.05077007]\n",
      "Loss in iteration 8979: 0.4231755920251784\n",
      "Theta: [-1.93756107  1.22700402  0.05076803]\n",
      "Loss in iteration 8980: 0.4231738940239711\n",
      "Theta: [-1.93763228  1.22705469  0.05076598]\n",
      "Loss in iteration 8981: 0.42317219653370514\n",
      "Theta: [-1.93770347  1.22710535  0.05076394]\n",
      "Loss in iteration 8982: 0.4231704995541999\n",
      "Theta: [-1.93777465  1.22715601  0.0507619 ]\n",
      "Loss in iteration 8983: 0.4231688030852742\n",
      "Theta: [-1.93784582  1.22720666  0.05075986]\n",
      "Loss in iteration 8984: 0.4231671071267472\n",
      "Theta: [-1.93791698  1.2272573   0.05075782]\n",
      "Loss in iteration 8985: 0.42316541167843874\n",
      "Theta: [-1.93798813  1.22730793  0.05075577]\n",
      "Loss in iteration 8986: 0.4231637167401676\n",
      "Theta: [-1.93805926  1.22735856  0.05075373]\n",
      "Loss in iteration 8987: 0.4231620223117538\n",
      "Theta: [-1.93813039  1.22740918  0.05075169]\n",
      "Loss in iteration 8988: 0.42316032839301654\n",
      "Theta: [-1.93820151  1.22745979  0.05074965]\n",
      "Loss in iteration 8989: 0.4231586349837755\n",
      "Theta: [-1.93827261  1.2275104   0.05074761]\n",
      "Loss in iteration 8990: 0.4231569420838504\n",
      "Theta: [-1.9383437   1.227561    0.05074557]\n",
      "Loss in iteration 8991: 0.4231552496930612\n",
      "Theta: [-1.93841479  1.22761159  0.05074353]\n",
      "Loss in iteration 8992: 0.4231535578112274\n",
      "Theta: [-1.93848586  1.22766217  0.05074149]\n",
      "Loss in iteration 8993: 0.42315186643816916\n",
      "Theta: [-1.93855692  1.22771275  0.05073945]\n",
      "Loss in iteration 8994: 0.42315017557370643\n",
      "Theta: [-1.93862797  1.22776332  0.05073741]\n",
      "Loss in iteration 8995: 0.4231484852176595\n",
      "Theta: [-1.93869901  1.22781388  0.05073538]\n",
      "Loss in iteration 8996: 0.42314679536984806\n",
      "Theta: [-1.93877004  1.22786443  0.05073334]\n",
      "Loss in iteration 8997: 0.4231451060300927\n",
      "Theta: [-1.93884105  1.22791498  0.0507313 ]\n",
      "Loss in iteration 8998: 0.4231434171982137\n",
      "Theta: [-1.93891206  1.22796552  0.05072926]\n",
      "Loss in iteration 8999: 0.42314172887403123\n",
      "Theta: [-1.93898306  1.22801605  0.05072722]\n",
      "Loss in iteration 9000: 0.4231400410573659\n",
      "Theta: [-1.93905404  1.22806658  0.05072518]\n",
      "Loss in iteration 9001: 0.4231383537480383\n",
      "Theta: [-1.93912501  1.2281171   0.05072315]\n",
      "Loss in iteration 9002: 0.42313666694586904\n",
      "Theta: [-1.93919598  1.22816761  0.05072111]\n",
      "Loss in iteration 9003: 0.4231349806506786\n",
      "Theta: [-1.93926693  1.22821811  0.05071907]\n",
      "Loss in iteration 9004: 0.42313329486228796\n",
      "Theta: [-1.93933787  1.22826861  0.05071704]\n",
      "Loss in iteration 9005: 0.4231316095805178\n",
      "Theta: [-1.9394088   1.22831909  0.050715  ]\n",
      "Loss in iteration 9006: 0.42312992480518924\n",
      "Theta: [-1.93947972  1.22836958  0.05071296]\n",
      "Loss in iteration 9007: 0.4231282405361231\n",
      "Theta: [-1.93955063  1.22842005  0.05071093]\n",
      "Loss in iteration 9008: 0.4231265567731403\n",
      "Theta: [-1.93962152  1.22847052  0.05070889]\n",
      "Loss in iteration 9009: 0.42312487351606237\n",
      "Theta: [-1.93969241  1.22852098  0.05070686]\n",
      "Loss in iteration 9010: 0.4231231907647101\n",
      "Theta: [-1.93976329  1.22857143  0.05070482]\n",
      "Loss in iteration 9011: 0.4231215085189051\n",
      "Theta: [-1.93983415  1.22862188  0.05070279]\n",
      "Loss in iteration 9012: 0.4231198267784687\n",
      "Theta: [-1.939905    1.22867231  0.05070075]\n",
      "Loss in iteration 9013: 0.4231181455432222\n",
      "Theta: [-1.93997585  1.22872274  0.05069872]\n",
      "Loss in iteration 9014: 0.42311646481298726\n",
      "Theta: [-1.94004668  1.22877317  0.05069668]\n",
      "Loss in iteration 9015: 0.42311478458758517\n",
      "Theta: [-1.9401175   1.22882358  0.05069465]\n",
      "Loss in iteration 9016: 0.42311310486683806\n",
      "Theta: [-1.94018831  1.22887399  0.05069262]\n",
      "Loss in iteration 9017: 0.42311142565056725\n",
      "Theta: [-1.94025911  1.22892439  0.05069058]\n",
      "Loss in iteration 9018: 0.42310974693859477\n",
      "Theta: [-1.9403299   1.22897479  0.05068855]\n",
      "Loss in iteration 9019: 0.4231080687307424\n",
      "Theta: [-1.94040068  1.22902518  0.05068652]\n",
      "Loss in iteration 9020: 0.42310639102683234\n",
      "Theta: [-1.94047144  1.22907555  0.05068448]\n",
      "Loss in iteration 9021: 0.4231047138266863\n",
      "Theta: [-1.9405422   1.22912593  0.05068245]\n",
      "Loss in iteration 9022: 0.4231030371301266\n",
      "Theta: [-1.94061295  1.22917629  0.05068042]\n",
      "Loss in iteration 9023: 0.42310136093697553\n",
      "Theta: [-1.94068368  1.22922665  0.05067839]\n",
      "Loss in iteration 9024: 0.42309968524705505\n",
      "Theta: [-1.9407544   1.229277    0.05067635]\n",
      "Loss in iteration 9025: 0.4230980100601876\n",
      "Theta: [-1.94082512  1.22932735  0.05067432]\n",
      "Loss in iteration 9026: 0.4230963353761957\n",
      "Theta: [-1.94089582  1.22937768  0.05067229]\n",
      "Loss in iteration 9027: 0.4230946611949018\n",
      "Theta: [-1.94096651  1.22942801  0.05067026]\n",
      "Loss in iteration 9028: 0.4230929875161285\n",
      "Theta: [-1.94103719  1.22947833  0.05066823]\n",
      "Loss in iteration 9029: 0.4230913143396984\n",
      "Theta: [-1.94110786  1.22952865  0.0506662 ]\n",
      "Loss in iteration 9030: 0.42308964166543406\n",
      "Theta: [-1.94117852  1.22957895  0.05066417]\n",
      "Loss in iteration 9031: 0.42308796949315863\n",
      "Theta: [-1.94124917  1.22962925  0.05066214]\n",
      "Loss in iteration 9032: 0.4230862978226947\n",
      "Theta: [-1.9413198   1.22967955  0.05066011]\n",
      "Loss in iteration 9033: 0.42308462665386515\n",
      "Theta: [-1.94139043  1.22972983  0.05065808]\n",
      "Loss in iteration 9034: 0.4230829559864931\n",
      "Theta: [-1.94146105  1.22978011  0.05065605]\n",
      "Loss in iteration 9035: 0.42308128582040166\n",
      "Theta: [-1.94153165  1.22983038  0.05065402]\n",
      "Loss in iteration 9036: 0.423079616155414\n",
      "Theta: [-1.94160224  1.22988065  0.05065199]\n",
      "Loss in iteration 9037: 0.4230779469913534\n",
      "Theta: [-1.94167283  1.2299309   0.05064996]\n",
      "Loss in iteration 9038: 0.42307627832804295\n",
      "Theta: [-1.9417434   1.22998115  0.05064793]\n",
      "Loss in iteration 9039: 0.4230746101653063\n",
      "Theta: [-1.94181396  1.23003139  0.05064591]\n",
      "Loss in iteration 9040: 0.4230729425029666\n",
      "Theta: [-1.94188451  1.23008163  0.05064388]\n",
      "Loss in iteration 9041: 0.42307127534084776\n",
      "Theta: [-1.94195505  1.23013186  0.05064185]\n",
      "Loss in iteration 9042: 0.42306960867877313\n",
      "Theta: [-1.94202558  1.23018208  0.05063982]\n",
      "Loss in iteration 9043: 0.42306794251656643\n",
      "Theta: [-1.9420961   1.23023229  0.05063779]\n",
      "Loss in iteration 9044: 0.42306627685405135\n",
      "Theta: [-1.94216661  1.2302825   0.05063577]\n",
      "Loss in iteration 9045: 0.42306461169105175\n",
      "Theta: [-1.9422371   1.2303327   0.05063374]\n",
      "Loss in iteration 9046: 0.4230629470273917\n",
      "Theta: [-1.94230759  1.23038289  0.05063171]\n",
      "Loss in iteration 9047: 0.42306128286289507\n",
      "Theta: [-1.94237806  1.23043307  0.05062969]\n",
      "Loss in iteration 9048: 0.4230596191973858\n",
      "Theta: [-1.94244853  1.23048325  0.05062766]\n",
      "Loss in iteration 9049: 0.4230579560306882\n",
      "Theta: [-1.94251898  1.23053342  0.05062564]\n",
      "Loss in iteration 9050: 0.4230562933626263\n",
      "Theta: [-1.94258942  1.23058358  0.05062361]\n",
      "Loss in iteration 9051: 0.42305463119302444\n",
      "Theta: [-1.94265985  1.23063374  0.05062159]\n",
      "Loss in iteration 9052: 0.4230529695217069\n",
      "Theta: [-1.94273028  1.23068388  0.05061956]\n",
      "Loss in iteration 9053: 0.42305130834849825\n",
      "Theta: [-1.94280069  1.23073403  0.05061754]\n",
      "Loss in iteration 9054: 0.42304964767322295\n",
      "Theta: [-1.94287109  1.23078416  0.05061551]\n",
      "Loss in iteration 9055: 0.42304798749570544\n",
      "Theta: [-1.94294147  1.23083429  0.05061349]\n",
      "Loss in iteration 9056: 0.4230463278157704\n",
      "Theta: [-1.94301185  1.23088441  0.05061146]\n",
      "Loss in iteration 9057: 0.42304466863324264\n",
      "Theta: [-1.94308222  1.23093452  0.05060944]\n",
      "Loss in iteration 9058: 0.42304300994794686\n",
      "Theta: [-1.94315258  1.23098462  0.05060741]\n",
      "Loss in iteration 9059: 0.4230413517597079\n",
      "Theta: [-1.94322292  1.23103472  0.05060539]\n",
      "Loss in iteration 9060: 0.42303969406835074\n",
      "Theta: [-1.94329326  1.23108481  0.05060337]\n",
      "Loss in iteration 9061: 0.42303803687370034\n",
      "Theta: [-1.94336358  1.23113489  0.05060134]\n",
      "Loss in iteration 9062: 0.423036380175582\n",
      "Theta: [-1.94343389  1.23118497  0.05059932]\n",
      "Loss in iteration 9063: 0.4230347239738206\n",
      "Theta: [-1.9435042   1.23123504  0.0505973 ]\n",
      "Loss in iteration 9064: 0.4230330682682414\n",
      "Theta: [-1.94357449  1.2312851   0.05059528]\n",
      "Loss in iteration 9065: 0.4230314130586699\n",
      "Theta: [-1.94364477  1.23133516  0.05059325]\n",
      "Loss in iteration 9066: 0.42302975834493123\n",
      "Theta: [-1.94371504  1.2313852   0.05059123]\n",
      "Loss in iteration 9067: 0.423028104126851\n",
      "Theta: [-1.9437853   1.23143524  0.05058921]\n",
      "Loss in iteration 9068: 0.42302645040425463\n",
      "Theta: [-1.94385555  1.23148528  0.05058719]\n",
      "Loss in iteration 9069: 0.42302479717696767\n",
      "Theta: [-1.94392579  1.2315353   0.05058517]\n",
      "Loss in iteration 9070: 0.42302314444481603\n",
      "Theta: [-1.94399602  1.23158532  0.05058315]\n",
      "Loss in iteration 9071: 0.4230214922076253\n",
      "Theta: [-1.94406623  1.23163533  0.05058113]\n",
      "Loss in iteration 9072: 0.42301984046522123\n",
      "Theta: [-1.94413644  1.23168534  0.05057911]\n",
      "Loss in iteration 9073: 0.42301818921742973\n",
      "Theta: [-1.94420663  1.23173533  0.05057709]\n",
      "Loss in iteration 9074: 0.4230165384640767\n",
      "Theta: [-1.94427682  1.23178532  0.05057507]\n",
      "Loss in iteration 9075: 0.42301488820498845\n",
      "Theta: [-1.94434699  1.23183531  0.05057305]\n",
      "Loss in iteration 9076: 0.42301323843999095\n",
      "Theta: [-1.94441716  1.23188528  0.05057103]\n",
      "Loss in iteration 9077: 0.4230115891689102\n",
      "Theta: [-1.94448731  1.23193525  0.05056901]\n",
      "Loss in iteration 9078: 0.4230099403915726\n",
      "Theta: [-1.94455745  1.23198521  0.05056699]\n",
      "Loss in iteration 9079: 0.42300829210780444\n",
      "Theta: [-1.94462758  1.23203517  0.05056497]\n",
      "Loss in iteration 9080: 0.4230066443174321\n",
      "Theta: [-1.9446977   1.23208511  0.05056295]\n",
      "Loss in iteration 9081: 0.4230049970202823\n",
      "Theta: [-1.94476781  1.23213505  0.05056093]\n",
      "Loss in iteration 9082: 0.42300335021618124\n",
      "Theta: [-1.94483791  1.23218498  0.05055892]\n",
      "Loss in iteration 9083: 0.4230017039049555\n",
      "Theta: [-1.944908    1.23223491  0.0505569 ]\n",
      "Loss in iteration 9084: 0.42300005808643193\n",
      "Theta: [-1.94497807  1.23228483  0.05055488]\n",
      "Loss in iteration 9085: 0.4229984127604374\n",
      "Theta: [-1.94504814  1.23233474  0.05055286]\n",
      "Loss in iteration 9086: 0.4229967679267985\n",
      "Theta: [-1.9451182   1.23238464  0.05055085]\n",
      "Loss in iteration 9087: 0.42299512358534236\n",
      "Theta: [-1.94518824  1.23243454  0.05054883]\n",
      "Loss in iteration 9088: 0.42299347973589574\n",
      "Theta: [-1.94525828  1.23248443  0.05054681]\n",
      "Loss in iteration 9089: 0.4229918363782859\n",
      "Theta: [-1.9453283   1.23253431  0.0505448 ]\n",
      "Loss in iteration 9090: 0.42299019351233985\n",
      "Theta: [-1.94539831  1.23258419  0.05054278]\n",
      "Loss in iteration 9091: 0.422988551137885\n",
      "Theta: [-1.94546832  1.23263405  0.05054077]\n",
      "Loss in iteration 9092: 0.4229869092547481\n",
      "Theta: [-1.94553831  1.23268392  0.05053875]\n",
      "Loss in iteration 9093: 0.4229852678627569\n",
      "Theta: [-1.94560829  1.23273377  0.05053673]\n",
      "Loss in iteration 9094: 0.4229836269617387\n",
      "Theta: [-1.94567826  1.23278362  0.05053472]\n",
      "Loss in iteration 9095: 0.4229819865515211\n",
      "Theta: [-1.94574822  1.23283345  0.0505327 ]\n",
      "Loss in iteration 9096: 0.4229803466319314\n",
      "Theta: [-1.94581817  1.23288329  0.05053069]\n",
      "Loss in iteration 9097: 0.42297870720279745\n",
      "Theta: [-1.94588811  1.23293311  0.05052868]\n",
      "Loss in iteration 9098: 0.4229770682639469\n",
      "Theta: [-1.94595804  1.23298293  0.05052666]\n",
      "Loss in iteration 9099: 0.4229754298152074\n",
      "Theta: [-1.94602795  1.23303274  0.05052465]\n",
      "Loss in iteration 9100: 0.422973791856407\n",
      "Theta: [-1.94609786  1.23308254  0.05052263]\n",
      "Loss in iteration 9101: 0.4229721543873734\n",
      "Theta: [-1.94616776  1.23313234  0.05052062]\n",
      "Loss in iteration 9102: 0.42297051740793484\n",
      "Theta: [-1.94623764  1.23318213  0.05051861]\n",
      "Loss in iteration 9103: 0.42296888091791923\n",
      "Theta: [-1.94630752  1.23323191  0.05051659]\n",
      "Loss in iteration 9104: 0.42296724491715454\n",
      "Theta: [-1.94637738  1.23328169  0.05051458]\n",
      "Loss in iteration 9105: 0.4229656094054694\n",
      "Theta: [-1.94644723  1.23333145  0.05051257]\n",
      "Loss in iteration 9106: 0.4229639743826916\n",
      "Theta: [-1.94651707  1.23338122  0.05051056]\n",
      "Loss in iteration 9107: 0.4229623398486498\n",
      "Theta: [-1.94658691  1.23343097  0.05050855]\n",
      "Loss in iteration 9108: 0.42296070580317247\n",
      "Theta: [-1.94665673  1.23348072  0.05050653]\n",
      "Loss in iteration 9109: 0.42295907224608775\n",
      "Theta: [-1.94672654  1.23353045  0.05050452]\n",
      "Loss in iteration 9110: 0.4229574391772246\n",
      "Theta: [-1.94679634  1.23358019  0.05050251]\n",
      "Loss in iteration 9111: 0.42295580659641124\n",
      "Theta: [-1.94686613  1.23362991  0.0505005 ]\n",
      "Loss in iteration 9112: 0.4229541745034768\n",
      "Theta: [-1.94693591  1.23367963  0.05049849]\n",
      "Loss in iteration 9113: 0.42295254289824974\n",
      "Theta: [-1.94700567  1.23372934  0.05049648]\n",
      "Loss in iteration 9114: 0.4229509117805591\n",
      "Theta: [-1.94707543  1.23377904  0.05049447]\n",
      "Loss in iteration 9115: 0.42294928115023384\n",
      "Theta: [-1.94714518  1.23382874  0.05049246]\n",
      "Loss in iteration 9116: 0.42294765100710274\n",
      "Theta: [-1.94721491  1.23387843  0.05049045]\n",
      "Loss in iteration 9117: 0.4229460213509949\n",
      "Theta: [-1.94728464  1.23392811  0.05048844]\n",
      "Loss in iteration 9118: 0.42294439218173957\n",
      "Theta: [-1.94735435  1.23397779  0.05048643]\n",
      "Loss in iteration 9119: 0.42294276349916593\n",
      "Theta: [-1.94742406  1.23402745  0.05048442]\n",
      "Loss in iteration 9120: 0.42294113530310334\n",
      "Theta: [-1.94749375  1.23407712  0.05048241]\n",
      "Loss in iteration 9121: 0.4229395075933809\n",
      "Theta: [-1.94756344  1.23412677  0.0504804 ]\n",
      "Loss in iteration 9122: 0.42293788036982816\n",
      "Theta: [-1.94763311  1.23417642  0.05047839]\n",
      "Loss in iteration 9123: 0.4229362536322748\n",
      "Theta: [-1.94770277  1.23422606  0.05047638]\n",
      "Loss in iteration 9124: 0.4229346273805501\n",
      "Theta: [-1.94777242  1.23427569  0.05047438]\n",
      "Loss in iteration 9125: 0.4229330016144837\n",
      "Theta: [-1.94784206  1.23432531  0.05047237]\n",
      "Loss in iteration 9126: 0.4229313763339055\n",
      "Theta: [-1.94791169  1.23437493  0.05047036]\n",
      "Loss in iteration 9127: 0.42292975153864526\n",
      "Theta: [-1.94798131  1.23442454  0.05046835]\n",
      "Loss in iteration 9128: 0.4229281272285328\n",
      "Theta: [-1.94805092  1.23447415  0.05046635]\n",
      "Loss in iteration 9129: 0.4229265034033978\n",
      "Theta: [-1.94812052  1.23452374  0.05046434]\n",
      "Loss in iteration 9130: 0.42292488006307055\n",
      "Theta: [-1.9481901   1.23457333  0.05046233]\n",
      "Loss in iteration 9131: 0.4229232572073809\n",
      "Theta: [-1.94825968  1.23462292  0.05046033]\n",
      "Loss in iteration 9132: 0.42292163483615924\n",
      "Theta: [-1.94832925  1.23467249  0.05045832]\n",
      "Loss in iteration 9133: 0.4229200129492354\n",
      "Theta: [-1.9483988   1.23472206  0.05045632]\n",
      "Loss in iteration 9134: 0.42291839154644006\n",
      "Theta: [-1.94846835  1.23477162  0.05045431]\n",
      "Loss in iteration 9135: 0.4229167706276033\n",
      "Theta: [-1.94853788  1.23482117  0.0504523 ]\n",
      "Loss in iteration 9136: 0.42291515019255554\n",
      "Theta: [-1.94860741  1.23487072  0.0504503 ]\n",
      "Loss in iteration 9137: 0.42291353024112743\n",
      "Theta: [-1.94867692  1.23492026  0.05044829]\n",
      "Loss in iteration 9138: 0.42291191077314927\n",
      "Theta: [-1.94874642  1.23496979  0.05044629]\n",
      "Loss in iteration 9139: 0.422910291788452\n",
      "Theta: [-1.94881591  1.23501932  0.05044429]\n",
      "Loss in iteration 9140: 0.4229086732868661\n",
      "Theta: [-1.9488854   1.23506884  0.05044228]\n",
      "Loss in iteration 9141: 0.42290705526822236\n",
      "Theta: [-1.94895487  1.23511835  0.05044028]\n",
      "Loss in iteration 9142: 0.42290543773235173\n",
      "Theta: [-1.94902433  1.23516785  0.05043827]\n",
      "Loss in iteration 9143: 0.42290382067908494\n",
      "Theta: [-1.94909378  1.23521735  0.05043627]\n",
      "Loss in iteration 9144: 0.42290220410825297\n",
      "Theta: [-1.94916322  1.23526684  0.05043427]\n",
      "Loss in iteration 9145: 0.4229005880196871\n",
      "Theta: [-1.94923265  1.23531633  0.05043226]\n",
      "Loss in iteration 9146: 0.42289897241321833\n",
      "Theta: [-1.94930206  1.2353658   0.05043026]\n",
      "Loss in iteration 9147: 0.4228973572886778\n",
      "Theta: [-1.94937147  1.23541527  0.05042826]\n",
      "Loss in iteration 9148: 0.4228957426458969\n",
      "Theta: [-1.94944087  1.23546473  0.05042626]\n",
      "Loss in iteration 9149: 0.42289412848470675\n",
      "Theta: [-1.94951025  1.23551419  0.05042425]\n",
      "Loss in iteration 9150: 0.42289251480493895\n",
      "Theta: [-1.94957963  1.23556363  0.05042225]\n",
      "Loss in iteration 9151: 0.4228909016064249\n",
      "Theta: [-1.949649    1.23561308  0.05042025]\n",
      "Loss in iteration 9152: 0.4228892888889961\n",
      "Theta: [-1.94971835  1.23566251  0.05041825]\n",
      "Loss in iteration 9153: 0.422887676652484\n",
      "Theta: [-1.9497877   1.23571194  0.05041625]\n",
      "Loss in iteration 9154: 0.42288606489672076\n",
      "Theta: [-1.94985703  1.23576136  0.05041425]\n",
      "Loss in iteration 9155: 0.42288445362153765\n",
      "Theta: [-1.94992635  1.23581077  0.05041225]\n",
      "Loss in iteration 9156: 0.4228828428267669\n",
      "Theta: [-1.94999566  1.23586017  0.05041025]\n",
      "Loss in iteration 9157: 0.4228812325122401\n",
      "Theta: [-1.95006497  1.23590957  0.05040825]\n",
      "Loss in iteration 9158: 0.4228796226777892\n",
      "Theta: [-1.95013426  1.23595896  0.05040625]\n",
      "Loss in iteration 9159: 0.4228780133232465\n",
      "Theta: [-1.95020354  1.23600835  0.05040425]\n",
      "Loss in iteration 9160: 0.42287640444844365\n",
      "Theta: [-1.95027281  1.23605772  0.05040225]\n",
      "Loss in iteration 9161: 0.4228747960532134\n",
      "Theta: [-1.95034207  1.23610709  0.05040025]\n",
      "Loss in iteration 9162: 0.4228731881373877\n",
      "Theta: [-1.95041132  1.23615646  0.05039825]\n",
      "Loss in iteration 9163: 0.4228715807007988\n",
      "Theta: [-1.95048056  1.23620581  0.05039625]\n",
      "Loss in iteration 9164: 0.42286997374327917\n",
      "Theta: [-1.95054979  1.23625516  0.05039425]\n",
      "Loss in iteration 9165: 0.42286836726466115\n",
      "Theta: [-1.950619    1.2363045   0.05039225]\n",
      "Loss in iteration 9166: 0.42286676126477746\n",
      "Theta: [-1.95068821  1.23635384  0.05039026]\n",
      "Loss in iteration 9167: 0.42286515574346045\n",
      "Theta: [-1.95075741  1.23640316  0.05038826]\n",
      "Loss in iteration 9168: 0.42286355070054304\n",
      "Theta: [-1.95082659  1.23645248  0.05038626]\n",
      "Loss in iteration 9169: 0.42286194613585787\n",
      "Theta: [-1.95089577  1.2365018   0.05038426]\n",
      "Loss in iteration 9170: 0.4228603420492376\n",
      "Theta: [-1.95096493  1.2365511   0.05038227]\n",
      "Loss in iteration 9171: 0.42285873844051525\n",
      "Theta: [-1.95103409  1.2366004   0.05038027]\n",
      "Loss in iteration 9172: 0.42285713530952357\n",
      "Theta: [-1.95110323  1.2366497   0.05037827]\n",
      "Loss in iteration 9173: 0.4228555326560959\n",
      "Theta: [-1.95117237  1.23669898  0.05037628]\n",
      "Loss in iteration 9174: 0.42285393048006503\n",
      "Theta: [-1.95124149  1.23674826  0.05037428]\n",
      "Loss in iteration 9175: 0.4228523287812643\n",
      "Theta: [-1.9513106   1.23679753  0.05037228]\n",
      "Loss in iteration 9176: 0.4228507275595267\n",
      "Theta: [-1.95137971  1.23684679  0.05037029]\n",
      "Loss in iteration 9177: 0.42284912681468567\n",
      "Theta: [-1.9514488   1.23689605  0.05036829]\n",
      "Loss in iteration 9178: 0.4228475265465746\n",
      "Theta: [-1.95151788  1.2369453   0.0503663 ]\n",
      "Loss in iteration 9179: 0.42284592675502686\n",
      "Theta: [-1.95158695  1.23699454  0.0503643 ]\n",
      "Loss in iteration 9180: 0.4228443274398759\n",
      "Theta: [-1.95165601  1.23704378  0.05036231]\n",
      "Loss in iteration 9181: 0.42284272860095534\n",
      "Theta: [-1.95172506  1.23709301  0.05036031]\n",
      "Loss in iteration 9182: 0.4228411302380987\n",
      "Theta: [-1.9517941   1.23714223  0.05035832]\n",
      "Loss in iteration 9183: 0.4228395323511399\n",
      "Theta: [-1.95186313  1.23719144  0.05035633]\n",
      "Loss in iteration 9184: 0.42283793493991245\n",
      "Theta: [-1.95193214  1.23724065  0.05035433]\n",
      "Loss in iteration 9185: 0.42283633800425063\n",
      "Theta: [-1.95200115  1.23728985  0.05035234]\n",
      "Loss in iteration 9186: 0.4228347415439878\n",
      "Theta: [-1.95207015  1.23733905  0.05035034]\n",
      "Loss in iteration 9187: 0.4228331455589583\n",
      "Theta: [-1.95213914  1.23738823  0.05034835]\n",
      "Loss in iteration 9188: 0.422831550048996\n",
      "Theta: [-1.95220811  1.23743741  0.05034636]\n",
      "Loss in iteration 9189: 0.42282995501393505\n",
      "Theta: [-1.95227708  1.23748659  0.05034437]\n",
      "Loss in iteration 9190: 0.4228283604536096\n",
      "Theta: [-1.95234603  1.23753575  0.05034237]\n",
      "Loss in iteration 9191: 0.422826766367854\n",
      "Theta: [-1.95241498  1.23758491  0.05034038]\n",
      "Loss in iteration 9192: 0.42282517275650267\n",
      "Theta: [-1.95248391  1.23763406  0.05033839]\n",
      "Loss in iteration 9193: 0.4228235796193897\n",
      "Theta: [-1.95255284  1.23768321  0.0503364 ]\n",
      "Loss in iteration 9194: 0.4228219869563498\n",
      "Theta: [-1.95262175  1.23773234  0.05033441]\n",
      "Loss in iteration 9195: 0.42282039476721744\n",
      "Theta: [-1.95269065  1.23778147  0.05033242]\n",
      "Loss in iteration 9196: 0.4228188030518272\n",
      "Theta: [-1.95275955  1.2378306   0.05033042]\n",
      "Loss in iteration 9197: 0.42281721181001364\n",
      "Theta: [-1.95282843  1.23787971  0.05032843]\n",
      "Loss in iteration 9198: 0.42281562104161163\n",
      "Theta: [-1.9528973   1.23792882  0.05032644]\n",
      "Loss in iteration 9199: 0.42281403074645607\n",
      "Theta: [-1.95296616  1.23797792  0.05032445]\n",
      "Loss in iteration 9200: 0.4228124409243816\n",
      "Theta: [-1.95303501  1.23802702  0.05032246]\n",
      "Loss in iteration 9201: 0.4228108515752232\n",
      "Theta: [-1.95310385  1.23807611  0.05032047]\n",
      "Loss in iteration 9202: 0.422809262698816\n",
      "Theta: [-1.95317268  1.23812519  0.05031848]\n",
      "Loss in iteration 9203: 0.422807674294995\n",
      "Theta: [-1.9532415   1.23817426  0.05031649]\n",
      "Loss in iteration 9204: 0.4228060863635954\n",
      "Theta: [-1.95331031  1.23822333  0.05031451]\n",
      "Loss in iteration 9205: 0.4228044989044525\n",
      "Theta: [-1.95337911  1.23827239  0.05031252]\n",
      "Loss in iteration 9206: 0.42280291191740127\n",
      "Theta: [-1.9534479   1.23832144  0.05031053]\n",
      "Loss in iteration 9207: 0.4228013254022771\n",
      "Theta: [-1.95351668  1.23837049  0.05030854]\n",
      "Loss in iteration 9208: 0.4227997393589159\n",
      "Theta: [-1.95358544  1.23841953  0.05030655]\n",
      "Loss in iteration 9209: 0.4227981537871527\n",
      "Theta: [-1.9536542   1.23846856  0.05030456]\n",
      "Loss in iteration 9210: 0.42279656868682297\n",
      "Theta: [-1.95372295  1.23851759  0.05030258]\n",
      "Loss in iteration 9211: 0.4227949840577627\n",
      "Theta: [-1.95379168  1.2385666   0.05030059]\n",
      "Loss in iteration 9212: 0.4227933998998076\n",
      "Theta: [-1.95386041  1.23861561  0.0502986 ]\n",
      "Loss in iteration 9213: 0.42279181621279305\n",
      "Theta: [-1.95392912  1.23866462  0.05029661]\n",
      "Loss in iteration 9214: 0.42279023299655505\n",
      "Theta: [-1.95399783  1.23871362  0.05029463]\n",
      "Loss in iteration 9215: 0.4227886502509296\n",
      "Theta: [-1.95406652  1.23876261  0.05029264]\n",
      "Loss in iteration 9216: 0.42278706797575255\n",
      "Theta: [-1.95413521  1.23881159  0.05029065]\n",
      "Loss in iteration 9217: 0.42278548617086\n",
      "Theta: [-1.95420388  1.23886057  0.05028867]\n",
      "Loss in iteration 9218: 0.42278390483608796\n",
      "Theta: [-1.95427254  1.23890953  0.05028668]\n",
      "Loss in iteration 9219: 0.42278232397127263\n",
      "Theta: [-1.9543412  1.2389585  0.0502847]\n",
      "Loss in iteration 9220: 0.42278074357625045\n",
      "Theta: [-1.95440984  1.23900745  0.05028271]\n",
      "Loss in iteration 9221: 0.4227791636508574\n",
      "Theta: [-1.95447847  1.2390564   0.05028073]\n",
      "Loss in iteration 9222: 0.42277758419493006\n",
      "Theta: [-1.95454709  1.23910534  0.05027874]\n",
      "Loss in iteration 9223: 0.42277600520830483\n",
      "Theta: [-1.9546157   1.23915427  0.05027676]\n",
      "Loss in iteration 9224: 0.4227744266908182\n",
      "Theta: [-1.9546843   1.2392032   0.05027477]\n",
      "Loss in iteration 9225: 0.4227728486423066\n",
      "Theta: [-1.95475289  1.23925212  0.05027279]\n",
      "Loss in iteration 9226: 0.42277127106260687\n",
      "Theta: [-1.95482147  1.23930104  0.05027081]\n",
      "Loss in iteration 9227: 0.4227696939515557\n",
      "Theta: [-1.95489004  1.23934994  0.05026882]\n",
      "Loss in iteration 9228: 0.4227681173089899\n",
      "Theta: [-1.9549586   1.23939884  0.05026684]\n",
      "Loss in iteration 9229: 0.4227665411347463\n",
      "Theta: [-1.95502715  1.23944773  0.05026486]\n",
      "Loss in iteration 9230: 0.4227649654286617\n",
      "Theta: [-1.95509569  1.23949662  0.05026287]\n",
      "Loss in iteration 9231: 0.42276339019057313\n",
      "Theta: [-1.95516422  1.2395455   0.05026089]\n",
      "Loss in iteration 9232: 0.4227618154203176\n",
      "Theta: [-1.95523273  1.23959437  0.05025891]\n",
      "Loss in iteration 9233: 0.4227602411177325\n",
      "Theta: [-1.95530124  1.23964323  0.05025692]\n",
      "Loss in iteration 9234: 0.42275866728265454\n",
      "Theta: [-1.95536974  1.23969209  0.05025494]\n",
      "Loss in iteration 9235: 0.4227570939149213\n",
      "Theta: [-1.95543822  1.23974094  0.05025296]\n",
      "Loss in iteration 9236: 0.42275552101437003\n",
      "Theta: [-1.9555067   1.23978978  0.05025098]\n",
      "Loss in iteration 9237: 0.42275394858083815\n",
      "Theta: [-1.95557517  1.23983862  0.050249  ]\n",
      "Loss in iteration 9238: 0.42275237661416304\n",
      "Theta: [-1.95564362  1.23988745  0.05024702]\n",
      "Loss in iteration 9239: 0.4227508051141822\n",
      "Theta: [-1.95571207  1.23993627  0.05024504]\n",
      "Loss in iteration 9240: 0.4227492340807334\n",
      "Theta: [-1.9557805   1.23998509  0.05024306]\n",
      "Loss in iteration 9241: 0.42274766351365406\n",
      "Theta: [-1.95584892  1.2400339   0.05024108]\n",
      "Loss in iteration 9242: 0.422746093412782\n",
      "Theta: [-1.95591734  1.2400827   0.05023909]\n",
      "Loss in iteration 9243: 0.42274452377795513\n",
      "Theta: [-1.95598574  1.24013149  0.05023711]\n",
      "Loss in iteration 9244: 0.42274295460901107\n",
      "Theta: [-1.95605414  1.24018028  0.05023514]\n",
      "Loss in iteration 9245: 0.4227413859057879\n",
      "Theta: [-1.95612252  1.24022906  0.05023316]\n",
      "Loss in iteration 9246: 0.4227398176681237\n",
      "Theta: [-1.95619089  1.24027783  0.05023118]\n",
      "Loss in iteration 9247: 0.4227382498958563\n",
      "Theta: [-1.95625925  1.2403266   0.0502292 ]\n",
      "Loss in iteration 9248: 0.4227366825888238\n",
      "Theta: [-1.9563276   1.24037536  0.05022722]\n",
      "Loss in iteration 9249: 0.4227351157468647\n",
      "Theta: [-1.95639595  1.24042411  0.05022524]\n",
      "Loss in iteration 9250: 0.42273354936981705\n",
      "Theta: [-1.95646428  1.24047286  0.05022326]\n",
      "Loss in iteration 9251: 0.42273198345751917\n",
      "Theta: [-1.9565326   1.2405216   0.05022128]\n",
      "Loss in iteration 9252: 0.4227304180098094\n",
      "Theta: [-1.95660091  1.24057033  0.05021931]\n",
      "Loss in iteration 9253: 0.4227288530265264\n",
      "Theta: [-1.95666921  1.24061906  0.05021733]\n",
      "Loss in iteration 9254: 0.4227272885075085\n",
      "Theta: [-1.9567375   1.24066777  0.05021535]\n",
      "Loss in iteration 9255: 0.42272572445259443\n",
      "Theta: [-1.95680578  1.24071649  0.05021337]\n",
      "Loss in iteration 9256: 0.4227241608616227\n",
      "Theta: [-1.95687405  1.24076519  0.0502114 ]\n",
      "Loss in iteration 9257: 0.42272259773443216\n",
      "Theta: [-1.95694231  1.24081389  0.05020942]\n",
      "Loss in iteration 9258: 0.42272103507086156\n",
      "Theta: [-1.95701055  1.24086258  0.05020744]\n",
      "Loss in iteration 9259: 0.42271947287074974\n",
      "Theta: [-1.95707879  1.24091126  0.05020547]\n",
      "Loss in iteration 9260: 0.42271791113393575\n",
      "Theta: [-1.95714702  1.24095994  0.05020349]\n",
      "Loss in iteration 9261: 0.42271634986025847\n",
      "Theta: [-1.95721524  1.24100861  0.05020152]\n",
      "Loss in iteration 9262: 0.422714789049557\n",
      "Theta: [-1.95728344  1.24105727  0.05019954]\n",
      "Loss in iteration 9263: 0.42271322870167016\n",
      "Theta: [-1.95735164  1.24110593  0.05019757]\n",
      "Loss in iteration 9264: 0.42271166881643774\n",
      "Theta: [-1.95741983  1.24115457  0.05019559]\n",
      "Loss in iteration 9265: 0.4227101093936985\n",
      "Theta: [-1.957488    1.24120322  0.05019362]\n",
      "Loss in iteration 9266: 0.422708550433292\n",
      "Theta: [-1.95755617  1.24125185  0.05019164]\n",
      "Loss in iteration 9267: 0.4227069919350575\n",
      "Theta: [-1.95762433  1.24130048  0.05018967]\n",
      "Loss in iteration 9268: 0.4227054338988346\n",
      "Theta: [-1.95769247  1.2413491   0.05018769]\n",
      "Loss in iteration 9269: 0.42270387632446266\n",
      "Theta: [-1.95776061  1.24139771  0.05018572]\n",
      "Loss in iteration 9270: 0.42270231921178153\n",
      "Theta: [-1.95782873  1.24144632  0.05018375]\n",
      "Loss in iteration 9271: 0.4227007625606305\n",
      "Theta: [-1.95789685  1.24149492  0.05018177]\n",
      "Loss in iteration 9272: 0.42269920637084957\n",
      "Theta: [-1.95796495  1.24154351  0.0501798 ]\n",
      "Loss in iteration 9273: 0.4226976506422785\n",
      "Theta: [-1.95803304  1.2415921   0.05017783]\n",
      "Loss in iteration 9274: 0.42269609537475694\n",
      "Theta: [-1.95810113  1.24164068  0.05017585]\n",
      "Loss in iteration 9275: 0.4226945405681253\n",
      "Theta: [-1.9581692   1.24168925  0.05017388]\n",
      "Loss in iteration 9276: 0.4226929862222228\n",
      "Theta: [-1.95823726  1.24173782  0.05017191]\n",
      "Loss in iteration 9277: 0.42269143233689005\n",
      "Theta: [-1.95830532  1.24178638  0.05016994]\n",
      "Loss in iteration 9278: 0.4226898789119671\n",
      "Theta: [-1.95837336  1.24183493  0.05016797]\n",
      "Loss in iteration 9279: 0.42268832594729405\n",
      "Theta: [-1.95844139  1.24188347  0.05016599]\n",
      "Loss in iteration 9280: 0.4226867734427111\n",
      "Theta: [-1.95850941  1.24193201  0.05016402]\n",
      "Loss in iteration 9281: 0.42268522139805875\n",
      "Theta: [-1.95857742  1.24198054  0.05016205]\n",
      "Loss in iteration 9282: 0.4226836698131773\n",
      "Theta: [-1.95864543  1.24202907  0.05016008]\n",
      "Loss in iteration 9283: 0.42268211868790684\n",
      "Theta: [-1.95871342  1.24207758  0.05015811]\n",
      "Loss in iteration 9284: 0.42268056802208853\n",
      "Theta: [-1.9587814   1.24212609  0.05015614]\n",
      "Loss in iteration 9285: 0.4226790178155626\n",
      "Theta: [-1.95884937  1.2421746   0.05015417]\n",
      "Loss in iteration 9286: 0.4226774680681696\n",
      "Theta: [-1.95891733  1.24222309  0.0501522 ]\n",
      "Loss in iteration 9287: 0.4226759187797504\n",
      "Theta: [-1.95898528  1.24227158  0.05015023]\n",
      "Loss in iteration 9288: 0.4226743699501458\n",
      "Theta: [-1.95905322  1.24232007  0.05014826]\n",
      "Loss in iteration 9289: 0.42267282157919644\n",
      "Theta: [-1.95912115  1.24236854  0.05014629]\n",
      "Loss in iteration 9290: 0.4226712736667437\n",
      "Theta: [-1.95918907  1.24241701  0.05014432]\n",
      "Loss in iteration 9291: 0.4226697262126278\n",
      "Theta: [-1.95925697  1.24246547  0.05014235]\n",
      "Loss in iteration 9292: 0.4226681792166904\n",
      "Theta: [-1.95932487  1.24251393  0.05014039]\n",
      "Loss in iteration 9293: 0.42266663267877247\n",
      "Theta: [-1.95939276  1.24256238  0.05013842]\n",
      "Loss in iteration 9294: 0.4226650865987151\n",
      "Theta: [-1.95946064  1.24261082  0.05013645]\n",
      "Loss in iteration 9295: 0.42266354097635933\n",
      "Theta: [-1.95952851  1.24265925  0.05013448]\n",
      "Loss in iteration 9296: 0.42266199581154706\n",
      "Theta: [-1.95959637  1.24270768  0.05013251]\n",
      "Loss in iteration 9297: 0.4226604511041189\n",
      "Theta: [-1.95966421  1.2427561   0.05013055]\n",
      "Loss in iteration 9298: 0.4226589068539168\n",
      "Theta: [-1.95973205  1.24280451  0.05012858]\n",
      "Loss in iteration 9299: 0.4226573630607821\n",
      "Theta: [-1.95979988  1.24285292  0.05012661]\n",
      "Loss in iteration 9300: 0.4226558197245565\n",
      "Theta: [-1.95986769  1.24290132  0.05012465]\n",
      "Loss in iteration 9301: 0.42265427684508133\n",
      "Theta: [-1.9599355   1.24294971  0.05012268]\n",
      "Loss in iteration 9302: 0.42265273442219853\n",
      "Theta: [-1.9600033   1.2429981   0.05012071]\n",
      "Loss in iteration 9303: 0.42265119245574967\n",
      "Theta: [-1.96007108  1.24304648  0.05011875]\n",
      "Loss in iteration 9304: 0.4226496509455768\n",
      "Theta: [-1.96013886  1.24309485  0.05011678]\n",
      "Loss in iteration 9305: 0.4226481098915216\n",
      "Theta: [-1.96020662  1.24314322  0.05011482]\n",
      "Loss in iteration 9306: 0.42264656929342614\n",
      "Theta: [-1.96027438  1.24319157  0.05011285]\n",
      "Loss in iteration 9307: 0.4226450291511325\n",
      "Theta: [-1.96034212  1.24323993  0.05011089]\n",
      "Loss in iteration 9308: 0.4226434894644824\n",
      "Theta: [-1.96040986  1.24328827  0.05010892]\n",
      "Loss in iteration 9309: 0.4226419502333186\n",
      "Theta: [-1.96047758  1.24333661  0.05010696]\n",
      "Loss in iteration 9310: 0.42264041145748293\n",
      "Theta: [-1.9605453   1.24338494  0.05010499]\n",
      "Loss in iteration 9311: 0.4226388731368175\n",
      "Theta: [-1.960613    1.24343326  0.05010303]\n",
      "Loss in iteration 9312: 0.422637335271165\n",
      "Theta: [-1.9606807   1.24348158  0.05010107]\n",
      "Loss in iteration 9313: 0.4226357978603678\n",
      "Theta: [-1.96074838  1.24352989  0.0500991 ]\n",
      "Loss in iteration 9314: 0.422634260904268\n",
      "Theta: [-1.96081606  1.24357819  0.05009714]\n",
      "Loss in iteration 9315: 0.4226327244027086\n",
      "Theta: [-1.96088372  1.24362649  0.05009518]\n",
      "Loss in iteration 9316: 0.42263118835553215\n",
      "Theta: [-1.96095137  1.24367478  0.05009321]\n",
      "Loss in iteration 9317: 0.4226296527625809\n",
      "Theta: [-1.96101901  1.24372306  0.05009125]\n",
      "Loss in iteration 9318: 0.42262811762369806\n",
      "Theta: [-1.96108665  1.24377134  0.05008929]\n",
      "Loss in iteration 9319: 0.4226265829387262\n",
      "Theta: [-1.96115427  1.24381961  0.05008733]\n",
      "Loss in iteration 9320: 0.42262504870750817\n",
      "Theta: [-1.96122188  1.24386787  0.05008536]\n",
      "Loss in iteration 9321: 0.4226235149298869\n",
      "Theta: [-1.96128949  1.24391613  0.0500834 ]\n",
      "Loss in iteration 9322: 0.42262198160570563\n",
      "Theta: [-1.96135708  1.24396438  0.05008144]\n",
      "Loss in iteration 9323: 0.42262044873480703\n",
      "Theta: [-1.96142466  1.24401262  0.05007948]\n",
      "Loss in iteration 9324: 0.4226189163170344\n",
      "Theta: [-1.96149223  1.24406085  0.05007752]\n",
      "Loss in iteration 9325: 0.42261738435223106\n",
      "Theta: [-1.96155979  1.24410908  0.05007556]\n",
      "Loss in iteration 9326: 0.42261585284023995\n",
      "Theta: [-1.96162734  1.2441573   0.0500736 ]\n",
      "Loss in iteration 9327: 0.42261432178090474\n",
      "Theta: [-1.96169488  1.24420552  0.05007164]\n",
      "Loss in iteration 9328: 0.4226127911740684\n",
      "Theta: [-1.96176242  1.24425372  0.05006968]\n",
      "Loss in iteration 9329: 0.4226112610195748\n",
      "Theta: [-1.96182994  1.24430192  0.05006772]\n",
      "Loss in iteration 9330: 0.4226097313172671\n",
      "Theta: [-1.96189745  1.24435012  0.05006576]\n",
      "Loss in iteration 9331: 0.42260820206698907\n",
      "Theta: [-1.96196495  1.24439831  0.0500638 ]\n",
      "Loss in iteration 9332: 0.42260667326858437\n",
      "Theta: [-1.96203244  1.24444649  0.05006184]\n",
      "Loss in iteration 9333: 0.42260514492189655\n",
      "Theta: [-1.96209992  1.24449466  0.05005988]\n",
      "Loss in iteration 9334: 0.4226036170267693\n",
      "Theta: [-1.96216739  1.24454282  0.05005792]\n",
      "Loss in iteration 9335: 0.4226020895830467\n",
      "Theta: [-1.96223485  1.24459098  0.05005596]\n",
      "Loss in iteration 9336: 0.4226005625905725\n",
      "Theta: [-1.9623023   1.24463914  0.05005401]\n",
      "Loss in iteration 9337: 0.42259903604919075\n",
      "Theta: [-1.96236974  1.24468728  0.05005205]\n",
      "Loss in iteration 9338: 0.4225975099587454\n",
      "Theta: [-1.96243717  1.24473542  0.05005009]\n",
      "Loss in iteration 9339: 0.42259598431908046\n",
      "Theta: [-1.96250459  1.24478355  0.05004813]\n",
      "Loss in iteration 9340: 0.42259445913004023\n",
      "Theta: [-1.962572    1.24483168  0.05004617]\n",
      "Loss in iteration 9341: 0.4225929343914689\n",
      "Theta: [-1.96263939  1.2448798   0.05004422]\n",
      "Loss in iteration 9342: 0.4225914101032105\n",
      "Theta: [-1.96270678  1.24492791  0.05004226]\n",
      "Loss in iteration 9343: 0.4225898862651097\n",
      "Theta: [-1.96277416  1.24497601  0.0500403 ]\n",
      "Loss in iteration 9344: 0.4225883628770106\n",
      "Theta: [-1.96284153  1.24502411  0.05003835]\n",
      "Loss in iteration 9345: 0.4225868399387581\n",
      "Theta: [-1.96290889  1.2450722   0.05003639]\n",
      "Loss in iteration 9346: 0.42258531745019634\n",
      "Theta: [-1.96297624  1.24512029  0.05003444]\n",
      "Loss in iteration 9347: 0.4225837954111701\n",
      "Theta: [-1.96304357  1.24516837  0.05003248]\n",
      "Loss in iteration 9348: 0.4225822738215239\n",
      "Theta: [-1.9631109   1.24521644  0.05003052]\n",
      "Loss in iteration 9349: 0.4225807526811025\n",
      "Theta: [-1.96317822  1.2452645   0.05002857]\n",
      "Loss in iteration 9350: 0.42257923198975084\n",
      "Theta: [-1.96324553  1.24531256  0.05002661]\n",
      "Loss in iteration 9351: 0.42257771174731373\n",
      "Theta: [-1.96331283  1.24536061  0.05002466]\n",
      "Loss in iteration 9352: 0.4225761919536358\n",
      "Theta: [-1.96338011  1.24540865  0.05002271]\n",
      "Loss in iteration 9353: 0.4225746726085623\n",
      "Theta: [-1.96344739  1.24545669  0.05002075]\n",
      "Loss in iteration 9354: 0.4225731537119383\n",
      "Theta: [-1.96351466  1.24550472  0.0500188 ]\n",
      "Loss in iteration 9355: 0.4225716352636089\n",
      "Theta: [-1.96358191  1.24555274  0.05001684]\n",
      "Loss in iteration 9356: 0.4225701172634189\n",
      "Theta: [-1.96364916  1.24560076  0.05001489]\n",
      "Loss in iteration 9357: 0.4225685997112141\n",
      "Theta: [-1.9637164   1.24564876  0.05001294]\n",
      "Loss in iteration 9358: 0.42256708260683934\n",
      "Theta: [-1.96378362  1.24569677  0.05001098]\n",
      "Loss in iteration 9359: 0.4225655659501403\n",
      "Theta: [-1.96385084  1.24574476  0.05000903]\n",
      "Loss in iteration 9360: 0.4225640497409622\n",
      "Theta: [-1.96391805  1.24579275  0.05000708]\n",
      "Loss in iteration 9361: 0.42256253397915056\n",
      "Theta: [-1.96398524  1.24584073  0.05000513]\n",
      "Loss in iteration 9362: 0.4225610186645509\n",
      "Theta: [-1.96405243  1.24588871  0.05000317]\n",
      "Loss in iteration 9363: 0.4225595037970091\n",
      "Theta: [-1.96411961  1.24593668  0.05000122]\n",
      "Loss in iteration 9364: 0.42255798937637024\n",
      "Theta: [-1.96418677  1.24598464  0.04999927]\n",
      "Loss in iteration 9365: 0.4225564754024807\n",
      "Theta: [-1.96425393  1.24603259  0.04999732]\n",
      "Loss in iteration 9366: 0.4225549618751861\n",
      "Theta: [-1.96432107  1.24608054  0.04999537]\n",
      "Loss in iteration 9367: 0.42255344879433204\n",
      "Theta: [-1.96438821  1.24612848  0.04999342]\n",
      "Loss in iteration 9368: 0.4225519361597646\n",
      "Theta: [-1.96445534  1.24617642  0.04999146]\n",
      "Loss in iteration 9369: 0.4225504239713299\n",
      "Theta: [-1.96452245  1.24622434  0.04998951]\n",
      "Loss in iteration 9370: 0.42254891222887403\n",
      "Theta: [-1.96458956  1.24627226  0.04998756]\n",
      "Loss in iteration 9371: 0.4225474009322428\n",
      "Theta: [-1.96465665  1.24632018  0.04998561]\n",
      "Loss in iteration 9372: 0.4225458900812825\n",
      "Theta: [-1.96472374  1.24636809  0.04998366]\n",
      "Loss in iteration 9373: 0.4225443796758395\n",
      "Theta: [-1.96479081  1.24641599  0.04998171]\n",
      "Loss in iteration 9374: 0.4225428697157602\n",
      "Theta: [-1.96485788  1.24646388  0.04997976]\n",
      "Loss in iteration 9375: 0.4225413602008907\n",
      "Theta: [-1.96492493  1.24651177  0.04997782]\n",
      "Loss in iteration 9376: 0.42253985113107745\n",
      "Theta: [-1.96499198  1.24655965  0.04997587]\n",
      "Loss in iteration 9377: 0.42253834250616734\n",
      "Theta: [-1.96505901  1.24660752  0.04997392]\n",
      "Loss in iteration 9378: 0.4225368343260065\n",
      "Theta: [-1.96512604  1.24665539  0.04997197]\n",
      "Loss in iteration 9379: 0.4225353265904415\n",
      "Theta: [-1.96519305  1.24670325  0.04997002]\n",
      "Loss in iteration 9380: 0.4225338192993194\n",
      "Theta: [-1.96526006  1.2467511   0.04996807]\n",
      "Loss in iteration 9381: 0.4225323124524867\n",
      "Theta: [-1.96532705  1.24679894  0.04996613]\n",
      "Loss in iteration 9382: 0.4225308060497904\n",
      "Theta: [-1.96539404  1.24684678  0.04996418]\n",
      "Loss in iteration 9383: 0.4225293000910771\n",
      "Theta: [-1.96546101  1.24689462  0.04996223]\n",
      "Loss in iteration 9384: 0.422527794576194\n",
      "Theta: [-1.96552797  1.24694244  0.04996028]\n",
      "Loss in iteration 9385: 0.42252628950498766\n",
      "Theta: [-1.96559493  1.24699026  0.04995834]\n",
      "Loss in iteration 9386: 0.42252478487730577\n",
      "Theta: [-1.96566187  1.24703807  0.04995639]\n",
      "Loss in iteration 9387: 0.422523280692995\n",
      "Theta: [-1.96572881  1.24708588  0.04995444]\n",
      "Loss in iteration 9388: 0.4225217769519027\n",
      "Theta: [-1.96579573  1.24713368  0.0499525 ]\n",
      "Loss in iteration 9389: 0.4225202736538762\n",
      "Theta: [-1.96586265  1.24718147  0.04995055]\n",
      "Loss in iteration 9390: 0.4225187707987624\n",
      "Theta: [-1.96592955  1.24722925  0.04994861]\n",
      "Loss in iteration 9391: 0.4225172683864092\n",
      "Theta: [-1.96599644  1.24727703  0.04994666]\n",
      "Loss in iteration 9392: 0.42251576641666366\n",
      "Theta: [-1.96606333  1.2473248   0.04994472]\n",
      "Loss in iteration 9393: 0.42251426488937355\n",
      "Theta: [-1.9661302   1.24737257  0.04994277]\n",
      "Loss in iteration 9394: 0.4225127638043862\n",
      "Theta: [-1.96619707  1.24742032  0.04994083]\n",
      "Loss in iteration 9395: 0.42251126316154947\n",
      "Theta: [-1.96626392  1.24746808  0.04993888]\n",
      "Loss in iteration 9396: 0.42250976296071074\n",
      "Theta: [-1.96633076  1.24751582  0.04993694]\n",
      "Loss in iteration 9397: 0.42250826320171825\n",
      "Theta: [-1.9663976   1.24756356  0.04993499]\n",
      "Loss in iteration 9398: 0.42250676388441927\n",
      "Theta: [-1.96646442  1.24761129  0.04993305]\n",
      "Loss in iteration 9399: 0.42250526500866187\n",
      "Theta: [-1.96653124  1.24765901  0.0499311 ]\n",
      "Loss in iteration 9400: 0.422503766574294\n",
      "Theta: [-1.96659804  1.24770673  0.04992916]\n",
      "Loss in iteration 9401: 0.4225022685811637\n",
      "Theta: [-1.96666483  1.24775444  0.04992722]\n",
      "Loss in iteration 9402: 0.42250077102911904\n",
      "Theta: [-1.96673162  1.24780214  0.04992528]\n",
      "Loss in iteration 9403: 0.4224992739180079\n",
      "Theta: [-1.96679839  1.24784984  0.04992333]\n",
      "Loss in iteration 9404: 0.4224977772476788\n",
      "Theta: [-1.96686515  1.24789753  0.04992139]\n",
      "Loss in iteration 9405: 0.4224962810179798\n",
      "Theta: [-1.96693191  1.24794521  0.04991945]\n",
      "Loss in iteration 9406: 0.42249478522875916\n",
      "Theta: [-1.96699865  1.24799289  0.04991751]\n",
      "Loss in iteration 9407: 0.4224932898798655\n",
      "Theta: [-1.96706538  1.24804056  0.04991556]\n",
      "Loss in iteration 9408: 0.42249179497114697\n",
      "Theta: [-1.96713211  1.24808822  0.04991362]\n",
      "Loss in iteration 9409: 0.4224903005024522\n",
      "Theta: [-1.96719882  1.24813588  0.04991168]\n",
      "Loss in iteration 9410: 0.4224888064736298\n",
      "Theta: [-1.96726553  1.24818353  0.04990974]\n",
      "Loss in iteration 9411: 0.42248731288452823\n",
      "Theta: [-1.96733222  1.24823117  0.0499078 ]\n",
      "Loss in iteration 9412: 0.4224858197349961\n",
      "Theta: [-1.9673989   1.24827881  0.04990586]\n",
      "Loss in iteration 9413: 0.4224843270248824\n",
      "Theta: [-1.96746558  1.24832644  0.04990392]\n",
      "Loss in iteration 9414: 0.4224828347540359\n",
      "Theta: [-1.96753224  1.24837406  0.04990198]\n",
      "Loss in iteration 9415: 0.42248134292230527\n",
      "Theta: [-1.96759889  1.24842168  0.04990004]\n",
      "Loss in iteration 9416: 0.42247985152953954\n",
      "Theta: [-1.96766554  1.24846929  0.0498981 ]\n",
      "Loss in iteration 9417: 0.4224783605755878\n",
      "Theta: [-1.96773217  1.24851689  0.04989616]\n",
      "Loss in iteration 9418: 0.422476870060299\n",
      "Theta: [-1.96779879  1.24856448  0.04989422]\n",
      "Loss in iteration 9419: 0.4224753799835221\n",
      "Theta: [-1.96786541  1.24861207  0.04989228]\n",
      "Loss in iteration 9420: 0.42247389034510663\n",
      "Theta: [-1.96793201  1.24865966  0.04989034]\n",
      "Loss in iteration 9421: 0.4224724011449014\n",
      "Theta: [-1.9679986   1.24870723  0.0498884 ]\n",
      "Loss in iteration 9422: 0.422470912382756\n",
      "Theta: [-1.96806519  1.2487548   0.04988646]\n",
      "Loss in iteration 9423: 0.42246942405851984\n",
      "Theta: [-1.96813176  1.24880236  0.04988453]\n",
      "Loss in iteration 9424: 0.42246793617204204\n",
      "Theta: [-1.96819833  1.24884992  0.04988259]\n",
      "Loss in iteration 9425: 0.42246644872317224\n",
      "Theta: [-1.96826488  1.24889747  0.04988065]\n",
      "Loss in iteration 9426: 0.42246496171176007\n",
      "Theta: [-1.96833142  1.24894501  0.04987871]\n",
      "Loss in iteration 9427: 0.4224634751376551\n",
      "Theta: [-1.96839796  1.24899254  0.04987678]\n",
      "Loss in iteration 9428: 0.42246198900070675\n",
      "Theta: [-1.96846448  1.24904007  0.04987484]\n",
      "Loss in iteration 9429: 0.4224605033007651\n",
      "Theta: [-1.96853099  1.24908759  0.0498729 ]\n",
      "Loss in iteration 9430: 0.42245901803767977\n",
      "Theta: [-1.9685975   1.24913511  0.04987097]\n",
      "Loss in iteration 9431: 0.4224575332113005\n",
      "Theta: [-1.96866399  1.24918262  0.04986903]\n",
      "Loss in iteration 9432: 0.42245604882147725\n",
      "Theta: [-1.96873048  1.24923012  0.04986709]\n",
      "Loss in iteration 9433: 0.42245456486806016\n",
      "Theta: [-1.96879695  1.24927761  0.04986516]\n",
      "Loss in iteration 9434: 0.42245308135089915\n",
      "Theta: [-1.96886341  1.2493251   0.04986322]\n",
      "Loss in iteration 9435: 0.42245159826984424\n",
      "Theta: [-1.96892987  1.24937258  0.04986129]\n",
      "Loss in iteration 9436: 0.4224501156247456\n",
      "Theta: [-1.96899631  1.24942006  0.04985935]\n",
      "Loss in iteration 9437: 0.4224486334154535\n",
      "Theta: [-1.96906275  1.24946752  0.04985742]\n",
      "Loss in iteration 9438: 0.4224471516418183\n",
      "Theta: [-1.96912917  1.24951498  0.04985548]\n",
      "Loss in iteration 9439: 0.4224456703036903\n",
      "Theta: [-1.96919558  1.24956244  0.04985355]\n",
      "Loss in iteration 9440: 0.42244418940091966\n",
      "Theta: [-1.96926199  1.24960989  0.04985161]\n",
      "Loss in iteration 9441: 0.42244270893335717\n",
      "Theta: [-1.96932838  1.24965733  0.04984968]\n",
      "Loss in iteration 9442: 0.42244122890085317\n",
      "Theta: [-1.96939477  1.24970476  0.04984775]\n",
      "Loss in iteration 9443: 0.42243974930325817\n",
      "Theta: [-1.96946114  1.24975219  0.04984581]\n",
      "Loss in iteration 9444: 0.4224382701404229\n",
      "Theta: [-1.96952751  1.24979961  0.04984388]\n",
      "Loss in iteration 9445: 0.4224367914121983\n",
      "Theta: [-1.96959386  1.24984702  0.04984195]\n",
      "Loss in iteration 9446: 0.42243531311843463\n",
      "Theta: [-1.96966021  1.24989443  0.04984001]\n",
      "Loss in iteration 9447: 0.42243383525898315\n",
      "Theta: [-1.96972654  1.24994183  0.04983808]\n",
      "Loss in iteration 9448: 0.4224323578336944\n",
      "Theta: [-1.96979287  1.24998923  0.04983615]\n",
      "Loss in iteration 9449: 0.4224308808424196\n",
      "Theta: [-1.96985918  1.25003661  0.04983422]\n",
      "Loss in iteration 9450: 0.42242940428500986\n",
      "Theta: [-1.96992549  1.25008399  0.04983228]\n",
      "Loss in iteration 9451: 0.42242792816131575\n",
      "Theta: [-1.96999178  1.25013137  0.04983035]\n",
      "Loss in iteration 9452: 0.4224264524711887\n",
      "Theta: [-1.97005807  1.25017873  0.04982842]\n",
      "Loss in iteration 9453: 0.42242497721448\n",
      "Theta: [-1.97012434  1.2502261   0.04982649]\n",
      "Loss in iteration 9454: 0.4224235023910408\n",
      "Theta: [-1.97019061  1.25027345  0.04982456]\n",
      "Loss in iteration 9455: 0.4224220280007224\n",
      "Theta: [-1.97025686  1.2503208   0.04982263]\n",
      "Loss in iteration 9456: 0.4224205540433762\n",
      "Theta: [-1.97032311  1.25036814  0.0498207 ]\n",
      "Loss in iteration 9457: 0.42241908051885346\n",
      "Theta: [-1.97038934  1.25041547  0.04981877]\n",
      "Loss in iteration 9458: 0.42241760742700585\n",
      "Theta: [-1.97045557  1.2504628   0.04981684]\n",
      "Loss in iteration 9459: 0.42241613476768497\n",
      "Theta: [-1.97052178  1.25051012  0.04981491]\n",
      "Loss in iteration 9460: 0.42241466254074217\n",
      "Theta: [-1.97058799  1.25055743  0.04981298]\n",
      "Loss in iteration 9461: 0.4224131907460295\n",
      "Theta: [-1.97065419  1.25060474  0.04981105]\n",
      "Loss in iteration 9462: 0.4224117193833984\n",
      "Theta: [-1.97072037  1.25065204  0.04980912]\n",
      "Loss in iteration 9463: 0.4224102484527007\n",
      "Theta: [-1.97078655  1.25069933  0.04980719]\n",
      "Loss in iteration 9464: 0.4224087779537883\n",
      "Theta: [-1.97085271  1.25074662  0.04980526]\n",
      "Loss in iteration 9465: 0.422407307886513\n",
      "Theta: [-1.97091887  1.2507939   0.04980333]\n",
      "Loss in iteration 9466: 0.42240583825072703\n",
      "Theta: [-1.97098502  1.25084117  0.04980141]\n",
      "Loss in iteration 9467: 0.42240436904628204\n",
      "Theta: [-1.97105115  1.25088844  0.04979948]\n",
      "Loss in iteration 9468: 0.4224029002730307\n",
      "Theta: [-1.97111728  1.2509357   0.04979755]\n",
      "Loss in iteration 9469: 0.4224014319308247\n",
      "Theta: [-1.9711834   1.25098295  0.04979562]\n",
      "Loss in iteration 9470: 0.4223999640195163\n",
      "Theta: [-1.9712495   1.2510302   0.04979369]\n",
      "Loss in iteration 9471: 0.42239849653895783\n",
      "Theta: [-1.9713156   1.25107744  0.04979177]\n",
      "Loss in iteration 9472: 0.42239702948900176\n",
      "Theta: [-1.97138169  1.25112467  0.04978984]\n",
      "Loss in iteration 9473: 0.4223955628695002\n",
      "Theta: [-1.97144776  1.2511719   0.04978791]\n",
      "Loss in iteration 9474: 0.4223940966803059\n",
      "Theta: [-1.97151383  1.25121912  0.04978599]\n",
      "Loss in iteration 9475: 0.42239263092127116\n",
      "Theta: [-1.97157989  1.25126633  0.04978406]\n",
      "Loss in iteration 9476: 0.4223911655922487\n",
      "Theta: [-1.97164594  1.25131354  0.04978214]\n",
      "Loss in iteration 9477: 0.42238970069309106\n",
      "Theta: [-1.97171197  1.25136074  0.04978021]\n",
      "Loss in iteration 9478: 0.4223882362236509\n",
      "Theta: [-1.971778    1.25140793  0.04977828]\n",
      "Loss in iteration 9479: 0.42238677218378107\n",
      "Theta: [-1.97184402  1.25145512  0.04977636]\n",
      "Loss in iteration 9480: 0.42238530857333445\n",
      "Theta: [-1.97191003  1.2515023   0.04977443]\n",
      "Loss in iteration 9481: 0.42238384539216367\n",
      "Theta: [-1.97197603  1.25154947  0.04977251]\n",
      "Loss in iteration 9482: 0.42238238264012196\n",
      "Theta: [-1.97204201  1.25159664  0.04977058]\n",
      "Loss in iteration 9483: 0.42238092031706204\n",
      "Theta: [-1.97210799  1.2516438   0.04976866]\n",
      "Loss in iteration 9484: 0.4223794584228369\n",
      "Theta: [-1.97217396  1.25169095  0.04976674]\n",
      "Loss in iteration 9485: 0.42237799695730016\n",
      "Theta: [-1.97223992  1.2517381   0.04976481]\n",
      "Loss in iteration 9486: 0.42237653592030466\n",
      "Theta: [-1.97230587  1.25178524  0.04976289]\n",
      "Loss in iteration 9487: 0.42237507531170343\n",
      "Theta: [-1.97237181  1.25183237  0.04976097]\n",
      "Loss in iteration 9488: 0.4223736151313501\n",
      "Theta: [-1.97243774  1.2518795   0.04975904]\n",
      "Loss in iteration 9489: 0.42237215537909784\n",
      "Theta: [-1.97250366  1.25192662  0.04975712]\n",
      "Loss in iteration 9490: 0.4223706960548001\n",
      "Theta: [-1.97256957  1.25197373  0.0497552 ]\n",
      "Loss in iteration 9491: 0.4223692371583104\n",
      "Theta: [-1.97263547  1.25202084  0.04975327]\n",
      "Loss in iteration 9492: 0.4223677786894821\n",
      "Theta: [-1.97270136  1.25206794  0.04975135]\n",
      "Loss in iteration 9493: 0.42236632064816904\n",
      "Theta: [-1.97276724  1.25211503  0.04974943]\n",
      "Loss in iteration 9494: 0.42236486303422466\n",
      "Theta: [-1.97283311  1.25216212  0.04974751]\n",
      "Loss in iteration 9495: 0.4223634058475028\n",
      "Theta: [-1.97289897  1.2522092   0.04974559]\n",
      "Loss in iteration 9496: 0.4223619490878572\n",
      "Theta: [-1.97296482  1.25225628  0.04974366]\n",
      "Loss in iteration 9497: 0.42236049275514165\n",
      "Theta: [-1.97303066  1.25230334  0.04974174]\n",
      "Loss in iteration 9498: 0.42235903684921\n",
      "Theta: [-1.97309649  1.2523504   0.04973982]\n",
      "Loss in iteration 9499: 0.4223575813699162\n",
      "Theta: [-1.97316231  1.25239746  0.0497379 ]\n",
      "Loss in iteration 9500: 0.4223561263171144\n",
      "Theta: [-1.97322812  1.2524445   0.04973598]\n",
      "Loss in iteration 9501: 0.42235467169065843\n",
      "Theta: [-1.97329392  1.25249154  0.04973406]\n",
      "Loss in iteration 9502: 0.42235321749040267\n",
      "Theta: [-1.97335971  1.25253858  0.04973214]\n",
      "Loss in iteration 9503: 0.422351763716201\n",
      "Theta: [-1.9734255   1.2525856   0.04973022]\n",
      "Loss in iteration 9504: 0.42235031036790815\n",
      "Theta: [-1.97349127  1.25263262  0.0497283 ]\n",
      "Loss in iteration 9505: 0.42234885744537787\n",
      "Theta: [-1.97355703  1.25267964  0.04972638]\n",
      "Loss in iteration 9506: 0.4223474049484648\n",
      "Theta: [-1.97362278  1.25272665  0.04972446]\n",
      "Loss in iteration 9507: 0.4223459528770233\n",
      "Theta: [-1.97368852  1.25277365  0.04972254]\n",
      "Loss in iteration 9508: 0.42234450123090794\n",
      "Theta: [-1.97375426  1.25282064  0.04972063]\n",
      "Loss in iteration 9509: 0.42234305000997296\n",
      "Theta: [-1.97381998  1.25286763  0.04971871]\n",
      "Loss in iteration 9510: 0.4223415992140735\n",
      "Theta: [-1.97388569  1.25291461  0.04971679]\n",
      "Loss in iteration 9511: 0.4223401488430636\n",
      "Theta: [-1.9739514   1.25296158  0.04971487]\n",
      "Loss in iteration 9512: 0.42233869889679837\n",
      "Theta: [-1.97401709  1.25300855  0.04971295]\n",
      "Loss in iteration 9513: 0.4223372493751324\n",
      "Theta: [-1.97408277  1.25305551  0.04971104]\n",
      "Loss in iteration 9514: 0.42233580027792067\n",
      "Theta: [-1.97414845  1.25310246  0.04970912]\n",
      "Loss in iteration 9515: 0.42233435160501803\n",
      "Theta: [-1.97421411  1.25314941  0.0497072 ]\n",
      "Loss in iteration 9516: 0.42233290335627927\n",
      "Theta: [-1.97427977  1.25319635  0.04970529]\n",
      "Loss in iteration 9517: 0.42233145553155965\n",
      "Theta: [-1.97434541  1.25324329  0.04970337]\n",
      "Loss in iteration 9518: 0.422330008130714\n",
      "Theta: [-1.97441104  1.25329021  0.04970145]\n",
      "Loss in iteration 9519: 0.42232856115359746\n",
      "Theta: [-1.97447667  1.25333713  0.04969954]\n",
      "Loss in iteration 9520: 0.42232711460006533\n",
      "Theta: [-1.97454228  1.25338405  0.04969762]\n",
      "Loss in iteration 9521: 0.422325668469973\n",
      "Theta: [-1.97460789  1.25343096  0.0496957 ]\n",
      "Loss in iteration 9522: 0.42232422276317544\n",
      "Theta: [-1.97467348  1.25347786  0.04969379]\n",
      "Loss in iteration 9523: 0.42232277747952834\n",
      "Theta: [-1.97473907  1.25352475  0.04969187]\n",
      "Loss in iteration 9524: 0.42232133261888677\n",
      "Theta: [-1.97480465  1.25357164  0.04968996]\n",
      "Loss in iteration 9525: 0.4223198881811063\n",
      "Theta: [-1.97487021  1.25361852  0.04968804]\n",
      "Loss in iteration 9526: 0.4223184441660427\n",
      "Theta: [-1.97493577  1.2536654   0.04968613]\n",
      "Loss in iteration 9527: 0.4223170005735513\n",
      "Theta: [-1.97500132  1.25371226  0.04968422]\n",
      "Loss in iteration 9528: 0.4223155574034881\n",
      "Theta: [-1.97506685  1.25375913  0.0496823 ]\n",
      "Loss in iteration 9529: 0.42231411465570823\n",
      "Theta: [-1.97513238  1.25380598  0.04968039]\n",
      "Loss in iteration 9530: 0.422312672330068\n",
      "Theta: [-1.9751979   1.25385283  0.04967847]\n",
      "Loss in iteration 9531: 0.42231123042642293\n",
      "Theta: [-1.9752634   1.25389967  0.04967656]\n",
      "Loss in iteration 9532: 0.42230978894462917\n",
      "Theta: [-1.9753289   1.25394651  0.04967465]\n",
      "Loss in iteration 9533: 0.4223083478845422\n",
      "Theta: [-1.97539439  1.25399333  0.04967273]\n",
      "Loss in iteration 9534: 0.42230690724601866\n",
      "Theta: [-1.97545987  1.25404016  0.04967082]\n",
      "Loss in iteration 9535: 0.4223054670289141\n",
      "Theta: [-1.97552534  1.25408697  0.04966891]\n",
      "Loss in iteration 9536: 0.4223040272330849\n",
      "Theta: [-1.9755908   1.25413378  0.049667  ]\n",
      "Loss in iteration 9537: 0.4223025878583871\n",
      "Theta: [-1.97565624  1.25418058  0.04966508]\n",
      "Loss in iteration 9538: 0.42230114890467696\n",
      "Theta: [-1.97572168  1.25422738  0.04966317]\n",
      "Loss in iteration 9539: 0.4222997103718108\n",
      "Theta: [-1.97578711  1.25427417  0.04966126]\n",
      "Loss in iteration 9540: 0.422298272259645\n",
      "Theta: [-1.97585253  1.25432095  0.04965935]\n",
      "Loss in iteration 9541: 0.422296834568036\n",
      "Theta: [-1.97591794  1.25436772  0.04965744]\n",
      "Loss in iteration 9542: 0.42229539729684007\n",
      "Theta: [-1.97598334  1.25441449  0.04965553]\n",
      "Loss in iteration 9543: 0.4222939604459139\n",
      "Theta: [-1.97604873  1.25446126  0.04965362]\n",
      "Loss in iteration 9544: 0.4222925240151141\n",
      "Theta: [-1.97611412  1.25450801  0.04965171]\n",
      "Loss in iteration 9545: 0.42229108800429743\n",
      "Theta: [-1.97617949  1.25455476  0.0496498 ]\n",
      "Loss in iteration 9546: 0.42228965241332017\n",
      "Theta: [-1.97624485  1.2546015   0.04964789]\n",
      "Loss in iteration 9547: 0.4222882172420394\n",
      "Theta: [-1.9763102   1.25464824  0.04964598]\n",
      "Loss in iteration 9548: 0.42228678249031193\n",
      "Theta: [-1.97637554  1.25469497  0.04964407]\n",
      "Loss in iteration 9549: 0.4222853481579944\n",
      "Theta: [-1.97644087  1.25474169  0.04964216]\n",
      "Loss in iteration 9550: 0.4222839142449441\n",
      "Theta: [-1.9765062   1.25478841  0.04964025]\n",
      "Loss in iteration 9551: 0.4222824807510176\n",
      "Theta: [-1.97657151  1.25483512  0.04963834]\n",
      "Loss in iteration 9552: 0.42228104767607244\n",
      "Theta: [-1.97663681  1.25488182  0.04963643]\n",
      "Loss in iteration 9553: 0.4222796150199653\n",
      "Theta: [-1.9767021   1.25492852  0.04963452]\n",
      "Loss in iteration 9554: 0.42227818278255347\n",
      "Theta: [-1.97676739  1.25497521  0.04963261]\n",
      "Loss in iteration 9555: 0.4222767509636944\n",
      "Theta: [-1.97683266  1.25502189  0.04963071]\n",
      "Loss in iteration 9556: 0.4222753195632451\n",
      "Theta: [-1.97689793  1.25506857  0.0496288 ]\n",
      "Loss in iteration 9557: 0.42227388858106296\n",
      "Theta: [-1.97696318  1.25511524  0.04962689]\n",
      "Loss in iteration 9558: 0.42227245801700525\n",
      "Theta: [-1.97702842  1.2551619   0.04962498]\n",
      "Loss in iteration 9559: 0.4222710278709297\n",
      "Theta: [-1.97709366  1.25520856  0.04962308]\n",
      "Loss in iteration 9560: 0.4222695981426935\n",
      "Theta: [-1.97715888  1.25525521  0.04962117]\n",
      "Loss in iteration 9561: 0.4222681688321547\n",
      "Theta: [-1.9772241   1.25530186  0.04961926]\n",
      "Loss in iteration 9562: 0.42226673993917047\n",
      "Theta: [-1.97728931  1.25534849  0.04961736]\n",
      "Loss in iteration 9563: 0.4222653114635986\n",
      "Theta: [-1.9773545   1.25539512  0.04961545]\n",
      "Loss in iteration 9564: 0.42226388340529686\n",
      "Theta: [-1.97741969  1.25544175  0.04961355]\n",
      "Loss in iteration 9565: 0.4222624557641231\n",
      "Theta: [-1.97748487  1.25548837  0.04961164]\n",
      "Loss in iteration 9566: 0.4222610285399352\n",
      "Theta: [-1.97755003  1.25553498  0.04960973]\n",
      "Loss in iteration 9567: 0.4222596017325909\n",
      "Theta: [-1.97761519  1.25558158  0.04960783]\n",
      "Loss in iteration 9568: 0.4222581753419483\n",
      "Theta: [-1.97768034  1.25562818  0.04960592]\n",
      "Loss in iteration 9569: 0.42225674936786534\n",
      "Theta: [-1.97774548  1.25567477  0.04960402]\n",
      "Loss in iteration 9570: 0.42225532381020014\n",
      "Theta: [-1.9778106   1.25572136  0.04960211]\n",
      "Loss in iteration 9571: 0.4222538986688108\n",
      "Theta: [-1.97787572  1.25576793  0.04960021]\n",
      "Loss in iteration 9572: 0.42225247394355586\n",
      "Theta: [-1.97794083  1.25581451  0.04959831]\n",
      "Loss in iteration 9573: 0.42225104963429316\n",
      "Theta: [-1.97800593  1.25586107  0.0495964 ]\n",
      "Loss in iteration 9574: 0.422249625740881\n",
      "Theta: [-1.97807102  1.25590763  0.0495945 ]\n",
      "Loss in iteration 9575: 0.42224820226317805\n",
      "Theta: [-1.9781361   1.25595418  0.04959259]\n",
      "Loss in iteration 9576: 0.42224677920104253\n",
      "Theta: [-1.97820117  1.25600073  0.04959069]\n",
      "Loss in iteration 9577: 0.422245356554333\n",
      "Theta: [-1.97826623  1.25604727  0.04958879]\n",
      "Loss in iteration 9578: 0.4222439343229078\n",
      "Theta: [-1.97833128  1.2560938   0.04958689]\n",
      "Loss in iteration 9579: 0.4222425125066258\n",
      "Theta: [-1.97839632  1.25614033  0.04958498]\n",
      "Loss in iteration 9580: 0.42224109110534563\n",
      "Theta: [-1.97846135  1.25618685  0.04958308]\n",
      "Loss in iteration 9581: 0.4222396701189259\n",
      "Theta: [-1.97852638  1.25623336  0.04958118]\n",
      "Loss in iteration 9582: 0.4222382495472254\n",
      "Theta: [-1.97859139  1.25627986  0.04957928]\n",
      "Loss in iteration 9583: 0.42223682939010293\n",
      "Theta: [-1.97865639  1.25632636  0.04957738]\n",
      "Loss in iteration 9584: 0.4222354096474173\n",
      "Theta: [-1.97872138  1.25637286  0.04957547]\n",
      "Loss in iteration 9585: 0.42223399031902775\n",
      "Theta: [-1.97878637  1.25641934  0.04957357]\n",
      "Loss in iteration 9586: 0.4222325714047929\n",
      "Theta: [-1.97885134  1.25646582  0.04957167]\n",
      "Loss in iteration 9587: 0.4222311529045719\n",
      "Theta: [-1.9789163   1.2565123   0.04956977]\n",
      "Loss in iteration 9588: 0.4222297348182241\n",
      "Theta: [-1.97898126  1.25655877  0.04956787]\n",
      "Loss in iteration 9589: 0.4222283171456087\n",
      "Theta: [-1.9790462   1.25660523  0.04956597]\n",
      "Loss in iteration 9590: 0.4222268998865843\n",
      "Theta: [-1.97911114  1.25665168  0.04956407]\n",
      "Loss in iteration 9591: 0.422225483041011\n",
      "Theta: [-1.97917606  1.25669813  0.04956217]\n",
      "Loss in iteration 9592: 0.42222406660874756\n",
      "Theta: [-1.97924098  1.25674457  0.04956027]\n",
      "Loss in iteration 9593: 0.4222226505896536\n",
      "Theta: [-1.97930588  1.256791    0.04955837]\n",
      "Loss in iteration 9594: 0.42222123498358854\n",
      "Theta: [-1.97937078  1.25683743  0.04955647]\n",
      "Loss in iteration 9595: 0.42221981979041173\n",
      "Theta: [-1.97943567  1.25688385  0.04955457]\n",
      "Loss in iteration 9596: 0.42221840500998303\n",
      "Theta: [-1.97950054  1.25693027  0.04955268]\n",
      "Loss in iteration 9597: 0.42221699064216184\n",
      "Theta: [-1.97956541  1.25697668  0.04955078]\n",
      "Loss in iteration 9598: 0.42221557668680804\n",
      "Theta: [-1.97963027  1.25702308  0.04954888]\n",
      "Loss in iteration 9599: 0.42221416314378096\n",
      "Theta: [-1.97969512  1.25706947  0.04954698]\n",
      "Loss in iteration 9600: 0.42221275001294095\n",
      "Theta: [-1.97975996  1.25711586  0.04954508]\n",
      "Loss in iteration 9601: 0.42221133729414745\n",
      "Theta: [-1.97982478  1.25716224  0.04954318]\n",
      "Loss in iteration 9602: 0.4222099249872604\n",
      "Theta: [-1.9798896   1.25720862  0.04954129]\n",
      "Loss in iteration 9603: 0.42220851309213975\n",
      "Theta: [-1.97995441  1.25725499  0.04953939]\n",
      "Loss in iteration 9604: 0.4222071016086458\n",
      "Theta: [-1.98001921  1.25730135  0.04953749]\n",
      "Loss in iteration 9605: 0.4222056905366386\n",
      "Theta: [-1.980084    1.25734771  0.0495356 ]\n",
      "Loss in iteration 9606: 0.42220427987597775\n",
      "Theta: [-1.98014878  1.25739406  0.0495337 ]\n",
      "Loss in iteration 9607: 0.4222028696265239\n",
      "Theta: [-1.98021356  1.2574404   0.0495318 ]\n",
      "Loss in iteration 9608: 0.42220145978813717\n",
      "Theta: [-1.98027832  1.25748674  0.04952991]\n",
      "Loss in iteration 9609: 0.4222000503606778\n",
      "Theta: [-1.98034307  1.25753307  0.04952801]\n",
      "Loss in iteration 9610: 0.4221986413440064\n",
      "Theta: [-1.98040781  1.25757939  0.04952612]\n",
      "Loss in iteration 9611: 0.42219723273798304\n",
      "Theta: [-1.98047254  1.25762571  0.04952422]\n",
      "Loss in iteration 9612: 0.42219582454246846\n",
      "Theta: [-1.98053727  1.25767202  0.04952233]\n",
      "Loss in iteration 9613: 0.42219441675732283\n",
      "Theta: [-1.98060198  1.25771832  0.04952043]\n",
      "Loss in iteration 9614: 0.42219300938240706\n",
      "Theta: [-1.98066668  1.25776462  0.04951854]\n",
      "Loss in iteration 9615: 0.42219160241758175\n",
      "Theta: [-1.98073138  1.25781091  0.04951664]\n",
      "Loss in iteration 9616: 0.42219019586270745\n",
      "Theta: [-1.98079606  1.2578572   0.04951475]\n",
      "Loss in iteration 9617: 0.42218878971764495\n",
      "Theta: [-1.98086074  1.25790347  0.04951285]\n",
      "Loss in iteration 9618: 0.422187383982255\n",
      "Theta: [-1.9809254   1.25794975  0.04951096]\n",
      "Loss in iteration 9619: 0.42218597865639873\n",
      "Theta: [-1.98099006  1.25799601  0.04950907]\n",
      "Loss in iteration 9620: 0.4221845737399368\n",
      "Theta: [-1.98105471  1.25804227  0.04950717]\n",
      "Loss in iteration 9621: 0.42218316923273025\n",
      "Theta: [-1.98111934  1.25808852  0.04950528]\n",
      "Loss in iteration 9622: 0.42218176513463995\n",
      "Theta: [-1.98118397  1.25813477  0.04950339]\n",
      "Loss in iteration 9623: 0.4221803614455273\n",
      "Theta: [-1.98124859  1.25818101  0.0495015 ]\n",
      "Loss in iteration 9624: 0.4221789581652532\n",
      "Theta: [-1.9813132   1.25822724  0.0494996 ]\n",
      "Loss in iteration 9625: 0.42217755529367873\n",
      "Theta: [-1.98137779  1.25827346  0.04949771]\n",
      "Loss in iteration 9626: 0.4221761528306655\n",
      "Theta: [-1.98144238  1.25831968  0.04949582]\n",
      "Loss in iteration 9627: 0.42217475077607447\n",
      "Theta: [-1.98150696  1.2583659   0.04949393]\n",
      "Loss in iteration 9628: 0.42217334912976734\n",
      "Theta: [-1.98157153  1.2584121   0.04949204]\n",
      "Loss in iteration 9629: 0.4221719478916054\n",
      "Theta: [-1.98163609  1.2584583   0.04949014]\n",
      "Loss in iteration 9630: 0.4221705470614498\n",
      "Theta: [-1.98170064  1.2585045   0.04948825]\n",
      "Loss in iteration 9631: 0.42216914663916244\n",
      "Theta: [-1.98176518  1.25855069  0.04948636]\n",
      "Loss in iteration 9632: 0.4221677466246048\n",
      "Theta: [-1.98182971  1.25859687  0.04948447]\n",
      "Loss in iteration 9633: 0.4221663470176386\n",
      "Theta: [-1.98189424  1.25864304  0.04948258]\n",
      "Loss in iteration 9634: 0.4221649478181254\n",
      "Theta: [-1.98195875  1.25868921  0.04948069]\n",
      "Loss in iteration 9635: 0.4221635490259269\n",
      "Theta: [-1.98202325  1.25873537  0.0494788 ]\n",
      "Loss in iteration 9636: 0.4221621506409053\n",
      "Theta: [-1.98208774  1.25878152  0.04947691]\n",
      "Loss in iteration 9637: 0.42216075266292186\n",
      "Theta: [-1.98215223  1.25882767  0.04947502]\n",
      "Loss in iteration 9638: 0.42215935509183894\n",
      "Theta: [-1.9822167   1.25887381  0.04947313]\n",
      "Loss in iteration 9639: 0.4221579579275183\n",
      "Theta: [-1.98228117  1.25891995  0.04947124]\n",
      "Loss in iteration 9640: 0.42215656116982203\n",
      "Theta: [-1.98234562  1.25896608  0.04946936]\n",
      "Loss in iteration 9641: 0.4221551648186124\n",
      "Theta: [-1.98241007  1.2590122   0.04946747]\n",
      "Loss in iteration 9642: 0.42215376887375133\n",
      "Theta: [-1.9824745   1.25905832  0.04946558]\n",
      "Loss in iteration 9643: 0.4221523733351009\n",
      "Theta: [-1.98253893  1.25910443  0.04946369]\n",
      "Loss in iteration 9644: 0.42215097820252384\n",
      "Theta: [-1.98260335  1.25915053  0.0494618 ]\n",
      "Loss in iteration 9645: 0.4221495834758818\n",
      "Theta: [-1.98266775  1.25919662  0.04945992]\n",
      "Loss in iteration 9646: 0.4221481891550377\n",
      "Theta: [-1.98273215  1.25924271  0.04945803]\n",
      "Loss in iteration 9647: 0.4221467952398536\n",
      "Theta: [-1.98279654  1.2592888   0.04945614]\n",
      "Loss in iteration 9648: 0.42214540173019216\n",
      "Theta: [-1.98286092  1.25933488  0.04945425]\n",
      "Loss in iteration 9649: 0.42214400862591567\n",
      "Theta: [-1.98292529  1.25938095  0.04945237]\n",
      "Loss in iteration 9650: 0.422142615926887\n",
      "Theta: [-1.98298964  1.25942701  0.04945048]\n",
      "Loss in iteration 9651: 0.42214122363296885\n",
      "Theta: [-1.98305399  1.25947307  0.04944859]\n",
      "Loss in iteration 9652: 0.42213983174402353\n",
      "Theta: [-1.98311834  1.25951912  0.04944671]\n",
      "Loss in iteration 9653: 0.422138440259914\n",
      "Theta: [-1.98318267  1.25956516  0.04944482]\n",
      "Loss in iteration 9654: 0.4221370491805031\n",
      "Theta: [-1.98324699  1.2596112   0.04944294]\n",
      "Loss in iteration 9655: 0.4221356585056536\n",
      "Theta: [-1.9833113   1.25965723  0.04944105]\n",
      "Loss in iteration 9656: 0.4221342682352286\n",
      "Theta: [-1.9833756   1.25970326  0.04943917]\n",
      "Loss in iteration 9657: 0.42213287836909075\n",
      "Theta: [-1.98343989  1.25974928  0.04943728]\n",
      "Loss in iteration 9658: 0.4221314889071032\n",
      "Theta: [-1.98350418  1.25979529  0.0494354 ]\n",
      "Loss in iteration 9659: 0.4221300998491291\n",
      "Theta: [-1.98356845  1.2598413   0.04943351]\n",
      "Loss in iteration 9660: 0.42212871119503165\n",
      "Theta: [-1.98363272  1.2598873   0.04943163]\n",
      "Loss in iteration 9661: 0.4221273229446737\n",
      "Theta: [-1.98369697  1.25993329  0.04942974]\n",
      "Loss in iteration 9662: 0.42212593509791885\n",
      "Theta: [-1.98376122  1.25997928  0.04942786]\n",
      "Loss in iteration 9663: 0.4221245476546303\n",
      "Theta: [-1.98382545  1.26002526  0.04942598]\n",
      "Loss in iteration 9664: 0.42212316061467126\n",
      "Theta: [-1.98388968  1.26007123  0.04942409]\n",
      "Loss in iteration 9665: 0.42212177397790535\n",
      "Theta: [-1.98395389  1.2601172   0.04942221]\n",
      "Loss in iteration 9666: 0.4221203877441959\n",
      "Theta: [-1.9840181   1.26016316  0.04942033]\n",
      "Loss in iteration 9667: 0.42211900191340646\n",
      "Theta: [-1.9840823   1.26020911  0.04941844]\n",
      "Loss in iteration 9668: 0.4221176164854004\n",
      "Theta: [-1.98414649  1.26025506  0.04941656]\n",
      "Loss in iteration 9669: 0.4221162314600416\n",
      "Theta: [-1.98421067  1.260301    0.04941468]\n",
      "Loss in iteration 9670: 0.42211484683719386\n",
      "Theta: [-1.98427483  1.26034694  0.0494128 ]\n",
      "Loss in iteration 9671: 0.4221134626167205\n",
      "Theta: [-1.98433899  1.26039287  0.04941092]\n",
      "Loss in iteration 9672: 0.4221120787984855\n",
      "Theta: [-1.98440314  1.26043879  0.04940903]\n",
      "Loss in iteration 9673: 0.42211069538235285\n",
      "Theta: [-1.98446729  1.2604847   0.04940715]\n",
      "Loss in iteration 9674: 0.4221093123681862\n",
      "Theta: [-1.98453142  1.26053061  0.04940527]\n",
      "Loss in iteration 9675: 0.4221079297558499\n",
      "Theta: [-1.98459554  1.26057652  0.04940339]\n",
      "Loss in iteration 9676: 0.4221065475452073\n",
      "Theta: [-1.98465965  1.26062241  0.04940151]\n",
      "Loss in iteration 9677: 0.4221051657361231\n",
      "Theta: [-1.98472375  1.2606683   0.04939963]\n",
      "Loss in iteration 9678: 0.42210378432846096\n",
      "Theta: [-1.98478785  1.26071419  0.04939775]\n",
      "Loss in iteration 9679: 0.42210240332208543\n",
      "Theta: [-1.98485193  1.26076006  0.04939587]\n",
      "Loss in iteration 9680: 0.42210102271686056\n",
      "Theta: [-1.984916    1.26080593  0.04939399]\n",
      "Loss in iteration 9681: 0.4220996425126505\n",
      "Theta: [-1.98498007  1.2608518   0.04939211]\n",
      "Loss in iteration 9682: 0.4220982627093196\n",
      "Theta: [-1.98504412  1.26089766  0.04939023]\n",
      "Loss in iteration 9683: 0.4220968833067325\n",
      "Theta: [-1.98510817  1.26094351  0.04938835]\n",
      "Loss in iteration 9684: 0.4220955043047534\n",
      "Theta: [-1.98517221  1.26098935  0.04938647]\n",
      "Loss in iteration 9685: 0.422094125703247\n",
      "Theta: [-1.98523623  1.26103519  0.04938459]\n",
      "Loss in iteration 9686: 0.42209274750207754\n",
      "Theta: [-1.98530025  1.26108102  0.04938271]\n",
      "Loss in iteration 9687: 0.42209136970110994\n",
      "Theta: [-1.98536426  1.26112685  0.04938084]\n",
      "Loss in iteration 9688: 0.4220899923002089\n",
      "Theta: [-1.98542826  1.26117267  0.04937896]\n",
      "Loss in iteration 9689: 0.42208861529923863\n",
      "Theta: [-1.98549225  1.26121848  0.04937708]\n",
      "Loss in iteration 9690: 0.42208723869806447\n",
      "Theta: [-1.98555623  1.26126429  0.0493752 ]\n",
      "Loss in iteration 9691: 0.4220858624965507\n",
      "Theta: [-1.9856202   1.26131009  0.04937333]\n",
      "Loss in iteration 9692: 0.4220844866945627\n",
      "Theta: [-1.98568416  1.26135588  0.04937145]\n",
      "Loss in iteration 9693: 0.4220831112919653\n",
      "Theta: [-1.98574811  1.26140167  0.04936957]\n",
      "Loss in iteration 9694: 0.4220817362886233\n",
      "Theta: [-1.98581205  1.26144745  0.04936769]\n",
      "Loss in iteration 9695: 0.42208036168440166\n",
      "Theta: [-1.98587598  1.26149322  0.04936582]\n",
      "Loss in iteration 9696: 0.4220789874791658\n",
      "Theta: [-1.98593991  1.26153899  0.04936394]\n",
      "Loss in iteration 9697: 0.4220776136727805\n",
      "Theta: [-1.98600382  1.26158475  0.04936207]\n",
      "Loss in iteration 9698: 0.42207624026511126\n",
      "Theta: [-1.98606772  1.26163051  0.04936019]\n",
      "Loss in iteration 9699: 0.4220748672560232\n",
      "Theta: [-1.98613162  1.26167626  0.04935831]\n",
      "Loss in iteration 9700: 0.4220734946453817\n",
      "Theta: [-1.9861955   1.261722    0.04935644]\n",
      "Loss in iteration 9701: 0.42207212243305187\n",
      "Theta: [-1.98625938  1.26176774  0.04935456]\n",
      "Loss in iteration 9702: 0.42207075061889954\n",
      "Theta: [-1.98632325  1.26181347  0.04935269]\n",
      "Loss in iteration 9703: 0.42206937920279\n",
      "Theta: [-1.9863871   1.26185919  0.04935081]\n",
      "Loss in iteration 9704: 0.42206800818458845\n",
      "Theta: [-1.98645095  1.26190491  0.04934894]\n",
      "Loss in iteration 9705: 0.42206663756416085\n",
      "Theta: [-1.98651479  1.26195062  0.04934707]\n",
      "Loss in iteration 9706: 0.42206526734137273\n",
      "Theta: [-1.98657862  1.26199632  0.04934519]\n",
      "Loss in iteration 9707: 0.4220638975160897\n",
      "Theta: [-1.98664244  1.26204202  0.04934332]\n",
      "Loss in iteration 9708: 0.4220625280881777\n",
      "Theta: [-1.98670624  1.26208771  0.04934144]\n",
      "Loss in iteration 9709: 0.42206115905750224\n",
      "Theta: [-1.98677005  1.26213339  0.04933957]\n",
      "Loss in iteration 9710: 0.4220597904239293\n",
      "Theta: [-1.98683384  1.26217907  0.0493377 ]\n",
      "Loss in iteration 9711: 0.42205842218732487\n",
      "Theta: [-1.98689762  1.26222474  0.04933583]\n",
      "Loss in iteration 9712: 0.42205705434755475\n",
      "Theta: [-1.98696139  1.26227041  0.04933395]\n",
      "Loss in iteration 9713: 0.4220556869044849\n",
      "Theta: [-1.98702515  1.26231607  0.04933208]\n",
      "Loss in iteration 9714: 0.4220543198579817\n",
      "Theta: [-1.98708891  1.26236172  0.04933021]\n",
      "Loss in iteration 9715: 0.4220529532079108\n",
      "Theta: [-1.98715265  1.26240737  0.04932834]\n",
      "Loss in iteration 9716: 0.4220515869541387\n",
      "Theta: [-1.98721638  1.26245301  0.04932646]\n",
      "Loss in iteration 9717: 0.42205022109653156\n",
      "Theta: [-1.98728011  1.26249864  0.04932459]\n",
      "Loss in iteration 9718: 0.42204885563495564\n",
      "Theta: [-1.98734382  1.26254427  0.04932272]\n",
      "Loss in iteration 9719: 0.4220474905692771\n",
      "Theta: [-1.98740753  1.26258989  0.04932085]\n",
      "Loss in iteration 9720: 0.42204612589936263\n",
      "Theta: [-1.98747123  1.2626355   0.04931898]\n",
      "Loss in iteration 9721: 0.4220447616250783\n",
      "Theta: [-1.98753491  1.26268111  0.04931711]\n",
      "Loss in iteration 9722: 0.42204339774629107\n",
      "Theta: [-1.98759859  1.26272671  0.04931524]\n",
      "Loss in iteration 9723: 0.4220420342628669\n",
      "Theta: [-1.98766226  1.26277231  0.04931337]\n",
      "Loss in iteration 9724: 0.42204067117467275\n",
      "Theta: [-1.98772592  1.2628179   0.0493115 ]\n",
      "Loss in iteration 9725: 0.42203930848157517\n",
      "Theta: [-1.98778957  1.26286348  0.04930963]\n",
      "Loss in iteration 9726: 0.422037946183441\n",
      "Theta: [-1.98785321  1.26290906  0.04930776]\n",
      "Loss in iteration 9727: 0.42203658428013674\n",
      "Theta: [-1.98791684  1.26295463  0.04930589]\n",
      "Loss in iteration 9728: 0.42203522277152933\n",
      "Theta: [-1.98798046  1.26300019  0.04930402]\n",
      "Loss in iteration 9729: 0.42203386165748563\n",
      "Theta: [-1.98804407  1.26304575  0.04930215]\n",
      "Loss in iteration 9730: 0.42203250093787253\n",
      "Theta: [-1.98810768  1.2630913   0.04930028]\n",
      "Loss in iteration 9731: 0.422031140612557\n",
      "Theta: [-1.98817127  1.26313684  0.04929841]\n",
      "Loss in iteration 9732: 0.422029780681406\n",
      "Theta: [-1.98823486  1.26318238  0.04929655]\n",
      "Loss in iteration 9733: 0.4220284211442868\n",
      "Theta: [-1.98829843  1.26322791  0.04929468]\n",
      "Loss in iteration 9734: 0.4220270620010663\n",
      "Theta: [-1.988362    1.26327344  0.04929281]\n",
      "Loss in iteration 9735: 0.42202570325161176\n",
      "Theta: [-1.98842555  1.26331896  0.04929094]\n",
      "Loss in iteration 9736: 0.4220243448957905\n",
      "Theta: [-1.9884891   1.26336447  0.04928908]\n",
      "Loss in iteration 9737: 0.4220229869334696\n",
      "Theta: [-1.98855264  1.26340998  0.04928721]\n",
      "Loss in iteration 9738: 0.4220216293645166\n",
      "Theta: [-1.98861616  1.26345548  0.04928534]\n",
      "Loss in iteration 9739: 0.4220202721887987\n",
      "Theta: [-1.98867968  1.26350097  0.04928347]\n",
      "Loss in iteration 9740: 0.42201891540618336\n",
      "Theta: [-1.98874319  1.26354646  0.04928161]\n",
      "Loss in iteration 9741: 0.4220175590165381\n",
      "Theta: [-1.98880669  1.26359194  0.04927974]\n",
      "Loss in iteration 9742: 0.42201620301973064\n",
      "Theta: [-1.98887018  1.26363741  0.04927788]\n",
      "Loss in iteration 9743: 0.4220148474156285\n",
      "Theta: [-1.98893366  1.26368288  0.04927601]\n",
      "Loss in iteration 9744: 0.42201349220409917\n",
      "Theta: [-1.98899713  1.26372834  0.04927414]\n",
      "Loss in iteration 9745: 0.4220121373850106\n",
      "Theta: [-1.9890606   1.2637738   0.04927228]\n",
      "Loss in iteration 9746: 0.4220107829582303\n",
      "Theta: [-1.98912405  1.26381924  0.04927041]\n",
      "Loss in iteration 9747: 0.42200942892362614\n",
      "Theta: [-1.98918749  1.26386469  0.04926855]\n",
      "Loss in iteration 9748: 0.4220080752810662\n",
      "Theta: [-1.98925093  1.26391012  0.04926668]\n",
      "Loss in iteration 9749: 0.4220067220304181\n",
      "Theta: [-1.98931435  1.26395555  0.04926482]\n",
      "Loss in iteration 9750: 0.42200536917154985\n",
      "Theta: [-1.98937777  1.26400098  0.04926296]\n",
      "Loss in iteration 9751: 0.42200401670432974\n",
      "Theta: [-1.98944117  1.26404639  0.04926109]\n",
      "Loss in iteration 9752: 0.42200266462862557\n",
      "Theta: [-1.98950457  1.2640918   0.04925923]\n",
      "Loss in iteration 9753: 0.42200131294430565\n",
      "Theta: [-1.98956796  1.26413721  0.04925736]\n",
      "Loss in iteration 9754: 0.421999961651238\n",
      "Theta: [-1.98963134  1.26418261  0.0492555 ]\n",
      "Loss in iteration 9755: 0.4219986107492909\n",
      "Theta: [-1.9896947   1.264228    0.04925364]\n",
      "Loss in iteration 9756: 0.4219972602383326\n",
      "Theta: [-1.98975806  1.26427338  0.04925178]\n",
      "Loss in iteration 9757: 0.42199591011823157\n",
      "Theta: [-1.98982141  1.26431876  0.04924991]\n",
      "Loss in iteration 9758: 0.4219945603888559\n",
      "Theta: [-1.98988476  1.26436414  0.04924805]\n",
      "Loss in iteration 9759: 0.4219932110500746\n",
      "Theta: [-1.98994809  1.2644095   0.04924619]\n",
      "Loss in iteration 9760: 0.42199186210175554\n",
      "Theta: [-1.99001141  1.26445486  0.04924433]\n",
      "Loss in iteration 9761: 0.42199051354376754\n",
      "Theta: [-1.99007472  1.26450022  0.04924246]\n",
      "Loss in iteration 9762: 0.4219891653759793\n",
      "Theta: [-1.99013803  1.26454556  0.0492406 ]\n",
      "Loss in iteration 9763: 0.42198781759825926\n",
      "Theta: [-1.99020132  1.26459091  0.04923874]\n",
      "Loss in iteration 9764: 0.42198647021047625\n",
      "Theta: [-1.9902646   1.26463624  0.04923688]\n",
      "Loss in iteration 9765: 0.42198512321249915\n",
      "Theta: [-1.99032788  1.26468157  0.04923502]\n",
      "Loss in iteration 9766: 0.4219837766041964\n",
      "Theta: [-1.99039115  1.26472689  0.04923316]\n",
      "Loss in iteration 9767: 0.4219824303854371\n",
      "Theta: [-1.9904544   1.26477221  0.0492313 ]\n",
      "Loss in iteration 9768: 0.42198108455609007\n",
      "Theta: [-1.99051765  1.26481752  0.04922944]\n",
      "Loss in iteration 9769: 0.4219797391160244\n",
      "Theta: [-1.99058089  1.26486282  0.04922758]\n",
      "Loss in iteration 9770: 0.42197839406510923\n",
      "Theta: [-1.99064412  1.26490812  0.04922572]\n",
      "Loss in iteration 9771: 0.4219770494032132\n",
      "Theta: [-1.99070734  1.26495341  0.04922386]\n",
      "Loss in iteration 9772: 0.4219757051302056\n",
      "Theta: [-1.99077055  1.26499869  0.049222  ]\n",
      "Loss in iteration 9773: 0.42197436124595566\n",
      "Theta: [-1.99083375  1.26504397  0.04922014]\n",
      "Loss in iteration 9774: 0.4219730177503328\n",
      "Theta: [-1.99089694  1.26508924  0.04921828]\n",
      "Loss in iteration 9775: 0.421971674643206\n",
      "Theta: [-1.99096012  1.2651345   0.04921642]\n",
      "Loss in iteration 9776: 0.4219703319244447\n",
      "Theta: [-1.9910233   1.26517976  0.04921456]\n",
      "Loss in iteration 9777: 0.4219689895939183\n",
      "Theta: [-1.99108646  1.26522502  0.04921271]\n",
      "Loss in iteration 9778: 0.421967647651496\n",
      "Theta: [-1.99114962  1.26527026  0.04921085]\n",
      "Loss in iteration 9779: 0.42196630609704777\n",
      "Theta: [-1.99121276  1.2653155   0.04920899]\n",
      "Loss in iteration 9780: 0.42196496493044267\n",
      "Theta: [-1.9912759   1.26536074  0.04920713]\n",
      "Loss in iteration 9781: 0.42196362415155064\n",
      "Theta: [-1.99133902  1.26540596  0.04920528]\n",
      "Loss in iteration 9782: 0.4219622837602408\n",
      "Theta: [-1.99140214  1.26545118  0.04920342]\n",
      "Loss in iteration 9783: 0.4219609437563834\n",
      "Theta: [-1.99146525  1.2654964   0.04920156]\n",
      "Loss in iteration 9784: 0.4219596041398481\n",
      "Theta: [-1.99152835  1.26554161  0.0491997 ]\n",
      "Loss in iteration 9785: 0.4219582649105045\n",
      "Theta: [-1.99159144  1.26558681  0.04919785]\n",
      "Loss in iteration 9786: 0.42195692606822244\n",
      "Theta: [-1.99165452  1.265632    0.04919599]\n",
      "Loss in iteration 9787: 0.42195558761287194\n",
      "Theta: [-1.99171759  1.26567719  0.04919414]\n",
      "Loss in iteration 9788: 0.42195424954432303\n",
      "Theta: [-1.99178065  1.26572238  0.04919228]\n",
      "Loss in iteration 9789: 0.4219529118624453\n",
      "Theta: [-1.9918437   1.26576755  0.04919042]\n",
      "Loss in iteration 9790: 0.4219515745671093\n",
      "Theta: [-1.99190675  1.26581272  0.04918857]\n",
      "Loss in iteration 9791: 0.4219502376581849\n",
      "Theta: [-1.99196978  1.26585789  0.04918671]\n",
      "Loss in iteration 9792: 0.4219489011355423\n",
      "Theta: [-1.99203281  1.26590305  0.04918486]\n",
      "Loss in iteration 9793: 0.42194756499905156\n",
      "Theta: [-1.99209582  1.2659482   0.049183  ]\n",
      "Loss in iteration 9794: 0.4219462292485831\n",
      "Theta: [-1.99215883  1.26599334  0.04918115]\n",
      "Loss in iteration 9795: 0.42194489388400713\n",
      "Theta: [-1.99222182  1.26603848  0.0491793 ]\n",
      "Loss in iteration 9796: 0.42194355890519425\n",
      "Theta: [-1.99228481  1.26608362  0.04917744]\n",
      "Loss in iteration 9797: 0.42194222431201456\n",
      "Theta: [-1.99234779  1.26612874  0.04917559]\n",
      "Loss in iteration 9798: 0.42194089010433866\n",
      "Theta: [-1.99241076  1.26617386  0.04917373]\n",
      "Loss in iteration 9799: 0.4219395562820371\n",
      "Theta: [-1.99247372  1.26621898  0.04917188]\n",
      "Loss in iteration 9800: 0.4219382228449804\n",
      "Theta: [-1.99253667  1.26626408  0.04917003]\n",
      "Loss in iteration 9801: 0.4219368897930393\n",
      "Theta: [-1.99259961  1.26630918  0.04916817]\n",
      "Loss in iteration 9802: 0.4219355571260842\n",
      "Theta: [-1.99266254  1.26635428  0.04916632]\n",
      "Loss in iteration 9803: 0.4219342248439861\n",
      "Theta: [-1.99272547  1.26639937  0.04916447]\n",
      "Loss in iteration 9804: 0.4219328929466155\n",
      "Theta: [-1.99278838  1.26644445  0.04916262]\n",
      "Loss in iteration 9805: 0.4219315614338436\n",
      "Theta: [-1.99285128  1.26648953  0.04916077]\n",
      "Loss in iteration 9806: 0.4219302303055409\n",
      "Theta: [-1.99291418  1.2665346   0.04915891]\n",
      "Loss in iteration 9807: 0.4219288995615786\n",
      "Theta: [-1.99297706  1.26657966  0.04915706]\n",
      "Loss in iteration 9808: 0.4219275692018274\n",
      "Theta: [-1.99303994  1.26662472  0.04915521]\n",
      "Loss in iteration 9809: 0.4219262392261585\n",
      "Theta: [-1.99310281  1.26666977  0.04915336]\n",
      "Loss in iteration 9810: 0.4219249096344431\n",
      "Theta: [-1.99316567  1.26671481  0.04915151]\n",
      "Loss in iteration 9811: 0.4219235804265522\n",
      "Theta: [-1.99322852  1.26675985  0.04914966]\n",
      "Loss in iteration 9812: 0.4219222516023569\n",
      "Theta: [-1.99329136  1.26680488  0.04914781]\n",
      "Loss in iteration 9813: 0.42192092316172874\n",
      "Theta: [-1.99335419  1.26684991  0.04914596]\n",
      "Loss in iteration 9814: 0.4219195951045386\n",
      "Theta: [-1.99341701  1.26689493  0.04914411]\n",
      "Loss in iteration 9815: 0.4219182674306579\n",
      "Theta: [-1.99347982  1.26693994  0.04914226]\n",
      "Loss in iteration 9816: 0.4219169401399583\n",
      "Theta: [-1.99354262  1.26698495  0.04914041]\n",
      "Loss in iteration 9817: 0.42191561323231097\n",
      "Theta: [-1.99360542  1.26702995  0.04913856]\n",
      "Loss in iteration 9818: 0.4219142867075875\n",
      "Theta: [-1.9936682   1.26707494  0.04913671]\n",
      "Loss in iteration 9819: 0.4219129605656595\n",
      "Theta: [-1.99373097  1.26711993  0.04913486]\n",
      "Loss in iteration 9820: 0.42191163480639843\n",
      "Theta: [-1.99379374  1.26716491  0.04913301]\n",
      "Loss in iteration 9821: 0.42191030942967606\n",
      "Theta: [-1.9938565   1.26720989  0.04913116]\n",
      "Loss in iteration 9822: 0.42190898443536395\n",
      "Theta: [-1.99391925  1.26725486  0.04912931]\n",
      "Loss in iteration 9823: 0.42190765982333384\n",
      "Theta: [-1.99398198  1.26729982  0.04912747]\n",
      "Loss in iteration 9824: 0.42190633559345764\n",
      "Theta: [-1.99404471  1.26734478  0.04912562]\n",
      "Loss in iteration 9825: 0.42190501174560713\n",
      "Theta: [-1.99410743  1.26738973  0.04912377]\n",
      "Loss in iteration 9826: 0.4219036882796543\n",
      "Theta: [-1.99417014  1.26743467  0.04912192]\n",
      "Loss in iteration 9827: 0.42190236519547086\n",
      "Theta: [-1.99423284  1.26747961  0.04912008]\n",
      "Loss in iteration 9828: 0.42190104249292903\n",
      "Theta: [-1.99429554  1.26752454  0.04911823]\n",
      "Loss in iteration 9829: 0.4218997201719008\n",
      "Theta: [-1.99435822  1.26756947  0.04911638]\n",
      "Loss in iteration 9830: 0.42189839823225833\n",
      "Theta: [-1.99442089  1.26761439  0.04911454]\n",
      "Loss in iteration 9831: 0.42189707667387344\n",
      "Theta: [-1.99448356  1.2676593   0.04911269]\n",
      "Loss in iteration 9832: 0.42189575549661873\n",
      "Theta: [-1.99454621  1.26770421  0.04911084]\n",
      "Loss in iteration 9833: 0.42189443470036636\n",
      "Theta: [-1.99460886  1.26774911  0.049109  ]\n",
      "Loss in iteration 9834: 0.4218931142849886\n",
      "Theta: [-1.9946715   1.267794    0.04910715]\n",
      "Loss in iteration 9835: 0.42189179425035767\n",
      "Theta: [-1.99473412  1.26783889  0.04910531]\n",
      "Loss in iteration 9836: 0.42189047459634615\n",
      "Theta: [-1.99479674  1.26788377  0.04910346]\n",
      "Loss in iteration 9837: 0.42188915532282634\n",
      "Theta: [-1.99485935  1.26792865  0.04910162]\n",
      "Loss in iteration 9838: 0.421887836429671\n",
      "Theta: [-1.99492195  1.26797352  0.04909977]\n",
      "Loss in iteration 9839: 0.42188651791675236\n",
      "Theta: [-1.99498454  1.26801838  0.04909793]\n",
      "Loss in iteration 9840: 0.4218851997839432\n",
      "Theta: [-1.99504713  1.26806324  0.04909608]\n",
      "Loss in iteration 9841: 0.4218838820311162\n",
      "Theta: [-1.9951097   1.26810809  0.04909424]\n",
      "Loss in iteration 9842: 0.4218825646581439\n",
      "Theta: [-1.99517226  1.26815293  0.04909239]\n",
      "Loss in iteration 9843: 0.42188124766489926\n",
      "Theta: [-1.99523482  1.26819777  0.04909055]\n",
      "Loss in iteration 9844: 0.42187993105125493\n",
      "Theta: [-1.99529736  1.2682426   0.04908871]\n",
      "Loss in iteration 9845: 0.42187861481708383\n",
      "Theta: [-1.9953599   1.26828743  0.04908686]\n",
      "Loss in iteration 9846: 0.42187729896225895\n",
      "Theta: [-1.99542242  1.26833225  0.04908502]\n",
      "Loss in iteration 9847: 0.42187598348665295\n",
      "Theta: [-1.99548494  1.26837706  0.04908318]\n",
      "Loss in iteration 9848: 0.4218746683901392\n",
      "Theta: [-1.99554745  1.26842186  0.04908134]\n",
      "Loss in iteration 9849: 0.4218733536725907\n",
      "Theta: [-1.99560995  1.26846667  0.04907949]\n",
      "Loss in iteration 9850: 0.4218720393338803\n",
      "Theta: [-1.99567244  1.26851146  0.04907765]\n",
      "Loss in iteration 9851: 0.4218707253738814\n",
      "Theta: [-1.99573492  1.26855625  0.04907581]\n",
      "Loss in iteration 9852: 0.421869411792467\n",
      "Theta: [-1.99579739  1.26860103  0.04907397]\n",
      "Loss in iteration 9853: 0.42186809858951074\n",
      "Theta: [-1.99585986  1.26864581  0.04907213]\n",
      "Loss in iteration 9854: 0.42186678576488545\n",
      "Theta: [-1.99592231  1.26869057  0.04907028]\n",
      "Loss in iteration 9855: 0.42186547331846486\n",
      "Theta: [-1.99598475  1.26873534  0.04906844]\n",
      "Loss in iteration 9856: 0.4218641612501222\n",
      "Theta: [-1.99604719  1.26878009  0.0490666 ]\n",
      "Loss in iteration 9857: 0.4218628495597308\n",
      "Theta: [-1.99610962  1.26882485  0.04906476]\n",
      "Loss in iteration 9858: 0.42186153824716444\n",
      "Theta: [-1.99617203  1.26886959  0.04906292]\n",
      "Loss in iteration 9859: 0.4218602273122966\n",
      "Theta: [-1.99623444  1.26891433  0.04906108]\n",
      "Loss in iteration 9860: 0.4218589167550008\n",
      "Theta: [-1.99629684  1.26895906  0.04905924]\n",
      "Loss in iteration 9861: 0.42185760657515076\n",
      "Theta: [-1.99635923  1.26900379  0.0490574 ]\n",
      "Loss in iteration 9862: 0.4218562967726202\n",
      "Theta: [-1.99642161  1.26904851  0.04905556]\n",
      "Loss in iteration 9863: 0.4218549873472828\n",
      "Theta: [-1.99648398  1.26909322  0.04905372]\n",
      "Loss in iteration 9864: 0.4218536782990124\n",
      "Theta: [-1.99654634  1.26913793  0.04905188]\n",
      "Loss in iteration 9865: 0.4218523696276828\n",
      "Theta: [-1.9966087   1.26918263  0.04905004]\n",
      "Loss in iteration 9866: 0.42185106133316813\n",
      "Theta: [-1.99667104  1.26922732  0.04904821]\n",
      "Loss in iteration 9867: 0.4218497534153423\n",
      "Theta: [-1.99673337  1.26927201  0.04904637]\n",
      "Loss in iteration 9868: 0.4218484458740791\n",
      "Theta: [-1.9967957   1.26931669  0.04904453]\n",
      "Loss in iteration 9869: 0.4218471387092527\n",
      "Theta: [-1.99685802  1.26936137  0.04904269]\n",
      "Loss in iteration 9870: 0.4218458319207371\n",
      "Theta: [-1.99692032  1.26940604  0.04904085]\n",
      "Loss in iteration 9871: 0.42184452550840673\n",
      "Theta: [-1.99698262  1.2694507   0.04903902]\n",
      "Loss in iteration 9872: 0.4218432194721357\n",
      "Theta: [-1.99704491  1.26949536  0.04903718]\n",
      "Loss in iteration 9873: 0.4218419138117979\n",
      "Theta: [-1.99710719  1.26954001  0.04903534]\n",
      "Loss in iteration 9874: 0.42184060852726823\n",
      "Theta: [-1.99716946  1.26958465  0.0490335 ]\n",
      "Loss in iteration 9875: 0.4218393036184206\n",
      "Theta: [-1.99723172  1.26962929  0.04903167]\n",
      "Loss in iteration 9876: 0.42183799908512964\n",
      "Theta: [-1.99729398  1.26967393  0.04902983]\n",
      "Loss in iteration 9877: 0.4218366949272696\n",
      "Theta: [-1.99735622  1.26971855  0.049028  ]\n",
      "Loss in iteration 9878: 0.42183539114471535\n",
      "Theta: [-1.99741845  1.26976317  0.04902616]\n",
      "Loss in iteration 9879: 0.4218340877373411\n",
      "Theta: [-1.99748068  1.26980779  0.04902432]\n",
      "Loss in iteration 9880: 0.42183278470502145\n",
      "Theta: [-1.9975429   1.26985239  0.04902249]\n",
      "Loss in iteration 9881: 0.42183148204763127\n",
      "Theta: [-1.9976051   1.269897    0.04902065]\n",
      "Loss in iteration 9882: 0.421830179765045\n",
      "Theta: [-1.9976673   1.26994159  0.04901882]\n",
      "Loss in iteration 9883: 0.4218288778571377\n",
      "Theta: [-1.99772949  1.26998618  0.04901698]\n",
      "Loss in iteration 9884: 0.42182757632378404\n",
      "Theta: [-1.99779167  1.27003076  0.04901515]\n",
      "Loss in iteration 9885: 0.4218262751648589\n",
      "Theta: [-1.99785384  1.27007534  0.04901331]\n",
      "Loss in iteration 9886: 0.42182497438023686\n",
      "Theta: [-1.997916    1.27011991  0.04901148]\n",
      "Loss in iteration 9887: 0.4218236739697934\n",
      "Theta: [-1.99797815  1.27016447  0.04900964]\n",
      "Loss in iteration 9888: 0.421822373933403\n",
      "Theta: [-1.9980403   1.27020903  0.04900781]\n",
      "Loss in iteration 9889: 0.4218210742709412\n",
      "Theta: [-1.99810243  1.27025358  0.04900598]\n",
      "Loss in iteration 9890: 0.4218197749822828\n",
      "Theta: [-1.99816456  1.27029813  0.04900414]\n",
      "Loss in iteration 9891: 0.42181847606730277\n",
      "Theta: [-1.99822667  1.27034267  0.04900231]\n",
      "Loss in iteration 9892: 0.4218171775258768\n",
      "Theta: [-1.99828878  1.2703872   0.04900048]\n",
      "Loss in iteration 9893: 0.4218158793578798\n",
      "Theta: [-1.99835088  1.27043173  0.04899865]\n",
      "Loss in iteration 9894: 0.4218145815631871\n",
      "Theta: [-1.99841297  1.27047625  0.04899681]\n",
      "Loss in iteration 9895: 0.421813284141674\n",
      "Theta: [-1.99847505  1.27052077  0.04899498]\n",
      "Loss in iteration 9896: 0.4218119870932162\n",
      "Theta: [-1.99853712  1.27056527  0.04899315]\n",
      "Loss in iteration 9897: 0.4218106904176888\n",
      "Theta: [-1.99859918  1.27060978  0.04899132]\n",
      "Loss in iteration 9898: 0.4218093941149674\n",
      "Theta: [-1.99866123  1.27065427  0.04898948]\n",
      "Loss in iteration 9899: 0.4218080981849274\n",
      "Theta: [-1.99872327  1.27069876  0.04898765]\n",
      "Loss in iteration 9900: 0.4218068026274446\n",
      "Theta: [-1.99878531  1.27074325  0.04898582]\n",
      "Loss in iteration 9901: 0.4218055074423947\n",
      "Theta: [-1.99884733  1.27078773  0.04898399]\n",
      "Loss in iteration 9902: 0.42180421262965295\n",
      "Theta: [-1.99890935  1.2708322   0.04898216]\n",
      "Loss in iteration 9903: 0.4218029181890957\n",
      "Theta: [-1.99897136  1.27087666  0.04898033]\n",
      "Loss in iteration 9904: 0.42180162412059813\n",
      "Theta: [-1.99903335  1.27092112  0.0489785 ]\n",
      "Loss in iteration 9905: 0.42180033042403653\n",
      "Theta: [-1.99909534  1.27096557  0.04897667]\n",
      "Loss in iteration 9906: 0.4217990370992867\n",
      "Theta: [-1.99915732  1.27101002  0.04897484]\n",
      "Loss in iteration 9907: 0.4217977441462243\n",
      "Theta: [-1.99921929  1.27105446  0.04897301]\n",
      "Loss in iteration 9908: 0.4217964515647256\n",
      "Theta: [-1.99928126  1.2710989   0.04897118]\n",
      "Loss in iteration 9909: 0.4217951593546665\n",
      "Theta: [-1.99934321  1.27114332  0.04896935]\n",
      "Loss in iteration 9910: 0.4217938675159231\n",
      "Theta: [-1.99940515  1.27118775  0.04896752]\n",
      "Loss in iteration 9911: 0.42179257604837145\n",
      "Theta: [-1.99946709  1.27123216  0.04896569]\n",
      "Loss in iteration 9912: 0.421791284951888\n",
      "Theta: [-1.99952901  1.27127657  0.04896386]\n",
      "Loss in iteration 9913: 0.42178999422634855\n",
      "Theta: [-1.99959093  1.27132098  0.04896204]\n",
      "Loss in iteration 9914: 0.42178870387162964\n",
      "Theta: [-1.99965284  1.27136537  0.04896021]\n",
      "Loss in iteration 9915: 0.4217874138876077\n",
      "Theta: [-1.99971474  1.27140976  0.04895838]\n",
      "Loss in iteration 9916: 0.42178612427415885\n",
      "Theta: [-1.99977663  1.27145415  0.04895655]\n",
      "Loss in iteration 9917: 0.42178483503115954\n",
      "Theta: [-1.99983851  1.27149853  0.04895472]\n",
      "Loss in iteration 9918: 0.4217835461584864\n",
      "Theta: [-1.99990038  1.2715429   0.0489529 ]\n",
      "Loss in iteration 9919: 0.4217822576560159\n",
      "Theta: [-1.99996224  1.27158727  0.04895107]\n",
      "Loss in iteration 9920: 0.42178096952362437\n",
      "Theta: [-2.00002409  1.27163163  0.04894924]\n",
      "Loss in iteration 9921: 0.4217796817611887\n",
      "Theta: [-2.00008594  1.27167598  0.04894742]\n",
      "Loss in iteration 9922: 0.4217783943685856\n",
      "Theta: [-2.00014777  1.27172033  0.04894559]\n",
      "Loss in iteration 9923: 0.4217771073456914\n",
      "Theta: [-2.0002096   1.27176467  0.04894376]\n",
      "Loss in iteration 9924: 0.4217758206923832\n",
      "Theta: [-2.00027141  1.27180901  0.04894194]\n",
      "Loss in iteration 9925: 0.4217745344085377\n",
      "Theta: [-2.00033322  1.27185334  0.04894011]\n",
      "Loss in iteration 9926: 0.42177324849403164\n",
      "Theta: [-2.00039502  1.27189766  0.04893829]\n",
      "Loss in iteration 9927: 0.4217719629487422\n",
      "Theta: [-2.00045681  1.27194198  0.04893646]\n",
      "Loss in iteration 9928: 0.42177067777254623\n",
      "Theta: [-2.00051859  1.27198629  0.04893464]\n",
      "Loss in iteration 9929: 0.42176939296532057\n",
      "Theta: [-2.00058037  1.2720306   0.04893281]\n",
      "Loss in iteration 9930: 0.4217681085269424\n",
      "Theta: [-2.00064213  1.27207489  0.04893099]\n",
      "Loss in iteration 9931: 0.42176682445728875\n",
      "Theta: [-2.00070388  1.27211919  0.04892916]\n",
      "Loss in iteration 9932: 0.42176554075623685\n",
      "Theta: [-2.00076563  1.27216347  0.04892734]\n",
      "Loss in iteration 9933: 0.42176425742366386\n",
      "Theta: [-2.00082736  1.27220775  0.04892551]\n",
      "Loss in iteration 9934: 0.42176297445944705\n",
      "Theta: [-2.00088909  1.27225203  0.04892369]\n",
      "Loss in iteration 9935: 0.4217616918634636\n",
      "Theta: [-2.00095081  1.2722963   0.04892187]\n",
      "Loss in iteration 9936: 0.4217604096355909\n",
      "Theta: [-2.00101252  1.27234056  0.04892004]\n",
      "Loss in iteration 9937: 0.42175912777570645\n",
      "Theta: [-2.00107422  1.27238481  0.04891822]\n",
      "Loss in iteration 9938: 0.4217578462836875\n",
      "Theta: [-2.00113591  1.27242906  0.0489164 ]\n",
      "Loss in iteration 9939: 0.42175656515941173\n",
      "Theta: [-2.00119759  1.27247331  0.04891457]\n",
      "Loss in iteration 9940: 0.4217552844027566\n",
      "Theta: [-2.00125926  1.27251755  0.04891275]\n",
      "Loss in iteration 9941: 0.4217540040135995\n",
      "Theta: [-2.00132093  1.27256178  0.04891093]\n",
      "Loss in iteration 9942: 0.42175272399181835\n",
      "Theta: [-2.00138258  1.272606    0.04890911]\n",
      "Loss in iteration 9943: 0.42175144433729067\n",
      "Theta: [-2.00144423  1.27265022  0.04890729]\n",
      "Loss in iteration 9944: 0.42175016504989427\n",
      "Theta: [-2.00150586  1.27269443  0.04890546]\n",
      "Loss in iteration 9945: 0.42174888612950673\n",
      "Theta: [-2.00156749  1.27273864  0.04890364]\n",
      "Loss in iteration 9946: 0.4217476075760061\n",
      "Theta: [-2.00162911  1.27278284  0.04890182]\n",
      "Loss in iteration 9947: 0.4217463293892701\n",
      "Theta: [-2.00169072  1.27282704  0.0489    ]\n",
      "Loss in iteration 9948: 0.4217450515691768\n",
      "Theta: [-2.00175232  1.27287123  0.04889818]\n",
      "Loss in iteration 9949: 0.421743774115604\n",
      "Theta: [-2.00181391  1.27291541  0.04889636]\n",
      "Loss in iteration 9950: 0.4217424970284297\n",
      "Theta: [-2.0018755   1.27295958  0.04889454]\n",
      "Loss in iteration 9951: 0.4217412203075321\n",
      "Theta: [-2.00193707  1.27300375  0.04889272]\n",
      "Loss in iteration 9952: 0.4217399439527893\n",
      "Theta: [-2.00199863  1.27304792  0.0488909 ]\n",
      "Loss in iteration 9953: 0.4217386679640793\n",
      "Theta: [-2.00206019  1.27309208  0.04888908]\n",
      "Loss in iteration 9954: 0.4217373923412805\n",
      "Theta: [-2.00212174  1.27313623  0.04888726]\n",
      "Loss in iteration 9955: 0.42173611708427095\n",
      "Theta: [-2.00218328  1.27318037  0.04888544]\n",
      "Loss in iteration 9956: 0.4217348421929292\n",
      "Theta: [-2.0022448   1.27322451  0.04888362]\n",
      "Loss in iteration 9957: 0.42173356766713327\n",
      "Theta: [-2.00230632  1.27326865  0.0488818 ]\n",
      "Loss in iteration 9958: 0.4217322935067618\n",
      "Theta: [-2.00236784  1.27331277  0.04887998]\n",
      "Loss in iteration 9959: 0.4217310197116931\n",
      "Theta: [-2.00242934  1.27335689  0.04887817]\n",
      "Loss in iteration 9960: 0.4217297462818057\n",
      "Theta: [-2.00249083  1.27340101  0.04887635]\n",
      "Loss in iteration 9961: 0.4217284732169783\n",
      "Theta: [-2.00255232  1.27344512  0.04887453]\n",
      "Loss in iteration 9962: 0.4217272005170893\n",
      "Theta: [-2.00261379  1.27348922  0.04887271]\n",
      "Loss in iteration 9963: 0.42172592818201743\n",
      "Theta: [-2.00267526  1.27353332  0.04887089]\n",
      "Loss in iteration 9964: 0.42172465621164124\n",
      "Theta: [-2.00273671  1.27357741  0.04886908]\n",
      "Loss in iteration 9965: 0.4217233846058396\n",
      "Theta: [-2.00279816  1.27362149  0.04886726]\n",
      "Loss in iteration 9966: 0.4217221133644911\n",
      "Theta: [-2.0028596   1.27366557  0.04886544]\n",
      "Loss in iteration 9967: 0.4217208424874749\n",
      "Theta: [-2.00292103  1.27370964  0.04886363]\n",
      "Loss in iteration 9968: 0.4217195719746696\n",
      "Theta: [-2.00298245  1.27375371  0.04886181]\n",
      "Loss in iteration 9969: 0.42171830182595405\n",
      "Theta: [-2.00304387  1.27379777  0.04885999]\n",
      "Loss in iteration 9970: 0.4217170320412073\n",
      "Theta: [-2.00310527  1.27384182  0.04885818]\n",
      "Loss in iteration 9971: 0.4217157626203087\n",
      "Theta: [-2.00316666  1.27388587  0.04885636]\n",
      "Loss in iteration 9972: 0.4217144935631369\n",
      "Theta: [-2.00322805  1.27392991  0.04885455]\n",
      "Loss in iteration 9973: 0.42171322486957097\n",
      "Theta: [-2.00328943  1.27397395  0.04885273]\n",
      "Loss in iteration 9974: 0.4217119565394903\n",
      "Theta: [-2.00335079  1.27401798  0.04885092]\n",
      "Loss in iteration 9975: 0.421710688572774\n",
      "Theta: [-2.00341215  1.274062    0.0488491 ]\n",
      "Loss in iteration 9976: 0.4217094209693013\n",
      "Theta: [-2.0034735   1.27410602  0.04884729]\n",
      "Loss in iteration 9977: 0.4217081537289517\n",
      "Theta: [-2.00353484  1.27415003  0.04884547]\n",
      "Loss in iteration 9978: 0.42170688685160435\n",
      "Theta: [-2.00359618  1.27419403  0.04884366]\n",
      "Loss in iteration 9979: 0.4217056203371385\n",
      "Theta: [-2.0036575   1.27423803  0.04884184]\n",
      "Loss in iteration 9980: 0.42170435418543384\n",
      "Theta: [-2.00371881  1.27428203  0.04884003]\n",
      "Loss in iteration 9981: 0.4217030883963699\n",
      "Theta: [-2.00378012  1.27432601  0.04883822]\n",
      "Loss in iteration 9982: 0.42170182296982595\n",
      "Theta: [-2.00384142  1.27436999  0.0488364 ]\n",
      "Loss in iteration 9983: 0.42170055790568184\n",
      "Theta: [-2.0039027   1.27441397  0.04883459]\n",
      "Loss in iteration 9984: 0.421699293203817\n",
      "Theta: [-2.00396398  1.27445794  0.04883278]\n",
      "Loss in iteration 9985: 0.42169802886411106\n",
      "Theta: [-2.00402525  1.2745019   0.04883096]\n",
      "Loss in iteration 9986: 0.42169676488644386\n",
      "Theta: [-2.00408651  1.27454585  0.04882915]\n",
      "Loss in iteration 9987: 0.4216955012706953\n",
      "Theta: [-2.00414776  1.27458981  0.04882734]\n",
      "Loss in iteration 9988: 0.421694238016745\n",
      "Theta: [-2.00420901  1.27463375  0.04882553]\n",
      "Loss in iteration 9989: 0.421692975124473\n",
      "Theta: [-2.00427024  1.27467769  0.04882371]\n",
      "Loss in iteration 9990: 0.4216917125937589\n",
      "Theta: [-2.00433146  1.27472162  0.0488219 ]\n",
      "Loss in iteration 9991: 0.42169045042448305\n",
      "Theta: [-2.00439268  1.27476555  0.04882009]\n",
      "Loss in iteration 9992: 0.42168918861652516\n",
      "Theta: [-2.00445389  1.27480946  0.04881828]\n",
      "Loss in iteration 9993: 0.4216879271697654\n",
      "Theta: [-2.00451509  1.27485338  0.04881647]\n",
      "Loss in iteration 9994: 0.4216866660840839\n",
      "Theta: [-2.00457627  1.27489729  0.04881466]\n",
      "Loss in iteration 9995: 0.42168540535936083\n",
      "Theta: [-2.00463746  1.27494119  0.04881285]\n",
      "Loss in iteration 9996: 0.4216841449954761\n",
      "Theta: [-2.00469863  1.27498508  0.04881104]\n",
      "Loss in iteration 9997: 0.42168288499231016\n",
      "Theta: [-2.00475979  1.27502897  0.04880923]\n",
      "Loss in iteration 9998: 0.4216816253497435\n",
      "Theta: [-2.00482094  1.27507286  0.04880742]\n",
      "Loss in iteration 9999: 0.42168036606765613\n",
      "Theta: [-2.00488209  1.27511673  0.04880561]\n",
      "[-2.00488209  1.27511673  0.04880561]\n"
     ]
    }
   ],
   "source": [
    "gradientModel = LogisticRegressionUsingGradientDescent()\n",
    "coffecients = gradientModel.fit(X, y)\n",
    "print(coffecients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:, 1], X[:, 2], c=y, cmap=plt.cm.Spectral)\n",
    "plt.xlabel('x_1')\n",
    "plt.ylabel('x_2')\n",
    "\n",
    "# Plot the decision boundary (line) using the optimized theta\n",
    "x_boundary = np.array([np.min(X[:, 1]), np.max(X[:, 1])])\n",
    "y_boundary = -(coffecients[0] + coffecients[1] * x_boundary) / coffecients[2]\n",
    "plt.plot(x_boundary, y_boundary, color='red')\n",
    "\n",
    "plt.title('Scatter Plot with Decision Boundary')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
